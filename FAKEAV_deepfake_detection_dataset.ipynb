{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import os\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import (Activation, Dropout, Flatten, Dense, GlobalMaxPooling2D,\n",
    "                          BatchNormalization, Input, Conv2D, GlobalAveragePooling2D,concatenate,Concatenate,multiply, LocallyConnected2D, Lambda)\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras import metrics\n",
    "from keras import backend as K\n",
    "import keras\n",
    "from keras.models import Model\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.applications import EfficientNetB7\n",
    "import skimage.io\n",
    "from skimage.transform import resize\n",
    "\n",
    "from tqdm import tqdm\n",
    "import PIL\n",
    "from PIL import Image, ImageOps\n",
    "import cv2\n",
    "from sklearn.utils import class_weight, shuffle\n",
    "from keras.losses import binary_crossentropy, categorical_crossentropy\n",
    "#from keras.applications.resnet50 import preprocess_input\n",
    "from keras.applications.densenet import DenseNet121,DenseNet169,preprocess_input\n",
    "import keras.backend as K\n",
    "import tensorflow as tf\n",
    "from sklearn.metrics import f1_score, fbeta_score, cohen_kappa_score\n",
    "\n",
    "import keras.callbacks as callbacks\n",
    "from keras.callbacks import Callback\n",
    "get_ipython().run_line_magic('config', 'InlineBackend.figure_format=\"svg\"')\n",
    "get_ipython().run_line_magic('matplotlib', 'inline')\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "SIZE = 224\n",
    "NUM_CLASSES = 2\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Model, load_model\n",
    "from keras.layers import Embedding, LSTM, Dropout, Dense, Input, Bidirectional, Flatten, Conv2D, MaxPooling2D, concatenate, Conv1D, MaxPooling1D\n",
    "import keras.backend as K\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.optimizers import Adam, RMSprop\n",
    "from keras.callbacks import ModelCheckpoint, CSVLogger, EarlyStopping\n",
    "from keras.layers import Conv2D, MaxPooling2D, Input, Dense, Flatten, concatenate\n",
    "from keras.models import Model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "\n",
    "\n",
    "def get_num_input():\n",
    "    df = pd.read_csv('/DATA/akanksha_2021cs39/Ad.csv')\n",
    "    df = df.drop(['filename'],axis=1)\n",
    "    columns = list(df.columns)\n",
    "    features = columns[:-1]\n",
    "    cls_name = columns[-1]\n",
    "    X = np.zeros((len(df), len(features)))\n",
    "    Y = list()\n",
    "    for i, row in df.iterrows():\n",
    "        X[i] = row[features]                    \n",
    "        Y.append(row[cls_name])\n",
    "\n",
    "    return (X, Y)\n",
    "X_num, Y = get_num_input()\n",
    "encoder = LabelEncoder()\n",
    "Y = encoder.fit_transform(Y)\n",
    "X_audio_train, X_audio_test, y_audio_train, y_audio_test = train_test_split( X_num, Y, test_size=0.2,random_state=42)\n",
    "#Scaling the Feature columns\n",
    "#scaler = StandardScaler()\n",
    "#X = scaler.fit_transform(np.array(data.iloc[:, :-1], dtype = float)\n",
    "\n",
    "#def get_img_input():\n",
    "    #df = pd.read_csv('/DATA/akanksha_2021cs39/visualdata.csv')\n",
    "    #X_img = np.zeros((len(df), 224, 224)) # change as per image size\n",
    "    #Y = list()\n",
    "    #for i, row in df.iterrows():\n",
    "        #X_img[i] = np.array(Image.open(row['X_img']))\n",
    "        #Y.append(row['class'])\n",
    "\n",
    "    #return (X_img, Y)\n",
    "    \n",
    "#X_img, Y_img = get_img_input() # use one of the Ys\n",
    "# X feature normalization, convert Y to one-hot representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df = pd.read_csv('/DATA/akanksha_2021cs39/fakeAV_audio.csv')\n",
    "#df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df = df.drop(21253)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.to_csv('Ad.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df2 = pd.read_csv('/DATA/akanksha_2021cs39/fakeAV_visual.csv')\n",
    "#df2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df2 = df2.drop([0 , 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df2.to_csv('Vd.csv', header=None, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_img_input():\n",
    "    df = pd.read_csv('/DATA/akanksha_2021cs39/Vd.csv')\n",
    "    columns = list(df.columns)\n",
    "    features = columns[:-1]\n",
    "    cls_name = columns[-1]\n",
    "    X = np.zeros((len(df), len(features)))\n",
    "    Y = list()\n",
    "    for i, row in df.iterrows():\n",
    "        X[i] = row[features]                    \n",
    "        Y.append(row[cls_name])\n",
    "\n",
    "    return (X, Y)\n",
    "X_img, Y_img = get_img_input()\n",
    "encoder = LabelEncoder()\n",
    "Y_img = encoder.fit_transform(Y_img)\n",
    "X_img_train, X_img_test, y_img_train, y_img_test = train_test_split( X_img, Y_img, test_size=0.2,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train=y_audio_train # both audio and video samples are synchronized so both have same levels that is why \n",
    "                                                     #initialized here with one (audio or video) label.\n",
    "y_test=y_audio_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(17001, 133)\n",
      "(17001, 50176)\n",
      "(4251, 133)\n",
      "(4251, 50176)\n",
      "(17001,)\n",
      "(17001,)\n",
      "(4251,)\n",
      "(4251,)\n"
     ]
    }
   ],
   "source": [
    "print(X_audio_train.shape)\n",
    "print(X_img_train.shape)\n",
    "print(X_audio_test.shape)\n",
    "print(X_img_test.shape)\n",
    "print(y_audio_train.shape)\n",
    "print(y_img_train.shape)\n",
    "print(y_audio_test.shape)\n",
    "print(y_img_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Conv2D, MaxPooling2D, Input, Dense, Flatten, concatenate\n",
    "from keras.models import Model\n",
    "import numpy as np\n",
    "from keras import regularizers\n",
    "from keras.layers import Dropout \n",
    "def compile_model():\n",
    "    img_input = Input(shape=(50176,)) \n",
    "    ## branch 1 with image input\n",
    "    x = Dense(1024, activation='relu', kernel_regularizer=regularizers.l2(0.01))(img_input)\n",
    "    x = Dropout(0.3)(x)\n",
    "    x = Dense(512, activation='relu', kernel_regularizer=regularizers.l2(0.01))(x)\n",
    "    x = Dropout(0.3)(x)\n",
    "    x = Dense(256, activation='relu', kernel_regularizer=regularizers.l2(0.01))(x)\n",
    "    x = Dropout(0.3)(x)\n",
    "    x = Dense(128, activation='relu', kernel_regularizer=regularizers.l2(0.01))(x)\n",
    "    x = Dropout(0.3)(x)\n",
    "    x = Dense(64, activation='relu', kernel_regularizer=regularizers.l2(0.01))(x)\n",
    "    x = Dropout(0.3)(x)\n",
    "    out_a = Dense(32, activation='relu', kernel_regularizer=regularizers.l2(0.01))(x)\n",
    "    \n",
    "    #x = MaxPooling2D((2, 2))(x)\n",
    "    #x = Flatten()(x)\n",
    "    #out_a = Dense(64)(x)\n",
    "\n",
    "    num_input = Input(shape=(133,))        ## branch 2 with numerical input\n",
    "    x1 = Dense(1024, activation='relu', kernel_regularizer=regularizers.l2(0.01))(num_input)\n",
    "    x1 = Dropout(0.3)(x1)\n",
    "    x1 = Dense(512, activation='relu', kernel_regularizer=regularizers.l2(0.01))(x1)\n",
    "    x1 = Dropout(0.3)(x1)\n",
    "    x1 = Dense(256, activation='relu', kernel_regularizer=regularizers.l2(0.01))(x1)\n",
    "    x1 = Dropout(0.3)(x1)\n",
    "    x1 = Dense(128, activation='relu', kernel_regularizer=regularizers.l2(0.01))(x1)\n",
    "    x1 = Dropout(0.3)(x1)\n",
    "    x1 = Dense(64, activation='relu', kernel_regularizer=regularizers.l2(0.01))(x1)\n",
    "    x1 = Dropout(0.3)(x1)\n",
    "    out_b = Dense(32, activation='relu', kernel_regularizer=regularizers.l2(0.01))(x1)\n",
    "\n",
    "    concatenated = concatenate([out_a, out_b])    ## concatenate the two branches\n",
    "    out = Dense(1, activation='sigmoid')(concatenated)\n",
    "    model = Model([img_input, num_input], out)\n",
    "    adam = Adam(lr=0.001, decay=1e-5)\n",
    "    print(model.summary())\n",
    "    model.compile(loss=\"binary_crossentropy\", optimizer=adam, metrics=[\"accuracy\"])\n",
    "    return model\n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "### Just for sanity check\n",
    "\n",
    "#print(model.predict(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 50176)]      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            [(None, 133)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 1024)         51381248    input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_6 (Dense)                 (None, 1024)         137216      input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 1024)         0           dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_5 (Dropout)             (None, 1024)         0           dense_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 512)          524800      dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_7 (Dense)                 (None, 512)          524800      dropout_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 512)          0           dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_6 (Dropout)             (None, 512)          0           dense_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 256)          131328      dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_8 (Dense)                 (None, 256)          131328      dropout_6[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 256)          0           dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_7 (Dropout)             (None, 256)          0           dense_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 128)          32896       dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_9 (Dense)                 (None, 128)          32896       dropout_7[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 128)          0           dense_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_8 (Dropout)             (None, 128)          0           dense_9[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 64)           8256        dropout_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_10 (Dense)                (None, 64)           8256        dropout_8[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)             (None, 64)           0           dense_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_9 (Dropout)             (None, 64)           0           dense_10[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_5 (Dense)                 (None, 32)           2080        dropout_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_11 (Dense)                (None, 32)           2080        dropout_9[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 64)           0           dense_5[0][0]                    \n",
      "                                                                 dense_11[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_12 (Dense)                (None, 1)            65          concatenate[0][0]                \n",
      "==================================================================================================\n",
      "Total params: 52,917,249\n",
      "Trainable params: 52,917,249\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model = compile_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "67/67 [==============================] - 25s 342ms/step - loss: 146.1197 - accuracy: 0.8989 - val_loss: 41.2719 - val_accuracy: 0.9475\n",
      "Epoch 2/1000\n",
      "67/67 [==============================] - 20s 298ms/step - loss: 44.1055 - accuracy: 0.8952 - val_loss: 30.5416 - val_accuracy: 0.9452\n",
      "Epoch 3/1000\n",
      "67/67 [==============================] - 19s 291ms/step - loss: 30.1039 - accuracy: 0.9006 - val_loss: 24.7888 - val_accuracy: 0.9475\n",
      "Epoch 4/1000\n",
      "67/67 [==============================] - 19s 287ms/step - loss: 23.2082 - accuracy: 0.9033 - val_loss: 21.0177 - val_accuracy: 0.9475\n",
      "Epoch 5/1000\n",
      "67/67 [==============================] - 19s 281ms/step - loss: 19.4581 - accuracy: 0.9364 - val_loss: 18.0318 - val_accuracy: 0.9475\n",
      "Epoch 6/1000\n",
      "67/67 [==============================] - 19s 280ms/step - loss: 17.1061 - accuracy: 0.9396 - val_loss: 16.2100 - val_accuracy: 0.9475\n",
      "Epoch 7/1000\n",
      "67/67 [==============================] - 19s 280ms/step - loss: 15.3120 - accuracy: 0.9425 - val_loss: 14.4695 - val_accuracy: 0.9475\n",
      "Epoch 8/1000\n",
      "67/67 [==============================] - 19s 283ms/step - loss: 14.0140 - accuracy: 0.9424 - val_loss: 13.4482 - val_accuracy: 0.9475\n",
      "Epoch 9/1000\n",
      "67/67 [==============================] - 20s 299ms/step - loss: 13.0460 - accuracy: 0.9425 - val_loss: 12.6977 - val_accuracy: 0.9475\n",
      "Epoch 10/1000\n",
      "67/67 [==============================] - 19s 288ms/step - loss: 12.2438 - accuracy: 0.9451 - val_loss: 11.9352 - val_accuracy: 0.9475\n",
      "Epoch 11/1000\n",
      "67/67 [==============================] - 19s 284ms/step - loss: 11.5690 - accuracy: 0.9454 - val_loss: 11.2283 - val_accuracy: 0.9475\n",
      "Epoch 12/1000\n",
      "67/67 [==============================] - 19s 284ms/step - loss: 11.1940 - accuracy: 0.9421 - val_loss: 10.9938 - val_accuracy: 0.9475\n",
      "Epoch 13/1000\n",
      "67/67 [==============================] - 19s 277ms/step - loss: 10.7217 - accuracy: 0.9452 - val_loss: 10.4215 - val_accuracy: 0.9475\n",
      "Epoch 14/1000\n",
      "67/67 [==============================] - 19s 280ms/step - loss: 10.2660 - accuracy: 0.9446 - val_loss: 10.1563 - val_accuracy: 0.9475\n",
      "Epoch 15/1000\n",
      "67/67 [==============================] - 19s 280ms/step - loss: 9.9014 - accuracy: 0.9445 - val_loss: 9.7602 - val_accuracy: 0.9475\n",
      "Epoch 16/1000\n",
      "67/67 [==============================] - 19s 288ms/step - loss: 9.6298 - accuracy: 0.9452 - val_loss: 9.4316 - val_accuracy: 0.9475\n",
      "Epoch 17/1000\n",
      "67/67 [==============================] - 20s 292ms/step - loss: 9.3413 - accuracy: 0.9442 - val_loss: 9.1733 - val_accuracy: 0.9475\n",
      "Epoch 18/1000\n",
      "67/67 [==============================] - 19s 281ms/step - loss: 9.1236 - accuracy: 0.9430 - val_loss: 8.9257 - val_accuracy: 0.9475\n",
      "Epoch 19/1000\n",
      "67/67 [==============================] - 19s 281ms/step - loss: 8.8731 - accuracy: 0.9430 - val_loss: 8.6872 - val_accuracy: 0.9475\n",
      "Epoch 20/1000\n",
      "67/67 [==============================] - 19s 283ms/step - loss: 8.6040 - accuracy: 0.9428 - val_loss: 8.4842 - val_accuracy: 0.9475\n",
      "Epoch 21/1000\n",
      "67/67 [==============================] - 19s 280ms/step - loss: 8.3485 - accuracy: 0.9441 - val_loss: 8.3167 - val_accuracy: 0.9475\n",
      "Epoch 22/1000\n",
      "67/67 [==============================] - 19s 278ms/step - loss: 8.1654 - accuracy: 0.9418 - val_loss: 8.0604 - val_accuracy: 0.9475\n",
      "Epoch 23/1000\n",
      "67/67 [==============================] - 19s 279ms/step - loss: 7.9874 - accuracy: 0.9427 - val_loss: 7.8713 - val_accuracy: 0.9475\n",
      "Epoch 24/1000\n",
      "67/67 [==============================] - 18s 275ms/step - loss: 7.8381 - accuracy: 0.9416 - val_loss: 7.6092 - val_accuracy: 0.9475\n",
      "Epoch 25/1000\n",
      "67/67 [==============================] - 19s 279ms/step - loss: 7.6076 - accuracy: 0.9397 - val_loss: 7.5507 - val_accuracy: 0.9475\n",
      "Epoch 26/1000\n",
      "67/67 [==============================] - 19s 279ms/step - loss: 7.5730 - accuracy: 0.9398 - val_loss: 7.2969 - val_accuracy: 0.9475\n",
      "Epoch 27/1000\n",
      "67/67 [==============================] - 19s 277ms/step - loss: 7.5209 - accuracy: 0.9338 - val_loss: 7.3799 - val_accuracy: 0.9475\n",
      "Epoch 28/1000\n",
      "67/67 [==============================] - 19s 278ms/step - loss: 7.3098 - accuracy: 0.9366 - val_loss: 7.2430 - val_accuracy: 0.9475\n",
      "Epoch 29/1000\n",
      "67/67 [==============================] - 20s 292ms/step - loss: 7.1864 - accuracy: 0.9366 - val_loss: 7.0004 - val_accuracy: 0.9475\n",
      "Epoch 30/1000\n",
      "67/67 [==============================] - 19s 286ms/step - loss: 7.0385 - accuracy: 0.9370 - val_loss: 6.7542 - val_accuracy: 0.9475\n",
      "Epoch 31/1000\n",
      "67/67 [==============================] - 19s 283ms/step - loss: 7.1882 - accuracy: 0.9355 - val_loss: 6.6977 - val_accuracy: 0.9475\n",
      "Epoch 32/1000\n",
      "67/67 [==============================] - 19s 283ms/step - loss: 6.5145 - accuracy: 0.9457 - val_loss: 6.3778 - val_accuracy: 0.9475\n",
      "Epoch 33/1000\n",
      "67/67 [==============================] - 19s 278ms/step - loss: 6.2948 - accuracy: 0.9458 - val_loss: 6.1940 - val_accuracy: 0.9475\n",
      "Epoch 34/1000\n",
      "67/67 [==============================] - 19s 284ms/step - loss: 6.1232 - accuracy: 0.9457 - val_loss: 6.0471 - val_accuracy: 0.9475\n",
      "Epoch 35/1000\n",
      "67/67 [==============================] - 19s 277ms/step - loss: 5.9568 - accuracy: 0.9457 - val_loss: 5.8773 - val_accuracy: 0.9475\n",
      "Epoch 36/1000\n",
      "67/67 [==============================] - 19s 279ms/step - loss: 5.7996 - accuracy: 0.9454 - val_loss: 5.7217 - val_accuracy: 0.9475\n",
      "Epoch 37/1000\n",
      "67/67 [==============================] - 19s 277ms/step - loss: 5.6478 - accuracy: 0.9457 - val_loss: 5.5590 - val_accuracy: 0.9475\n",
      "Epoch 38/1000\n",
      "67/67 [==============================] - 19s 281ms/step - loss: 5.5204 - accuracy: 0.9457 - val_loss: 5.4113 - val_accuracy: 0.9475\n",
      "Epoch 39/1000\n",
      "67/67 [==============================] - 19s 277ms/step - loss: 5.3846 - accuracy: 0.9456 - val_loss: 5.2831 - val_accuracy: 0.9475\n",
      "Epoch 40/1000\n",
      "67/67 [==============================] - 19s 281ms/step - loss: 5.2288 - accuracy: 0.9458 - val_loss: 5.1557 - val_accuracy: 0.9475\n",
      "Epoch 41/1000\n",
      "67/67 [==============================] - 19s 277ms/step - loss: 5.0996 - accuracy: 0.9458 - val_loss: 5.0611 - val_accuracy: 0.9475\n",
      "Epoch 42/1000\n",
      "67/67 [==============================] - 19s 279ms/step - loss: 4.9664 - accuracy: 0.9458 - val_loss: 4.8820 - val_accuracy: 0.9475\n",
      "Epoch 43/1000\n",
      "67/67 [==============================] - 19s 285ms/step - loss: 4.8464 - accuracy: 0.9454 - val_loss: 4.8317 - val_accuracy: 0.9475\n",
      "Epoch 44/1000\n",
      "67/67 [==============================] - 19s 288ms/step - loss: 4.7413 - accuracy: 0.9458 - val_loss: 4.6453 - val_accuracy: 0.9475\n",
      "Epoch 45/1000\n",
      "67/67 [==============================] - 19s 288ms/step - loss: 4.5956 - accuracy: 0.9459 - val_loss: 4.5199 - val_accuracy: 0.9475\n",
      "Epoch 46/1000\n",
      "67/67 [==============================] - 20s 297ms/step - loss: 4.4938 - accuracy: 0.9456 - val_loss: 4.4294 - val_accuracy: 0.9475\n",
      "Epoch 47/1000\n",
      "67/67 [==============================] - 19s 289ms/step - loss: 4.3876 - accuracy: 0.9458 - val_loss: 4.3145 - val_accuracy: 0.9475\n",
      "Epoch 48/1000\n",
      "67/67 [==============================] - 19s 288ms/step - loss: 4.2647 - accuracy: 0.9458 - val_loss: 4.2159 - val_accuracy: 0.9475\n",
      "Epoch 49/1000\n",
      "67/67 [==============================] - 19s 282ms/step - loss: 4.1609 - accuracy: 0.9458 - val_loss: 4.0856 - val_accuracy: 0.9475\n",
      "Epoch 50/1000\n",
      "67/67 [==============================] - 20s 291ms/step - loss: 4.0988 - accuracy: 0.9455 - val_loss: 4.0089 - val_accuracy: 0.9475\n",
      "Epoch 51/1000\n",
      "67/67 [==============================] - 19s 285ms/step - loss: 3.9583 - accuracy: 0.9459 - val_loss: 3.8978 - val_accuracy: 0.9475\n",
      "Epoch 52/1000\n",
      "67/67 [==============================] - 18s 276ms/step - loss: 3.8532 - accuracy: 0.9457 - val_loss: 3.7781 - val_accuracy: 0.9475\n",
      "Epoch 53/1000\n",
      "67/67 [==============================] - 19s 276ms/step - loss: 3.7645 - accuracy: 0.9457 - val_loss: 3.7112 - val_accuracy: 0.9475\n",
      "Epoch 54/1000\n",
      "67/67 [==============================] - 18s 276ms/step - loss: 3.7071 - accuracy: 0.9448 - val_loss: 3.6170 - val_accuracy: 0.9475\n",
      "Epoch 55/1000\n",
      "67/67 [==============================] - 18s 276ms/step - loss: 3.5719 - accuracy: 0.9458 - val_loss: 3.5295 - val_accuracy: 0.9475\n",
      "Epoch 56/1000\n",
      "67/67 [==============================] - 19s 278ms/step - loss: 3.4906 - accuracy: 0.9454 - val_loss: 3.4634 - val_accuracy: 0.9475\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/1000\n",
      "67/67 [==============================] - 19s 284ms/step - loss: 3.4270 - accuracy: 0.9454 - val_loss: 3.3661 - val_accuracy: 0.9475\n",
      "Epoch 58/1000\n",
      "67/67 [==============================] - 19s 281ms/step - loss: 3.3015 - accuracy: 0.9458 - val_loss: 3.2394 - val_accuracy: 0.9475\n",
      "Epoch 59/1000\n",
      "67/67 [==============================] - 19s 278ms/step - loss: 3.1956 - accuracy: 0.9459 - val_loss: 3.1364 - val_accuracy: 0.9475\n",
      "Epoch 60/1000\n",
      "67/67 [==============================] - 19s 278ms/step - loss: 3.1404 - accuracy: 0.9457 - val_loss: 3.0803 - val_accuracy: 0.9475\n",
      "Epoch 61/1000\n",
      "67/67 [==============================] - 18s 276ms/step - loss: 3.0402 - accuracy: 0.9458 - val_loss: 2.9885 - val_accuracy: 0.9475\n",
      "Epoch 62/1000\n",
      "67/67 [==============================] - 19s 284ms/step - loss: 2.9624 - accuracy: 0.9458 - val_loss: 2.9090 - val_accuracy: 0.9475\n",
      "Epoch 63/1000\n",
      "67/67 [==============================] - 19s 282ms/step - loss: 2.9006 - accuracy: 0.9458 - val_loss: 2.8249 - val_accuracy: 0.9475\n",
      "Epoch 64/1000\n",
      "67/67 [==============================] - 20s 294ms/step - loss: 2.7963 - accuracy: 0.9456 - val_loss: 2.7385 - val_accuracy: 0.9475\n",
      "Epoch 65/1000\n",
      "67/67 [==============================] - 20s 292ms/step - loss: 2.7135 - accuracy: 0.9459 - val_loss: 2.6697 - val_accuracy: 0.9475\n",
      "Epoch 66/1000\n",
      "67/67 [==============================] - 20s 292ms/step - loss: 2.6561 - accuracy: 0.9457 - val_loss: 2.5962 - val_accuracy: 0.9475\n",
      "Epoch 67/1000\n",
      "67/67 [==============================] - 19s 290ms/step - loss: 2.5603 - accuracy: 0.9458 - val_loss: 2.5005 - val_accuracy: 0.9475\n",
      "Epoch 68/1000\n",
      "67/67 [==============================] - 19s 286ms/step - loss: 2.5130 - accuracy: 0.9454 - val_loss: 2.4730 - val_accuracy: 0.9475\n",
      "Epoch 69/1000\n",
      "67/67 [==============================] - 20s 291ms/step - loss: 2.4333 - accuracy: 0.9457 - val_loss: 2.3877 - val_accuracy: 0.9475\n",
      "Epoch 70/1000\n",
      "67/67 [==============================] - 20s 292ms/step - loss: 2.3675 - accuracy: 0.9458 - val_loss: 2.3269 - val_accuracy: 0.9475\n",
      "Epoch 71/1000\n",
      "67/67 [==============================] - 19s 286ms/step - loss: 2.3160 - accuracy: 0.9454 - val_loss: 2.2661 - val_accuracy: 0.9475\n",
      "Epoch 72/1000\n",
      "67/67 [==============================] - 19s 280ms/step - loss: 2.2256 - accuracy: 0.9459 - val_loss: 2.1876 - val_accuracy: 0.9475\n",
      "Epoch 73/1000\n",
      "67/67 [==============================] - 19s 278ms/step - loss: 2.1519 - accuracy: 0.9459 - val_loss: 2.0920 - val_accuracy: 0.9475\n",
      "Epoch 74/1000\n",
      "67/67 [==============================] - 19s 288ms/step - loss: 2.0731 - accuracy: 0.9458 - val_loss: 2.0360 - val_accuracy: 0.9475\n",
      "Epoch 75/1000\n",
      "67/67 [==============================] - 19s 284ms/step - loss: 2.0172 - accuracy: 0.9459 - val_loss: 1.9552 - val_accuracy: 0.9475\n",
      "Epoch 76/1000\n",
      "67/67 [==============================] - 19s 282ms/step - loss: 1.9421 - accuracy: 0.9459 - val_loss: 1.9040 - val_accuracy: 0.9475\n",
      "Epoch 77/1000\n",
      "67/67 [==============================] - 19s 281ms/step - loss: 1.8855 - accuracy: 0.9458 - val_loss: 1.8556 - val_accuracy: 0.9475\n",
      "Epoch 78/1000\n",
      "67/67 [==============================] - 19s 281ms/step - loss: 1.8214 - accuracy: 0.9459 - val_loss: 1.7793 - val_accuracy: 0.9475\n",
      "Epoch 79/1000\n",
      "67/67 [==============================] - 19s 285ms/step - loss: 1.7573 - accuracy: 0.9459 - val_loss: 1.7222 - val_accuracy: 0.9475\n",
      "Epoch 80/1000\n",
      "67/67 [==============================] - 19s 289ms/step - loss: 1.7267 - accuracy: 0.9458 - val_loss: 1.7018 - val_accuracy: 0.9475\n",
      "Epoch 81/1000\n",
      "67/67 [==============================] - 19s 282ms/step - loss: 1.6825 - accuracy: 0.9458 - val_loss: 1.6306 - val_accuracy: 0.9475\n",
      "Epoch 82/1000\n",
      "67/67 [==============================] - 20s 298ms/step - loss: 1.6018 - accuracy: 0.9458 - val_loss: 1.5894 - val_accuracy: 0.9475\n",
      "Epoch 83/1000\n",
      "67/67 [==============================] - 19s 291ms/step - loss: 1.5380 - accuracy: 0.9459 - val_loss: 1.4939 - val_accuracy: 0.9475\n",
      "Epoch 84/1000\n",
      "67/67 [==============================] - 20s 293ms/step - loss: 1.4717 - accuracy: 0.9459 - val_loss: 1.4348 - val_accuracy: 0.9475\n",
      "Epoch 85/1000\n",
      "67/67 [==============================] - 20s 294ms/step - loss: 1.4225 - accuracy: 0.9459 - val_loss: 1.3981 - val_accuracy: 0.9475\n",
      "Epoch 86/1000\n",
      "67/67 [==============================] - 19s 288ms/step - loss: 1.3835 - accuracy: 0.9459 - val_loss: 1.3564 - val_accuracy: 0.9475\n",
      "Epoch 87/1000\n",
      "67/67 [==============================] - 19s 288ms/step - loss: 1.3419 - accuracy: 0.9459 - val_loss: 1.3164 - val_accuracy: 0.9475\n",
      "Epoch 88/1000\n",
      "67/67 [==============================] - 19s 287ms/step - loss: 1.3078 - accuracy: 0.9459 - val_loss: 1.2705 - val_accuracy: 0.9475\n",
      "Epoch 89/1000\n",
      "67/67 [==============================] - 19s 288ms/step - loss: 1.2680 - accuracy: 0.9458 - val_loss: 1.2287 - val_accuracy: 0.9475\n",
      "Epoch 90/1000\n",
      "67/67 [==============================] - 19s 282ms/step - loss: 1.2178 - accuracy: 0.9459 - val_loss: 1.1815 - val_accuracy: 0.9475\n",
      "Epoch 91/1000\n",
      "67/67 [==============================] - 19s 279ms/step - loss: 1.1525 - accuracy: 0.9459 - val_loss: 1.1174 - val_accuracy: 0.9475\n",
      "Epoch 92/1000\n",
      "67/67 [==============================] - 19s 277ms/step - loss: 1.1065 - accuracy: 0.9459 - val_loss: 1.0779 - val_accuracy: 0.9475\n",
      "Epoch 93/1000\n",
      "67/67 [==============================] - 19s 284ms/step - loss: 1.0691 - accuracy: 0.9459 - val_loss: 1.0437 - val_accuracy: 0.9475\n",
      "Epoch 94/1000\n",
      "67/67 [==============================] - 19s 280ms/step - loss: 1.0477 - accuracy: 0.9458 - val_loss: 1.0278 - val_accuracy: 0.9475\n",
      "Epoch 95/1000\n",
      "67/67 [==============================] - 18s 276ms/step - loss: 1.0354 - accuracy: 0.9458 - val_loss: 1.0028 - val_accuracy: 0.9475\n",
      "Epoch 96/1000\n",
      "67/67 [==============================] - 19s 278ms/step - loss: 0.9835 - accuracy: 0.9459 - val_loss: 0.9396 - val_accuracy: 0.9475\n",
      "Epoch 97/1000\n",
      "67/67 [==============================] - 19s 286ms/step - loss: 0.9279 - accuracy: 0.9459 - val_loss: 0.8945 - val_accuracy: 0.9475\n",
      "Epoch 98/1000\n",
      "67/67 [==============================] - 19s 288ms/step - loss: 0.8863 - accuracy: 0.9459 - val_loss: 0.8581 - val_accuracy: 0.9475\n",
      "Epoch 99/1000\n",
      "67/67 [==============================] - 19s 292ms/step - loss: 0.8464 - accuracy: 0.9459 - val_loss: 0.8335 - val_accuracy: 0.9475\n",
      "Epoch 100/1000\n",
      "67/67 [==============================] - 19s 285ms/step - loss: 0.8127 - accuracy: 0.9459 - val_loss: 0.7892 - val_accuracy: 0.9475\n",
      "Epoch 101/1000\n",
      "67/67 [==============================] - 19s 286ms/step - loss: 0.7844 - accuracy: 0.9459 - val_loss: 0.7647 - val_accuracy: 0.9475\n",
      "Epoch 102/1000\n",
      "67/67 [==============================] - 19s 291ms/step - loss: 0.7571 - accuracy: 0.9459 - val_loss: 0.7408 - val_accuracy: 0.9475\n",
      "Epoch 103/1000\n",
      "67/67 [==============================] - 20s 293ms/step - loss: 0.7357 - accuracy: 0.9459 - val_loss: 0.7265 - val_accuracy: 0.9475\n",
      "Epoch 104/1000\n",
      "67/67 [==============================] - 20s 295ms/step - loss: 0.7098 - accuracy: 0.9459 - val_loss: 0.6915 - val_accuracy: 0.9475\n",
      "Epoch 105/1000\n",
      "67/67 [==============================] - 20s 295ms/step - loss: 0.6865 - accuracy: 0.9459 - val_loss: 0.6599 - val_accuracy: 0.9475\n",
      "Epoch 106/1000\n",
      "67/67 [==============================] - 20s 292ms/step - loss: 0.6495 - accuracy: 0.9459 - val_loss: 0.6273 - val_accuracy: 0.9475\n",
      "Epoch 107/1000\n",
      "67/67 [==============================] - 20s 292ms/step - loss: 0.6266 - accuracy: 0.9459 - val_loss: 0.6115 - val_accuracy: 0.9475\n",
      "Epoch 108/1000\n",
      "67/67 [==============================] - 19s 287ms/step - loss: 0.6008 - accuracy: 0.9459 - val_loss: 0.5804 - val_accuracy: 0.9475\n",
      "Epoch 109/1000\n",
      "67/67 [==============================] - 19s 289ms/step - loss: 0.5763 - accuracy: 0.9459 - val_loss: 0.5621 - val_accuracy: 0.9475\n",
      "Epoch 110/1000\n",
      "67/67 [==============================] - 19s 288ms/step - loss: 0.5557 - accuracy: 0.9459 - val_loss: 0.5440 - val_accuracy: 0.9475\n",
      "Epoch 111/1000\n",
      "67/67 [==============================] - 19s 283ms/step - loss: 0.5350 - accuracy: 0.9459 - val_loss: 0.5162 - val_accuracy: 0.9475\n",
      "Epoch 112/1000\n",
      "67/67 [==============================] - 19s 282ms/step - loss: 0.5137 - accuracy: 0.9459 - val_loss: 0.4971 - val_accuracy: 0.9475\n",
      "Epoch 113/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "67/67 [==============================] - 18s 275ms/step - loss: 0.4964 - accuracy: 0.9459 - val_loss: 0.4894 - val_accuracy: 0.9475\n",
      "Epoch 114/1000\n",
      "67/67 [==============================] - 19s 285ms/step - loss: 0.4790 - accuracy: 0.9459 - val_loss: 0.4636 - val_accuracy: 0.9475\n",
      "Epoch 115/1000\n",
      "67/67 [==============================] - 19s 282ms/step - loss: 0.4626 - accuracy: 0.9459 - val_loss: 0.4463 - val_accuracy: 0.9475\n",
      "Epoch 116/1000\n",
      "67/67 [==============================] - 19s 285ms/step - loss: 0.4464 - accuracy: 0.9459 - val_loss: 0.4304 - val_accuracy: 0.9475\n",
      "Epoch 117/1000\n",
      "67/67 [==============================] - 19s 288ms/step - loss: 0.4294 - accuracy: 0.9459 - val_loss: 0.4157 - val_accuracy: 0.9475\n",
      "Epoch 118/1000\n",
      "67/67 [==============================] - 19s 282ms/step - loss: 0.4144 - accuracy: 0.9459 - val_loss: 0.4006 - val_accuracy: 0.9475\n",
      "Epoch 119/1000\n",
      "67/67 [==============================] - 19s 290ms/step - loss: 0.3998 - accuracy: 0.9459 - val_loss: 0.3886 - val_accuracy: 0.9475\n",
      "Epoch 120/1000\n",
      "67/67 [==============================] - 19s 282ms/step - loss: 0.3902 - accuracy: 0.9459 - val_loss: 0.3765 - val_accuracy: 0.9475\n",
      "Epoch 121/1000\n",
      "67/67 [==============================] - 20s 294ms/step - loss: 0.3764 - accuracy: 0.9459 - val_loss: 0.3640 - val_accuracy: 0.9475\n",
      "Epoch 122/1000\n",
      "67/67 [==============================] - 20s 293ms/step - loss: 0.3641 - accuracy: 0.9459 - val_loss: 0.3532 - val_accuracy: 0.9475\n",
      "Epoch 123/1000\n",
      "67/67 [==============================] - 20s 292ms/step - loss: 0.3547 - accuracy: 0.9459 - val_loss: 0.3469 - val_accuracy: 0.9475\n",
      "Epoch 124/1000\n",
      "67/67 [==============================] - 20s 296ms/step - loss: 0.3448 - accuracy: 0.9459 - val_loss: 0.3324 - val_accuracy: 0.9475\n",
      "Epoch 125/1000\n",
      "67/67 [==============================] - 19s 285ms/step - loss: 0.3353 - accuracy: 0.9459 - val_loss: 0.3252 - val_accuracy: 0.9475\n",
      "Epoch 126/1000\n",
      "67/67 [==============================] - 19s 285ms/step - loss: 0.3253 - accuracy: 0.9459 - val_loss: 0.3153 - val_accuracy: 0.9475\n",
      "Epoch 127/1000\n",
      "67/67 [==============================] - 19s 290ms/step - loss: 0.3176 - accuracy: 0.9459 - val_loss: 0.3059 - val_accuracy: 0.9475\n",
      "Epoch 128/1000\n",
      "67/67 [==============================] - 20s 292ms/step - loss: 0.3084 - accuracy: 0.9459 - val_loss: 0.2978 - val_accuracy: 0.9475\n",
      "Epoch 129/1000\n",
      "67/67 [==============================] - 19s 291ms/step - loss: 0.2999 - accuracy: 0.9459 - val_loss: 0.2968 - val_accuracy: 0.9475\n",
      "Epoch 130/1000\n",
      "67/67 [==============================] - 19s 287ms/step - loss: 0.2957 - accuracy: 0.9459 - val_loss: 0.2837 - val_accuracy: 0.9475\n",
      "Epoch 131/1000\n",
      "67/67 [==============================] - 19s 279ms/step - loss: 0.2862 - accuracy: 0.9459 - val_loss: 0.2783 - val_accuracy: 0.9475\n",
      "Epoch 132/1000\n",
      "67/67 [==============================] - 19s 280ms/step - loss: 0.2806 - accuracy: 0.9459 - val_loss: 0.2711 - val_accuracy: 0.9475\n",
      "Epoch 133/1000\n",
      "67/67 [==============================] - 19s 287ms/step - loss: 0.2746 - accuracy: 0.9459 - val_loss: 0.2659 - val_accuracy: 0.9475\n",
      "Epoch 134/1000\n",
      "67/67 [==============================] - 20s 293ms/step - loss: 0.2706 - accuracy: 0.9459 - val_loss: 0.2649 - val_accuracy: 0.9475\n",
      "Epoch 135/1000\n",
      "67/67 [==============================] - 19s 289ms/step - loss: 0.2680 - accuracy: 0.9459 - val_loss: 0.2552 - val_accuracy: 0.9475\n",
      "Epoch 136/1000\n",
      "67/67 [==============================] - 19s 279ms/step - loss: 0.2601 - accuracy: 0.9459 - val_loss: 0.2527 - val_accuracy: 0.9475\n",
      "Epoch 137/1000\n",
      "67/67 [==============================] - 19s 283ms/step - loss: 0.2563 - accuracy: 0.9459 - val_loss: 0.2468 - val_accuracy: 0.9475\n",
      "Epoch 138/1000\n",
      "67/67 [==============================] - 19s 279ms/step - loss: 0.2528 - accuracy: 0.9459 - val_loss: 0.2542 - val_accuracy: 0.9475\n",
      "Epoch 139/1000\n",
      "67/67 [==============================] - 19s 280ms/step - loss: 0.2504 - accuracy: 0.9459 - val_loss: 0.2558 - val_accuracy: 0.9475\n",
      "Epoch 140/1000\n",
      "67/67 [==============================] - 19s 285ms/step - loss: 0.2459 - accuracy: 0.9459 - val_loss: 0.2372 - val_accuracy: 0.9475\n",
      "Epoch 141/1000\n",
      "67/67 [==============================] - 19s 290ms/step - loss: 0.2396 - accuracy: 0.9459 - val_loss: 0.2328 - val_accuracy: 0.9475\n",
      "Epoch 142/1000\n",
      "67/67 [==============================] - 19s 285ms/step - loss: 0.2391 - accuracy: 0.9459 - val_loss: 0.2393 - val_accuracy: 0.9475\n",
      "Epoch 143/1000\n",
      "67/67 [==============================] - 20s 297ms/step - loss: 0.2382 - accuracy: 0.9459 - val_loss: 0.2273 - val_accuracy: 0.9475\n",
      "Epoch 144/1000\n",
      "67/67 [==============================] - 20s 295ms/step - loss: 0.2325 - accuracy: 0.9459 - val_loss: 0.2248 - val_accuracy: 0.9475\n",
      "Epoch 145/1000\n",
      "67/67 [==============================] - 20s 294ms/step - loss: 0.2293 - accuracy: 0.9459 - val_loss: 0.2229 - val_accuracy: 0.9475\n",
      "Epoch 146/1000\n",
      "67/67 [==============================] - 20s 297ms/step - loss: 0.2272 - accuracy: 0.9459 - val_loss: 0.2232 - val_accuracy: 0.9475\n",
      "Epoch 147/1000\n",
      "67/67 [==============================] - 20s 293ms/step - loss: 0.2282 - accuracy: 0.9459 - val_loss: 0.2206 - val_accuracy: 0.9475\n",
      "Epoch 148/1000\n",
      "67/67 [==============================] - 20s 300ms/step - loss: 0.2247 - accuracy: 0.9459 - val_loss: 0.2235 - val_accuracy: 0.9475\n",
      "Epoch 149/1000\n",
      "67/67 [==============================] - 20s 293ms/step - loss: 0.2248 - accuracy: 0.9459 - val_loss: 0.2183 - val_accuracy: 0.9475\n",
      "Epoch 150/1000\n",
      "67/67 [==============================] - 19s 288ms/step - loss: 0.2213 - accuracy: 0.9459 - val_loss: 0.2157 - val_accuracy: 0.9475\n",
      "Epoch 151/1000\n",
      "67/67 [==============================] - 19s 290ms/step - loss: 0.2192 - accuracy: 0.9459 - val_loss: 0.2177 - val_accuracy: 0.9475\n",
      "Epoch 152/1000\n",
      "67/67 [==============================] - 19s 291ms/step - loss: 0.2175 - accuracy: 0.9459 - val_loss: 0.2147 - val_accuracy: 0.9475\n",
      "Epoch 153/1000\n",
      "67/67 [==============================] - 20s 292ms/step - loss: 0.2202 - accuracy: 0.9459 - val_loss: 0.2117 - val_accuracy: 0.9475\n",
      "Epoch 154/1000\n",
      "67/67 [==============================] - 19s 287ms/step - loss: 0.2169 - accuracy: 0.9459 - val_loss: 0.2092 - val_accuracy: 0.9475\n",
      "Epoch 155/1000\n",
      "67/67 [==============================] - 19s 286ms/step - loss: 0.2156 - accuracy: 0.9459 - val_loss: 0.2081 - val_accuracy: 0.9475\n",
      "Epoch 156/1000\n",
      "67/67 [==============================] - 19s 279ms/step - loss: 0.2151 - accuracy: 0.9459 - val_loss: 0.2072 - val_accuracy: 0.9475\n",
      "Epoch 157/1000\n",
      "67/67 [==============================] - 19s 288ms/step - loss: 0.2153 - accuracy: 0.9459 - val_loss: 0.2093 - val_accuracy: 0.9475\n",
      "Epoch 158/1000\n",
      "67/67 [==============================] - 19s 285ms/step - loss: 0.2131 - accuracy: 0.9459 - val_loss: 0.2065 - val_accuracy: 0.9475\n",
      "Epoch 159/1000\n",
      "67/67 [==============================] - 19s 284ms/step - loss: 0.2143 - accuracy: 0.9459 - val_loss: 0.2080 - val_accuracy: 0.9475\n",
      "Epoch 160/1000\n",
      "67/67 [==============================] - 19s 282ms/step - loss: 0.2109 - accuracy: 0.9459 - val_loss: 0.2064 - val_accuracy: 0.9475\n",
      "Epoch 161/1000\n",
      "67/67 [==============================] - 19s 290ms/step - loss: 0.2141 - accuracy: 0.9459 - val_loss: 0.2152 - val_accuracy: 0.9475\n",
      "Epoch 162/1000\n",
      "67/67 [==============================] - 20s 295ms/step - loss: 0.2119 - accuracy: 0.9459 - val_loss: 0.2053 - val_accuracy: 0.9475\n",
      "Epoch 163/1000\n",
      "67/67 [==============================] - 19s 287ms/step - loss: 0.2097 - accuracy: 0.9459 - val_loss: 0.2031 - val_accuracy: 0.9475\n",
      "Epoch 164/1000\n",
      "67/67 [==============================] - 20s 294ms/step - loss: 0.2101 - accuracy: 0.9459 - val_loss: 0.2029 - val_accuracy: 0.9475\n",
      "Epoch 165/1000\n",
      "67/67 [==============================] - 20s 292ms/step - loss: 0.2099 - accuracy: 0.9459 - val_loss: 0.2025 - val_accuracy: 0.9475\n",
      "Epoch 166/1000\n",
      "67/67 [==============================] - 20s 296ms/step - loss: 0.2097 - accuracy: 0.9459 - val_loss: 0.2022 - val_accuracy: 0.9475\n",
      "Epoch 167/1000\n",
      "67/67 [==============================] - 19s 291ms/step - loss: 0.2089 - accuracy: 0.9459 - val_loss: 0.2091 - val_accuracy: 0.9475\n",
      "Epoch 168/1000\n",
      "67/67 [==============================] - 19s 286ms/step - loss: 0.2096 - accuracy: 0.9459 - val_loss: 0.2017 - val_accuracy: 0.9475\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 169/1000\n",
      "67/67 [==============================] - 20s 294ms/step - loss: 0.2070 - accuracy: 0.9459 - val_loss: 0.2005 - val_accuracy: 0.9475\n",
      "Epoch 170/1000\n",
      "67/67 [==============================] - 19s 290ms/step - loss: 0.2078 - accuracy: 0.9459 - val_loss: 0.2018 - val_accuracy: 0.9475\n",
      "Epoch 171/1000\n",
      "67/67 [==============================] - 20s 292ms/step - loss: 0.2068 - accuracy: 0.9459 - val_loss: 0.2007 - val_accuracy: 0.9475\n",
      "Epoch 172/1000\n",
      "67/67 [==============================] - 19s 285ms/step - loss: 0.2063 - accuracy: 0.9459 - val_loss: 0.2063 - val_accuracy: 0.9475\n",
      "Epoch 173/1000\n",
      "67/67 [==============================] - 19s 288ms/step - loss: 0.2070 - accuracy: 0.9459 - val_loss: 0.2009 - val_accuracy: 0.9475\n",
      "Epoch 174/1000\n",
      "67/67 [==============================] - 20s 295ms/step - loss: 0.2071 - accuracy: 0.9459 - val_loss: 0.2007 - val_accuracy: 0.9475\n",
      "Epoch 175/1000\n",
      "67/67 [==============================] - 18s 275ms/step - loss: 0.2092 - accuracy: 0.9459 - val_loss: 0.2017 - val_accuracy: 0.9475\n",
      "Epoch 176/1000\n",
      "67/67 [==============================] - 19s 279ms/step - loss: 0.2057 - accuracy: 0.9459 - val_loss: 0.1993 - val_accuracy: 0.9475\n",
      "Epoch 177/1000\n",
      "67/67 [==============================] - 19s 281ms/step - loss: 0.2090 - accuracy: 0.9459 - val_loss: 0.2026 - val_accuracy: 0.9475\n",
      "Epoch 178/1000\n",
      "67/67 [==============================] - 19s 289ms/step - loss: 0.2064 - accuracy: 0.9459 - val_loss: 0.2062 - val_accuracy: 0.9475\n",
      "Epoch 179/1000\n",
      "67/67 [==============================] - 19s 286ms/step - loss: 0.2073 - accuracy: 0.9459 - val_loss: 0.2011 - val_accuracy: 0.9475\n",
      "Epoch 180/1000\n",
      "67/67 [==============================] - 19s 289ms/step - loss: 0.2067 - accuracy: 0.9459 - val_loss: 0.2118 - val_accuracy: 0.9475\n",
      "Epoch 181/1000\n",
      "67/67 [==============================] - 19s 289ms/step - loss: 0.2076 - accuracy: 0.9459 - val_loss: 0.1997 - val_accuracy: 0.9475\n",
      "Epoch 182/1000\n",
      "67/67 [==============================] - 19s 281ms/step - loss: 0.2061 - accuracy: 0.9459 - val_loss: 0.1995 - val_accuracy: 0.9475\n",
      "Epoch 183/1000\n",
      "67/67 [==============================] - 20s 295ms/step - loss: 0.2057 - accuracy: 0.9459 - val_loss: 0.2026 - val_accuracy: 0.9475\n",
      "Epoch 184/1000\n",
      "67/67 [==============================] - 19s 290ms/step - loss: 0.2058 - accuracy: 0.9459 - val_loss: 0.2005 - val_accuracy: 0.9475\n",
      "Epoch 185/1000\n",
      "67/67 [==============================] - 20s 292ms/step - loss: 0.2076 - accuracy: 0.9459 - val_loss: 0.2006 - val_accuracy: 0.9475\n",
      "Epoch 186/1000\n",
      "67/67 [==============================] - 19s 290ms/step - loss: 0.2063 - accuracy: 0.9459 - val_loss: 0.1988 - val_accuracy: 0.9475\n",
      "Epoch 187/1000\n",
      "67/67 [==============================] - 20s 297ms/step - loss: 0.2046 - accuracy: 0.9459 - val_loss: 0.1991 - val_accuracy: 0.9475\n",
      "Epoch 188/1000\n",
      "67/67 [==============================] - 20s 294ms/step - loss: 0.2050 - accuracy: 0.9459 - val_loss: 0.2064 - val_accuracy: 0.9475\n",
      "Epoch 189/1000\n",
      "67/67 [==============================] - 20s 298ms/step - loss: 0.2074 - accuracy: 0.9459 - val_loss: 0.2007 - val_accuracy: 0.9475\n",
      "Epoch 190/1000\n",
      "67/67 [==============================] - 20s 293ms/step - loss: 0.2066 - accuracy: 0.9459 - val_loss: 0.2005 - val_accuracy: 0.9475\n",
      "Epoch 191/1000\n",
      "67/67 [==============================] - 20s 297ms/step - loss: 0.2058 - accuracy: 0.9459 - val_loss: 0.1989 - val_accuracy: 0.9475\n",
      "Epoch 192/1000\n",
      "67/67 [==============================] - 19s 291ms/step - loss: 0.2047 - accuracy: 0.9459 - val_loss: 0.1988 - val_accuracy: 0.9475\n",
      "Epoch 193/1000\n",
      "67/67 [==============================] - 19s 287ms/step - loss: 0.2056 - accuracy: 0.9459 - val_loss: 0.2019 - val_accuracy: 0.9475\n",
      "Epoch 194/1000\n",
      "67/67 [==============================] - 19s 290ms/step - loss: 0.2060 - accuracy: 0.9459 - val_loss: 0.1990 - val_accuracy: 0.9475\n",
      "Epoch 195/1000\n",
      "67/67 [==============================] - 19s 287ms/step - loss: 0.2056 - accuracy: 0.9459 - val_loss: 0.2007 - val_accuracy: 0.9475\n",
      "Epoch 196/1000\n",
      "67/67 [==============================] - 19s 287ms/step - loss: 0.2044 - accuracy: 0.9459 - val_loss: 0.1985 - val_accuracy: 0.9475\n",
      "Epoch 197/1000\n",
      "67/67 [==============================] - 19s 289ms/step - loss: 0.2047 - accuracy: 0.9459 - val_loss: 0.1992 - val_accuracy: 0.9475\n",
      "Epoch 198/1000\n",
      "67/67 [==============================] - 19s 287ms/step - loss: 0.2068 - accuracy: 0.9459 - val_loss: 0.1992 - val_accuracy: 0.9475\n",
      "Epoch 199/1000\n",
      "67/67 [==============================] - 19s 289ms/step - loss: 0.2062 - accuracy: 0.9459 - val_loss: 0.2000 - val_accuracy: 0.9475\n",
      "Epoch 200/1000\n",
      "67/67 [==============================] - 19s 289ms/step - loss: 0.2051 - accuracy: 0.9459 - val_loss: 0.1982 - val_accuracy: 0.9475\n",
      "Epoch 201/1000\n",
      "67/67 [==============================] - 19s 284ms/step - loss: 0.2052 - accuracy: 0.9459 - val_loss: 0.1992 - val_accuracy: 0.9475\n",
      "Epoch 202/1000\n",
      "67/67 [==============================] - 19s 290ms/step - loss: 0.2051 - accuracy: 0.9459 - val_loss: 0.1984 - val_accuracy: 0.9475\n",
      "Epoch 203/1000\n",
      "67/67 [==============================] - 20s 292ms/step - loss: 0.2041 - accuracy: 0.9459 - val_loss: 0.1986 - val_accuracy: 0.9475\n",
      "Epoch 204/1000\n",
      "67/67 [==============================] - 19s 288ms/step - loss: 0.2044 - accuracy: 0.9459 - val_loss: 0.2052 - val_accuracy: 0.9475\n",
      "Epoch 205/1000\n",
      "67/67 [==============================] - 20s 302ms/step - loss: 0.2069 - accuracy: 0.9459 - val_loss: 0.1990 - val_accuracy: 0.9475\n",
      "Epoch 206/1000\n",
      "67/67 [==============================] - 20s 293ms/step - loss: 0.2053 - accuracy: 0.9459 - val_loss: 0.2024 - val_accuracy: 0.9475\n",
      "Epoch 207/1000\n",
      "67/67 [==============================] - 20s 296ms/step - loss: 0.2053 - accuracy: 0.9459 - val_loss: 0.1982 - val_accuracy: 0.9475\n",
      "Epoch 208/1000\n",
      "67/67 [==============================] - 20s 298ms/step - loss: 0.2060 - accuracy: 0.9459 - val_loss: 0.1986 - val_accuracy: 0.9475\n",
      "Epoch 209/1000\n",
      "67/67 [==============================] - 20s 299ms/step - loss: 0.2056 - accuracy: 0.9459 - val_loss: 0.1999 - val_accuracy: 0.9475\n",
      "Epoch 210/1000\n",
      "67/67 [==============================] - 20s 296ms/step - loss: 0.2035 - accuracy: 0.9459 - val_loss: 0.1993 - val_accuracy: 0.9475\n",
      "Epoch 211/1000\n",
      "67/67 [==============================] - 20s 299ms/step - loss: 0.2049 - accuracy: 0.9459 - val_loss: 0.1979 - val_accuracy: 0.9475\n",
      "Epoch 212/1000\n",
      "67/67 [==============================] - 20s 295ms/step - loss: 0.2033 - accuracy: 0.9459 - val_loss: 0.1991 - val_accuracy: 0.9475\n",
      "Epoch 213/1000\n",
      "67/67 [==============================] - 20s 296ms/step - loss: 0.2028 - accuracy: 0.9459 - val_loss: 0.1974 - val_accuracy: 0.9475\n",
      "Epoch 214/1000\n",
      "67/67 [==============================] - 20s 296ms/step - loss: 0.2054 - accuracy: 0.9459 - val_loss: 0.2027 - val_accuracy: 0.9475\n",
      "Epoch 215/1000\n",
      "67/67 [==============================] - 20s 291ms/step - loss: 0.2069 - accuracy: 0.9459 - val_loss: 0.2036 - val_accuracy: 0.9475\n",
      "Epoch 216/1000\n",
      "67/67 [==============================] - 20s 292ms/step - loss: 0.2068 - accuracy: 0.9459 - val_loss: 0.1993 - val_accuracy: 0.9475\n",
      "Epoch 217/1000\n",
      "67/67 [==============================] - 19s 285ms/step - loss: 0.2049 - accuracy: 0.9459 - val_loss: 0.2012 - val_accuracy: 0.9475\n",
      "Epoch 218/1000\n",
      "67/67 [==============================] - 19s 280ms/step - loss: 0.2053 - accuracy: 0.9459 - val_loss: 0.1981 - val_accuracy: 0.9475\n",
      "Epoch 219/1000\n",
      "67/67 [==============================] - 19s 289ms/step - loss: 0.2040 - accuracy: 0.9459 - val_loss: 0.1998 - val_accuracy: 0.9475\n",
      "Epoch 220/1000\n",
      "67/67 [==============================] - 19s 286ms/step - loss: 0.2045 - accuracy: 0.9459 - val_loss: 0.2006 - val_accuracy: 0.9475\n",
      "Epoch 221/1000\n",
      "67/67 [==============================] - 19s 283ms/step - loss: 0.2059 - accuracy: 0.9459 - val_loss: 0.1990 - val_accuracy: 0.9475\n",
      "Epoch 222/1000\n",
      "67/67 [==============================] - 19s 282ms/step - loss: 0.2053 - accuracy: 0.9459 - val_loss: 0.1989 - val_accuracy: 0.9475\n",
      "Epoch 223/1000\n",
      "67/67 [==============================] - 19s 284ms/step - loss: 0.2056 - accuracy: 0.9459 - val_loss: 0.1999 - val_accuracy: 0.9475\n",
      "Epoch 224/1000\n",
      "67/67 [==============================] - 19s 280ms/step - loss: 0.2045 - accuracy: 0.9459 - val_loss: 0.1983 - val_accuracy: 0.9475\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 225/1000\n",
      "67/67 [==============================] - 19s 283ms/step - loss: 0.2067 - accuracy: 0.9459 - val_loss: 0.2076 - val_accuracy: 0.9475\n",
      "Epoch 226/1000\n",
      "67/67 [==============================] - 19s 286ms/step - loss: 0.2050 - accuracy: 0.9459 - val_loss: 0.1987 - val_accuracy: 0.9475\n",
      "Epoch 227/1000\n",
      "67/67 [==============================] - 19s 291ms/step - loss: 0.2055 - accuracy: 0.9459 - val_loss: 0.2014 - val_accuracy: 0.9475\n",
      "Epoch 228/1000\n",
      "67/67 [==============================] - 19s 290ms/step - loss: 0.2051 - accuracy: 0.9459 - val_loss: 0.1989 - val_accuracy: 0.9475\n",
      "Epoch 229/1000\n",
      "67/67 [==============================] - 21s 313ms/step - loss: 0.2045 - accuracy: 0.9459 - val_loss: 0.1981 - val_accuracy: 0.9475\n",
      "Epoch 230/1000\n",
      "67/67 [==============================] - 23s 342ms/step - loss: 0.2045 - accuracy: 0.9459 - val_loss: 0.2010 - val_accuracy: 0.9475\n",
      "Epoch 231/1000\n",
      "67/67 [==============================] - 23s 344ms/step - loss: 0.2038 - accuracy: 0.9459 - val_loss: 0.1976 - val_accuracy: 0.9475\n",
      "Epoch 232/1000\n",
      "67/67 [==============================] - 23s 342ms/step - loss: 0.2042 - accuracy: 0.9459 - val_loss: 0.1977 - val_accuracy: 0.9475\n",
      "Epoch 233/1000\n",
      "67/67 [==============================] - 23s 340ms/step - loss: 0.2047 - accuracy: 0.9459 - val_loss: 0.1981 - val_accuracy: 0.9475\n",
      "Epoch 234/1000\n",
      "67/67 [==============================] - 23s 341ms/step - loss: 0.2049 - accuracy: 0.9459 - val_loss: 0.1984 - val_accuracy: 0.9475\n",
      "Epoch 235/1000\n",
      "67/67 [==============================] - 23s 344ms/step - loss: 0.2044 - accuracy: 0.9459 - val_loss: 0.2011 - val_accuracy: 0.9475\n",
      "Epoch 236/1000\n",
      "67/67 [==============================] - 23s 344ms/step - loss: 0.2059 - accuracy: 0.9459 - val_loss: 0.1978 - val_accuracy: 0.9475\n",
      "Epoch 237/1000\n",
      "67/67 [==============================] - 23s 343ms/step - loss: 0.2036 - accuracy: 0.9459 - val_loss: 0.1976 - val_accuracy: 0.9475\n",
      "Epoch 238/1000\n",
      "67/67 [==============================] - 23s 339ms/step - loss: 0.2050 - accuracy: 0.9459 - val_loss: 0.1976 - val_accuracy: 0.9475\n",
      "Epoch 239/1000\n",
      "67/67 [==============================] - 23s 342ms/step - loss: 0.2051 - accuracy: 0.9459 - val_loss: 0.1987 - val_accuracy: 0.9475\n",
      "Epoch 240/1000\n",
      "67/67 [==============================] - 23s 343ms/step - loss: 0.2067 - accuracy: 0.9459 - val_loss: 0.1976 - val_accuracy: 0.9475\n",
      "Epoch 241/1000\n",
      "67/67 [==============================] - 23s 341ms/step - loss: 0.2057 - accuracy: 0.9459 - val_loss: 0.1980 - val_accuracy: 0.9475\n",
      "Epoch 242/1000\n",
      "67/67 [==============================] - 23s 342ms/step - loss: 0.2046 - accuracy: 0.9459 - val_loss: 0.2026 - val_accuracy: 0.9475\n",
      "Epoch 243/1000\n",
      "67/67 [==============================] - 23s 342ms/step - loss: 0.2055 - accuracy: 0.9459 - val_loss: 0.2036 - val_accuracy: 0.9475\n",
      "Epoch 244/1000\n",
      "67/67 [==============================] - 24s 352ms/step - loss: 0.2034 - accuracy: 0.9459 - val_loss: 0.1991 - val_accuracy: 0.9475\n",
      "Epoch 245/1000\n",
      "67/67 [==============================] - 23s 345ms/step - loss: 0.2053 - accuracy: 0.9459 - val_loss: 0.1994 - val_accuracy: 0.9475\n",
      "Epoch 246/1000\n",
      "67/67 [==============================] - 23s 341ms/step - loss: 0.2068 - accuracy: 0.9459 - val_loss: 0.1994 - val_accuracy: 0.9475\n",
      "Epoch 247/1000\n",
      "67/67 [==============================] - 23s 343ms/step - loss: 0.2059 - accuracy: 0.9459 - val_loss: 0.1982 - val_accuracy: 0.9475\n",
      "Epoch 248/1000\n",
      "67/67 [==============================] - 23s 340ms/step - loss: 0.2048 - accuracy: 0.9459 - val_loss: 0.1988 - val_accuracy: 0.9475\n",
      "Epoch 249/1000\n",
      "67/67 [==============================] - 23s 344ms/step - loss: 0.2042 - accuracy: 0.9459 - val_loss: 0.1991 - val_accuracy: 0.9475\n",
      "Epoch 250/1000\n",
      "67/67 [==============================] - 23s 340ms/step - loss: 0.2036 - accuracy: 0.9459 - val_loss: 0.1974 - val_accuracy: 0.9475\n",
      "Epoch 251/1000\n",
      "67/67 [==============================] - 23s 341ms/step - loss: 0.2037 - accuracy: 0.9459 - val_loss: 0.1989 - val_accuracy: 0.9475\n",
      "Epoch 252/1000\n",
      "67/67 [==============================] - 23s 339ms/step - loss: 0.2041 - accuracy: 0.9459 - val_loss: 0.1975 - val_accuracy: 0.9475\n",
      "Epoch 253/1000\n",
      "67/67 [==============================] - 23s 343ms/step - loss: 0.2043 - accuracy: 0.9459 - val_loss: 0.1979 - val_accuracy: 0.9475\n",
      "Epoch 254/1000\n",
      "67/67 [==============================] - 23s 343ms/step - loss: 0.2039 - accuracy: 0.9459 - val_loss: 0.1967 - val_accuracy: 0.9475\n",
      "Epoch 255/1000\n",
      "67/67 [==============================] - 23s 342ms/step - loss: 0.2033 - accuracy: 0.9459 - val_loss: 0.1981 - val_accuracy: 0.9475\n",
      "Epoch 256/1000\n",
      "67/67 [==============================] - 23s 347ms/step - loss: 0.2035 - accuracy: 0.9459 - val_loss: 0.2001 - val_accuracy: 0.9475\n",
      "Epoch 257/1000\n",
      "67/67 [==============================] - 23s 341ms/step - loss: 0.2052 - accuracy: 0.9459 - val_loss: 0.1973 - val_accuracy: 0.9475\n",
      "Epoch 258/1000\n",
      "67/67 [==============================] - 23s 341ms/step - loss: 0.2042 - accuracy: 0.9459 - val_loss: 0.1981 - val_accuracy: 0.9475\n",
      "Epoch 259/1000\n",
      "67/67 [==============================] - 23s 340ms/step - loss: 0.2034 - accuracy: 0.9459 - val_loss: 0.1975 - val_accuracy: 0.9475\n",
      "Epoch 260/1000\n",
      "67/67 [==============================] - 23s 342ms/step - loss: 0.2033 - accuracy: 0.9459 - val_loss: 0.1976 - val_accuracy: 0.9475\n",
      "Epoch 261/1000\n",
      "67/67 [==============================] - 23s 341ms/step - loss: 0.2057 - accuracy: 0.9459 - val_loss: 0.1978 - val_accuracy: 0.9475\n",
      "Epoch 262/1000\n",
      "67/67 [==============================] - 23s 341ms/step - loss: 0.2029 - accuracy: 0.9459 - val_loss: 0.1985 - val_accuracy: 0.9475\n",
      "Epoch 263/1000\n",
      "67/67 [==============================] - 24s 357ms/step - loss: 0.2035 - accuracy: 0.9459 - val_loss: 0.1969 - val_accuracy: 0.9475\n",
      "Epoch 264/1000\n",
      "67/67 [==============================] - 23s 344ms/step - loss: 0.2041 - accuracy: 0.9459 - val_loss: 0.1979 - val_accuracy: 0.9475\n",
      "Epoch 265/1000\n",
      "67/67 [==============================] - 23s 341ms/step - loss: 0.2060 - accuracy: 0.9459 - val_loss: 0.1982 - val_accuracy: 0.9475\n",
      "Epoch 266/1000\n",
      "67/67 [==============================] - 23s 342ms/step - loss: 0.2034 - accuracy: 0.9459 - val_loss: 0.1971 - val_accuracy: 0.9475\n",
      "Epoch 267/1000\n",
      "67/67 [==============================] - 23s 344ms/step - loss: 0.2035 - accuracy: 0.9459 - val_loss: 0.1972 - val_accuracy: 0.9475\n",
      "Epoch 268/1000\n",
      "67/67 [==============================] - 23s 340ms/step - loss: 0.2048 - accuracy: 0.9459 - val_loss: 0.1988 - val_accuracy: 0.9475\n",
      "Epoch 269/1000\n",
      "67/67 [==============================] - 23s 342ms/step - loss: 0.2062 - accuracy: 0.9459 - val_loss: 0.1974 - val_accuracy: 0.9475\n",
      "Epoch 270/1000\n",
      "67/67 [==============================] - 23s 342ms/step - loss: 0.2030 - accuracy: 0.9459 - val_loss: 0.1970 - val_accuracy: 0.9475\n",
      "Epoch 271/1000\n",
      "67/67 [==============================] - 23s 343ms/step - loss: 0.2040 - accuracy: 0.9459 - val_loss: 0.2022 - val_accuracy: 0.9475\n",
      "Epoch 272/1000\n",
      "67/67 [==============================] - 23s 345ms/step - loss: 0.2038 - accuracy: 0.9459 - val_loss: 0.1975 - val_accuracy: 0.9475\n",
      "Epoch 273/1000\n",
      "67/67 [==============================] - 23s 340ms/step - loss: 0.2047 - accuracy: 0.9459 - val_loss: 0.2035 - val_accuracy: 0.9475\n",
      "Epoch 274/1000\n",
      "67/67 [==============================] - 23s 343ms/step - loss: 0.2038 - accuracy: 0.9459 - val_loss: 0.1965 - val_accuracy: 0.9475\n",
      "Epoch 275/1000\n",
      "67/67 [==============================] - 23s 346ms/step - loss: 0.2037 - accuracy: 0.9459 - val_loss: 0.1984 - val_accuracy: 0.9475\n",
      "Epoch 276/1000\n",
      "67/67 [==============================] - 23s 339ms/step - loss: 0.2023 - accuracy: 0.9459 - val_loss: 0.1978 - val_accuracy: 0.9475\n",
      "Epoch 277/1000\n",
      "67/67 [==============================] - 23s 343ms/step - loss: 0.2061 - accuracy: 0.9459 - val_loss: 0.1994 - val_accuracy: 0.9475\n",
      "Epoch 278/1000\n",
      "67/67 [==============================] - 23s 342ms/step - loss: 0.2035 - accuracy: 0.9459 - val_loss: 0.1969 - val_accuracy: 0.9475\n",
      "Epoch 279/1000\n",
      "67/67 [==============================] - 23s 342ms/step - loss: 0.2039 - accuracy: 0.9459 - val_loss: 0.2003 - val_accuracy: 0.9475\n",
      "Epoch 280/1000\n",
      "67/67 [==============================] - 23s 345ms/step - loss: 0.2031 - accuracy: 0.9459 - val_loss: 0.1971 - val_accuracy: 0.9475\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 281/1000\n",
      "67/67 [==============================] - 24s 356ms/step - loss: 0.2052 - accuracy: 0.9459 - val_loss: 0.1975 - val_accuracy: 0.9475\n",
      "Epoch 282/1000\n",
      "67/67 [==============================] - 24s 360ms/step - loss: 0.2032 - accuracy: 0.9459 - val_loss: 0.1977 - val_accuracy: 0.9475\n",
      "Epoch 283/1000\n",
      "67/67 [==============================] - 24s 356ms/step - loss: 0.2060 - accuracy: 0.9459 - val_loss: 0.1983 - val_accuracy: 0.9475\n",
      "Epoch 284/1000\n",
      "67/67 [==============================] - 23s 351ms/step - loss: 0.2044 - accuracy: 0.9459 - val_loss: 0.1985 - val_accuracy: 0.9475\n",
      "Epoch 285/1000\n",
      "67/67 [==============================] - 26s 396ms/step - loss: 0.2025 - accuracy: 0.9459 - val_loss: 0.2044 - val_accuracy: 0.9475\n",
      "Epoch 286/1000\n",
      "67/67 [==============================] - 28s 414ms/step - loss: 0.2036 - accuracy: 0.9459 - val_loss: 0.1965 - val_accuracy: 0.9475\n",
      "Epoch 287/1000\n",
      "67/67 [==============================] - 27s 401ms/step - loss: 0.2039 - accuracy: 0.9459 - val_loss: 0.1964 - val_accuracy: 0.9475\n",
      "Epoch 288/1000\n",
      "67/67 [==============================] - 27s 408ms/step - loss: 0.2030 - accuracy: 0.9459 - val_loss: 0.2086 - val_accuracy: 0.9475\n",
      "Epoch 289/1000\n",
      "67/67 [==============================] - 26s 392ms/step - loss: 0.2057 - accuracy: 0.9459 - val_loss: 0.1985 - val_accuracy: 0.9475\n",
      "Epoch 290/1000\n",
      "67/67 [==============================] - 27s 410ms/step - loss: 0.2027 - accuracy: 0.9459 - val_loss: 0.1973 - val_accuracy: 0.9475\n",
      "Epoch 291/1000\n",
      "67/67 [==============================] - 27s 398ms/step - loss: 0.2048 - accuracy: 0.9459 - val_loss: 0.1960 - val_accuracy: 0.9475\n",
      "Epoch 292/1000\n",
      "67/67 [==============================] - 27s 409ms/step - loss: 0.2034 - accuracy: 0.9459 - val_loss: 0.1987 - val_accuracy: 0.9475\n",
      "Epoch 293/1000\n",
      "67/67 [==============================] - 26s 391ms/step - loss: 0.2032 - accuracy: 0.9459 - val_loss: 0.1962 - val_accuracy: 0.9475\n",
      "Epoch 294/1000\n",
      "67/67 [==============================] - 28s 415ms/step - loss: 0.2017 - accuracy: 0.9459 - val_loss: 0.2008 - val_accuracy: 0.9475\n",
      "Epoch 295/1000\n",
      "67/67 [==============================] - 29s 436ms/step - loss: 0.2051 - accuracy: 0.9459 - val_loss: 0.1970 - val_accuracy: 0.9475\n",
      "Epoch 296/1000\n",
      "67/67 [==============================] - 27s 400ms/step - loss: 0.2038 - accuracy: 0.9459 - val_loss: 0.1967 - val_accuracy: 0.9475\n",
      "Epoch 297/1000\n",
      "67/67 [==============================] - 28s 412ms/step - loss: 0.2051 - accuracy: 0.9459 - val_loss: 0.1969 - val_accuracy: 0.9475\n",
      "Epoch 298/1000\n",
      "67/67 [==============================] - 27s 410ms/step - loss: 0.2022 - accuracy: 0.9459 - val_loss: 0.1962 - val_accuracy: 0.9475\n",
      "Epoch 299/1000\n",
      "67/67 [==============================] - 28s 422ms/step - loss: 0.2047 - accuracy: 0.9459 - val_loss: 0.1977 - val_accuracy: 0.9475\n",
      "Epoch 300/1000\n",
      "67/67 [==============================] - 26s 392ms/step - loss: 0.2038 - accuracy: 0.9459 - val_loss: 0.1977 - val_accuracy: 0.9475\n",
      "Epoch 301/1000\n",
      "67/67 [==============================] - 28s 415ms/step - loss: 0.2027 - accuracy: 0.9459 - val_loss: 0.1970 - val_accuracy: 0.9475\n",
      "Epoch 302/1000\n",
      "67/67 [==============================] - 26s 389ms/step - loss: 0.2036 - accuracy: 0.9459 - val_loss: 0.1967 - val_accuracy: 0.9475\n",
      "Epoch 303/1000\n",
      "67/67 [==============================] - 28s 419ms/step - loss: 0.2052 - accuracy: 0.9459 - val_loss: 0.1983 - val_accuracy: 0.9475\n",
      "Epoch 304/1000\n",
      "67/67 [==============================] - 26s 394ms/step - loss: 0.2028 - accuracy: 0.9459 - val_loss: 0.1972 - val_accuracy: 0.9475\n",
      "Epoch 305/1000\n",
      "67/67 [==============================] - 28s 413ms/step - loss: 0.2036 - accuracy: 0.9459 - val_loss: 0.2012 - val_accuracy: 0.9475\n",
      "Epoch 306/1000\n",
      "67/67 [==============================] - 27s 398ms/step - loss: 0.2043 - accuracy: 0.9459 - val_loss: 0.2004 - val_accuracy: 0.9475\n",
      "Epoch 307/1000\n",
      "67/67 [==============================] - 28s 413ms/step - loss: 0.2035 - accuracy: 0.9459 - val_loss: 0.1959 - val_accuracy: 0.9475\n",
      "Epoch 308/1000\n",
      "67/67 [==============================] - 26s 394ms/step - loss: 0.2017 - accuracy: 0.9459 - val_loss: 0.1976 - val_accuracy: 0.9475\n",
      "Epoch 309/1000\n",
      "67/67 [==============================] - 27s 409ms/step - loss: 0.2023 - accuracy: 0.9459 - val_loss: 0.1972 - val_accuracy: 0.9475\n",
      "Epoch 310/1000\n",
      "67/67 [==============================] - 27s 401ms/step - loss: 0.2037 - accuracy: 0.9459 - val_loss: 0.2003 - val_accuracy: 0.9475\n",
      "Epoch 311/1000\n",
      "67/67 [==============================] - 28s 412ms/step - loss: 0.2018 - accuracy: 0.9459 - val_loss: 0.1981 - val_accuracy: 0.9475\n",
      "Epoch 312/1000\n",
      "67/67 [==============================] - 27s 403ms/step - loss: 0.2030 - accuracy: 0.9459 - val_loss: 0.1960 - val_accuracy: 0.9475\n",
      "Epoch 313/1000\n",
      "67/67 [==============================] - 28s 413ms/step - loss: 0.2046 - accuracy: 0.9459 - val_loss: 0.1968 - val_accuracy: 0.9475\n",
      "Epoch 314/1000\n",
      "67/67 [==============================] - 28s 413ms/step - loss: 0.2037 - accuracy: 0.9459 - val_loss: 0.1966 - val_accuracy: 0.9475\n",
      "Epoch 315/1000\n",
      "67/67 [==============================] - 27s 402ms/step - loss: 0.2018 - accuracy: 0.9459 - val_loss: 0.1983 - val_accuracy: 0.9475\n",
      "Epoch 316/1000\n",
      "67/67 [==============================] - 26s 396ms/step - loss: 0.2022 - accuracy: 0.9459 - val_loss: 0.1982 - val_accuracy: 0.9475\n",
      "Epoch 317/1000\n",
      "67/67 [==============================] - 27s 403ms/step - loss: 0.2028 - accuracy: 0.9459 - val_loss: 0.1984 - val_accuracy: 0.9475\n",
      "Epoch 318/1000\n",
      "67/67 [==============================] - 27s 404ms/step - loss: 0.2026 - accuracy: 0.9459 - val_loss: 0.1984 - val_accuracy: 0.9475\n",
      "Epoch 319/1000\n",
      "67/67 [==============================] - 27s 403ms/step - loss: 0.2034 - accuracy: 0.9459 - val_loss: 0.1987 - val_accuracy: 0.9475\n",
      "Epoch 320/1000\n",
      "67/67 [==============================] - 27s 399ms/step - loss: 0.2025 - accuracy: 0.9459 - val_loss: 0.1962 - val_accuracy: 0.9475\n",
      "Epoch 321/1000\n",
      "67/67 [==============================] - 27s 401ms/step - loss: 0.2053 - accuracy: 0.9459 - val_loss: 0.1975 - val_accuracy: 0.9475\n",
      "Epoch 322/1000\n",
      "67/67 [==============================] - 26s 386ms/step - loss: 0.2018 - accuracy: 0.9459 - val_loss: 0.1957 - val_accuracy: 0.9475\n",
      "Epoch 323/1000\n",
      "67/67 [==============================] - 27s 400ms/step - loss: 0.2029 - accuracy: 0.9459 - val_loss: 0.1963 - val_accuracy: 0.9475\n",
      "Epoch 324/1000\n",
      "67/67 [==============================] - 27s 400ms/step - loss: 0.2017 - accuracy: 0.9459 - val_loss: 0.1982 - val_accuracy: 0.9475\n",
      "Epoch 325/1000\n",
      "67/67 [==============================] - 27s 406ms/step - loss: 0.2023 - accuracy: 0.9459 - val_loss: 0.1969 - val_accuracy: 0.9475\n",
      "Epoch 326/1000\n",
      "67/67 [==============================] - 27s 401ms/step - loss: 0.2033 - accuracy: 0.9459 - val_loss: 0.1966 - val_accuracy: 0.9475\n",
      "Epoch 327/1000\n",
      "67/67 [==============================] - 27s 407ms/step - loss: 0.2021 - accuracy: 0.9459 - val_loss: 0.1962 - val_accuracy: 0.9475\n",
      "Epoch 328/1000\n",
      "67/67 [==============================] - 28s 418ms/step - loss: 0.2021 - accuracy: 0.9459 - val_loss: 0.1993 - val_accuracy: 0.9475\n",
      "Epoch 329/1000\n",
      "67/67 [==============================] - 28s 414ms/step - loss: 0.2041 - accuracy: 0.9459 - val_loss: 0.1983 - val_accuracy: 0.9475\n",
      "Epoch 330/1000\n",
      "67/67 [==============================] - 26s 395ms/step - loss: 0.2014 - accuracy: 0.9459 - val_loss: 0.1963 - val_accuracy: 0.9475\n",
      "Epoch 331/1000\n",
      "67/67 [==============================] - 27s 410ms/step - loss: 0.2033 - accuracy: 0.9459 - val_loss: 0.1970 - val_accuracy: 0.9475\n",
      "Epoch 332/1000\n",
      "67/67 [==============================] - 27s 400ms/step - loss: 0.2028 - accuracy: 0.9459 - val_loss: 0.1963 - val_accuracy: 0.9475\n",
      "Epoch 333/1000\n",
      "67/67 [==============================] - 27s 410ms/step - loss: 0.2039 - accuracy: 0.9459 - val_loss: 0.1982 - val_accuracy: 0.9475\n",
      "Epoch 334/1000\n",
      "67/67 [==============================] - 27s 398ms/step - loss: 0.2039 - accuracy: 0.9459 - val_loss: 0.1960 - val_accuracy: 0.9475\n",
      "Epoch 335/1000\n",
      "67/67 [==============================] - 27s 412ms/step - loss: 0.2020 - accuracy: 0.9459 - val_loss: 0.1957 - val_accuracy: 0.9475\n",
      "Epoch 336/1000\n",
      "67/67 [==============================] - 26s 392ms/step - loss: 0.2019 - accuracy: 0.9459 - val_loss: 0.1964 - val_accuracy: 0.9475\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 337/1000\n",
      "67/67 [==============================] - 28s 413ms/step - loss: 0.2032 - accuracy: 0.9459 - val_loss: 0.1979 - val_accuracy: 0.9475\n",
      "Epoch 338/1000\n",
      "67/67 [==============================] - 27s 397ms/step - loss: 0.2029 - accuracy: 0.9459 - val_loss: 0.1963 - val_accuracy: 0.9475\n",
      "Epoch 339/1000\n",
      "67/67 [==============================] - 28s 412ms/step - loss: 0.2012 - accuracy: 0.9459 - val_loss: 0.1961 - val_accuracy: 0.9475\n",
      "Epoch 340/1000\n",
      "67/67 [==============================] - 27s 403ms/step - loss: 0.2022 - accuracy: 0.9459 - val_loss: 0.1970 - val_accuracy: 0.9475\n",
      "Epoch 341/1000\n",
      "67/67 [==============================] - 27s 397ms/step - loss: 0.2026 - accuracy: 0.9459 - val_loss: 0.1963 - val_accuracy: 0.9475\n",
      "Epoch 342/1000\n",
      "67/67 [==============================] - 28s 420ms/step - loss: 0.2020 - accuracy: 0.9459 - val_loss: 0.1991 - val_accuracy: 0.9475\n",
      "Epoch 343/1000\n",
      "67/67 [==============================] - 28s 418ms/step - loss: 0.2019 - accuracy: 0.9459 - val_loss: 0.1970 - val_accuracy: 0.9475\n",
      "Epoch 344/1000\n",
      "67/67 [==============================] - 27s 409ms/step - loss: 0.2036 - accuracy: 0.9459 - val_loss: 0.1960 - val_accuracy: 0.9475\n",
      "Epoch 345/1000\n",
      "67/67 [==============================] - 27s 403ms/step - loss: 0.2037 - accuracy: 0.9459 - val_loss: 0.1978 - val_accuracy: 0.9475\n",
      "Epoch 346/1000\n",
      "67/67 [==============================] - 26s 391ms/step - loss: 0.2013 - accuracy: 0.9459 - val_loss: 0.1967 - val_accuracy: 0.9475\n",
      "Epoch 347/1000\n",
      "67/67 [==============================] - 28s 417ms/step - loss: 0.2038 - accuracy: 0.9459 - val_loss: 0.1960 - val_accuracy: 0.9475\n",
      "Epoch 348/1000\n",
      "67/67 [==============================] - 26s 394ms/step - loss: 0.2032 - accuracy: 0.9459 - val_loss: 0.1971 - val_accuracy: 0.9475\n",
      "Epoch 349/1000\n",
      "67/67 [==============================] - 27s 410ms/step - loss: 0.2038 - accuracy: 0.9459 - val_loss: 0.1955 - val_accuracy: 0.9475\n",
      "Epoch 350/1000\n",
      "67/67 [==============================] - 27s 402ms/step - loss: 0.2019 - accuracy: 0.9459 - val_loss: 0.1988 - val_accuracy: 0.9475\n",
      "Epoch 351/1000\n",
      "67/67 [==============================] - 27s 401ms/step - loss: 0.2025 - accuracy: 0.9459 - val_loss: 0.1961 - val_accuracy: 0.9475\n",
      "Epoch 352/1000\n",
      "67/67 [==============================] - 27s 399ms/step - loss: 0.2025 - accuracy: 0.9459 - val_loss: 0.1961 - val_accuracy: 0.9475\n",
      "Epoch 353/1000\n",
      "67/67 [==============================] - 27s 400ms/step - loss: 0.2015 - accuracy: 0.9459 - val_loss: 0.1964 - val_accuracy: 0.9475\n",
      "Epoch 354/1000\n",
      "67/67 [==============================] - 27s 402ms/step - loss: 0.2029 - accuracy: 0.9459 - val_loss: 0.1989 - val_accuracy: 0.9475\n",
      "Epoch 355/1000\n",
      "67/67 [==============================] - 24s 363ms/step - loss: 0.2013 - accuracy: 0.9459 - val_loss: 0.1955 - val_accuracy: 0.9475\n",
      "Epoch 356/1000\n",
      "67/67 [==============================] - 22s 324ms/step - loss: 0.2013 - accuracy: 0.9459 - val_loss: 0.1963 - val_accuracy: 0.9475\n",
      "Epoch 357/1000\n",
      "67/67 [==============================] - 25s 378ms/step - loss: 0.2036 - accuracy: 0.9459 - val_loss: 0.2034 - val_accuracy: 0.9475\n",
      "Epoch 358/1000\n",
      "67/67 [==============================] - 26s 395ms/step - loss: 0.2019 - accuracy: 0.9459 - val_loss: 0.1995 - val_accuracy: 0.9475\n",
      "Epoch 359/1000\n",
      "67/67 [==============================] - 28s 416ms/step - loss: 0.2005 - accuracy: 0.9459 - val_loss: 0.1980 - val_accuracy: 0.9475\n",
      "Epoch 360/1000\n",
      "67/67 [==============================] - 27s 409ms/step - loss: 0.2020 - accuracy: 0.9459 - val_loss: 0.2030 - val_accuracy: 0.9475\n",
      "Epoch 361/1000\n",
      "67/67 [==============================] - 27s 399ms/step - loss: 0.2035 - accuracy: 0.9459 - val_loss: 0.2025 - val_accuracy: 0.9475\n",
      "Epoch 362/1000\n",
      "67/67 [==============================] - 28s 416ms/step - loss: 0.2032 - accuracy: 0.9459 - val_loss: 0.1968 - val_accuracy: 0.9475\n",
      "Epoch 363/1000\n",
      "67/67 [==============================] - 26s 393ms/step - loss: 0.2018 - accuracy: 0.9459 - val_loss: 0.1977 - val_accuracy: 0.9475\n",
      "Epoch 364/1000\n",
      "67/67 [==============================] - 27s 399ms/step - loss: 0.2015 - accuracy: 0.9459 - val_loss: 0.1986 - val_accuracy: 0.9475\n",
      "Epoch 365/1000\n",
      "67/67 [==============================] - 27s 411ms/step - loss: 0.2033 - accuracy: 0.9459 - val_loss: 0.1954 - val_accuracy: 0.9475\n",
      "Epoch 366/1000\n",
      "67/67 [==============================] - 27s 398ms/step - loss: 0.2018 - accuracy: 0.9459 - val_loss: 0.1951 - val_accuracy: 0.9475\n",
      "Epoch 367/1000\n",
      "67/67 [==============================] - 27s 411ms/step - loss: 0.2008 - accuracy: 0.9459 - val_loss: 0.1970 - val_accuracy: 0.9475\n",
      "Epoch 368/1000\n",
      "67/67 [==============================] - 27s 402ms/step - loss: 0.2027 - accuracy: 0.9459 - val_loss: 0.1981 - val_accuracy: 0.9475\n",
      "Epoch 369/1000\n",
      "67/67 [==============================] - 26s 385ms/step - loss: 0.2031 - accuracy: 0.9459 - val_loss: 0.1953 - val_accuracy: 0.9475\n",
      "Epoch 370/1000\n",
      "67/67 [==============================] - 28s 414ms/step - loss: 0.2022 - accuracy: 0.9459 - val_loss: 0.1999 - val_accuracy: 0.9475\n",
      "Epoch 371/1000\n",
      "67/67 [==============================] - 27s 396ms/step - loss: 0.2031 - accuracy: 0.9459 - val_loss: 0.1971 - val_accuracy: 0.9475\n",
      "Epoch 372/1000\n",
      "67/67 [==============================] - 27s 403ms/step - loss: 0.2033 - accuracy: 0.9459 - val_loss: 0.1970 - val_accuracy: 0.9475\n",
      "Epoch 373/1000\n",
      "67/67 [==============================] - 27s 403ms/step - loss: 0.2029 - accuracy: 0.9459 - val_loss: 0.1952 - val_accuracy: 0.9475\n",
      "Epoch 374/1000\n",
      "67/67 [==============================] - 26s 391ms/step - loss: 0.2030 - accuracy: 0.9459 - val_loss: 0.1956 - val_accuracy: 0.9475\n",
      "Epoch 375/1000\n",
      "67/67 [==============================] - 28s 412ms/step - loss: 0.2012 - accuracy: 0.9459 - val_loss: 0.1986 - val_accuracy: 0.9475\n",
      "Epoch 376/1000\n",
      "67/67 [==============================] - 26s 395ms/step - loss: 0.2038 - accuracy: 0.9459 - val_loss: 0.1964 - val_accuracy: 0.9475\n",
      "Epoch 377/1000\n",
      "67/67 [==============================] - 28s 423ms/step - loss: 0.2034 - accuracy: 0.9459 - val_loss: 0.1965 - val_accuracy: 0.9475\n",
      "Epoch 378/1000\n",
      "67/67 [==============================] - 28s 423ms/step - loss: 0.2020 - accuracy: 0.9459 - val_loss: 0.1977 - val_accuracy: 0.9475\n",
      "Epoch 379/1000\n",
      "67/67 [==============================] - 27s 400ms/step - loss: 0.2024 - accuracy: 0.9459 - val_loss: 0.1986 - val_accuracy: 0.9475\n",
      "Epoch 380/1000\n",
      "67/67 [==============================] - 27s 399ms/step - loss: 0.2024 - accuracy: 0.9459 - val_loss: 0.2020 - val_accuracy: 0.9475\n",
      "Epoch 381/1000\n",
      "67/67 [==============================] - 27s 399ms/step - loss: 0.2022 - accuracy: 0.9459 - val_loss: 0.1965 - val_accuracy: 0.9475\n",
      "Epoch 382/1000\n",
      "67/67 [==============================] - 27s 401ms/step - loss: 0.2024 - accuracy: 0.9459 - val_loss: 0.1968 - val_accuracy: 0.9475\n",
      "Epoch 383/1000\n",
      "67/67 [==============================] - 26s 390ms/step - loss: 0.2023 - accuracy: 0.9459 - val_loss: 0.1967 - val_accuracy: 0.9475\n",
      "Epoch 384/1000\n",
      "67/67 [==============================] - 27s 405ms/step - loss: 0.2016 - accuracy: 0.9459 - val_loss: 0.1953 - val_accuracy: 0.9475\n",
      "Epoch 385/1000\n",
      "67/67 [==============================] - 27s 400ms/step - loss: 0.2027 - accuracy: 0.9459 - val_loss: 0.1965 - val_accuracy: 0.9475\n",
      "Epoch 386/1000\n",
      "67/67 [==============================] - 27s 405ms/step - loss: 0.2021 - accuracy: 0.9459 - val_loss: 0.1987 - val_accuracy: 0.9475\n",
      "Epoch 387/1000\n",
      "67/67 [==============================] - 27s 403ms/step - loss: 0.2012 - accuracy: 0.9459 - val_loss: 0.1971 - val_accuracy: 0.9475\n",
      "Epoch 388/1000\n",
      "67/67 [==============================] - 26s 393ms/step - loss: 0.2024 - accuracy: 0.9459 - val_loss: 0.1960 - val_accuracy: 0.9475\n",
      "Epoch 389/1000\n",
      "67/67 [==============================] - 27s 410ms/step - loss: 0.2044 - accuracy: 0.9459 - val_loss: 0.2039 - val_accuracy: 0.9475\n",
      "Epoch 390/1000\n",
      "67/67 [==============================] - 26s 393ms/step - loss: 0.2043 - accuracy: 0.9459 - val_loss: 0.1981 - val_accuracy: 0.9475\n",
      "Epoch 391/1000\n",
      "67/67 [==============================] - 27s 404ms/step - loss: 0.2019 - accuracy: 0.9459 - val_loss: 0.1956 - val_accuracy: 0.9475\n",
      "Epoch 392/1000\n",
      "67/67 [==============================] - 27s 399ms/step - loss: 0.2026 - accuracy: 0.9459 - val_loss: 0.1976 - val_accuracy: 0.9475\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 393/1000\n",
      "67/67 [==============================] - 28s 417ms/step - loss: 0.2025 - accuracy: 0.9459 - val_loss: 0.1959 - val_accuracy: 0.9475\n",
      "Epoch 394/1000\n",
      "67/67 [==============================] - 28s 421ms/step - loss: 0.2032 - accuracy: 0.9459 - val_loss: 0.1975 - val_accuracy: 0.9475\n",
      "Epoch 395/1000\n",
      "67/67 [==============================] - 26s 393ms/step - loss: 0.2049 - accuracy: 0.9459 - val_loss: 0.1991 - val_accuracy: 0.9475\n",
      "Epoch 396/1000\n",
      "67/67 [==============================] - 27s 408ms/step - loss: 0.2030 - accuracy: 0.9459 - val_loss: 0.1982 - val_accuracy: 0.9475\n",
      "Epoch 397/1000\n",
      "67/67 [==============================] - 27s 399ms/step - loss: 0.2021 - accuracy: 0.9459 - val_loss: 0.1973 - val_accuracy: 0.9475\n",
      "Epoch 398/1000\n",
      "67/67 [==============================] - 26s 391ms/step - loss: 0.2019 - accuracy: 0.9459 - val_loss: 0.1974 - val_accuracy: 0.9475\n",
      "Epoch 399/1000\n",
      "67/67 [==============================] - 27s 408ms/step - loss: 0.2026 - accuracy: 0.9459 - val_loss: 0.1975 - val_accuracy: 0.9475\n",
      "Epoch 400/1000\n",
      "67/67 [==============================] - 26s 387ms/step - loss: 0.2014 - accuracy: 0.9459 - val_loss: 0.1953 - val_accuracy: 0.9475\n",
      "Epoch 401/1000\n",
      "67/67 [==============================] - 27s 409ms/step - loss: 0.2016 - accuracy: 0.9459 - val_loss: 0.1966 - val_accuracy: 0.9475\n",
      "Epoch 402/1000\n",
      "67/67 [==============================] - 27s 406ms/step - loss: 0.2039 - accuracy: 0.9459 - val_loss: 0.2000 - val_accuracy: 0.9475\n",
      "Epoch 403/1000\n",
      "67/67 [==============================] - 26s 394ms/step - loss: 0.2029 - accuracy: 0.9459 - val_loss: 0.1978 - val_accuracy: 0.9475\n",
      "Epoch 404/1000\n",
      "67/67 [==============================] - 27s 408ms/step - loss: 0.2020 - accuracy: 0.9459 - val_loss: 0.1961 - val_accuracy: 0.9475\n",
      "Epoch 405/1000\n",
      "67/67 [==============================] - 26s 390ms/step - loss: 0.2011 - accuracy: 0.9459 - val_loss: 0.1954 - val_accuracy: 0.9475\n",
      "Epoch 406/1000\n",
      "67/67 [==============================] - 28s 412ms/step - loss: 0.2009 - accuracy: 0.9459 - val_loss: 0.1965 - val_accuracy: 0.9475\n",
      "Epoch 407/1000\n",
      "67/67 [==============================] - 27s 397ms/step - loss: 0.2015 - accuracy: 0.9459 - val_loss: 0.1989 - val_accuracy: 0.9475\n",
      "Epoch 408/1000\n",
      "67/67 [==============================] - 27s 397ms/step - loss: 0.2004 - accuracy: 0.9459 - val_loss: 0.1953 - val_accuracy: 0.9475\n",
      "Epoch 409/1000\n",
      "67/67 [==============================] - 27s 406ms/step - loss: 0.2024 - accuracy: 0.9459 - val_loss: 0.1984 - val_accuracy: 0.9475\n",
      "Epoch 410/1000\n",
      "67/67 [==============================] - 27s 404ms/step - loss: 0.2026 - accuracy: 0.9459 - val_loss: 0.1960 - val_accuracy: 0.9475\n",
      "Epoch 411/1000\n",
      "67/67 [==============================] - 27s 400ms/step - loss: 0.2044 - accuracy: 0.9459 - val_loss: 0.1976 - val_accuracy: 0.9475\n",
      "Epoch 412/1000\n",
      "67/67 [==============================] - 27s 397ms/step - loss: 0.2027 - accuracy: 0.9459 - val_loss: 0.1970 - val_accuracy: 0.9475\n",
      "Epoch 413/1000\n",
      "67/67 [==============================] - 27s 398ms/step - loss: 0.2055 - accuracy: 0.9459 - val_loss: 0.1961 - val_accuracy: 0.9475\n",
      "Epoch 414/1000\n",
      "67/67 [==============================] - 27s 398ms/step - loss: 0.2032 - accuracy: 0.9459 - val_loss: 0.1962 - val_accuracy: 0.9475\n",
      "Epoch 415/1000\n",
      "67/67 [==============================] - 26s 383ms/step - loss: 0.2027 - accuracy: 0.9459 - val_loss: 0.1954 - val_accuracy: 0.9475\n",
      "Epoch 416/1000\n",
      "67/67 [==============================] - 28s 417ms/step - loss: 0.2032 - accuracy: 0.9459 - val_loss: 0.1961 - val_accuracy: 0.9475\n",
      "Epoch 417/1000\n",
      "67/67 [==============================] - 26s 391ms/step - loss: 0.2027 - accuracy: 0.9459 - val_loss: 0.1965 - val_accuracy: 0.9475\n",
      "Epoch 418/1000\n",
      "67/67 [==============================] - 27s 401ms/step - loss: 0.2039 - accuracy: 0.9459 - val_loss: 0.1958 - val_accuracy: 0.9475\n",
      "Epoch 419/1000\n",
      "67/67 [==============================] - 27s 400ms/step - loss: 0.2018 - accuracy: 0.9459 - val_loss: 0.1986 - val_accuracy: 0.9475\n",
      "Epoch 420/1000\n",
      "67/67 [==============================] - 26s 393ms/step - loss: 0.2031 - accuracy: 0.9459 - val_loss: 0.1952 - val_accuracy: 0.9475\n",
      "Epoch 421/1000\n",
      "67/67 [==============================] - 28s 419ms/step - loss: 0.2033 - accuracy: 0.9459 - val_loss: 0.1999 - val_accuracy: 0.9475\n",
      "Epoch 422/1000\n",
      "67/67 [==============================] - 26s 387ms/step - loss: 0.2030 - accuracy: 0.9459 - val_loss: 0.1947 - val_accuracy: 0.9475\n",
      "Epoch 423/1000\n",
      "67/67 [==============================] - 27s 402ms/step - loss: 0.2026 - accuracy: 0.9459 - val_loss: 0.1948 - val_accuracy: 0.9475\n",
      "Epoch 424/1000\n",
      "67/67 [==============================] - 27s 409ms/step - loss: 0.2034 - accuracy: 0.9459 - val_loss: 0.2015 - val_accuracy: 0.9475\n",
      "Epoch 425/1000\n",
      "67/67 [==============================] - 27s 399ms/step - loss: 0.2006 - accuracy: 0.9459 - val_loss: 0.1949 - val_accuracy: 0.9475\n",
      "Epoch 426/1000\n",
      "67/67 [==============================] - 28s 423ms/step - loss: 0.2016 - accuracy: 0.9459 - val_loss: 0.1961 - val_accuracy: 0.9475\n",
      "Epoch 427/1000\n",
      "67/67 [==============================] - 27s 397ms/step - loss: 0.2026 - accuracy: 0.9459 - val_loss: 0.1965 - val_accuracy: 0.9475\n",
      "Epoch 428/1000\n",
      "67/67 [==============================] - 27s 399ms/step - loss: 0.2028 - accuracy: 0.9459 - val_loss: 0.1989 - val_accuracy: 0.9475\n",
      "Epoch 429/1000\n",
      "67/67 [==============================] - 28s 412ms/step - loss: 0.2028 - accuracy: 0.9459 - val_loss: 0.1962 - val_accuracy: 0.9475\n",
      "Epoch 430/1000\n",
      "67/67 [==============================] - 26s 389ms/step - loss: 0.2030 - accuracy: 0.9459 - val_loss: 0.2048 - val_accuracy: 0.9475\n",
      "Epoch 431/1000\n",
      "67/67 [==============================] - 27s 409ms/step - loss: 0.2054 - accuracy: 0.9459 - val_loss: 0.2004 - val_accuracy: 0.9475\n",
      "Epoch 432/1000\n",
      "67/67 [==============================] - 28s 417ms/step - loss: 0.2038 - accuracy: 0.9459 - val_loss: 0.1946 - val_accuracy: 0.9475\n",
      "Epoch 433/1000\n",
      "67/67 [==============================] - 28s 412ms/step - loss: 0.2021 - accuracy: 0.9459 - val_loss: 0.1972 - val_accuracy: 0.9475\n",
      "Epoch 434/1000\n",
      "67/67 [==============================] - 28s 417ms/step - loss: 0.2028 - accuracy: 0.9459 - val_loss: 0.1968 - val_accuracy: 0.9475\n",
      "Epoch 435/1000\n",
      "67/67 [==============================] - 27s 406ms/step - loss: 0.2023 - accuracy: 0.9459 - val_loss: 0.1953 - val_accuracy: 0.9475\n",
      "Epoch 436/1000\n",
      "67/67 [==============================] - 27s 400ms/step - loss: 0.2031 - accuracy: 0.9459 - val_loss: 0.1975 - val_accuracy: 0.9475\n",
      "Epoch 437/1000\n",
      "67/67 [==============================] - 26s 389ms/step - loss: 0.2032 - accuracy: 0.9459 - val_loss: 0.1970 - val_accuracy: 0.9475\n",
      "Epoch 438/1000\n",
      "67/67 [==============================] - 28s 412ms/step - loss: 0.2068 - accuracy: 0.9459 - val_loss: 0.1999 - val_accuracy: 0.9475\n",
      "Epoch 439/1000\n",
      "67/67 [==============================] - 26s 396ms/step - loss: 0.2019 - accuracy: 0.9459 - val_loss: 0.1973 - val_accuracy: 0.9475\n",
      "Epoch 440/1000\n",
      "67/67 [==============================] - 27s 402ms/step - loss: 0.2013 - accuracy: 0.9459 - val_loss: 0.1958 - val_accuracy: 0.9475\n",
      "Epoch 441/1000\n",
      "67/67 [==============================] - 27s 397ms/step - loss: 0.2033 - accuracy: 0.9459 - val_loss: 0.1959 - val_accuracy: 0.9475\n",
      "Epoch 442/1000\n",
      "67/67 [==============================] - 27s 401ms/step - loss: 0.2045 - accuracy: 0.9459 - val_loss: 0.2004 - val_accuracy: 0.9475\n",
      "Epoch 443/1000\n",
      "67/67 [==============================] - 27s 409ms/step - loss: 0.2051 - accuracy: 0.9459 - val_loss: 0.1945 - val_accuracy: 0.9475\n",
      "Epoch 444/1000\n",
      "67/67 [==============================] - 27s 399ms/step - loss: 0.2018 - accuracy: 0.9459 - val_loss: 0.1939 - val_accuracy: 0.9475\n",
      "Epoch 445/1000\n",
      "67/67 [==============================] - 26s 386ms/step - loss: 0.2023 - accuracy: 0.9459 - val_loss: 0.1948 - val_accuracy: 0.9475\n",
      "Epoch 446/1000\n",
      "67/67 [==============================] - 27s 409ms/step - loss: 0.2014 - accuracy: 0.9459 - val_loss: 0.1958 - val_accuracy: 0.9475\n",
      "Epoch 447/1000\n",
      "67/67 [==============================] - 27s 397ms/step - loss: 0.2023 - accuracy: 0.9459 - val_loss: 0.1964 - val_accuracy: 0.9475\n",
      "Epoch 448/1000\n",
      "67/67 [==============================] - 27s 403ms/step - loss: 0.2028 - accuracy: 0.9459 - val_loss: 0.1945 - val_accuracy: 0.9475\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 449/1000\n",
      "67/67 [==============================] - 27s 407ms/step - loss: 0.2015 - accuracy: 0.9459 - val_loss: 0.1949 - val_accuracy: 0.9475\n",
      "Epoch 450/1000\n",
      "67/67 [==============================] - 26s 391ms/step - loss: 0.2032 - accuracy: 0.9459 - val_loss: 0.1959 - val_accuracy: 0.9475\n",
      "Epoch 451/1000\n",
      "67/67 [==============================] - 27s 408ms/step - loss: 0.2014 - accuracy: 0.9459 - val_loss: 0.1958 - val_accuracy: 0.9475\n",
      "Epoch 452/1000\n",
      "67/67 [==============================] - 26s 388ms/step - loss: 0.2031 - accuracy: 0.9459 - val_loss: 0.2044 - val_accuracy: 0.9475\n",
      "Epoch 453/1000\n",
      "67/67 [==============================] - 27s 404ms/step - loss: 0.2032 - accuracy: 0.9459 - val_loss: 0.1959 - val_accuracy: 0.9475\n",
      "Epoch 454/1000\n",
      "67/67 [==============================] - 26s 393ms/step - loss: 0.2052 - accuracy: 0.9459 - val_loss: 0.1973 - val_accuracy: 0.9475\n",
      "Epoch 455/1000\n",
      "67/67 [==============================] - 26s 389ms/step - loss: 0.2017 - accuracy: 0.9459 - val_loss: 0.1957 - val_accuracy: 0.9475\n",
      "Epoch 456/1000\n",
      "67/67 [==============================] - 27s 406ms/step - loss: 0.2026 - accuracy: 0.9459 - val_loss: 0.1961 - val_accuracy: 0.9475\n",
      "Epoch 457/1000\n",
      "67/67 [==============================] - 26s 389ms/step - loss: 0.2025 - accuracy: 0.9459 - val_loss: 0.1952 - val_accuracy: 0.9475\n",
      "Epoch 458/1000\n",
      "67/67 [==============================] - 27s 408ms/step - loss: 0.2028 - accuracy: 0.9459 - val_loss: 0.1956 - val_accuracy: 0.9475\n",
      "Epoch 459/1000\n",
      "67/67 [==============================] - 27s 403ms/step - loss: 0.2024 - accuracy: 0.9459 - val_loss: 0.1939 - val_accuracy: 0.9475\n",
      "Epoch 460/1000\n",
      "67/67 [==============================] - 27s 404ms/step - loss: 0.2008 - accuracy: 0.9459 - val_loss: 0.1963 - val_accuracy: 0.9475\n",
      "Epoch 461/1000\n",
      "67/67 [==============================] - 27s 409ms/step - loss: 0.2018 - accuracy: 0.9459 - val_loss: 0.1974 - val_accuracy: 0.9475\n",
      "Epoch 462/1000\n",
      "67/67 [==============================] - 26s 387ms/step - loss: 0.2025 - accuracy: 0.9459 - val_loss: 0.1963 - val_accuracy: 0.9475\n",
      "Epoch 463/1000\n",
      "67/67 [==============================] - 27s 406ms/step - loss: 0.2017 - accuracy: 0.9459 - val_loss: 0.1975 - val_accuracy: 0.9475\n",
      "Epoch 464/1000\n",
      "67/67 [==============================] - 27s 402ms/step - loss: 0.2030 - accuracy: 0.9459 - val_loss: 0.1980 - val_accuracy: 0.9475\n",
      "Epoch 465/1000\n",
      "67/67 [==============================] - 26s 391ms/step - loss: 0.2015 - accuracy: 0.9459 - val_loss: 0.1965 - val_accuracy: 0.9475\n",
      "Epoch 466/1000\n",
      "67/67 [==============================] - 27s 404ms/step - loss: 0.2029 - accuracy: 0.9459 - val_loss: 0.1949 - val_accuracy: 0.9475\n",
      "Epoch 467/1000\n",
      "67/67 [==============================] - 26s 386ms/step - loss: 0.2017 - accuracy: 0.9459 - val_loss: 0.1953 - val_accuracy: 0.9475\n",
      "Epoch 468/1000\n",
      "67/67 [==============================] - 28s 417ms/step - loss: 0.2033 - accuracy: 0.9459 - val_loss: 0.2006 - val_accuracy: 0.9475\n",
      "Epoch 469/1000\n",
      "67/67 [==============================] - 27s 401ms/step - loss: 0.2042 - accuracy: 0.9459 - val_loss: 0.1967 - val_accuracy: 0.9475\n",
      "Epoch 470/1000\n",
      "67/67 [==============================] - 29s 428ms/step - loss: 0.2022 - accuracy: 0.9459 - val_loss: 0.1947 - val_accuracy: 0.9475\n",
      "Epoch 471/1000\n",
      "67/67 [==============================] - 28s 420ms/step - loss: 0.2037 - accuracy: 0.9459 - val_loss: 0.1945 - val_accuracy: 0.9475\n",
      "Epoch 472/1000\n",
      "67/67 [==============================] - 28s 415ms/step - loss: 0.2021 - accuracy: 0.9459 - val_loss: 0.1943 - val_accuracy: 0.9475\n",
      "Epoch 473/1000\n",
      "67/67 [==============================] - 27s 399ms/step - loss: 0.2008 - accuracy: 0.9459 - val_loss: 0.1950 - val_accuracy: 0.9475\n",
      "Epoch 474/1000\n",
      "67/67 [==============================] - 27s 400ms/step - loss: 0.2028 - accuracy: 0.9459 - val_loss: 0.1942 - val_accuracy: 0.9475\n",
      "Epoch 475/1000\n",
      "67/67 [==============================] - 28s 426ms/step - loss: 0.2013 - accuracy: 0.9459 - val_loss: 0.1967 - val_accuracy: 0.9475\n",
      "Epoch 476/1000\n",
      "67/67 [==============================] - 27s 402ms/step - loss: 0.2008 - accuracy: 0.9459 - val_loss: 0.1998 - val_accuracy: 0.9475\n",
      "Epoch 477/1000\n",
      "67/67 [==============================] - 26s 383ms/step - loss: 0.2041 - accuracy: 0.9459 - val_loss: 0.1969 - val_accuracy: 0.9475\n",
      "Epoch 478/1000\n",
      "67/67 [==============================] - 23s 339ms/step - loss: 0.2029 - accuracy: 0.9459 - val_loss: 0.2002 - val_accuracy: 0.9475\n",
      "Epoch 479/1000\n",
      "67/67 [==============================] - 21s 318ms/step - loss: 0.2052 - accuracy: 0.9459 - val_loss: 0.1975 - val_accuracy: 0.9475\n",
      "Epoch 480/1000\n",
      "67/67 [==============================] - 25s 381ms/step - loss: 0.2018 - accuracy: 0.9459 - val_loss: 0.1949 - val_accuracy: 0.9475\n",
      "Epoch 481/1000\n",
      "67/67 [==============================] - 27s 398ms/step - loss: 0.2025 - accuracy: 0.9459 - val_loss: 0.1944 - val_accuracy: 0.9475\n",
      "Epoch 482/1000\n",
      "67/67 [==============================] - 26s 395ms/step - loss: 0.2013 - accuracy: 0.9459 - val_loss: 0.1955 - val_accuracy: 0.9475\n",
      "Epoch 483/1000\n",
      "67/67 [==============================] - 27s 404ms/step - loss: 0.2027 - accuracy: 0.9459 - val_loss: 0.1946 - val_accuracy: 0.9475\n",
      "Epoch 484/1000\n",
      "67/67 [==============================] - 26s 393ms/step - loss: 0.2005 - accuracy: 0.9459 - val_loss: 0.1939 - val_accuracy: 0.9475\n",
      "Epoch 485/1000\n",
      "67/67 [==============================] - 28s 419ms/step - loss: 0.2002 - accuracy: 0.9459 - val_loss: 0.1949 - val_accuracy: 0.9475\n",
      "Epoch 486/1000\n",
      "67/67 [==============================] - 26s 390ms/step - loss: 0.2039 - accuracy: 0.9459 - val_loss: 0.1941 - val_accuracy: 0.9475\n",
      "Epoch 487/1000\n",
      "67/67 [==============================] - 27s 406ms/step - loss: 0.2034 - accuracy: 0.9459 - val_loss: 0.1949 - val_accuracy: 0.9475\n",
      "Epoch 488/1000\n",
      "67/67 [==============================] - 27s 405ms/step - loss: 0.2012 - accuracy: 0.9459 - val_loss: 0.2024 - val_accuracy: 0.9475\n",
      "Epoch 489/1000\n",
      "67/67 [==============================] - 26s 395ms/step - loss: 0.2021 - accuracy: 0.9459 - val_loss: 0.1944 - val_accuracy: 0.9475\n",
      "Epoch 490/1000\n",
      "67/67 [==============================] - 28s 416ms/step - loss: 0.2022 - accuracy: 0.9459 - val_loss: 0.1950 - val_accuracy: 0.9475\n",
      "Epoch 491/1000\n",
      "67/67 [==============================] - 26s 396ms/step - loss: 0.2016 - accuracy: 0.9459 - val_loss: 0.1959 - val_accuracy: 0.9475\n",
      "Epoch 492/1000\n",
      "67/67 [==============================] - 28s 413ms/step - loss: 0.2020 - accuracy: 0.9459 - val_loss: 0.1950 - val_accuracy: 0.9475\n",
      "Epoch 493/1000\n",
      "67/67 [==============================] - 28s 423ms/step - loss: 0.2017 - accuracy: 0.9459 - val_loss: 0.1954 - val_accuracy: 0.9475\n",
      "Epoch 494/1000\n",
      "67/67 [==============================] - 27s 396ms/step - loss: 0.2011 - accuracy: 0.9459 - val_loss: 0.1941 - val_accuracy: 0.9475\n",
      "Epoch 495/1000\n",
      "67/67 [==============================] - 28s 419ms/step - loss: 0.2022 - accuracy: 0.9459 - val_loss: 0.1950 - val_accuracy: 0.9475\n",
      "Epoch 496/1000\n",
      "67/67 [==============================] - 26s 394ms/step - loss: 0.2014 - accuracy: 0.9459 - val_loss: 0.1946 - val_accuracy: 0.9475\n",
      "Epoch 497/1000\n",
      "67/67 [==============================] - 28s 415ms/step - loss: 0.2037 - accuracy: 0.9459 - val_loss: 0.1967 - val_accuracy: 0.9475\n",
      "Epoch 498/1000\n",
      "67/67 [==============================] - 30s 446ms/step - loss: 0.2028 - accuracy: 0.9459 - val_loss: 0.1953 - val_accuracy: 0.9475\n",
      "Epoch 499/1000\n",
      "67/67 [==============================] - 27s 400ms/step - loss: 0.2002 - accuracy: 0.9459 - val_loss: 0.1957 - val_accuracy: 0.9475\n",
      "Epoch 500/1000\n",
      "67/67 [==============================] - 27s 404ms/step - loss: 0.2021 - accuracy: 0.9459 - val_loss: 0.1988 - val_accuracy: 0.9475\n",
      "Epoch 501/1000\n",
      "67/67 [==============================] - 27s 406ms/step - loss: 0.2017 - accuracy: 0.9459 - val_loss: 0.1943 - val_accuracy: 0.9475\n",
      "Epoch 502/1000\n",
      "67/67 [==============================] - 27s 407ms/step - loss: 0.2002 - accuracy: 0.9459 - val_loss: 0.1957 - val_accuracy: 0.9475\n",
      "Epoch 503/1000\n",
      "67/67 [==============================] - 27s 398ms/step - loss: 0.2025 - accuracy: 0.9459 - val_loss: 0.1949 - val_accuracy: 0.9475\n",
      "Epoch 504/1000\n",
      "67/67 [==============================] - 27s 401ms/step - loss: 0.2027 - accuracy: 0.9459 - val_loss: 0.1942 - val_accuracy: 0.9475\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 505/1000\n",
      "67/67 [==============================] - 27s 404ms/step - loss: 0.2020 - accuracy: 0.9459 - val_loss: 0.1942 - val_accuracy: 0.9475\n",
      "Epoch 506/1000\n",
      "67/67 [==============================] - 27s 411ms/step - loss: 0.2039 - accuracy: 0.9459 - val_loss: 0.1943 - val_accuracy: 0.9475\n",
      "Epoch 507/1000\n",
      "67/67 [==============================] - 27s 408ms/step - loss: 0.2019 - accuracy: 0.9459 - val_loss: 0.1958 - val_accuracy: 0.9475\n",
      "Epoch 508/1000\n",
      "67/67 [==============================] - 29s 437ms/step - loss: 0.2009 - accuracy: 0.9459 - val_loss: 0.1956 - val_accuracy: 0.9475\n",
      "Epoch 509/1000\n",
      "67/67 [==============================] - 26s 395ms/step - loss: 0.2003 - accuracy: 0.9459 - val_loss: 0.1941 - val_accuracy: 0.9475\n",
      "Epoch 510/1000\n",
      "67/67 [==============================] - 28s 412ms/step - loss: 0.2006 - accuracy: 0.9459 - val_loss: 0.1970 - val_accuracy: 0.9475\n",
      "Epoch 511/1000\n",
      "67/67 [==============================] - 27s 406ms/step - loss: 0.2037 - accuracy: 0.9459 - val_loss: 0.1954 - val_accuracy: 0.9475\n",
      "Epoch 512/1000\n",
      "67/67 [==============================] - 27s 404ms/step - loss: 0.2007 - accuracy: 0.9459 - val_loss: 0.1938 - val_accuracy: 0.9475\n",
      "Epoch 513/1000\n",
      "67/67 [==============================] - 28s 414ms/step - loss: 0.2015 - accuracy: 0.9459 - val_loss: 0.1948 - val_accuracy: 0.9475\n",
      "Epoch 514/1000\n",
      "67/67 [==============================] - 27s 397ms/step - loss: 0.2011 - accuracy: 0.9459 - val_loss: 0.1943 - val_accuracy: 0.9475\n",
      "Epoch 515/1000\n",
      "67/67 [==============================] - 28s 416ms/step - loss: 0.2020 - accuracy: 0.9459 - val_loss: 0.1946 - val_accuracy: 0.9475\n",
      "Epoch 516/1000\n",
      "67/67 [==============================] - 27s 397ms/step - loss: 0.2010 - accuracy: 0.9459 - val_loss: 0.1939 - val_accuracy: 0.9475\n",
      "Epoch 517/1000\n",
      "67/67 [==============================] - 28s 412ms/step - loss: 0.2008 - accuracy: 0.9459 - val_loss: 0.1962 - val_accuracy: 0.9475\n",
      "Epoch 518/1000\n",
      "67/67 [==============================] - 27s 406ms/step - loss: 0.2029 - accuracy: 0.9459 - val_loss: 0.1945 - val_accuracy: 0.9475\n",
      "Epoch 519/1000\n",
      "67/67 [==============================] - 27s 399ms/step - loss: 0.2010 - accuracy: 0.9459 - val_loss: 0.1942 - val_accuracy: 0.9475\n",
      "Epoch 520/1000\n",
      "67/67 [==============================] - 28s 414ms/step - loss: 0.2038 - accuracy: 0.9459 - val_loss: 0.2011 - val_accuracy: 0.9475\n",
      "Epoch 521/1000\n",
      "67/67 [==============================] - 26s 393ms/step - loss: 0.2007 - accuracy: 0.9459 - val_loss: 0.1939 - val_accuracy: 0.9475\n",
      "Epoch 522/1000\n",
      "67/67 [==============================] - 28s 423ms/step - loss: 0.2001 - accuracy: 0.9459 - val_loss: 0.1938 - val_accuracy: 0.9475\n",
      "Epoch 523/1000\n",
      "67/67 [==============================] - 27s 411ms/step - loss: 0.2007 - accuracy: 0.9459 - val_loss: 0.1946 - val_accuracy: 0.9475\n",
      "Epoch 524/1000\n",
      "67/67 [==============================] - 28s 413ms/step - loss: 0.2021 - accuracy: 0.9459 - val_loss: 0.1940 - val_accuracy: 0.9475\n",
      "Epoch 525/1000\n",
      "67/67 [==============================] - 27s 410ms/step - loss: 0.2010 - accuracy: 0.9459 - val_loss: 0.1937 - val_accuracy: 0.9475\n",
      "Epoch 526/1000\n",
      "67/67 [==============================] - 26s 394ms/step - loss: 0.2018 - accuracy: 0.9459 - val_loss: 0.1937 - val_accuracy: 0.9475\n",
      "Epoch 527/1000\n",
      "67/67 [==============================] - 28s 424ms/step - loss: 0.2018 - accuracy: 0.9459 - val_loss: 0.1954 - val_accuracy: 0.9475\n",
      "Epoch 528/1000\n",
      "67/67 [==============================] - 28s 421ms/step - loss: 0.2002 - accuracy: 0.9459 - val_loss: 0.1957 - val_accuracy: 0.9475\n",
      "Epoch 529/1000\n",
      "67/67 [==============================] - 27s 408ms/step - loss: 0.2032 - accuracy: 0.9459 - val_loss: 0.1943 - val_accuracy: 0.9475\n",
      "Epoch 530/1000\n",
      "67/67 [==============================] - 27s 406ms/step - loss: 0.2028 - accuracy: 0.9459 - val_loss: 0.1992 - val_accuracy: 0.9475\n",
      "Epoch 531/1000\n",
      "67/67 [==============================] - 27s 406ms/step - loss: 0.2016 - accuracy: 0.9459 - val_loss: 0.1958 - val_accuracy: 0.9475\n",
      "Epoch 532/1000\n",
      "67/67 [==============================] - 26s 394ms/step - loss: 0.2013 - accuracy: 0.9459 - val_loss: 0.2062 - val_accuracy: 0.9475\n",
      "Epoch 533/1000\n",
      "67/67 [==============================] - 28s 420ms/step - loss: 0.2029 - accuracy: 0.9459 - val_loss: 0.1941 - val_accuracy: 0.9475\n",
      "Epoch 534/1000\n",
      "67/67 [==============================] - 28s 413ms/step - loss: 0.2017 - accuracy: 0.9459 - val_loss: 0.1944 - val_accuracy: 0.9475\n",
      "Epoch 535/1000\n",
      "67/67 [==============================] - 27s 404ms/step - loss: 0.2018 - accuracy: 0.9459 - val_loss: 0.1948 - val_accuracy: 0.9475\n",
      "Epoch 536/1000\n",
      "67/67 [==============================] - 28s 426ms/step - loss: 0.2011 - accuracy: 0.9459 - val_loss: 0.1980 - val_accuracy: 0.9475\n",
      "Epoch 537/1000\n",
      "67/67 [==============================] - 27s 403ms/step - loss: 0.2019 - accuracy: 0.9459 - val_loss: 0.1943 - val_accuracy: 0.9475\n",
      "Epoch 538/1000\n",
      "67/67 [==============================] - 28s 419ms/step - loss: 0.2009 - accuracy: 0.9459 - val_loss: 0.1952 - val_accuracy: 0.9475\n",
      "Epoch 539/1000\n",
      "67/67 [==============================] - 28s 422ms/step - loss: 0.2019 - accuracy: 0.9459 - val_loss: 0.1966 - val_accuracy: 0.9475\n",
      "Epoch 540/1000\n",
      "67/67 [==============================] - 28s 420ms/step - loss: 0.2017 - accuracy: 0.9459 - val_loss: 0.1980 - val_accuracy: 0.9475\n",
      "Epoch 541/1000\n",
      "67/67 [==============================] - 28s 422ms/step - loss: 0.2030 - accuracy: 0.9459 - val_loss: 0.1973 - val_accuracy: 0.9475\n",
      "Epoch 542/1000\n",
      "67/67 [==============================] - 26s 394ms/step - loss: 0.2008 - accuracy: 0.9459 - val_loss: 0.1958 - val_accuracy: 0.9475\n",
      "Epoch 543/1000\n",
      "67/67 [==============================] - 28s 421ms/step - loss: 0.2013 - accuracy: 0.9459 - val_loss: 0.1964 - val_accuracy: 0.9475\n",
      "Epoch 544/1000\n",
      "67/67 [==============================] - 27s 402ms/step - loss: 0.2023 - accuracy: 0.9459 - val_loss: 0.2076 - val_accuracy: 0.9475\n",
      "Epoch 545/1000\n",
      "67/67 [==============================] - 28s 416ms/step - loss: 0.2034 - accuracy: 0.9459 - val_loss: 0.1958 - val_accuracy: 0.9475\n",
      "Epoch 546/1000\n",
      "67/67 [==============================] - 27s 408ms/step - loss: 0.2019 - accuracy: 0.9459 - val_loss: 0.1942 - val_accuracy: 0.9475\n",
      "Epoch 547/1000\n",
      "67/67 [==============================] - 27s 404ms/step - loss: 0.1999 - accuracy: 0.9459 - val_loss: 0.1935 - val_accuracy: 0.9475\n",
      "Epoch 548/1000\n",
      "67/67 [==============================] - 28s 413ms/step - loss: 0.2012 - accuracy: 0.9459 - val_loss: 0.2019 - val_accuracy: 0.9475\n",
      "Epoch 549/1000\n",
      "67/67 [==============================] - 27s 401ms/step - loss: 0.2008 - accuracy: 0.9459 - val_loss: 0.1935 - val_accuracy: 0.9475\n",
      "Epoch 550/1000\n",
      "67/67 [==============================] - 28s 413ms/step - loss: 0.2007 - accuracy: 0.9459 - val_loss: 0.1946 - val_accuracy: 0.9475\n",
      "Epoch 551/1000\n",
      "67/67 [==============================] - 27s 398ms/step - loss: 0.2017 - accuracy: 0.9459 - val_loss: 0.1954 - val_accuracy: 0.9475\n",
      "Epoch 552/1000\n",
      "67/67 [==============================] - 28s 419ms/step - loss: 0.2006 - accuracy: 0.9459 - val_loss: 0.1947 - val_accuracy: 0.9475\n",
      "Epoch 553/1000\n",
      "67/67 [==============================] - 27s 398ms/step - loss: 0.2014 - accuracy: 0.9459 - val_loss: 0.1946 - val_accuracy: 0.9475\n",
      "Epoch 554/1000\n",
      "67/67 [==============================] - 28s 412ms/step - loss: 0.2013 - accuracy: 0.9459 - val_loss: 0.1949 - val_accuracy: 0.9475\n",
      "Epoch 555/1000\n",
      "67/67 [==============================] - 27s 409ms/step - loss: 0.2013 - accuracy: 0.9459 - val_loss: 0.1938 - val_accuracy: 0.9475\n",
      "Epoch 556/1000\n",
      "67/67 [==============================] - 28s 413ms/step - loss: 0.2014 - accuracy: 0.9459 - val_loss: 0.1965 - val_accuracy: 0.9475\n",
      "Epoch 557/1000\n",
      "67/67 [==============================] - 28s 426ms/step - loss: 0.2033 - accuracy: 0.9459 - val_loss: 0.1952 - val_accuracy: 0.9475\n",
      "Epoch 558/1000\n",
      "67/67 [==============================] - 27s 401ms/step - loss: 0.2012 - accuracy: 0.9459 - val_loss: 0.1942 - val_accuracy: 0.9475\n",
      "Epoch 559/1000\n",
      "67/67 [==============================] - 26s 390ms/step - loss: 0.2005 - accuracy: 0.9459 - val_loss: 0.1943 - val_accuracy: 0.9475\n",
      "Epoch 560/1000\n",
      "67/67 [==============================] - 27s 406ms/step - loss: 0.2030 - accuracy: 0.9459 - val_loss: 0.1953 - val_accuracy: 0.9475\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 561/1000\n",
      "67/67 [==============================] - 27s 407ms/step - loss: 0.2014 - accuracy: 0.9459 - val_loss: 0.1992 - val_accuracy: 0.9475\n",
      "Epoch 562/1000\n",
      "67/67 [==============================] - 26s 389ms/step - loss: 0.2015 - accuracy: 0.9459 - val_loss: 0.1946 - val_accuracy: 0.9475\n",
      "Epoch 563/1000\n",
      "67/67 [==============================] - 27s 408ms/step - loss: 0.2020 - accuracy: 0.9459 - val_loss: 0.1990 - val_accuracy: 0.9475\n",
      "Epoch 564/1000\n",
      "67/67 [==============================] - 26s 390ms/step - loss: 0.2018 - accuracy: 0.9459 - val_loss: 0.1934 - val_accuracy: 0.9475\n",
      "Epoch 565/1000\n",
      "67/67 [==============================] - 26s 395ms/step - loss: 0.2014 - accuracy: 0.9459 - val_loss: 0.1964 - val_accuracy: 0.9475\n",
      "Epoch 566/1000\n",
      "67/67 [==============================] - 27s 399ms/step - loss: 0.2014 - accuracy: 0.9459 - val_loss: 0.1939 - val_accuracy: 0.9475\n",
      "Epoch 567/1000\n",
      "67/67 [==============================] - 26s 390ms/step - loss: 0.2004 - accuracy: 0.9459 - val_loss: 0.1956 - val_accuracy: 0.9475\n",
      "Epoch 568/1000\n",
      "67/67 [==============================] - 27s 406ms/step - loss: 0.2006 - accuracy: 0.9459 - val_loss: 0.1951 - val_accuracy: 0.9475\n",
      "Epoch 569/1000\n",
      "67/67 [==============================] - 26s 392ms/step - loss: 0.2021 - accuracy: 0.9459 - val_loss: 0.1935 - val_accuracy: 0.9475\n",
      "Epoch 570/1000\n",
      "67/67 [==============================] - 27s 404ms/step - loss: 0.2046 - accuracy: 0.9459 - val_loss: 0.1982 - val_accuracy: 0.9475\n",
      "Epoch 571/1000\n",
      "67/67 [==============================] - 26s 394ms/step - loss: 0.2032 - accuracy: 0.9459 - val_loss: 0.1945 - val_accuracy: 0.9475\n",
      "Epoch 572/1000\n",
      "67/67 [==============================] - 27s 397ms/step - loss: 0.2008 - accuracy: 0.9459 - val_loss: 0.1948 - val_accuracy: 0.9475\n",
      "Epoch 573/1000\n",
      "67/67 [==============================] - 28s 424ms/step - loss: 0.2012 - accuracy: 0.9459 - val_loss: 0.1984 - val_accuracy: 0.9475\n",
      "Epoch 574/1000\n",
      "67/67 [==============================] - 27s 403ms/step - loss: 0.1993 - accuracy: 0.9459 - val_loss: 0.1944 - val_accuracy: 0.9475\n",
      "Epoch 575/1000\n",
      "67/67 [==============================] - 27s 405ms/step - loss: 0.2004 - accuracy: 0.9459 - val_loss: 0.1934 - val_accuracy: 0.9475\n",
      "Epoch 576/1000\n",
      "67/67 [==============================] - 27s 401ms/step - loss: 0.2012 - accuracy: 0.9459 - val_loss: 0.1940 - val_accuracy: 0.9475\n",
      "Epoch 577/1000\n",
      "67/67 [==============================] - 26s 392ms/step - loss: 0.2011 - accuracy: 0.9459 - val_loss: 0.2053 - val_accuracy: 0.9475\n",
      "Epoch 578/1000\n",
      "67/67 [==============================] - 27s 408ms/step - loss: 0.2062 - accuracy: 0.9459 - val_loss: 0.1937 - val_accuracy: 0.9475\n",
      "Epoch 579/1000\n",
      "67/67 [==============================] - 26s 388ms/step - loss: 0.2005 - accuracy: 0.9459 - val_loss: 0.1950 - val_accuracy: 0.9475\n",
      "Epoch 580/1000\n",
      "67/67 [==============================] - 27s 408ms/step - loss: 0.1999 - accuracy: 0.9459 - val_loss: 0.1937 - val_accuracy: 0.9475\n",
      "Epoch 581/1000\n",
      "67/67 [==============================] - 27s 400ms/step - loss: 0.2008 - accuracy: 0.9459 - val_loss: 0.1986 - val_accuracy: 0.9475\n",
      "Epoch 582/1000\n",
      "67/67 [==============================] - 26s 395ms/step - loss: 0.2014 - accuracy: 0.9459 - val_loss: 0.1947 - val_accuracy: 0.9475\n",
      "Epoch 583/1000\n",
      "67/67 [==============================] - 27s 400ms/step - loss: 0.2019 - accuracy: 0.9459 - val_loss: 0.1941 - val_accuracy: 0.9475\n",
      "Epoch 584/1000\n",
      "67/67 [==============================] - 27s 399ms/step - loss: 0.2034 - accuracy: 0.9459 - val_loss: 0.1996 - val_accuracy: 0.9475\n",
      "Epoch 585/1000\n",
      "67/67 [==============================] - 27s 399ms/step - loss: 0.2026 - accuracy: 0.9459 - val_loss: 0.1970 - val_accuracy: 0.9475\n",
      "Epoch 586/1000\n",
      "67/67 [==============================] - 26s 395ms/step - loss: 0.2022 - accuracy: 0.9459 - val_loss: 0.1941 - val_accuracy: 0.9475\n",
      "Epoch 587/1000\n",
      "67/67 [==============================] - 26s 384ms/step - loss: 0.2013 - accuracy: 0.9459 - val_loss: 0.1948 - val_accuracy: 0.9475\n",
      "Epoch 588/1000\n",
      "67/67 [==============================] - 28s 413ms/step - loss: 0.2023 - accuracy: 0.9459 - val_loss: 0.1953 - val_accuracy: 0.9475\n",
      "Epoch 589/1000\n",
      "67/67 [==============================] - 27s 403ms/step - loss: 0.2020 - accuracy: 0.9459 - val_loss: 0.1945 - val_accuracy: 0.9475\n",
      "Epoch 590/1000\n",
      "67/67 [==============================] - 27s 406ms/step - loss: 0.2010 - accuracy: 0.9459 - val_loss: 0.1939 - val_accuracy: 0.9475\n",
      "Epoch 591/1000\n",
      "67/67 [==============================] - 27s 400ms/step - loss: 0.2011 - accuracy: 0.9459 - val_loss: 0.1950 - val_accuracy: 0.9475\n",
      "Epoch 592/1000\n",
      "67/67 [==============================] - 27s 408ms/step - loss: 0.2041 - accuracy: 0.9459 - val_loss: 0.2027 - val_accuracy: 0.9475\n",
      "Epoch 593/1000\n",
      "67/67 [==============================] - 29s 432ms/step - loss: 0.2022 - accuracy: 0.9459 - val_loss: 0.1934 - val_accuracy: 0.9475\n",
      "Epoch 594/1000\n",
      "67/67 [==============================] - 28s 414ms/step - loss: 0.2039 - accuracy: 0.9459 - val_loss: 0.1942 - val_accuracy: 0.9475\n",
      "Epoch 595/1000\n",
      "67/67 [==============================] - 28s 426ms/step - loss: 0.2030 - accuracy: 0.9459 - val_loss: 0.1938 - val_accuracy: 0.9475\n",
      "Epoch 596/1000\n",
      "67/67 [==============================] - 27s 400ms/step - loss: 0.2026 - accuracy: 0.9459 - val_loss: 0.2000 - val_accuracy: 0.9475\n",
      "Epoch 597/1000\n",
      "67/67 [==============================] - 26s 387ms/step - loss: 0.2027 - accuracy: 0.9459 - val_loss: 0.1939 - val_accuracy: 0.9475\n",
      "Epoch 598/1000\n",
      "67/67 [==============================] - 27s 408ms/step - loss: 0.2005 - accuracy: 0.9459 - val_loss: 0.1934 - val_accuracy: 0.9475\n",
      "Epoch 599/1000\n",
      "67/67 [==============================] - 24s 353ms/step - loss: 0.2013 - accuracy: 0.9459 - val_loss: 0.1950 - val_accuracy: 0.9475\n",
      "Epoch 600/1000\n",
      "67/67 [==============================] - 23s 338ms/step - loss: 0.2009 - accuracy: 0.9459 - val_loss: 0.1934 - val_accuracy: 0.9475\n",
      "Epoch 601/1000\n",
      "67/67 [==============================] - 24s 352ms/step - loss: 0.2010 - accuracy: 0.9459 - val_loss: 0.1968 - val_accuracy: 0.9475\n",
      "Epoch 602/1000\n",
      "67/67 [==============================] - 21s 317ms/step - loss: 0.2019 - accuracy: 0.9459 - val_loss: 0.1953 - val_accuracy: 0.9475\n",
      "Epoch 603/1000\n",
      "67/67 [==============================] - 27s 412ms/step - loss: 0.2006 - accuracy: 0.9459 - val_loss: 0.1968 - val_accuracy: 0.9475\n",
      "Epoch 604/1000\n",
      "67/67 [==============================] - 26s 392ms/step - loss: 0.2016 - accuracy: 0.9459 - val_loss: 0.1952 - val_accuracy: 0.9475\n",
      "Epoch 605/1000\n",
      "67/67 [==============================] - 27s 411ms/step - loss: 0.2007 - accuracy: 0.9459 - val_loss: 0.1936 - val_accuracy: 0.9475\n",
      "Epoch 606/1000\n",
      "67/67 [==============================] - 28s 416ms/step - loss: 0.2005 - accuracy: 0.9459 - val_loss: 0.1935 - val_accuracy: 0.9475\n",
      "Epoch 607/1000\n",
      "67/67 [==============================] - 27s 397ms/step - loss: 0.2015 - accuracy: 0.9459 - val_loss: 0.1941 - val_accuracy: 0.9475\n",
      "Epoch 608/1000\n",
      "67/67 [==============================] - 28s 411ms/step - loss: 0.2020 - accuracy: 0.9459 - val_loss: 0.1971 - val_accuracy: 0.9475\n",
      "Epoch 609/1000\n",
      "67/67 [==============================] - 26s 387ms/step - loss: 0.1999 - accuracy: 0.9459 - val_loss: 0.1953 - val_accuracy: 0.9475\n",
      "Epoch 610/1000\n",
      "67/67 [==============================] - 27s 407ms/step - loss: 0.2032 - accuracy: 0.9459 - val_loss: 0.1942 - val_accuracy: 0.9475\n",
      "Epoch 611/1000\n",
      "67/67 [==============================] - 27s 399ms/step - loss: 0.2022 - accuracy: 0.9459 - val_loss: 0.1951 - val_accuracy: 0.9475\n",
      "Epoch 612/1000\n",
      "67/67 [==============================] - 27s 399ms/step - loss: 0.2016 - accuracy: 0.9459 - val_loss: 0.1932 - val_accuracy: 0.9475\n",
      "Epoch 613/1000\n",
      "67/67 [==============================] - 27s 398ms/step - loss: 0.2009 - accuracy: 0.9459 - val_loss: 0.1938 - val_accuracy: 0.9475\n",
      "Epoch 614/1000\n",
      "67/67 [==============================] - 25s 378ms/step - loss: 0.2013 - accuracy: 0.9459 - val_loss: 0.1939 - val_accuracy: 0.9475\n",
      "Epoch 615/1000\n",
      "67/67 [==============================] - 27s 403ms/step - loss: 0.2019 - accuracy: 0.9459 - val_loss: 0.1933 - val_accuracy: 0.9475\n",
      "Epoch 616/1000\n",
      "67/67 [==============================] - 27s 406ms/step - loss: 0.2013 - accuracy: 0.9459 - val_loss: 0.1933 - val_accuracy: 0.9475\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 617/1000\n",
      "67/67 [==============================] - 26s 387ms/step - loss: 0.2026 - accuracy: 0.9459 - val_loss: 0.1987 - val_accuracy: 0.9475\n",
      "Epoch 618/1000\n",
      "67/67 [==============================] - 27s 406ms/step - loss: 0.2015 - accuracy: 0.9459 - val_loss: 0.1952 - val_accuracy: 0.9475\n",
      "Epoch 619/1000\n",
      "67/67 [==============================] - 26s 391ms/step - loss: 0.2013 - accuracy: 0.9459 - val_loss: 0.2004 - val_accuracy: 0.9475\n",
      "Epoch 620/1000\n",
      "67/67 [==============================] - 27s 409ms/step - loss: 0.2006 - accuracy: 0.9459 - val_loss: 0.1931 - val_accuracy: 0.9475\n",
      "Epoch 621/1000\n",
      "67/67 [==============================] - 27s 400ms/step - loss: 0.2016 - accuracy: 0.9459 - val_loss: 0.1941 - val_accuracy: 0.9475\n",
      "Epoch 622/1000\n",
      "67/67 [==============================] - 26s 394ms/step - loss: 0.2006 - accuracy: 0.9459 - val_loss: 0.1938 - val_accuracy: 0.9475\n",
      "Epoch 623/1000\n",
      "67/67 [==============================] - 27s 402ms/step - loss: 0.2009 - accuracy: 0.9459 - val_loss: 0.1997 - val_accuracy: 0.9475\n",
      "Epoch 624/1000\n",
      "67/67 [==============================] - 26s 391ms/step - loss: 0.2010 - accuracy: 0.9459 - val_loss: 0.1940 - val_accuracy: 0.9475\n",
      "Epoch 625/1000\n",
      "67/67 [==============================] - 27s 403ms/step - loss: 0.2024 - accuracy: 0.9459 - val_loss: 0.1962 - val_accuracy: 0.9475\n",
      "Epoch 626/1000\n",
      "67/67 [==============================] - 26s 386ms/step - loss: 0.2008 - accuracy: 0.9459 - val_loss: 0.1944 - val_accuracy: 0.9475\n",
      "Epoch 627/1000\n",
      "67/67 [==============================] - 27s 409ms/step - loss: 0.1991 - accuracy: 0.9459 - val_loss: 0.1932 - val_accuracy: 0.9475\n",
      "Epoch 628/1000\n",
      "67/67 [==============================] - 29s 432ms/step - loss: 0.2002 - accuracy: 0.9459 - val_loss: 0.1953 - val_accuracy: 0.9475\n",
      "Epoch 629/1000\n",
      "67/67 [==============================] - 26s 390ms/step - loss: 0.2001 - accuracy: 0.9459 - val_loss: 0.1970 - val_accuracy: 0.9475\n",
      "Epoch 630/1000\n",
      "67/67 [==============================] - 28s 413ms/step - loss: 0.2005 - accuracy: 0.9459 - val_loss: 0.1934 - val_accuracy: 0.9475\n",
      "Epoch 631/1000\n",
      "67/67 [==============================] - 27s 397ms/step - loss: 0.2006 - accuracy: 0.9459 - val_loss: 0.1930 - val_accuracy: 0.9475\n",
      "Epoch 632/1000\n",
      "67/67 [==============================] - 27s 405ms/step - loss: 0.2019 - accuracy: 0.9459 - val_loss: 0.1946 - val_accuracy: 0.9475\n",
      "Epoch 633/1000\n",
      "67/67 [==============================] - 28s 414ms/step - loss: 0.2000 - accuracy: 0.9459 - val_loss: 0.1952 - val_accuracy: 0.9475\n",
      "Epoch 634/1000\n",
      "67/67 [==============================] - 27s 406ms/step - loss: 0.2013 - accuracy: 0.9459 - val_loss: 0.1945 - val_accuracy: 0.9475\n",
      "Epoch 635/1000\n",
      "67/67 [==============================] - 28s 412ms/step - loss: 0.2015 - accuracy: 0.9459 - val_loss: 0.1940 - val_accuracy: 0.9475\n",
      "Epoch 636/1000\n",
      "67/67 [==============================] - 26s 391ms/step - loss: 0.2008 - accuracy: 0.9459 - val_loss: 0.1936 - val_accuracy: 0.9475\n",
      "Epoch 637/1000\n",
      "67/67 [==============================] - 27s 401ms/step - loss: 0.2007 - accuracy: 0.9459 - val_loss: 0.1965 - val_accuracy: 0.9475\n",
      "Epoch 638/1000\n",
      "67/67 [==============================] - 27s 406ms/step - loss: 0.2005 - accuracy: 0.9459 - val_loss: 0.1944 - val_accuracy: 0.9475\n",
      "Epoch 639/1000\n",
      "67/67 [==============================] - 26s 392ms/step - loss: 0.2008 - accuracy: 0.9459 - val_loss: 0.1938 - val_accuracy: 0.9475\n",
      "Epoch 640/1000\n",
      "67/67 [==============================] - 24s 354ms/step - loss: 0.2021 - accuracy: 0.9459 - val_loss: 0.1977 - val_accuracy: 0.9475\n",
      "Epoch 641/1000\n",
      "67/67 [==============================] - 23s 338ms/step - loss: 0.2018 - accuracy: 0.9459 - val_loss: 0.1980 - val_accuracy: 0.9475\n",
      "Epoch 642/1000\n",
      "67/67 [==============================] - 23s 346ms/step - loss: 0.2021 - accuracy: 0.9459 - val_loss: 0.1942 - val_accuracy: 0.9475\n",
      "Epoch 643/1000\n",
      "67/67 [==============================] - 23s 338ms/step - loss: 0.2017 - accuracy: 0.9459 - val_loss: 0.1971 - val_accuracy: 0.9475\n",
      "Epoch 644/1000\n",
      "67/67 [==============================] - 23s 336ms/step - loss: 0.2014 - accuracy: 0.9459 - val_loss: 0.1958 - val_accuracy: 0.9475\n",
      "Epoch 645/1000\n",
      "67/67 [==============================] - 23s 337ms/step - loss: 0.2014 - accuracy: 0.9459 - val_loss: 0.1935 - val_accuracy: 0.9475\n",
      "Epoch 646/1000\n",
      "67/67 [==============================] - 23s 338ms/step - loss: 0.2003 - accuracy: 0.9459 - val_loss: 0.1943 - val_accuracy: 0.9475\n",
      "Epoch 647/1000\n",
      "67/67 [==============================] - 22s 336ms/step - loss: 0.2007 - accuracy: 0.9459 - val_loss: 0.2082 - val_accuracy: 0.9475\n",
      "Epoch 648/1000\n",
      "67/67 [==============================] - 23s 345ms/step - loss: 0.2052 - accuracy: 0.9459 - val_loss: 0.1941 - val_accuracy: 0.9475\n",
      "Epoch 649/1000\n",
      "67/67 [==============================] - 24s 353ms/step - loss: 0.2017 - accuracy: 0.9459 - val_loss: 0.2080 - val_accuracy: 0.9475\n",
      "Epoch 650/1000\n",
      "67/67 [==============================] - 23s 348ms/step - loss: 0.2025 - accuracy: 0.9459 - val_loss: 0.1937 - val_accuracy: 0.9475\n",
      "Epoch 651/1000\n",
      "67/67 [==============================] - 23s 339ms/step - loss: 0.2008 - accuracy: 0.9459 - val_loss: 0.1936 - val_accuracy: 0.9475\n",
      "Epoch 652/1000\n",
      "67/67 [==============================] - 22s 334ms/step - loss: 0.1998 - accuracy: 0.9459 - val_loss: 0.1963 - val_accuracy: 0.9475\n",
      "Epoch 653/1000\n",
      "67/67 [==============================] - 23s 337ms/step - loss: 0.1999 - accuracy: 0.9459 - val_loss: 0.1932 - val_accuracy: 0.9475\n",
      "Epoch 654/1000\n",
      "67/67 [==============================] - 23s 338ms/step - loss: 0.2005 - accuracy: 0.9459 - val_loss: 0.1936 - val_accuracy: 0.9475\n",
      "Epoch 655/1000\n",
      "67/67 [==============================] - 23s 337ms/step - loss: 0.2005 - accuracy: 0.9459 - val_loss: 0.1933 - val_accuracy: 0.9475\n",
      "Epoch 656/1000\n",
      "67/67 [==============================] - 23s 338ms/step - loss: 0.2035 - accuracy: 0.9459 - val_loss: 0.1943 - val_accuracy: 0.9475\n",
      "Epoch 657/1000\n",
      "67/67 [==============================] - 23s 339ms/step - loss: 0.2007 - accuracy: 0.9459 - val_loss: 0.1938 - val_accuracy: 0.9475\n",
      "Epoch 658/1000\n",
      "67/67 [==============================] - 22s 336ms/step - loss: 0.1996 - accuracy: 0.9459 - val_loss: 0.1932 - val_accuracy: 0.9475\n",
      "Epoch 659/1000\n",
      "67/67 [==============================] - 23s 338ms/step - loss: 0.2028 - accuracy: 0.9459 - val_loss: 0.1934 - val_accuracy: 0.9475\n",
      "Epoch 660/1000\n",
      "67/67 [==============================] - 23s 337ms/step - loss: 0.2028 - accuracy: 0.9459 - val_loss: 0.1939 - val_accuracy: 0.9475\n",
      "Epoch 661/1000\n",
      "67/67 [==============================] - 22s 335ms/step - loss: 0.2006 - accuracy: 0.9459 - val_loss: 0.1931 - val_accuracy: 0.9475\n",
      "Epoch 662/1000\n",
      "67/67 [==============================] - 23s 339ms/step - loss: 0.2008 - accuracy: 0.9459 - val_loss: 0.1943 - val_accuracy: 0.9475\n",
      "Epoch 663/1000\n",
      "67/67 [==============================] - 23s 338ms/step - loss: 0.2007 - accuracy: 0.9459 - val_loss: 0.1979 - val_accuracy: 0.9475\n",
      "Epoch 664/1000\n",
      "67/67 [==============================] - 22s 335ms/step - loss: 0.2005 - accuracy: 0.9459 - val_loss: 0.1943 - val_accuracy: 0.9475\n",
      "Epoch 665/1000\n",
      "67/67 [==============================] - 23s 338ms/step - loss: 0.2004 - accuracy: 0.9459 - val_loss: 0.1962 - val_accuracy: 0.9475\n",
      "Epoch 666/1000\n",
      "67/67 [==============================] - 23s 337ms/step - loss: 0.2011 - accuracy: 0.9459 - val_loss: 0.1951 - val_accuracy: 0.9475\n",
      "Epoch 667/1000\n",
      "67/67 [==============================] - 23s 339ms/step - loss: 0.1999 - accuracy: 0.9459 - val_loss: 0.1958 - val_accuracy: 0.9475\n",
      "Epoch 668/1000\n",
      "67/67 [==============================] - 23s 337ms/step - loss: 0.1995 - accuracy: 0.9459 - val_loss: 0.1933 - val_accuracy: 0.9475\n",
      "Epoch 669/1000\n",
      "67/67 [==============================] - 23s 340ms/step - loss: 0.2002 - accuracy: 0.9459 - val_loss: 0.1932 - val_accuracy: 0.9475\n",
      "Epoch 670/1000\n",
      "67/67 [==============================] - 23s 349ms/step - loss: 0.2003 - accuracy: 0.9459 - val_loss: 0.1958 - val_accuracy: 0.9475\n",
      "Epoch 671/1000\n",
      "67/67 [==============================] - 23s 347ms/step - loss: 0.2018 - accuracy: 0.9459 - val_loss: 0.1941 - val_accuracy: 0.9475\n",
      "Epoch 672/1000\n",
      "67/67 [==============================] - 22s 334ms/step - loss: 0.2010 - accuracy: 0.9459 - val_loss: 0.1936 - val_accuracy: 0.9475\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 673/1000\n",
      "67/67 [==============================] - 22s 333ms/step - loss: 0.2005 - accuracy: 0.9459 - val_loss: 0.1937 - val_accuracy: 0.9475\n",
      "Epoch 674/1000\n",
      "67/67 [==============================] - 23s 337ms/step - loss: 0.1998 - accuracy: 0.9459 - val_loss: 0.1960 - val_accuracy: 0.9475\n",
      "Epoch 675/1000\n",
      "67/67 [==============================] - 23s 337ms/step - loss: 0.2014 - accuracy: 0.9459 - val_loss: 0.1965 - val_accuracy: 0.9475\n",
      "Epoch 676/1000\n",
      "67/67 [==============================] - 23s 338ms/step - loss: 0.2012 - accuracy: 0.9459 - val_loss: 0.1936 - val_accuracy: 0.9475\n",
      "Epoch 677/1000\n",
      "67/67 [==============================] - 22s 336ms/step - loss: 0.2022 - accuracy: 0.9459 - val_loss: 0.1935 - val_accuracy: 0.9475\n",
      "Epoch 678/1000\n",
      "67/67 [==============================] - 23s 339ms/step - loss: 0.2002 - accuracy: 0.9459 - val_loss: 0.1938 - val_accuracy: 0.9475\n",
      "Epoch 679/1000\n",
      "67/67 [==============================] - 23s 338ms/step - loss: 0.2017 - accuracy: 0.9459 - val_loss: 0.1935 - val_accuracy: 0.9475\n",
      "Epoch 680/1000\n",
      "67/67 [==============================] - 22s 336ms/step - loss: 0.2003 - accuracy: 0.9459 - val_loss: 0.1951 - val_accuracy: 0.9475\n",
      "Epoch 681/1000\n",
      "67/67 [==============================] - 23s 339ms/step - loss: 0.2008 - accuracy: 0.9459 - val_loss: 0.1935 - val_accuracy: 0.9475\n",
      "Epoch 682/1000\n",
      "67/67 [==============================] - 23s 339ms/step - loss: 0.2004 - accuracy: 0.9459 - val_loss: 0.1930 - val_accuracy: 0.9475\n",
      "Epoch 683/1000\n",
      "67/67 [==============================] - 23s 339ms/step - loss: 0.1994 - accuracy: 0.9459 - val_loss: 0.1948 - val_accuracy: 0.9475\n",
      "Epoch 684/1000\n",
      "67/67 [==============================] - 23s 337ms/step - loss: 0.2020 - accuracy: 0.9459 - val_loss: 0.1946 - val_accuracy: 0.9475\n",
      "Epoch 685/1000\n",
      "67/67 [==============================] - 23s 340ms/step - loss: 0.1999 - accuracy: 0.9459 - val_loss: 0.1948 - val_accuracy: 0.9475\n",
      "Epoch 686/1000\n",
      "67/67 [==============================] - 22s 335ms/step - loss: 0.2026 - accuracy: 0.9459 - val_loss: 0.2017 - val_accuracy: 0.9475\n",
      "Epoch 687/1000\n",
      "67/67 [==============================] - 22s 336ms/step - loss: 0.2019 - accuracy: 0.9459 - val_loss: 0.1945 - val_accuracy: 0.9475\n",
      "Epoch 688/1000\n",
      "67/67 [==============================] - 23s 347ms/step - loss: 0.1996 - accuracy: 0.9459 - val_loss: 0.1928 - val_accuracy: 0.9475\n",
      "Epoch 689/1000\n",
      "67/67 [==============================] - 23s 346ms/step - loss: 0.2016 - accuracy: 0.9459 - val_loss: 0.1936 - val_accuracy: 0.9475\n",
      "Epoch 690/1000\n",
      "67/67 [==============================] - 22s 333ms/step - loss: 0.2006 - accuracy: 0.9459 - val_loss: 0.1962 - val_accuracy: 0.9475\n",
      "Epoch 691/1000\n",
      "67/67 [==============================] - 23s 339ms/step - loss: 0.2021 - accuracy: 0.9459 - val_loss: 0.1932 - val_accuracy: 0.9475\n",
      "Epoch 692/1000\n",
      "67/67 [==============================] - 23s 337ms/step - loss: 0.2005 - accuracy: 0.9459 - val_loss: 0.1959 - val_accuracy: 0.9475\n",
      "Epoch 693/1000\n",
      "67/67 [==============================] - 23s 339ms/step - loss: 0.2009 - accuracy: 0.9459 - val_loss: 0.1978 - val_accuracy: 0.9475\n",
      "Epoch 694/1000\n",
      "67/67 [==============================] - 23s 337ms/step - loss: 0.2016 - accuracy: 0.9459 - val_loss: 0.1936 - val_accuracy: 0.9475\n",
      "Epoch 695/1000\n",
      "67/67 [==============================] - 23s 337ms/step - loss: 0.2015 - accuracy: 0.9459 - val_loss: 0.1926 - val_accuracy: 0.9475\n",
      "Epoch 696/1000\n",
      "67/67 [==============================] - 23s 338ms/step - loss: 0.2002 - accuracy: 0.9459 - val_loss: 0.1932 - val_accuracy: 0.9475\n",
      "Epoch 697/1000\n",
      "67/67 [==============================] - 23s 342ms/step - loss: 0.2012 - accuracy: 0.9459 - val_loss: 0.1969 - val_accuracy: 0.9475\n",
      "Epoch 698/1000\n",
      "67/67 [==============================] - 23s 337ms/step - loss: 0.2001 - accuracy: 0.9459 - val_loss: 0.1934 - val_accuracy: 0.9475\n",
      "Epoch 699/1000\n",
      "67/67 [==============================] - 23s 340ms/step - loss: 0.2002 - accuracy: 0.9459 - val_loss: 0.1934 - val_accuracy: 0.9475\n",
      "Epoch 700/1000\n",
      "67/67 [==============================] - 23s 339ms/step - loss: 0.2019 - accuracy: 0.9459 - val_loss: 0.1949 - val_accuracy: 0.9475\n",
      "Epoch 701/1000\n",
      "67/67 [==============================] - 23s 341ms/step - loss: 0.2016 - accuracy: 0.9459 - val_loss: 0.1985 - val_accuracy: 0.9475\n",
      "Epoch 702/1000\n",
      "67/67 [==============================] - 23s 338ms/step - loss: 0.2030 - accuracy: 0.9459 - val_loss: 0.1940 - val_accuracy: 0.9475\n",
      "Epoch 703/1000\n",
      "67/67 [==============================] - 22s 335ms/step - loss: 0.2005 - accuracy: 0.9459 - val_loss: 0.1928 - val_accuracy: 0.9475\n",
      "Epoch 704/1000\n",
      "67/67 [==============================] - 23s 339ms/step - loss: 0.1993 - accuracy: 0.9459 - val_loss: 0.1944 - val_accuracy: 0.9475\n",
      "Epoch 705/1000\n",
      "67/67 [==============================] - 22s 335ms/step - loss: 0.2010 - accuracy: 0.9459 - val_loss: 0.1932 - val_accuracy: 0.9475\n",
      "Epoch 706/1000\n",
      "67/67 [==============================] - 23s 337ms/step - loss: 0.1996 - accuracy: 0.9459 - val_loss: 0.1966 - val_accuracy: 0.9475\n",
      "Epoch 707/1000\n",
      "67/67 [==============================] - 22s 334ms/step - loss: 0.2013 - accuracy: 0.9459 - val_loss: 0.1951 - val_accuracy: 0.9475\n",
      "Epoch 708/1000\n",
      "67/67 [==============================] - 23s 343ms/step - loss: 0.2006 - accuracy: 0.9459 - val_loss: 0.1939 - val_accuracy: 0.9475\n",
      "Epoch 709/1000\n",
      "67/67 [==============================] - 23s 350ms/step - loss: 0.2005 - accuracy: 0.9459 - val_loss: 0.1976 - val_accuracy: 0.9475\n",
      "Epoch 710/1000\n",
      "67/67 [==============================] - 23s 346ms/step - loss: 0.2004 - accuracy: 0.9459 - val_loss: 0.1956 - val_accuracy: 0.9475\n",
      "Epoch 711/1000\n",
      "67/67 [==============================] - 23s 339ms/step - loss: 0.2019 - accuracy: 0.9459 - val_loss: 0.1969 - val_accuracy: 0.9475\n",
      "Epoch 712/1000\n",
      "67/67 [==============================] - 23s 338ms/step - loss: 0.2004 - accuracy: 0.9459 - val_loss: 0.1952 - val_accuracy: 0.9475\n",
      "Epoch 713/1000\n",
      "67/67 [==============================] - 23s 337ms/step - loss: 0.1999 - accuracy: 0.9459 - val_loss: 0.1935 - val_accuracy: 0.9475\n",
      "Epoch 714/1000\n",
      "67/67 [==============================] - 22s 335ms/step - loss: 0.1995 - accuracy: 0.9459 - val_loss: 0.1936 - val_accuracy: 0.9475\n",
      "Epoch 715/1000\n",
      "67/67 [==============================] - 22s 336ms/step - loss: 0.1999 - accuracy: 0.9459 - val_loss: 0.1928 - val_accuracy: 0.9475\n",
      "Epoch 716/1000\n",
      "67/67 [==============================] - 23s 338ms/step - loss: 0.1994 - accuracy: 0.9459 - val_loss: 0.1984 - val_accuracy: 0.9475\n",
      "Epoch 717/1000\n",
      "67/67 [==============================] - 22s 336ms/step - loss: 0.2009 - accuracy: 0.9459 - val_loss: 0.1945 - val_accuracy: 0.9475\n",
      "Epoch 718/1000\n",
      "67/67 [==============================] - 23s 336ms/step - loss: 0.2002 - accuracy: 0.9459 - val_loss: 0.1933 - val_accuracy: 0.9475\n",
      "Epoch 719/1000\n",
      "67/67 [==============================] - 23s 338ms/step - loss: 0.1998 - accuracy: 0.9459 - val_loss: 0.1928 - val_accuracy: 0.9475\n",
      "Epoch 720/1000\n",
      "67/67 [==============================] - 22s 335ms/step - loss: 0.2010 - accuracy: 0.9459 - val_loss: 0.1930 - val_accuracy: 0.9475\n",
      "Epoch 721/1000\n",
      "67/67 [==============================] - 23s 337ms/step - loss: 0.2005 - accuracy: 0.9459 - val_loss: 0.1941 - val_accuracy: 0.9475\n",
      "Epoch 722/1000\n",
      "67/67 [==============================] - 22s 333ms/step - loss: 0.2009 - accuracy: 0.9459 - val_loss: 0.1926 - val_accuracy: 0.9475\n",
      "Epoch 723/1000\n",
      "67/67 [==============================] - 23s 337ms/step - loss: 0.2020 - accuracy: 0.9459 - val_loss: 0.1946 - val_accuracy: 0.9475\n",
      "Epoch 724/1000\n",
      "67/67 [==============================] - 22s 333ms/step - loss: 0.2009 - accuracy: 0.9459 - val_loss: 0.1945 - val_accuracy: 0.9475\n",
      "Epoch 725/1000\n",
      "67/67 [==============================] - 23s 339ms/step - loss: 0.2005 - accuracy: 0.9459 - val_loss: 0.1938 - val_accuracy: 0.9475\n",
      "Epoch 726/1000\n",
      "67/67 [==============================] - 23s 337ms/step - loss: 0.2013 - accuracy: 0.9459 - val_loss: 0.1933 - val_accuracy: 0.9475\n",
      "Epoch 727/1000\n",
      "67/67 [==============================] - 23s 337ms/step - loss: 0.2001 - accuracy: 0.9459 - val_loss: 0.1936 - val_accuracy: 0.9475\n",
      "Epoch 728/1000\n",
      "67/67 [==============================] - 23s 339ms/step - loss: 0.2009 - accuracy: 0.9459 - val_loss: 0.1939 - val_accuracy: 0.9475\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 729/1000\n",
      "67/67 [==============================] - 22s 332ms/step - loss: 0.2005 - accuracy: 0.9459 - val_loss: 0.1953 - val_accuracy: 0.9475\n",
      "Epoch 730/1000\n",
      "67/67 [==============================] - 22s 335ms/step - loss: 0.1989 - accuracy: 0.9459 - val_loss: 0.1943 - val_accuracy: 0.9475\n",
      "Epoch 731/1000\n",
      "67/67 [==============================] - 23s 347ms/step - loss: 0.2009 - accuracy: 0.9459 - val_loss: 0.1929 - val_accuracy: 0.9475\n",
      "Epoch 732/1000\n",
      "67/67 [==============================] - 24s 355ms/step - loss: 0.2016 - accuracy: 0.9459 - val_loss: 0.1966 - val_accuracy: 0.9475\n",
      "Epoch 733/1000\n",
      "67/67 [==============================] - 22s 324ms/step - loss: 0.2015 - accuracy: 0.9459 - val_loss: 0.1941 - val_accuracy: 0.9475\n",
      "Epoch 734/1000\n",
      "67/67 [==============================] - 19s 286ms/step - loss: 0.2013 - accuracy: 0.9459 - val_loss: 0.1942 - val_accuracy: 0.9475\n",
      "Epoch 735/1000\n",
      "67/67 [==============================] - 19s 284ms/step - loss: 0.2002 - accuracy: 0.9459 - val_loss: 0.1980 - val_accuracy: 0.9475\n",
      "Epoch 736/1000\n",
      "67/67 [==============================] - 19s 283ms/step - loss: 0.2004 - accuracy: 0.9459 - val_loss: 0.1933 - val_accuracy: 0.9475\n",
      "Epoch 737/1000\n",
      "67/67 [==============================] - 19s 277ms/step - loss: 0.2009 - accuracy: 0.9459 - val_loss: 0.1933 - val_accuracy: 0.9475\n",
      "Epoch 738/1000\n",
      "67/67 [==============================] - 22s 326ms/step - loss: 0.2024 - accuracy: 0.9459 - val_loss: 0.1979 - val_accuracy: 0.9475\n",
      "Epoch 739/1000\n",
      "67/67 [==============================] - 22s 334ms/step - loss: 0.2030 - accuracy: 0.9459 - val_loss: 0.1939 - val_accuracy: 0.9475\n",
      "Epoch 740/1000\n",
      "67/67 [==============================] - 22s 336ms/step - loss: 0.2017 - accuracy: 0.9459 - val_loss: 0.1937 - val_accuracy: 0.9475\n",
      "Epoch 741/1000\n",
      "67/67 [==============================] - 22s 334ms/step - loss: 0.2003 - accuracy: 0.9459 - val_loss: 0.1939 - val_accuracy: 0.9475\n",
      "Epoch 742/1000\n",
      "67/67 [==============================] - 22s 334ms/step - loss: 0.2009 - accuracy: 0.9459 - val_loss: 0.1976 - val_accuracy: 0.9475\n",
      "Epoch 743/1000\n",
      "67/67 [==============================] - 22s 335ms/step - loss: 0.2015 - accuracy: 0.9459 - val_loss: 0.1941 - val_accuracy: 0.9475\n",
      "Epoch 744/1000\n",
      "67/67 [==============================] - 22s 336ms/step - loss: 0.1998 - accuracy: 0.9459 - val_loss: 0.1929 - val_accuracy: 0.9475\n",
      "Epoch 745/1000\n",
      "67/67 [==============================] - 22s 334ms/step - loss: 0.2017 - accuracy: 0.9459 - val_loss: 0.1926 - val_accuracy: 0.9475\n",
      "Epoch 746/1000\n",
      "67/67 [==============================] - 22s 335ms/step - loss: 0.2000 - accuracy: 0.9459 - val_loss: 0.1928 - val_accuracy: 0.9475\n",
      "Epoch 747/1000\n",
      "67/67 [==============================] - 22s 334ms/step - loss: 0.2002 - accuracy: 0.9459 - val_loss: 0.1932 - val_accuracy: 0.9475\n",
      "Epoch 748/1000\n",
      "67/67 [==============================] - 22s 333ms/step - loss: 0.2003 - accuracy: 0.9459 - val_loss: 0.1929 - val_accuracy: 0.9475\n",
      "Epoch 749/1000\n",
      "67/67 [==============================] - 22s 336ms/step - loss: 0.1995 - accuracy: 0.9459 - val_loss: 0.1940 - val_accuracy: 0.9475\n",
      "Epoch 750/1000\n",
      "67/67 [==============================] - 23s 337ms/step - loss: 0.2018 - accuracy: 0.9459 - val_loss: 0.1936 - val_accuracy: 0.9475\n",
      "Epoch 751/1000\n",
      "67/67 [==============================] - 22s 333ms/step - loss: 0.2013 - accuracy: 0.9459 - val_loss: 0.1929 - val_accuracy: 0.9475\n",
      "Epoch 752/1000\n",
      "67/67 [==============================] - 22s 328ms/step - loss: 0.2002 - accuracy: 0.9459 - val_loss: 0.1929 - val_accuracy: 0.9475\n",
      "Epoch 753/1000\n",
      "67/67 [==============================] - 22s 335ms/step - loss: 0.1992 - accuracy: 0.9459 - val_loss: 0.1938 - val_accuracy: 0.9475\n",
      "Epoch 754/1000\n",
      "67/67 [==============================] - 22s 333ms/step - loss: 0.1989 - accuracy: 0.9459 - val_loss: 0.1932 - val_accuracy: 0.9475\n",
      "Epoch 755/1000\n",
      "67/67 [==============================] - 23s 348ms/step - loss: 0.2004 - accuracy: 0.9459 - val_loss: 0.1936 - val_accuracy: 0.9475\n",
      "Epoch 756/1000\n",
      "67/67 [==============================] - 23s 339ms/step - loss: 0.2012 - accuracy: 0.9459 - val_loss: 0.1930 - val_accuracy: 0.9475\n",
      "Epoch 757/1000\n",
      "67/67 [==============================] - 22s 333ms/step - loss: 0.2000 - accuracy: 0.9459 - val_loss: 0.1952 - val_accuracy: 0.9475\n",
      "Epoch 758/1000\n",
      "67/67 [==============================] - 22s 336ms/step - loss: 0.2009 - accuracy: 0.9459 - val_loss: 0.1931 - val_accuracy: 0.9475\n",
      "Epoch 759/1000\n",
      "67/67 [==============================] - 22s 336ms/step - loss: 0.2005 - accuracy: 0.9459 - val_loss: 0.1955 - val_accuracy: 0.9475\n",
      "Epoch 760/1000\n",
      "67/67 [==============================] - 23s 337ms/step - loss: 0.2001 - accuracy: 0.9459 - val_loss: 0.1977 - val_accuracy: 0.9475\n",
      "Epoch 761/1000\n",
      "67/67 [==============================] - 23s 339ms/step - loss: 0.2013 - accuracy: 0.9459 - val_loss: 0.1958 - val_accuracy: 0.9475\n",
      "Epoch 762/1000\n",
      "67/67 [==============================] - 22s 335ms/step - loss: 0.1999 - accuracy: 0.9459 - val_loss: 0.1948 - val_accuracy: 0.9475\n",
      "Epoch 763/1000\n",
      "67/67 [==============================] - 22s 336ms/step - loss: 0.2004 - accuracy: 0.9459 - val_loss: 0.1930 - val_accuracy: 0.9475\n",
      "Epoch 764/1000\n",
      "67/67 [==============================] - 22s 335ms/step - loss: 0.1990 - accuracy: 0.9459 - val_loss: 0.1936 - val_accuracy: 0.9475\n",
      "Epoch 765/1000\n",
      "67/67 [==============================] - 22s 335ms/step - loss: 0.2022 - accuracy: 0.9459 - val_loss: 0.1947 - val_accuracy: 0.9475\n",
      "Epoch 766/1000\n",
      "67/67 [==============================] - 22s 335ms/step - loss: 0.1999 - accuracy: 0.9459 - val_loss: 0.1946 - val_accuracy: 0.9475\n",
      "Epoch 767/1000\n",
      "67/67 [==============================] - 23s 340ms/step - loss: 0.2019 - accuracy: 0.9459 - val_loss: 0.1935 - val_accuracy: 0.9475\n",
      "Epoch 768/1000\n",
      "67/67 [==============================] - 23s 345ms/step - loss: 0.2009 - accuracy: 0.9459 - val_loss: 0.1939 - val_accuracy: 0.9475\n",
      "Epoch 769/1000\n",
      "67/67 [==============================] - 23s 348ms/step - loss: 0.1999 - accuracy: 0.9459 - val_loss: 0.1942 - val_accuracy: 0.9475\n",
      "Epoch 770/1000\n",
      "67/67 [==============================] - 23s 341ms/step - loss: 0.1990 - accuracy: 0.9459 - val_loss: 0.1926 - val_accuracy: 0.9475\n",
      "Epoch 771/1000\n",
      "67/67 [==============================] - 22s 335ms/step - loss: 0.1999 - accuracy: 0.9459 - val_loss: 0.1949 - val_accuracy: 0.9475\n",
      "Epoch 772/1000\n",
      "67/67 [==============================] - 22s 336ms/step - loss: 0.2006 - accuracy: 0.9459 - val_loss: 0.1986 - val_accuracy: 0.9475\n",
      "Epoch 773/1000\n",
      "67/67 [==============================] - 22s 335ms/step - loss: 0.1998 - accuracy: 0.9459 - val_loss: 0.1927 - val_accuracy: 0.9475\n",
      "Epoch 774/1000\n",
      "67/67 [==============================] - 22s 336ms/step - loss: 0.2012 - accuracy: 0.9459 - val_loss: 0.1988 - val_accuracy: 0.9475\n",
      "Epoch 775/1000\n",
      "67/67 [==============================] - 23s 340ms/step - loss: 0.2018 - accuracy: 0.9459 - val_loss: 0.1969 - val_accuracy: 0.9475\n",
      "Epoch 776/1000\n",
      "67/67 [==============================] - 23s 338ms/step - loss: 0.2022 - accuracy: 0.9459 - val_loss: 0.1926 - val_accuracy: 0.9475\n",
      "Epoch 777/1000\n",
      "67/67 [==============================] - 23s 337ms/step - loss: 0.1992 - accuracy: 0.9459 - val_loss: 0.1936 - val_accuracy: 0.9475\n",
      "Epoch 778/1000\n",
      "67/67 [==============================] - 23s 338ms/step - loss: 0.1989 - accuracy: 0.9459 - val_loss: 0.1941 - val_accuracy: 0.9475\n",
      "Epoch 779/1000\n",
      "67/67 [==============================] - 22s 333ms/step - loss: 0.1998 - accuracy: 0.9459 - val_loss: 0.1932 - val_accuracy: 0.9475\n",
      "Epoch 780/1000\n",
      "67/67 [==============================] - 23s 337ms/step - loss: 0.2001 - accuracy: 0.9459 - val_loss: 0.1960 - val_accuracy: 0.9475\n",
      "Epoch 781/1000\n",
      "67/67 [==============================] - 23s 337ms/step - loss: 0.2013 - accuracy: 0.9459 - val_loss: 0.1994 - val_accuracy: 0.9475\n",
      "Epoch 782/1000\n",
      "67/67 [==============================] - 23s 338ms/step - loss: 0.1993 - accuracy: 0.9459 - val_loss: 0.1986 - val_accuracy: 0.9475\n",
      "Epoch 783/1000\n",
      "67/67 [==============================] - 23s 338ms/step - loss: 0.2040 - accuracy: 0.9459 - val_loss: 0.1941 - val_accuracy: 0.9475\n",
      "Epoch 784/1000\n",
      "67/67 [==============================] - 22s 335ms/step - loss: 0.2009 - accuracy: 0.9459 - val_loss: 0.1945 - val_accuracy: 0.9475\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 785/1000\n",
      "67/67 [==============================] - 23s 337ms/step - loss: 0.1996 - accuracy: 0.9459 - val_loss: 0.1956 - val_accuracy: 0.9475\n",
      "Epoch 786/1000\n",
      "67/67 [==============================] - 23s 337ms/step - loss: 0.1993 - accuracy: 0.9459 - val_loss: 0.1932 - val_accuracy: 0.9475\n",
      "Epoch 787/1000\n",
      "67/67 [==============================] - 23s 343ms/step - loss: 0.1987 - accuracy: 0.9459 - val_loss: 0.1929 - val_accuracy: 0.9475\n",
      "Epoch 788/1000\n",
      "67/67 [==============================] - 22s 333ms/step - loss: 0.1997 - accuracy: 0.9459 - val_loss: 0.1948 - val_accuracy: 0.9475\n",
      "Epoch 789/1000\n",
      "67/67 [==============================] - 22s 336ms/step - loss: 0.1992 - accuracy: 0.9459 - val_loss: 0.1947 - val_accuracy: 0.9475\n",
      "Epoch 790/1000\n",
      "67/67 [==============================] - 23s 343ms/step - loss: 0.2014 - accuracy: 0.9459 - val_loss: 0.1974 - val_accuracy: 0.9475\n",
      "Epoch 791/1000\n",
      "67/67 [==============================] - 23s 347ms/step - loss: 0.2013 - accuracy: 0.9459 - val_loss: 0.1952 - val_accuracy: 0.9475\n",
      "Epoch 792/1000\n",
      "67/67 [==============================] - 23s 343ms/step - loss: 0.1995 - accuracy: 0.9459 - val_loss: 0.1938 - val_accuracy: 0.9475\n",
      "Epoch 793/1000\n",
      "67/67 [==============================] - 23s 337ms/step - loss: 0.2005 - accuracy: 0.9459 - val_loss: 0.1926 - val_accuracy: 0.9475\n",
      "Epoch 794/1000\n",
      "67/67 [==============================] - 23s 337ms/step - loss: 0.1982 - accuracy: 0.9459 - val_loss: 0.1938 - val_accuracy: 0.9475\n",
      "Epoch 795/1000\n",
      "67/67 [==============================] - 22s 336ms/step - loss: 0.2010 - accuracy: 0.9459 - val_loss: 0.1945 - val_accuracy: 0.9475\n",
      "Epoch 796/1000\n",
      "67/67 [==============================] - 23s 336ms/step - loss: 0.2007 - accuracy: 0.9459 - val_loss: 0.1939 - val_accuracy: 0.9475\n",
      "Epoch 797/1000\n",
      "67/67 [==============================] - 23s 338ms/step - loss: 0.2032 - accuracy: 0.9459 - val_loss: 0.1927 - val_accuracy: 0.9475\n",
      "Epoch 798/1000\n",
      "67/67 [==============================] - 22s 336ms/step - loss: 0.2002 - accuracy: 0.9459 - val_loss: 0.1925 - val_accuracy: 0.9475\n",
      "Epoch 799/1000\n",
      "67/67 [==============================] - 23s 337ms/step - loss: 0.2008 - accuracy: 0.9459 - val_loss: 0.1932 - val_accuracy: 0.9475\n",
      "Epoch 800/1000\n",
      "67/67 [==============================] - 23s 338ms/step - loss: 0.1997 - accuracy: 0.9459 - val_loss: 0.1951 - val_accuracy: 0.9475\n",
      "Epoch 801/1000\n",
      "67/67 [==============================] - 23s 340ms/step - loss: 0.2011 - accuracy: 0.9459 - val_loss: 0.1936 - val_accuracy: 0.9475\n",
      "Epoch 802/1000\n",
      "67/67 [==============================] - 22s 334ms/step - loss: 0.1991 - accuracy: 0.9459 - val_loss: 0.1926 - val_accuracy: 0.9475\n",
      "Epoch 803/1000\n",
      "67/67 [==============================] - 23s 337ms/step - loss: 0.1986 - accuracy: 0.9459 - val_loss: 0.1922 - val_accuracy: 0.9475\n",
      "Epoch 804/1000\n",
      "67/67 [==============================] - 23s 338ms/step - loss: 0.2005 - accuracy: 0.9459 - val_loss: 0.1923 - val_accuracy: 0.9475\n",
      "Epoch 805/1000\n",
      "67/67 [==============================] - 22s 336ms/step - loss: 0.2013 - accuracy: 0.9459 - val_loss: 0.1922 - val_accuracy: 0.9475\n",
      "Epoch 806/1000\n",
      "67/67 [==============================] - 23s 339ms/step - loss: 0.1990 - accuracy: 0.9459 - val_loss: 0.1924 - val_accuracy: 0.9475\n",
      "Epoch 807/1000\n",
      "67/67 [==============================] - 23s 338ms/step - loss: 0.2005 - accuracy: 0.9459 - val_loss: 0.1974 - val_accuracy: 0.9475\n",
      "Epoch 808/1000\n",
      "67/67 [==============================] - 23s 340ms/step - loss: 0.1997 - accuracy: 0.9459 - val_loss: 0.1939 - val_accuracy: 0.9475\n",
      "Epoch 809/1000\n",
      "67/67 [==============================] - 23s 340ms/step - loss: 0.1998 - accuracy: 0.9459 - val_loss: 0.1944 - val_accuracy: 0.9475\n",
      "Epoch 810/1000\n",
      "67/67 [==============================] - 23s 338ms/step - loss: 0.2016 - accuracy: 0.9459 - val_loss: 0.1939 - val_accuracy: 0.9475\n",
      "Epoch 811/1000\n",
      "67/67 [==============================] - 23s 339ms/step - loss: 0.2007 - accuracy: 0.9459 - val_loss: 0.1935 - val_accuracy: 0.9475\n",
      "Epoch 812/1000\n",
      "67/67 [==============================] - 23s 346ms/step - loss: 0.1996 - accuracy: 0.9459 - val_loss: 0.1966 - val_accuracy: 0.9475\n",
      "Epoch 813/1000\n",
      "67/67 [==============================] - 23s 344ms/step - loss: 0.2003 - accuracy: 0.9459 - val_loss: 0.1966 - val_accuracy: 0.9475\n",
      "Epoch 814/1000\n",
      "67/67 [==============================] - 23s 340ms/step - loss: 0.1994 - accuracy: 0.9459 - val_loss: 0.1938 - val_accuracy: 0.9475\n",
      "Epoch 815/1000\n",
      "67/67 [==============================] - 23s 337ms/step - loss: 0.2010 - accuracy: 0.9459 - val_loss: 0.1936 - val_accuracy: 0.9475\n",
      "Epoch 816/1000\n",
      "67/67 [==============================] - 23s 336ms/step - loss: 0.2003 - accuracy: 0.9459 - val_loss: 0.1926 - val_accuracy: 0.9475\n",
      "Epoch 817/1000\n",
      "67/67 [==============================] - 23s 337ms/step - loss: 0.1994 - accuracy: 0.9459 - val_loss: 0.1955 - val_accuracy: 0.9475\n",
      "Epoch 818/1000\n",
      "67/67 [==============================] - 23s 337ms/step - loss: 0.1998 - accuracy: 0.9459 - val_loss: 0.1938 - val_accuracy: 0.9475\n",
      "Epoch 819/1000\n",
      "67/67 [==============================] - 22s 335ms/step - loss: 0.2017 - accuracy: 0.9459 - val_loss: 0.1980 - val_accuracy: 0.9475\n",
      "Epoch 820/1000\n",
      "67/67 [==============================] - 22s 335ms/step - loss: 0.2027 - accuracy: 0.9459 - val_loss: 0.1931 - val_accuracy: 0.9475\n",
      "Epoch 821/1000\n",
      "67/67 [==============================] - 23s 338ms/step - loss: 0.2012 - accuracy: 0.9459 - val_loss: 0.1974 - val_accuracy: 0.9475\n",
      "Epoch 822/1000\n",
      "67/67 [==============================] - 22s 335ms/step - loss: 0.2012 - accuracy: 0.9459 - val_loss: 0.1932 - val_accuracy: 0.9475\n",
      "Epoch 823/1000\n",
      "67/67 [==============================] - 22s 331ms/step - loss: 0.1995 - accuracy: 0.9459 - val_loss: 0.1936 - val_accuracy: 0.9475\n",
      "Epoch 824/1000\n",
      "67/67 [==============================] - 22s 335ms/step - loss: 0.2003 - accuracy: 0.9459 - val_loss: 0.1938 - val_accuracy: 0.9475\n",
      "Epoch 825/1000\n",
      "67/67 [==============================] - 22s 336ms/step - loss: 0.1998 - accuracy: 0.9459 - val_loss: 0.1968 - val_accuracy: 0.9475\n",
      "Epoch 826/1000\n",
      "67/67 [==============================] - 23s 338ms/step - loss: 0.2013 - accuracy: 0.9459 - val_loss: 0.1957 - val_accuracy: 0.9475\n",
      "Epoch 827/1000\n",
      "67/67 [==============================] - 22s 334ms/step - loss: 0.2008 - accuracy: 0.9459 - val_loss: 0.1928 - val_accuracy: 0.9475\n",
      "Epoch 828/1000\n",
      "67/67 [==============================] - 22s 333ms/step - loss: 0.1998 - accuracy: 0.9459 - val_loss: 0.1926 - val_accuracy: 0.9475\n",
      "Epoch 829/1000\n",
      "67/67 [==============================] - 23s 340ms/step - loss: 0.1994 - accuracy: 0.9459 - val_loss: 0.1947 - val_accuracy: 0.9475\n",
      "Epoch 830/1000\n",
      "67/67 [==============================] - 23s 346ms/step - loss: 0.1986 - accuracy: 0.9459 - val_loss: 0.1923 - val_accuracy: 0.9475\n",
      "Epoch 831/1000\n",
      "67/67 [==============================] - 23s 344ms/step - loss: 0.2004 - accuracy: 0.9459 - val_loss: 0.1938 - val_accuracy: 0.9475\n",
      "Epoch 832/1000\n",
      "67/67 [==============================] - 23s 342ms/step - loss: 0.2019 - accuracy: 0.9459 - val_loss: 0.1935 - val_accuracy: 0.9475\n",
      "Epoch 833/1000\n",
      "67/67 [==============================] - 23s 336ms/step - loss: 0.1981 - accuracy: 0.9459 - val_loss: 0.1929 - val_accuracy: 0.9475\n",
      "Epoch 834/1000\n",
      "67/67 [==============================] - 23s 341ms/step - loss: 0.1997 - accuracy: 0.9459 - val_loss: 0.1933 - val_accuracy: 0.9475\n",
      "Epoch 835/1000\n",
      "67/67 [==============================] - 22s 333ms/step - loss: 0.1994 - accuracy: 0.9459 - val_loss: 0.1964 - val_accuracy: 0.9475\n",
      "Epoch 836/1000\n",
      "67/67 [==============================] - 23s 344ms/step - loss: 0.2000 - accuracy: 0.9459 - val_loss: 0.1935 - val_accuracy: 0.9475\n",
      "Epoch 837/1000\n",
      "67/67 [==============================] - 23s 342ms/step - loss: 0.1983 - accuracy: 0.9459 - val_loss: 0.1943 - val_accuracy: 0.9475\n",
      "Epoch 838/1000\n",
      "67/67 [==============================] - 22s 335ms/step - loss: 0.2011 - accuracy: 0.9459 - val_loss: 0.1930 - val_accuracy: 0.9475\n",
      "Epoch 839/1000\n",
      "67/67 [==============================] - 22s 333ms/step - loss: 0.1987 - accuracy: 0.9459 - val_loss: 0.1932 - val_accuracy: 0.9475\n",
      "Epoch 840/1000\n",
      "67/67 [==============================] - 22s 335ms/step - loss: 0.1995 - accuracy: 0.9459 - val_loss: 0.2059 - val_accuracy: 0.9475\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 841/1000\n",
      "67/67 [==============================] - 23s 338ms/step - loss: 0.2006 - accuracy: 0.9459 - val_loss: 0.1960 - val_accuracy: 0.9475\n",
      "Epoch 842/1000\n",
      "67/67 [==============================] - 23s 343ms/step - loss: 0.2009 - accuracy: 0.9459 - val_loss: 0.1973 - val_accuracy: 0.9475\n",
      "Epoch 843/1000\n",
      "67/67 [==============================] - 23s 338ms/step - loss: 0.2007 - accuracy: 0.9459 - val_loss: 0.1940 - val_accuracy: 0.9475\n",
      "Epoch 844/1000\n",
      "67/67 [==============================] - 22s 336ms/step - loss: 0.2007 - accuracy: 0.9459 - val_loss: 0.1937 - val_accuracy: 0.9475\n",
      "Epoch 845/1000\n",
      "67/67 [==============================] - 23s 339ms/step - loss: 0.1993 - accuracy: 0.9459 - val_loss: 0.1940 - val_accuracy: 0.9475\n",
      "Epoch 846/1000\n",
      "67/67 [==============================] - 24s 352ms/step - loss: 0.2022 - accuracy: 0.9459 - val_loss: 0.1934 - val_accuracy: 0.9475\n",
      "Epoch 847/1000\n",
      "67/67 [==============================] - 25s 369ms/step - loss: 0.2014 - accuracy: 0.9459 - val_loss: 0.1946 - val_accuracy: 0.9475\n",
      "Epoch 848/1000\n",
      "67/67 [==============================] - 25s 368ms/step - loss: 0.2003 - accuracy: 0.9459 - val_loss: 0.1942 - val_accuracy: 0.9475\n",
      "Epoch 849/1000\n",
      "67/67 [==============================] - 25s 377ms/step - loss: 0.1989 - accuracy: 0.9459 - val_loss: 0.1921 - val_accuracy: 0.9475\n",
      "Epoch 850/1000\n",
      "67/67 [==============================] - 23s 347ms/step - loss: 0.1993 - accuracy: 0.9459 - val_loss: 0.1929 - val_accuracy: 0.9475\n",
      "Epoch 851/1000\n",
      "67/67 [==============================] - 23s 347ms/step - loss: 0.1995 - accuracy: 0.9459 - val_loss: 0.1923 - val_accuracy: 0.9475\n",
      "Epoch 852/1000\n",
      "67/67 [==============================] - 23s 337ms/step - loss: 0.1998 - accuracy: 0.9459 - val_loss: 0.1986 - val_accuracy: 0.9475\n",
      "Epoch 853/1000\n",
      "67/67 [==============================] - 23s 337ms/step - loss: 0.2011 - accuracy: 0.9459 - val_loss: 0.1929 - val_accuracy: 0.9475\n",
      "Epoch 854/1000\n",
      "67/67 [==============================] - 23s 336ms/step - loss: 0.1984 - accuracy: 0.9459 - val_loss: 0.1924 - val_accuracy: 0.9475\n",
      "Epoch 855/1000\n",
      "67/67 [==============================] - 23s 345ms/step - loss: 0.2000 - accuracy: 0.9459 - val_loss: 0.1938 - val_accuracy: 0.9475\n",
      "Epoch 856/1000\n",
      "67/67 [==============================] - 24s 351ms/step - loss: 0.2011 - accuracy: 0.9459 - val_loss: 0.1941 - val_accuracy: 0.9475\n",
      "Epoch 857/1000\n",
      "67/67 [==============================] - 23s 341ms/step - loss: 0.1999 - accuracy: 0.9459 - val_loss: 0.1995 - val_accuracy: 0.9475\n",
      "Epoch 858/1000\n",
      "67/67 [==============================] - 23s 350ms/step - loss: 0.2006 - accuracy: 0.9459 - val_loss: 0.1931 - val_accuracy: 0.9475\n",
      "Epoch 859/1000\n",
      "67/67 [==============================] - 23s 345ms/step - loss: 0.2014 - accuracy: 0.9459 - val_loss: 0.1921 - val_accuracy: 0.9475\n",
      "Epoch 860/1000\n",
      "67/67 [==============================] - 23s 344ms/step - loss: 0.1994 - accuracy: 0.9459 - val_loss: 0.1929 - val_accuracy: 0.9475\n",
      "Epoch 861/1000\n",
      "67/67 [==============================] - 23s 347ms/step - loss: 0.1991 - accuracy: 0.9459 - val_loss: 0.2000 - val_accuracy: 0.9475\n",
      "Epoch 862/1000\n",
      "67/67 [==============================] - 23s 343ms/step - loss: 0.2004 - accuracy: 0.9459 - val_loss: 0.1942 - val_accuracy: 0.9475\n",
      "Epoch 863/1000\n",
      "67/67 [==============================] - 23s 342ms/step - loss: 0.2003 - accuracy: 0.9459 - val_loss: 0.1924 - val_accuracy: 0.9475\n",
      "Epoch 864/1000\n",
      "67/67 [==============================] - 24s 354ms/step - loss: 0.1982 - accuracy: 0.9459 - val_loss: 0.1921 - val_accuracy: 0.9475\n",
      "Epoch 865/1000\n",
      "67/67 [==============================] - 23s 340ms/step - loss: 0.2000 - accuracy: 0.9459 - val_loss: 0.1947 - val_accuracy: 0.9475\n",
      "Epoch 866/1000\n",
      "67/67 [==============================] - 23s 338ms/step - loss: 0.1997 - accuracy: 0.9459 - val_loss: 0.1920 - val_accuracy: 0.9475\n",
      "Epoch 867/1000\n",
      "67/67 [==============================] - 23s 336ms/step - loss: 0.2006 - accuracy: 0.9459 - val_loss: 0.1934 - val_accuracy: 0.9475\n",
      "Epoch 868/1000\n",
      "67/67 [==============================] - 23s 338ms/step - loss: 0.1988 - accuracy: 0.9459 - val_loss: 0.1970 - val_accuracy: 0.9475\n",
      "Epoch 869/1000\n",
      "67/67 [==============================] - 23s 337ms/step - loss: 0.1991 - accuracy: 0.9459 - val_loss: 0.1918 - val_accuracy: 0.9475\n",
      "Epoch 870/1000\n",
      "67/67 [==============================] - 23s 338ms/step - loss: 0.1991 - accuracy: 0.9459 - val_loss: 0.1941 - val_accuracy: 0.9475\n",
      "Epoch 871/1000\n",
      "67/67 [==============================] - 23s 340ms/step - loss: 0.1990 - accuracy: 0.9459 - val_loss: 0.1925 - val_accuracy: 0.9475\n",
      "Epoch 872/1000\n",
      "67/67 [==============================] - 24s 354ms/step - loss: 0.1993 - accuracy: 0.9459 - val_loss: 0.1924 - val_accuracy: 0.9475\n",
      "Epoch 873/1000\n",
      "67/67 [==============================] - 23s 344ms/step - loss: 0.1988 - accuracy: 0.9459 - val_loss: 0.1948 - val_accuracy: 0.9475\n",
      "Epoch 874/1000\n",
      "67/67 [==============================] - 23s 345ms/step - loss: 0.1999 - accuracy: 0.9459 - val_loss: 0.1941 - val_accuracy: 0.9475\n",
      "Epoch 875/1000\n",
      "67/67 [==============================] - 23s 342ms/step - loss: 0.1999 - accuracy: 0.9459 - val_loss: 0.1938 - val_accuracy: 0.9475\n",
      "Epoch 876/1000\n",
      "67/67 [==============================] - 21s 319ms/step - loss: 0.1991 - accuracy: 0.9459 - val_loss: 0.1955 - val_accuracy: 0.9475\n",
      "Epoch 877/1000\n",
      "67/67 [==============================] - 19s 281ms/step - loss: 0.2019 - accuracy: 0.9459 - val_loss: 0.1943 - val_accuracy: 0.9475\n",
      "Epoch 878/1000\n",
      "67/67 [==============================] - 19s 280ms/step - loss: 0.2020 - accuracy: 0.9459 - val_loss: 0.1934 - val_accuracy: 0.9475\n",
      "Epoch 879/1000\n",
      "67/67 [==============================] - 19s 280ms/step - loss: 0.2005 - accuracy: 0.9459 - val_loss: 0.1943 - val_accuracy: 0.9475\n",
      "Epoch 880/1000\n",
      "67/67 [==============================] - 19s 277ms/step - loss: 0.2001 - accuracy: 0.9459 - val_loss: 0.1935 - val_accuracy: 0.9475\n",
      "Epoch 881/1000\n",
      "67/67 [==============================] - 22s 331ms/step - loss: 0.2011 - accuracy: 0.9459 - val_loss: 0.1940 - val_accuracy: 0.9475\n",
      "Epoch 882/1000\n",
      "67/67 [==============================] - 23s 338ms/step - loss: 0.1993 - accuracy: 0.9459 - val_loss: 0.1931 - val_accuracy: 0.9475\n",
      "Epoch 883/1000\n",
      "67/67 [==============================] - 23s 339ms/step - loss: 0.2031 - accuracy: 0.9459 - val_loss: 0.1927 - val_accuracy: 0.9475\n",
      "Epoch 884/1000\n",
      "67/67 [==============================] - 24s 352ms/step - loss: 0.1994 - accuracy: 0.9459 - val_loss: 0.1972 - val_accuracy: 0.9475\n",
      "Epoch 885/1000\n",
      "67/67 [==============================] - 23s 344ms/step - loss: 0.2003 - accuracy: 0.9459 - val_loss: 0.1987 - val_accuracy: 0.9475\n",
      "Epoch 886/1000\n",
      "67/67 [==============================] - 23s 351ms/step - loss: 0.1999 - accuracy: 0.9459 - val_loss: 0.1925 - val_accuracy: 0.9475\n",
      "Epoch 887/1000\n",
      "67/67 [==============================] - 23s 349ms/step - loss: 0.1993 - accuracy: 0.9459 - val_loss: 0.1922 - val_accuracy: 0.9475\n",
      "Epoch 888/1000\n",
      "67/67 [==============================] - 23s 347ms/step - loss: 0.1977 - accuracy: 0.9459 - val_loss: 0.1931 - val_accuracy: 0.9475\n",
      "Epoch 889/1000\n",
      "67/67 [==============================] - 24s 364ms/step - loss: 0.1997 - accuracy: 0.9459 - val_loss: 0.1929 - val_accuracy: 0.9475\n",
      "Epoch 890/1000\n",
      "67/67 [==============================] - 23s 345ms/step - loss: 0.2000 - accuracy: 0.9459 - val_loss: 0.1925 - val_accuracy: 0.9475\n",
      "Epoch 891/1000\n",
      "67/67 [==============================] - 23s 337ms/step - loss: 0.2003 - accuracy: 0.9459 - val_loss: 0.1921 - val_accuracy: 0.9475\n",
      "Epoch 892/1000\n",
      "67/67 [==============================] - 23s 346ms/step - loss: 0.1983 - accuracy: 0.9459 - val_loss: 0.1931 - val_accuracy: 0.9475\n",
      "Epoch 893/1000\n",
      "67/67 [==============================] - 25s 367ms/step - loss: 0.2012 - accuracy: 0.9459 - val_loss: 0.1930 - val_accuracy: 0.9475\n",
      "Epoch 894/1000\n",
      "67/67 [==============================] - 28s 420ms/step - loss: 0.2005 - accuracy: 0.9459 - val_loss: 0.1927 - val_accuracy: 0.9475\n",
      "Epoch 895/1000\n",
      "67/67 [==============================] - 27s 397ms/step - loss: 0.1992 - accuracy: 0.9459 - val_loss: 0.1924 - val_accuracy: 0.9475\n",
      "Epoch 896/1000\n",
      "67/67 [==============================] - 27s 407ms/step - loss: 0.1996 - accuracy: 0.9459 - val_loss: 0.1919 - val_accuracy: 0.9475\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 897/1000\n",
      "67/67 [==============================] - 27s 404ms/step - loss: 0.2022 - accuracy: 0.9459 - val_loss: 0.1933 - val_accuracy: 0.9475\n",
      "Epoch 898/1000\n",
      "67/67 [==============================] - 27s 404ms/step - loss: 0.1998 - accuracy: 0.9459 - val_loss: 0.1928 - val_accuracy: 0.9475\n",
      "Epoch 899/1000\n",
      "67/67 [==============================] - 24s 354ms/step - loss: 0.1984 - accuracy: 0.9459 - val_loss: 0.1940 - val_accuracy: 0.9475\n",
      "Epoch 900/1000\n",
      "67/67 [==============================] - 22s 334ms/step - loss: 0.1994 - accuracy: 0.9459 - val_loss: 0.1928 - val_accuracy: 0.9475\n",
      "Epoch 901/1000\n",
      "67/67 [==============================] - 23s 337ms/step - loss: 0.2018 - accuracy: 0.9459 - val_loss: 0.1940 - val_accuracy: 0.9475\n",
      "Epoch 902/1000\n",
      "67/67 [==============================] - 23s 339ms/step - loss: 0.2000 - accuracy: 0.9459 - val_loss: 0.1928 - val_accuracy: 0.9475\n",
      "Epoch 903/1000\n",
      "67/67 [==============================] - 23s 336ms/step - loss: 0.2007 - accuracy: 0.9459 - val_loss: 0.1949 - val_accuracy: 0.9475\n",
      "Epoch 904/1000\n",
      "67/67 [==============================] - 22s 333ms/step - loss: 0.2006 - accuracy: 0.9459 - val_loss: 0.1932 - val_accuracy: 0.9475\n",
      "Epoch 905/1000\n",
      "67/67 [==============================] - 22s 334ms/step - loss: 0.1986 - accuracy: 0.9459 - val_loss: 0.1951 - val_accuracy: 0.9475\n",
      "Epoch 906/1000\n",
      "67/67 [==============================] - 22s 334ms/step - loss: 0.2006 - accuracy: 0.9459 - val_loss: 0.1930 - val_accuracy: 0.9475\n",
      "Epoch 907/1000\n",
      "67/67 [==============================] - 22s 334ms/step - loss: 0.1977 - accuracy: 0.9459 - val_loss: 0.1943 - val_accuracy: 0.9475\n",
      "Epoch 908/1000\n",
      "67/67 [==============================] - 22s 335ms/step - loss: 0.2007 - accuracy: 0.9459 - val_loss: 0.1943 - val_accuracy: 0.9475\n",
      "Epoch 909/1000\n",
      "67/67 [==============================] - 23s 338ms/step - loss: 0.1995 - accuracy: 0.9459 - val_loss: 0.1959 - val_accuracy: 0.9475\n",
      "Epoch 910/1000\n",
      "67/67 [==============================] - 22s 335ms/step - loss: 0.1987 - accuracy: 0.9459 - val_loss: 0.1927 - val_accuracy: 0.9475\n",
      "Epoch 911/1000\n",
      "67/67 [==============================] - 23s 338ms/step - loss: 0.2005 - accuracy: 0.9459 - val_loss: 0.1922 - val_accuracy: 0.9475\n",
      "Epoch 912/1000\n",
      "67/67 [==============================] - 22s 335ms/step - loss: 0.1995 - accuracy: 0.9459 - val_loss: 0.1924 - val_accuracy: 0.9475\n",
      "Epoch 913/1000\n",
      "67/67 [==============================] - 22s 331ms/step - loss: 0.2003 - accuracy: 0.9459 - val_loss: 0.1981 - val_accuracy: 0.9475\n",
      "Epoch 914/1000\n",
      "67/67 [==============================] - 23s 347ms/step - loss: 0.1999 - accuracy: 0.9459 - val_loss: 0.1920 - val_accuracy: 0.9475\n",
      "Epoch 915/1000\n",
      "67/67 [==============================] - 23s 345ms/step - loss: 0.1995 - accuracy: 0.9459 - val_loss: 0.1937 - val_accuracy: 0.9475\n",
      "Epoch 916/1000\n",
      "67/67 [==============================] - 22s 334ms/step - loss: 0.1997 - accuracy: 0.9459 - val_loss: 0.1978 - val_accuracy: 0.9475\n",
      "Epoch 917/1000\n",
      "67/67 [==============================] - 22s 335ms/step - loss: 0.1999 - accuracy: 0.9459 - val_loss: 0.1921 - val_accuracy: 0.9475\n",
      "Epoch 918/1000\n",
      "67/67 [==============================] - 22s 335ms/step - loss: 0.1994 - accuracy: 0.9459 - val_loss: 0.1963 - val_accuracy: 0.9475\n",
      "Epoch 919/1000\n",
      "67/67 [==============================] - 22s 335ms/step - loss: 0.2000 - accuracy: 0.9459 - val_loss: 0.1926 - val_accuracy: 0.9475\n",
      "Epoch 920/1000\n",
      "67/67 [==============================] - 22s 335ms/step - loss: 0.2038 - accuracy: 0.9459 - val_loss: 0.1958 - val_accuracy: 0.9475\n",
      "Epoch 921/1000\n",
      "67/67 [==============================] - 22s 335ms/step - loss: 0.1986 - accuracy: 0.9459 - val_loss: 0.1987 - val_accuracy: 0.9475\n",
      "Epoch 922/1000\n",
      "67/67 [==============================] - 22s 335ms/step - loss: 0.2003 - accuracy: 0.9459 - val_loss: 0.1923 - val_accuracy: 0.9475\n",
      "Epoch 923/1000\n",
      "67/67 [==============================] - 22s 334ms/step - loss: 0.1977 - accuracy: 0.9459 - val_loss: 0.1922 - val_accuracy: 0.9475\n",
      "Epoch 924/1000\n",
      "67/67 [==============================] - 23s 337ms/step - loss: 0.2009 - accuracy: 0.9459 - val_loss: 0.1934 - val_accuracy: 0.9475\n",
      "Epoch 925/1000\n",
      "67/67 [==============================] - 22s 335ms/step - loss: 0.2001 - accuracy: 0.9459 - val_loss: 0.1939 - val_accuracy: 0.9475\n",
      "Epoch 926/1000\n",
      "67/67 [==============================] - 22s 335ms/step - loss: 0.1982 - accuracy: 0.9459 - val_loss: 0.1943 - val_accuracy: 0.9475\n",
      "Epoch 927/1000\n",
      "67/67 [==============================] - 22s 336ms/step - loss: 0.1987 - accuracy: 0.9459 - val_loss: 0.1926 - val_accuracy: 0.9475\n",
      "Epoch 928/1000\n",
      "67/67 [==============================] - 22s 336ms/step - loss: 0.2009 - accuracy: 0.9459 - val_loss: 0.1920 - val_accuracy: 0.9475\n",
      "Epoch 929/1000\n",
      "67/67 [==============================] - 22s 335ms/step - loss: 0.1991 - accuracy: 0.9459 - val_loss: 0.1943 - val_accuracy: 0.9475\n",
      "Epoch 930/1000\n",
      "67/67 [==============================] - 22s 335ms/step - loss: 0.2001 - accuracy: 0.9459 - val_loss: 0.1931 - val_accuracy: 0.9475\n",
      "Epoch 931/1000\n",
      "67/67 [==============================] - 22s 336ms/step - loss: 0.1984 - accuracy: 0.9459 - val_loss: 0.1936 - val_accuracy: 0.9475\n",
      "Epoch 932/1000\n",
      "67/67 [==============================] - 22s 335ms/step - loss: 0.2003 - accuracy: 0.9459 - val_loss: 0.1941 - val_accuracy: 0.9475\n",
      "Epoch 933/1000\n",
      "67/67 [==============================] - 22s 335ms/step - loss: 0.2002 - accuracy: 0.9459 - val_loss: 0.2004 - val_accuracy: 0.9475\n",
      "Epoch 934/1000\n",
      "67/67 [==============================] - 23s 344ms/step - loss: 0.2006 - accuracy: 0.9459 - val_loss: 0.1927 - val_accuracy: 0.9475\n",
      "Epoch 935/1000\n",
      "67/67 [==============================] - 23s 338ms/step - loss: 0.1988 - accuracy: 0.9459 - val_loss: 0.1921 - val_accuracy: 0.9475\n",
      "Epoch 936/1000\n",
      "67/67 [==============================] - 23s 345ms/step - loss: 0.1989 - accuracy: 0.9459 - val_loss: 0.1993 - val_accuracy: 0.9475\n",
      "Epoch 937/1000\n",
      "67/67 [==============================] - 22s 334ms/step - loss: 0.1995 - accuracy: 0.9459 - val_loss: 0.1932 - val_accuracy: 0.9475\n",
      "Epoch 938/1000\n",
      "67/67 [==============================] - 22s 335ms/step - loss: 0.1982 - accuracy: 0.9459 - val_loss: 0.1920 - val_accuracy: 0.9475\n",
      "Epoch 939/1000\n",
      "67/67 [==============================] - 22s 334ms/step - loss: 0.1999 - accuracy: 0.9459 - val_loss: 0.1953 - val_accuracy: 0.9475\n",
      "Epoch 940/1000\n",
      "67/67 [==============================] - 22s 336ms/step - loss: 0.2011 - accuracy: 0.9459 - val_loss: 0.1945 - val_accuracy: 0.9475\n",
      "Epoch 941/1000\n",
      "67/67 [==============================] - 23s 338ms/step - loss: 0.2010 - accuracy: 0.9459 - val_loss: 0.1927 - val_accuracy: 0.9475\n",
      "Epoch 942/1000\n",
      "67/67 [==============================] - 23s 337ms/step - loss: 0.1986 - accuracy: 0.9459 - val_loss: 0.1928 - val_accuracy: 0.9475\n",
      "Epoch 943/1000\n",
      "67/67 [==============================] - 22s 336ms/step - loss: 0.1990 - accuracy: 0.9459 - val_loss: 0.1980 - val_accuracy: 0.9475\n",
      "Epoch 944/1000\n",
      "67/67 [==============================] - 22s 333ms/step - loss: 0.2007 - accuracy: 0.9459 - val_loss: 0.1932 - val_accuracy: 0.9475\n",
      "Epoch 945/1000\n",
      "67/67 [==============================] - 23s 337ms/step - loss: 0.1984 - accuracy: 0.9459 - val_loss: 0.1931 - val_accuracy: 0.9475\n",
      "Epoch 946/1000\n",
      "67/67 [==============================] - 23s 337ms/step - loss: 0.2014 - accuracy: 0.9459 - val_loss: 0.2009 - val_accuracy: 0.9475\n",
      "Epoch 947/1000\n",
      "67/67 [==============================] - 22s 334ms/step - loss: 0.2000 - accuracy: 0.9459 - val_loss: 0.1970 - val_accuracy: 0.9475\n",
      "Epoch 948/1000\n",
      "67/67 [==============================] - 22s 332ms/step - loss: 0.1975 - accuracy: 0.9459 - val_loss: 0.1928 - val_accuracy: 0.9475\n",
      "Epoch 949/1000\n",
      "67/67 [==============================] - 23s 339ms/step - loss: 0.2013 - accuracy: 0.9459 - val_loss: 0.1926 - val_accuracy: 0.9475\n",
      "Epoch 950/1000\n",
      "67/67 [==============================] - 22s 333ms/step - loss: 0.1986 - accuracy: 0.9459 - val_loss: 0.1917 - val_accuracy: 0.9475\n",
      "Epoch 951/1000\n",
      "67/67 [==============================] - 22s 333ms/step - loss: 0.1992 - accuracy: 0.9459 - val_loss: 0.1940 - val_accuracy: 0.9475\n",
      "Epoch 952/1000\n",
      "67/67 [==============================] - 22s 335ms/step - loss: 0.1993 - accuracy: 0.9459 - val_loss: 0.1959 - val_accuracy: 0.9475\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 953/1000\n",
      "67/67 [==============================] - 22s 335ms/step - loss: 0.1994 - accuracy: 0.9459 - val_loss: 0.1943 - val_accuracy: 0.9475\n",
      "Epoch 954/1000\n",
      "67/67 [==============================] - 22s 335ms/step - loss: 0.2020 - accuracy: 0.9459 - val_loss: 0.1928 - val_accuracy: 0.9475\n",
      "Epoch 955/1000\n",
      "67/67 [==============================] - 22s 335ms/step - loss: 0.1989 - accuracy: 0.9459 - val_loss: 0.1932 - val_accuracy: 0.9475\n",
      "Epoch 956/1000\n",
      "67/67 [==============================] - 22s 330ms/step - loss: 0.1991 - accuracy: 0.9459 - val_loss: 0.1932 - val_accuracy: 0.9475\n",
      "Epoch 957/1000\n",
      "67/67 [==============================] - 22s 333ms/step - loss: 0.1995 - accuracy: 0.9459 - val_loss: 0.1931 - val_accuracy: 0.9475\n",
      "Epoch 958/1000\n",
      "67/67 [==============================] - 23s 343ms/step - loss: 0.2005 - accuracy: 0.9459 - val_loss: 0.1919 - val_accuracy: 0.9475\n",
      "Epoch 959/1000\n",
      "67/67 [==============================] - 23s 345ms/step - loss: 0.1990 - accuracy: 0.9459 - val_loss: 0.1930 - val_accuracy: 0.9475\n",
      "Epoch 960/1000\n",
      "67/67 [==============================] - 23s 341ms/step - loss: 0.2019 - accuracy: 0.9459 - val_loss: 0.1933 - val_accuracy: 0.9475\n",
      "Epoch 961/1000\n",
      "67/67 [==============================] - 22s 336ms/step - loss: 0.1986 - accuracy: 0.9459 - val_loss: 0.1920 - val_accuracy: 0.9475\n",
      "Epoch 962/1000\n",
      "67/67 [==============================] - 22s 333ms/step - loss: 0.1993 - accuracy: 0.9459 - val_loss: 0.1926 - val_accuracy: 0.9475\n",
      "Epoch 963/1000\n",
      "67/67 [==============================] - 22s 336ms/step - loss: 0.1998 - accuracy: 0.9459 - val_loss: 0.1920 - val_accuracy: 0.9475\n",
      "Epoch 964/1000\n",
      "67/67 [==============================] - 22s 333ms/step - loss: 0.1996 - accuracy: 0.9459 - val_loss: 0.1939 - val_accuracy: 0.9475\n",
      "Epoch 965/1000\n",
      "67/67 [==============================] - 22s 335ms/step - loss: 0.2015 - accuracy: 0.9459 - val_loss: 0.1932 - val_accuracy: 0.9475\n",
      "Epoch 966/1000\n",
      "67/67 [==============================] - 22s 334ms/step - loss: 0.1994 - accuracy: 0.9459 - val_loss: 0.1928 - val_accuracy: 0.9475\n",
      "Epoch 967/1000\n",
      "67/67 [==============================] - 22s 335ms/step - loss: 0.2003 - accuracy: 0.9459 - val_loss: 0.1933 - val_accuracy: 0.9475\n",
      "Epoch 968/1000\n",
      "67/67 [==============================] - 22s 336ms/step - loss: 0.1986 - accuracy: 0.9459 - val_loss: 0.1922 - val_accuracy: 0.9475\n",
      "Epoch 969/1000\n",
      "67/67 [==============================] - 23s 337ms/step - loss: 0.1986 - accuracy: 0.9459 - val_loss: 0.1925 - val_accuracy: 0.9475\n",
      "Epoch 970/1000\n",
      "67/67 [==============================] - 22s 332ms/step - loss: 0.1995 - accuracy: 0.9459 - val_loss: 0.1925 - val_accuracy: 0.9475\n",
      "Epoch 971/1000\n",
      "67/67 [==============================] - 22s 333ms/step - loss: 0.2000 - accuracy: 0.9459 - val_loss: 0.1991 - val_accuracy: 0.9475\n",
      "Epoch 972/1000\n",
      "67/67 [==============================] - 22s 334ms/step - loss: 0.2026 - accuracy: 0.9459 - val_loss: 0.1978 - val_accuracy: 0.9475\n",
      "Epoch 973/1000\n",
      "67/67 [==============================] - 23s 336ms/step - loss: 0.1990 - accuracy: 0.9459 - val_loss: 0.1938 - val_accuracy: 0.9475\n",
      "Epoch 974/1000\n",
      "67/67 [==============================] - 23s 339ms/step - loss: 0.1994 - accuracy: 0.9459 - val_loss: 0.1931 - val_accuracy: 0.9475\n",
      "Epoch 975/1000\n",
      "67/67 [==============================] - 23s 337ms/step - loss: 0.1996 - accuracy: 0.9459 - val_loss: 0.1964 - val_accuracy: 0.9475\n",
      "Epoch 976/1000\n",
      "67/67 [==============================] - 22s 332ms/step - loss: 0.1996 - accuracy: 0.9459 - val_loss: 0.1932 - val_accuracy: 0.9475\n",
      "Epoch 977/1000\n",
      "67/67 [==============================] - 22s 334ms/step - loss: 0.1992 - accuracy: 0.9459 - val_loss: 0.1933 - val_accuracy: 0.9475\n",
      "Epoch 978/1000\n",
      "67/67 [==============================] - 22s 331ms/step - loss: 0.2003 - accuracy: 0.9459 - val_loss: 0.1990 - val_accuracy: 0.9475\n",
      "Epoch 979/1000\n",
      "67/67 [==============================] - 22s 334ms/step - loss: 0.1995 - accuracy: 0.9459 - val_loss: 0.1945 - val_accuracy: 0.9475\n",
      "Epoch 980/1000\n",
      "67/67 [==============================] - 23s 337ms/step - loss: 0.1994 - accuracy: 0.9459 - val_loss: 0.1919 - val_accuracy: 0.9475\n",
      "Epoch 981/1000\n",
      "67/67 [==============================] - 22s 334ms/step - loss: 0.1988 - accuracy: 0.9459 - val_loss: 0.1915 - val_accuracy: 0.9475\n",
      "Epoch 982/1000\n",
      "67/67 [==============================] - 22s 335ms/step - loss: 0.1982 - accuracy: 0.9459 - val_loss: 0.1960 - val_accuracy: 0.9475\n",
      "Epoch 983/1000\n",
      "67/67 [==============================] - 23s 347ms/step - loss: 0.2014 - accuracy: 0.9459 - val_loss: 0.1924 - val_accuracy: 0.9475\n",
      "Epoch 984/1000\n",
      "67/67 [==============================] - 23s 341ms/step - loss: 0.1996 - accuracy: 0.9459 - val_loss: 0.1936 - val_accuracy: 0.9475\n",
      "Epoch 985/1000\n",
      "67/67 [==============================] - 22s 334ms/step - loss: 0.1992 - accuracy: 0.9459 - val_loss: 0.1930 - val_accuracy: 0.9475\n",
      "Epoch 986/1000\n",
      "67/67 [==============================] - 22s 334ms/step - loss: 0.1989 - accuracy: 0.9459 - val_loss: 0.1925 - val_accuracy: 0.9475\n",
      "Epoch 987/1000\n",
      "67/67 [==============================] - 22s 333ms/step - loss: 0.1998 - accuracy: 0.9459 - val_loss: 0.1965 - val_accuracy: 0.9475\n",
      "Epoch 988/1000\n",
      "67/67 [==============================] - 22s 332ms/step - loss: 0.2008 - accuracy: 0.9459 - val_loss: 0.1930 - val_accuracy: 0.9475\n",
      "Epoch 989/1000\n",
      "67/67 [==============================] - 23s 337ms/step - loss: 0.1986 - accuracy: 0.9459 - val_loss: 0.1928 - val_accuracy: 0.9475\n",
      "Epoch 990/1000\n",
      "67/67 [==============================] - 22s 334ms/step - loss: 0.1987 - accuracy: 0.9459 - val_loss: 0.1930 - val_accuracy: 0.9475\n",
      "Epoch 991/1000\n",
      "67/67 [==============================] - 22s 334ms/step - loss: 0.1989 - accuracy: 0.9459 - val_loss: 0.1931 - val_accuracy: 0.9475\n",
      "Epoch 992/1000\n",
      "67/67 [==============================] - 22s 335ms/step - loss: 0.2013 - accuracy: 0.9459 - val_loss: 0.1935 - val_accuracy: 0.9475\n",
      "Epoch 993/1000\n",
      "67/67 [==============================] - 22s 334ms/step - loss: 0.2007 - accuracy: 0.9459 - val_loss: 0.1925 - val_accuracy: 0.9475\n",
      "Epoch 994/1000\n",
      "67/67 [==============================] - 22s 336ms/step - loss: 0.1991 - accuracy: 0.9459 - val_loss: 0.1936 - val_accuracy: 0.9475\n",
      "Epoch 995/1000\n",
      "67/67 [==============================] - 22s 335ms/step - loss: 0.1997 - accuracy: 0.9459 - val_loss: 0.1931 - val_accuracy: 0.9475\n",
      "Epoch 996/1000\n",
      "67/67 [==============================] - 22s 331ms/step - loss: 0.1991 - accuracy: 0.9459 - val_loss: 0.1923 - val_accuracy: 0.9475\n",
      "Epoch 997/1000\n",
      "67/67 [==============================] - 22s 333ms/step - loss: 0.1988 - accuracy: 0.9459 - val_loss: 0.1920 - val_accuracy: 0.9475\n",
      "Epoch 998/1000\n",
      "67/67 [==============================] - 22s 334ms/step - loss: 0.1995 - accuracy: 0.9459 - val_loss: 0.1918 - val_accuracy: 0.9475\n",
      "Epoch 999/1000\n",
      "67/67 [==============================] - 22s 333ms/step - loss: 0.1995 - accuracy: 0.9459 - val_loss: 0.1923 - val_accuracy: 0.9475\n",
      "Epoch 1000/1000\n",
      "67/67 [==============================] - 22s 332ms/step - loss: 0.1982 - accuracy: 0.9459 - val_loss: 0.1914 - val_accuracy: 0.9475\n"
     ]
    }
   ],
   "source": [
    "from keras.callbacks import EarlyStopping\n",
    "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=100)\n",
    "history=model.fit([X_img_train, X_audio_train], y_train, batch_size=256, epochs=1000,\n",
    "                            validation_data=([X_img_test, X_audio_test], y_test), callbacks=[es])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_hist(hist):\n",
    "    plt.plot(hist.history[\"accuracy\"])\n",
    "    plt.plot(hist.history[\"val_accuracy\"])\n",
    "    plt.title(\"model accuracy\")\n",
    "    plt.ylabel(\"accuracy\")\n",
    "    plt.xlabel(\"epoch\")\n",
    "    plt.legend([\"train\", \"validation\"], loc=\"lower right\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_loss(hist):\n",
    "    plt.plot(hist.history['loss'])\n",
    "    plt.plot(hist.history['val_loss'])\n",
    "    plt.title('model loss')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(['train', 'validation'], loc='upper right')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"utf-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       "  \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Created with matplotlib (https://matplotlib.org/) -->\n",
       "<svg height=\"277.314375pt\" version=\"1.1\" viewBox=\"0 0 388.965625 277.314375\" width=\"388.965625pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       " <metadata>\n",
       "  <rdf:RDF xmlns:cc=\"http://creativecommons.org/ns#\" xmlns:dc=\"http://purl.org/dc/elements/1.1/\" xmlns:rdf=\"http://www.w3.org/1999/02/22-rdf-syntax-ns#\">\n",
       "   <cc:Work>\n",
       "    <dc:type rdf:resource=\"http://purl.org/dc/dcmitype/StillImage\"/>\n",
       "    <dc:date>2022-04-13T08:59:56.576547</dc:date>\n",
       "    <dc:format>image/svg+xml</dc:format>\n",
       "    <dc:creator>\n",
       "     <cc:Agent>\n",
       "      <dc:title>Matplotlib v3.3.4, https://matplotlib.org/</dc:title>\n",
       "     </cc:Agent>\n",
       "    </dc:creator>\n",
       "   </cc:Work>\n",
       "  </rdf:RDF>\n",
       " </metadata>\n",
       " <defs>\n",
       "  <style type=\"text/css\">*{stroke-linecap:butt;stroke-linejoin:round;}</style>\n",
       " </defs>\n",
       " <g id=\"figure_1\">\n",
       "  <g id=\"patch_1\">\n",
       "   <path d=\"M -0 277.314375 \n",
       "L 388.965625 277.314375 \n",
       "L 388.965625 0 \n",
       "L -0 0 \n",
       "z\n",
       "\" style=\"fill:none;\"/>\n",
       "  </g>\n",
       "  <g id=\"axes_1\">\n",
       "   <g id=\"patch_2\">\n",
       "    <path d=\"M 46.965625 239.758125 \n",
       "L 381.765625 239.758125 \n",
       "L 381.765625 22.318125 \n",
       "L 46.965625 22.318125 \n",
       "z\n",
       "\" style=\"fill:#ffffff;\"/>\n",
       "   </g>\n",
       "   <g id=\"matplotlib.axis_1\">\n",
       "    <g id=\"xtick_1\">\n",
       "     <g id=\"line2d_1\">\n",
       "      <defs>\n",
       "       <path d=\"M 0 0 \n",
       "L 0 3.5 \n",
       "\" id=\"mc1659f370c\" style=\"stroke:#000000;stroke-width:0.8;\"/>\n",
       "      </defs>\n",
       "      <g>\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"62.183807\" xlink:href=\"#mc1659f370c\" y=\"239.758125\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_1\">\n",
       "      <!-- 0 -->\n",
       "      <g transform=\"translate(59.002557 254.356562)scale(0.1 -0.1)\">\n",
       "       <defs>\n",
       "        <path d=\"M 31.78125 66.40625 \n",
       "Q 24.171875 66.40625 20.328125 58.90625 \n",
       "Q 16.5 51.421875 16.5 36.375 \n",
       "Q 16.5 21.390625 20.328125 13.890625 \n",
       "Q 24.171875 6.390625 31.78125 6.390625 \n",
       "Q 39.453125 6.390625 43.28125 13.890625 \n",
       "Q 47.125 21.390625 47.125 36.375 \n",
       "Q 47.125 51.421875 43.28125 58.90625 \n",
       "Q 39.453125 66.40625 31.78125 66.40625 \n",
       "z\n",
       "M 31.78125 74.21875 \n",
       "Q 44.046875 74.21875 50.515625 64.515625 \n",
       "Q 56.984375 54.828125 56.984375 36.375 \n",
       "Q 56.984375 17.96875 50.515625 8.265625 \n",
       "Q 44.046875 -1.421875 31.78125 -1.421875 \n",
       "Q 19.53125 -1.421875 13.0625 8.265625 \n",
       "Q 6.59375 17.96875 6.59375 36.375 \n",
       "Q 6.59375 54.828125 13.0625 64.515625 \n",
       "Q 19.53125 74.21875 31.78125 74.21875 \n",
       "z\n",
       "\" id=\"DejaVuSans-48\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#DejaVuSans-48\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_2\">\n",
       "     <g id=\"line2d_2\">\n",
       "      <g>\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"123.117468\" xlink:href=\"#mc1659f370c\" y=\"239.758125\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_2\">\n",
       "      <!-- 200 -->\n",
       "      <g transform=\"translate(113.573718 254.356562)scale(0.1 -0.1)\">\n",
       "       <defs>\n",
       "        <path d=\"M 19.1875 8.296875 \n",
       "L 53.609375 8.296875 \n",
       "L 53.609375 0 \n",
       "L 7.328125 0 \n",
       "L 7.328125 8.296875 \n",
       "Q 12.9375 14.109375 22.625 23.890625 \n",
       "Q 32.328125 33.6875 34.8125 36.53125 \n",
       "Q 39.546875 41.84375 41.421875 45.53125 \n",
       "Q 43.3125 49.21875 43.3125 52.78125 \n",
       "Q 43.3125 58.59375 39.234375 62.25 \n",
       "Q 35.15625 65.921875 28.609375 65.921875 \n",
       "Q 23.96875 65.921875 18.8125 64.3125 \n",
       "Q 13.671875 62.703125 7.8125 59.421875 \n",
       "L 7.8125 69.390625 \n",
       "Q 13.765625 71.78125 18.9375 73 \n",
       "Q 24.125 74.21875 28.421875 74.21875 \n",
       "Q 39.75 74.21875 46.484375 68.546875 \n",
       "Q 53.21875 62.890625 53.21875 53.421875 \n",
       "Q 53.21875 48.921875 51.53125 44.890625 \n",
       "Q 49.859375 40.875 45.40625 35.40625 \n",
       "Q 44.1875 33.984375 37.640625 27.21875 \n",
       "Q 31.109375 20.453125 19.1875 8.296875 \n",
       "z\n",
       "\" id=\"DejaVuSans-50\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#DejaVuSans-50\"/>\n",
       "       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n",
       "       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_3\">\n",
       "     <g id=\"line2d_3\">\n",
       "      <g>\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"184.051129\" xlink:href=\"#mc1659f370c\" y=\"239.758125\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_3\">\n",
       "      <!-- 400 -->\n",
       "      <g transform=\"translate(174.507379 254.356562)scale(0.1 -0.1)\">\n",
       "       <defs>\n",
       "        <path d=\"M 37.796875 64.3125 \n",
       "L 12.890625 25.390625 \n",
       "L 37.796875 25.390625 \n",
       "z\n",
       "M 35.203125 72.90625 \n",
       "L 47.609375 72.90625 \n",
       "L 47.609375 25.390625 \n",
       "L 58.015625 25.390625 \n",
       "L 58.015625 17.1875 \n",
       "L 47.609375 17.1875 \n",
       "L 47.609375 0 \n",
       "L 37.796875 0 \n",
       "L 37.796875 17.1875 \n",
       "L 4.890625 17.1875 \n",
       "L 4.890625 26.703125 \n",
       "z\n",
       "\" id=\"DejaVuSans-52\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#DejaVuSans-52\"/>\n",
       "       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n",
       "       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_4\">\n",
       "     <g id=\"line2d_4\">\n",
       "      <g>\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"244.98479\" xlink:href=\"#mc1659f370c\" y=\"239.758125\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_4\">\n",
       "      <!-- 600 -->\n",
       "      <g transform=\"translate(235.44104 254.356562)scale(0.1 -0.1)\">\n",
       "       <defs>\n",
       "        <path d=\"M 33.015625 40.375 \n",
       "Q 26.375 40.375 22.484375 35.828125 \n",
       "Q 18.609375 31.296875 18.609375 23.390625 \n",
       "Q 18.609375 15.53125 22.484375 10.953125 \n",
       "Q 26.375 6.390625 33.015625 6.390625 \n",
       "Q 39.65625 6.390625 43.53125 10.953125 \n",
       "Q 47.40625 15.53125 47.40625 23.390625 \n",
       "Q 47.40625 31.296875 43.53125 35.828125 \n",
       "Q 39.65625 40.375 33.015625 40.375 \n",
       "z\n",
       "M 52.59375 71.296875 \n",
       "L 52.59375 62.3125 \n",
       "Q 48.875 64.0625 45.09375 64.984375 \n",
       "Q 41.3125 65.921875 37.59375 65.921875 \n",
       "Q 27.828125 65.921875 22.671875 59.328125 \n",
       "Q 17.53125 52.734375 16.796875 39.40625 \n",
       "Q 19.671875 43.65625 24.015625 45.921875 \n",
       "Q 28.375 48.1875 33.59375 48.1875 \n",
       "Q 44.578125 48.1875 50.953125 41.515625 \n",
       "Q 57.328125 34.859375 57.328125 23.390625 \n",
       "Q 57.328125 12.15625 50.6875 5.359375 \n",
       "Q 44.046875 -1.421875 33.015625 -1.421875 \n",
       "Q 20.359375 -1.421875 13.671875 8.265625 \n",
       "Q 6.984375 17.96875 6.984375 36.375 \n",
       "Q 6.984375 53.65625 15.1875 63.9375 \n",
       "Q 23.390625 74.21875 37.203125 74.21875 \n",
       "Q 40.921875 74.21875 44.703125 73.484375 \n",
       "Q 48.484375 72.75 52.59375 71.296875 \n",
       "z\n",
       "\" id=\"DejaVuSans-54\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#DejaVuSans-54\"/>\n",
       "       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n",
       "       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_5\">\n",
       "     <g id=\"line2d_5\">\n",
       "      <g>\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"305.918451\" xlink:href=\"#mc1659f370c\" y=\"239.758125\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_5\">\n",
       "      <!-- 800 -->\n",
       "      <g transform=\"translate(296.374701 254.356562)scale(0.1 -0.1)\">\n",
       "       <defs>\n",
       "        <path d=\"M 31.78125 34.625 \n",
       "Q 24.75 34.625 20.71875 30.859375 \n",
       "Q 16.703125 27.09375 16.703125 20.515625 \n",
       "Q 16.703125 13.921875 20.71875 10.15625 \n",
       "Q 24.75 6.390625 31.78125 6.390625 \n",
       "Q 38.8125 6.390625 42.859375 10.171875 \n",
       "Q 46.921875 13.96875 46.921875 20.515625 \n",
       "Q 46.921875 27.09375 42.890625 30.859375 \n",
       "Q 38.875 34.625 31.78125 34.625 \n",
       "z\n",
       "M 21.921875 38.8125 \n",
       "Q 15.578125 40.375 12.03125 44.71875 \n",
       "Q 8.5 49.078125 8.5 55.328125 \n",
       "Q 8.5 64.0625 14.71875 69.140625 \n",
       "Q 20.953125 74.21875 31.78125 74.21875 \n",
       "Q 42.671875 74.21875 48.875 69.140625 \n",
       "Q 55.078125 64.0625 55.078125 55.328125 \n",
       "Q 55.078125 49.078125 51.53125 44.71875 \n",
       "Q 48 40.375 41.703125 38.8125 \n",
       "Q 48.828125 37.15625 52.796875 32.3125 \n",
       "Q 56.78125 27.484375 56.78125 20.515625 \n",
       "Q 56.78125 9.90625 50.3125 4.234375 \n",
       "Q 43.84375 -1.421875 31.78125 -1.421875 \n",
       "Q 19.734375 -1.421875 13.25 4.234375 \n",
       "Q 6.78125 9.90625 6.78125 20.515625 \n",
       "Q 6.78125 27.484375 10.78125 32.3125 \n",
       "Q 14.796875 37.15625 21.921875 38.8125 \n",
       "z\n",
       "M 18.3125 54.390625 \n",
       "Q 18.3125 48.734375 21.84375 45.5625 \n",
       "Q 25.390625 42.390625 31.78125 42.390625 \n",
       "Q 38.140625 42.390625 41.71875 45.5625 \n",
       "Q 45.3125 48.734375 45.3125 54.390625 \n",
       "Q 45.3125 60.0625 41.71875 63.234375 \n",
       "Q 38.140625 66.40625 31.78125 66.40625 \n",
       "Q 25.390625 66.40625 21.84375 63.234375 \n",
       "Q 18.3125 60.0625 18.3125 54.390625 \n",
       "z\n",
       "\" id=\"DejaVuSans-56\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#DejaVuSans-56\"/>\n",
       "       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n",
       "       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_6\">\n",
       "     <g id=\"line2d_6\">\n",
       "      <g>\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"366.852111\" xlink:href=\"#mc1659f370c\" y=\"239.758125\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_6\">\n",
       "      <!-- 1000 -->\n",
       "      <g transform=\"translate(354.127111 254.356562)scale(0.1 -0.1)\">\n",
       "       <defs>\n",
       "        <path d=\"M 12.40625 8.296875 \n",
       "L 28.515625 8.296875 \n",
       "L 28.515625 63.921875 \n",
       "L 10.984375 60.40625 \n",
       "L 10.984375 69.390625 \n",
       "L 28.421875 72.90625 \n",
       "L 38.28125 72.90625 \n",
       "L 38.28125 8.296875 \n",
       "L 54.390625 8.296875 \n",
       "L 54.390625 0 \n",
       "L 12.40625 0 \n",
       "z\n",
       "\" id=\"DejaVuSans-49\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#DejaVuSans-49\"/>\n",
       "       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n",
       "       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\n",
       "       <use x=\"190.869141\" xlink:href=\"#DejaVuSans-48\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"text_7\">\n",
       "     <!-- Epoch -->\n",
       "     <g transform=\"translate(199.054688 268.034687)scale(0.1 -0.1)\">\n",
       "      <defs>\n",
       "       <path d=\"M 9.8125 72.90625 \n",
       "L 55.90625 72.90625 \n",
       "L 55.90625 64.59375 \n",
       "L 19.671875 64.59375 \n",
       "L 19.671875 43.015625 \n",
       "L 54.390625 43.015625 \n",
       "L 54.390625 34.71875 \n",
       "L 19.671875 34.71875 \n",
       "L 19.671875 8.296875 \n",
       "L 56.78125 8.296875 \n",
       "L 56.78125 0 \n",
       "L 9.8125 0 \n",
       "z\n",
       "\" id=\"DejaVuSans-69\"/>\n",
       "       <path d=\"M 18.109375 8.203125 \n",
       "L 18.109375 -20.796875 \n",
       "L 9.078125 -20.796875 \n",
       "L 9.078125 54.6875 \n",
       "L 18.109375 54.6875 \n",
       "L 18.109375 46.390625 \n",
       "Q 20.953125 51.265625 25.265625 53.625 \n",
       "Q 29.59375 56 35.59375 56 \n",
       "Q 45.5625 56 51.78125 48.09375 \n",
       "Q 58.015625 40.1875 58.015625 27.296875 \n",
       "Q 58.015625 14.40625 51.78125 6.484375 \n",
       "Q 45.5625 -1.421875 35.59375 -1.421875 \n",
       "Q 29.59375 -1.421875 25.265625 0.953125 \n",
       "Q 20.953125 3.328125 18.109375 8.203125 \n",
       "z\n",
       "M 48.6875 27.296875 \n",
       "Q 48.6875 37.203125 44.609375 42.84375 \n",
       "Q 40.53125 48.484375 33.40625 48.484375 \n",
       "Q 26.265625 48.484375 22.1875 42.84375 \n",
       "Q 18.109375 37.203125 18.109375 27.296875 \n",
       "Q 18.109375 17.390625 22.1875 11.75 \n",
       "Q 26.265625 6.109375 33.40625 6.109375 \n",
       "Q 40.53125 6.109375 44.609375 11.75 \n",
       "Q 48.6875 17.390625 48.6875 27.296875 \n",
       "z\n",
       "\" id=\"DejaVuSans-112\"/>\n",
       "       <path d=\"M 30.609375 48.390625 \n",
       "Q 23.390625 48.390625 19.1875 42.75 \n",
       "Q 14.984375 37.109375 14.984375 27.296875 \n",
       "Q 14.984375 17.484375 19.15625 11.84375 \n",
       "Q 23.34375 6.203125 30.609375 6.203125 \n",
       "Q 37.796875 6.203125 41.984375 11.859375 \n",
       "Q 46.1875 17.53125 46.1875 27.296875 \n",
       "Q 46.1875 37.015625 41.984375 42.703125 \n",
       "Q 37.796875 48.390625 30.609375 48.390625 \n",
       "z\n",
       "M 30.609375 56 \n",
       "Q 42.328125 56 49.015625 48.375 \n",
       "Q 55.71875 40.765625 55.71875 27.296875 \n",
       "Q 55.71875 13.875 49.015625 6.21875 \n",
       "Q 42.328125 -1.421875 30.609375 -1.421875 \n",
       "Q 18.84375 -1.421875 12.171875 6.21875 \n",
       "Q 5.515625 13.875 5.515625 27.296875 \n",
       "Q 5.515625 40.765625 12.171875 48.375 \n",
       "Q 18.84375 56 30.609375 56 \n",
       "z\n",
       "\" id=\"DejaVuSans-111\"/>\n",
       "       <path d=\"M 48.78125 52.59375 \n",
       "L 48.78125 44.1875 \n",
       "Q 44.96875 46.296875 41.140625 47.34375 \n",
       "Q 37.3125 48.390625 33.40625 48.390625 \n",
       "Q 24.65625 48.390625 19.8125 42.84375 \n",
       "Q 14.984375 37.3125 14.984375 27.296875 \n",
       "Q 14.984375 17.28125 19.8125 11.734375 \n",
       "Q 24.65625 6.203125 33.40625 6.203125 \n",
       "Q 37.3125 6.203125 41.140625 7.25 \n",
       "Q 44.96875 8.296875 48.78125 10.40625 \n",
       "L 48.78125 2.09375 \n",
       "Q 45.015625 0.34375 40.984375 -0.53125 \n",
       "Q 36.96875 -1.421875 32.421875 -1.421875 \n",
       "Q 20.0625 -1.421875 12.78125 6.34375 \n",
       "Q 5.515625 14.109375 5.515625 27.296875 \n",
       "Q 5.515625 40.671875 12.859375 48.328125 \n",
       "Q 20.21875 56 33.015625 56 \n",
       "Q 37.15625 56 41.109375 55.140625 \n",
       "Q 45.0625 54.296875 48.78125 52.59375 \n",
       "z\n",
       "\" id=\"DejaVuSans-99\"/>\n",
       "       <path d=\"M 54.890625 33.015625 \n",
       "L 54.890625 0 \n",
       "L 45.90625 0 \n",
       "L 45.90625 32.71875 \n",
       "Q 45.90625 40.484375 42.875 44.328125 \n",
       "Q 39.84375 48.1875 33.796875 48.1875 \n",
       "Q 26.515625 48.1875 22.3125 43.546875 \n",
       "Q 18.109375 38.921875 18.109375 30.90625 \n",
       "L 18.109375 0 \n",
       "L 9.078125 0 \n",
       "L 9.078125 75.984375 \n",
       "L 18.109375 75.984375 \n",
       "L 18.109375 46.1875 \n",
       "Q 21.34375 51.125 25.703125 53.5625 \n",
       "Q 30.078125 56 35.796875 56 \n",
       "Q 45.21875 56 50.046875 50.171875 \n",
       "Q 54.890625 44.34375 54.890625 33.015625 \n",
       "z\n",
       "\" id=\"DejaVuSans-104\"/>\n",
       "      </defs>\n",
       "      <use xlink:href=\"#DejaVuSans-69\"/>\n",
       "      <use x=\"63.183594\" xlink:href=\"#DejaVuSans-112\"/>\n",
       "      <use x=\"126.660156\" xlink:href=\"#DejaVuSans-111\"/>\n",
       "      <use x=\"187.841797\" xlink:href=\"#DejaVuSans-99\"/>\n",
       "      <use x=\"242.822266\" xlink:href=\"#DejaVuSans-104\"/>\n",
       "     </g>\n",
       "    </g>\n",
       "   </g>\n",
       "   <g id=\"matplotlib.axis_2\">\n",
       "    <g id=\"ytick_1\">\n",
       "     <g id=\"line2d_7\">\n",
       "      <defs>\n",
       "       <path d=\"M 0 0 \n",
       "L -3.5 0 \n",
       "\" id=\"md8b4d747c4\" style=\"stroke:#000000;stroke-width:0.8;\"/>\n",
       "      </defs>\n",
       "      <g>\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"46.965625\" xlink:href=\"#md8b4d747c4\" y=\"230.133718\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_8\">\n",
       "      <!-- 0 -->\n",
       "      <g transform=\"translate(33.603125 233.932936)scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-48\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_2\">\n",
       "     <g id=\"line2d_8\">\n",
       "      <g>\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"46.965625\" xlink:href=\"#md8b4d747c4\" y=\"203.041958\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_9\">\n",
       "      <!-- 20 -->\n",
       "      <g transform=\"translate(27.240625 206.841177)scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-50\"/>\n",
       "       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_3\">\n",
       "     <g id=\"line2d_9\">\n",
       "      <g>\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"46.965625\" xlink:href=\"#md8b4d747c4\" y=\"175.950198\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_10\">\n",
       "      <!-- 40 -->\n",
       "      <g transform=\"translate(27.240625 179.749417)scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-52\"/>\n",
       "       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_4\">\n",
       "     <g id=\"line2d_10\">\n",
       "      <g>\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"46.965625\" xlink:href=\"#md8b4d747c4\" y=\"148.858438\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_11\">\n",
       "      <!-- 60 -->\n",
       "      <g transform=\"translate(27.240625 152.657657)scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-54\"/>\n",
       "       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_5\">\n",
       "     <g id=\"line2d_11\">\n",
       "      <g>\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"46.965625\" xlink:href=\"#md8b4d747c4\" y=\"121.766678\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_12\">\n",
       "      <!-- 80 -->\n",
       "      <g transform=\"translate(27.240625 125.565897)scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-56\"/>\n",
       "       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_6\">\n",
       "     <g id=\"line2d_12\">\n",
       "      <g>\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"46.965625\" xlink:href=\"#md8b4d747c4\" y=\"94.674919\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_13\">\n",
       "      <!-- 100 -->\n",
       "      <g transform=\"translate(20.878125 98.474137)scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-49\"/>\n",
       "       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n",
       "       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_7\">\n",
       "     <g id=\"line2d_13\">\n",
       "      <g>\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"46.965625\" xlink:href=\"#md8b4d747c4\" y=\"67.583159\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_14\">\n",
       "      <!-- 120 -->\n",
       "      <g transform=\"translate(20.878125 71.382378)scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-49\"/>\n",
       "       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-50\"/>\n",
       "       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_8\">\n",
       "     <g id=\"line2d_14\">\n",
       "      <g>\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"46.965625\" xlink:href=\"#md8b4d747c4\" y=\"40.491399\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_15\">\n",
       "      <!-- 140 -->\n",
       "      <g transform=\"translate(20.878125 44.290618)scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-49\"/>\n",
       "       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-52\"/>\n",
       "       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"text_16\">\n",
       "     <!-- Loss -->\n",
       "     <g transform=\"translate(14.798438 142.005312)rotate(-90)scale(0.1 -0.1)\">\n",
       "      <defs>\n",
       "       <path d=\"M 9.8125 72.90625 \n",
       "L 19.671875 72.90625 \n",
       "L 19.671875 8.296875 \n",
       "L 55.171875 8.296875 \n",
       "L 55.171875 0 \n",
       "L 9.8125 0 \n",
       "z\n",
       "\" id=\"DejaVuSans-76\"/>\n",
       "       <path d=\"M 44.28125 53.078125 \n",
       "L 44.28125 44.578125 \n",
       "Q 40.484375 46.53125 36.375 47.5 \n",
       "Q 32.28125 48.484375 27.875 48.484375 \n",
       "Q 21.1875 48.484375 17.84375 46.4375 \n",
       "Q 14.5 44.390625 14.5 40.28125 \n",
       "Q 14.5 37.15625 16.890625 35.375 \n",
       "Q 19.28125 33.59375 26.515625 31.984375 \n",
       "L 29.59375 31.296875 \n",
       "Q 39.15625 29.25 43.1875 25.515625 \n",
       "Q 47.21875 21.78125 47.21875 15.09375 \n",
       "Q 47.21875 7.46875 41.1875 3.015625 \n",
       "Q 35.15625 -1.421875 24.609375 -1.421875 \n",
       "Q 20.21875 -1.421875 15.453125 -0.5625 \n",
       "Q 10.6875 0.296875 5.421875 2 \n",
       "L 5.421875 11.28125 \n",
       "Q 10.40625 8.6875 15.234375 7.390625 \n",
       "Q 20.0625 6.109375 24.8125 6.109375 \n",
       "Q 31.15625 6.109375 34.5625 8.28125 \n",
       "Q 37.984375 10.453125 37.984375 14.40625 \n",
       "Q 37.984375 18.0625 35.515625 20.015625 \n",
       "Q 33.0625 21.96875 24.703125 23.78125 \n",
       "L 21.578125 24.515625 \n",
       "Q 13.234375 26.265625 9.515625 29.90625 \n",
       "Q 5.8125 33.546875 5.8125 39.890625 \n",
       "Q 5.8125 47.609375 11.28125 51.796875 \n",
       "Q 16.75 56 26.8125 56 \n",
       "Q 31.78125 56 36.171875 55.265625 \n",
       "Q 40.578125 54.546875 44.28125 53.078125 \n",
       "z\n",
       "\" id=\"DejaVuSans-115\"/>\n",
       "      </defs>\n",
       "      <use xlink:href=\"#DejaVuSans-76\"/>\n",
       "      <use x=\"53.962891\" xlink:href=\"#DejaVuSans-111\"/>\n",
       "      <use x=\"115.144531\" xlink:href=\"#DejaVuSans-115\"/>\n",
       "      <use x=\"167.244141\" xlink:href=\"#DejaVuSans-115\"/>\n",
       "     </g>\n",
       "    </g>\n",
       "   </g>\n",
       "   <g id=\"line2d_15\">\n",
       "    <path clip-path=\"url(#p62fb7c4089)\" d=\"M 62.183807 32.201761 \n",
       "L 62.488475 170.388933 \n",
       "L 62.793143 189.355314 \n",
       "L 63.097812 198.696155 \n",
       "L 63.40248 203.775953 \n",
       "L 64.011817 209.392244 \n",
       "L 64.621153 212.461811 \n",
       "L 65.23049 214.462441 \n",
       "L 65.839826 215.610269 \n",
       "L 66.449163 216.721464 \n",
       "L 68.277173 218.824875 \n",
       "L 69.495846 219.828509 \n",
       "L 70.105183 219.94605 \n",
       "L 70.714519 220.399093 \n",
       "L 71.019188 220.599393 \n",
       "L 71.323856 220.396658 \n",
       "L 71.628524 221.309222 \n",
       "L 72.542529 222.06476 \n",
       "L 74.370539 223.225893 \n",
       "L 76.198549 224.190271 \n",
       "L 77.72189 224.914249 \n",
       "L 82.901252 226.837562 \n",
       "L 88.080613 228.259581 \n",
       "L 93.564642 229.172268 \n",
       "L 99.048672 229.640476 \n",
       "L 106.056043 229.82317 \n",
       "L 121.594126 229.856903 \n",
       "L 188.621153 229.858418 \n",
       "L 237.67275 229.861377 \n",
       "L 242.547443 229.859778 \n",
       "L 257.47619 229.859939 \n",
       "L 313.23049 229.863084 \n",
       "L 329.37791 229.86004 \n",
       "L 345.829998 229.86234 \n",
       "L 366.547443 229.865203 \n",
       "L 366.547443 229.865203 \n",
       "\" style=\"fill:none;stroke:#1f77b4;stroke-linecap:square;stroke-width:1.5;\"/>\n",
       "   </g>\n",
       "   <g id=\"line2d_16\">\n",
       "    <path clip-path=\"url(#p62fb7c4089)\" d=\"M 62.183807 174.227359 \n",
       "L 62.488475 188.762439 \n",
       "L 63.097812 201.66336 \n",
       "L 63.40248 205.708002 \n",
       "L 64.011817 210.533498 \n",
       "L 64.621153 212.933559 \n",
       "L 65.23049 214.924033 \n",
       "L 65.535158 215.241645 \n",
       "L 65.839826 216.016837 \n",
       "L 66.144495 216.376107 \n",
       "L 66.753831 217.357844 \n",
       "L 67.972505 218.64112 \n",
       "L 68.581841 219.215207 \n",
       "L 69.800514 220.249425 \n",
       "L 70.105183 220.137005 \n",
       "L 70.409851 220.322459 \n",
       "L 71.019188 220.984532 \n",
       "L 71.323856 221.061072 \n",
       "L 71.933193 221.743467 \n",
       "L 74.675207 223.520642 \n",
       "L 74.979876 223.588702 \n",
       "L 75.589212 224.011148 \n",
       "L 77.417222 224.853843 \n",
       "L 78.331227 225.234161 \n",
       "L 82.901252 226.899338 \n",
       "L 89.603954 228.62016 \n",
       "L 93.259974 229.149619 \n",
       "L 95.69732 229.434489 \n",
       "L 99.962677 229.693269 \n",
       "L 104.837369 229.818375 \n",
       "L 107.884053 229.838782 \n",
       "L 117.938107 229.862124 \n",
       "L 294.036387 229.869905 \n",
       "L 308.355797 229.870366 \n",
       "L 355.274716 229.873617 \n",
       "L 366.547443 229.874489 \n",
       "L 366.547443 229.874489 \n",
       "\" style=\"fill:none;stroke:#ff7f0e;stroke-linecap:square;stroke-width:1.5;\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_3\">\n",
       "    <path d=\"M 46.965625 239.758125 \n",
       "L 46.965625 22.318125 \n",
       "\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_4\">\n",
       "    <path d=\"M 381.765625 239.758125 \n",
       "L 381.765625 22.318125 \n",
       "\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_5\">\n",
       "    <path d=\"M 46.965625 239.758125 \n",
       "L 381.765625 239.758125 \n",
       "\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_6\">\n",
       "    <path d=\"M 46.965625 22.318125 \n",
       "L 381.765625 22.318125 \n",
       "\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n",
       "   </g>\n",
       "   <g id=\"text_17\">\n",
       "    <!-- model loss -->\n",
       "    <g transform=\"translate(182.185938 16.318125)scale(0.12 -0.12)\">\n",
       "     <defs>\n",
       "      <path d=\"M 52 44.1875 \n",
       "Q 55.375 50.25 60.0625 53.125 \n",
       "Q 64.75 56 71.09375 56 \n",
       "Q 79.640625 56 84.28125 50.015625 \n",
       "Q 88.921875 44.046875 88.921875 33.015625 \n",
       "L 88.921875 0 \n",
       "L 79.890625 0 \n",
       "L 79.890625 32.71875 \n",
       "Q 79.890625 40.578125 77.09375 44.375 \n",
       "Q 74.3125 48.1875 68.609375 48.1875 \n",
       "Q 61.625 48.1875 57.5625 43.546875 \n",
       "Q 53.515625 38.921875 53.515625 30.90625 \n",
       "L 53.515625 0 \n",
       "L 44.484375 0 \n",
       "L 44.484375 32.71875 \n",
       "Q 44.484375 40.625 41.703125 44.40625 \n",
       "Q 38.921875 48.1875 33.109375 48.1875 \n",
       "Q 26.21875 48.1875 22.15625 43.53125 \n",
       "Q 18.109375 38.875 18.109375 30.90625 \n",
       "L 18.109375 0 \n",
       "L 9.078125 0 \n",
       "L 9.078125 54.6875 \n",
       "L 18.109375 54.6875 \n",
       "L 18.109375 46.1875 \n",
       "Q 21.1875 51.21875 25.484375 53.609375 \n",
       "Q 29.78125 56 35.6875 56 \n",
       "Q 41.65625 56 45.828125 52.96875 \n",
       "Q 50 49.953125 52 44.1875 \n",
       "z\n",
       "\" id=\"DejaVuSans-109\"/>\n",
       "      <path d=\"M 45.40625 46.390625 \n",
       "L 45.40625 75.984375 \n",
       "L 54.390625 75.984375 \n",
       "L 54.390625 0 \n",
       "L 45.40625 0 \n",
       "L 45.40625 8.203125 \n",
       "Q 42.578125 3.328125 38.25 0.953125 \n",
       "Q 33.9375 -1.421875 27.875 -1.421875 \n",
       "Q 17.96875 -1.421875 11.734375 6.484375 \n",
       "Q 5.515625 14.40625 5.515625 27.296875 \n",
       "Q 5.515625 40.1875 11.734375 48.09375 \n",
       "Q 17.96875 56 27.875 56 \n",
       "Q 33.9375 56 38.25 53.625 \n",
       "Q 42.578125 51.265625 45.40625 46.390625 \n",
       "z\n",
       "M 14.796875 27.296875 \n",
       "Q 14.796875 17.390625 18.875 11.75 \n",
       "Q 22.953125 6.109375 30.078125 6.109375 \n",
       "Q 37.203125 6.109375 41.296875 11.75 \n",
       "Q 45.40625 17.390625 45.40625 27.296875 \n",
       "Q 45.40625 37.203125 41.296875 42.84375 \n",
       "Q 37.203125 48.484375 30.078125 48.484375 \n",
       "Q 22.953125 48.484375 18.875 42.84375 \n",
       "Q 14.796875 37.203125 14.796875 27.296875 \n",
       "z\n",
       "\" id=\"DejaVuSans-100\"/>\n",
       "      <path d=\"M 56.203125 29.59375 \n",
       "L 56.203125 25.203125 \n",
       "L 14.890625 25.203125 \n",
       "Q 15.484375 15.921875 20.484375 11.0625 \n",
       "Q 25.484375 6.203125 34.421875 6.203125 \n",
       "Q 39.59375 6.203125 44.453125 7.46875 \n",
       "Q 49.3125 8.734375 54.109375 11.28125 \n",
       "L 54.109375 2.78125 \n",
       "Q 49.265625 0.734375 44.1875 -0.34375 \n",
       "Q 39.109375 -1.421875 33.890625 -1.421875 \n",
       "Q 20.796875 -1.421875 13.15625 6.1875 \n",
       "Q 5.515625 13.8125 5.515625 26.8125 \n",
       "Q 5.515625 40.234375 12.765625 48.109375 \n",
       "Q 20.015625 56 32.328125 56 \n",
       "Q 43.359375 56 49.78125 48.890625 \n",
       "Q 56.203125 41.796875 56.203125 29.59375 \n",
       "z\n",
       "M 47.21875 32.234375 \n",
       "Q 47.125 39.59375 43.09375 43.984375 \n",
       "Q 39.0625 48.390625 32.421875 48.390625 \n",
       "Q 24.90625 48.390625 20.390625 44.140625 \n",
       "Q 15.875 39.890625 15.1875 32.171875 \n",
       "z\n",
       "\" id=\"DejaVuSans-101\"/>\n",
       "      <path d=\"M 9.421875 75.984375 \n",
       "L 18.40625 75.984375 \n",
       "L 18.40625 0 \n",
       "L 9.421875 0 \n",
       "z\n",
       "\" id=\"DejaVuSans-108\"/>\n",
       "      <path id=\"DejaVuSans-32\"/>\n",
       "     </defs>\n",
       "     <use xlink:href=\"#DejaVuSans-109\"/>\n",
       "     <use x=\"97.412109\" xlink:href=\"#DejaVuSans-111\"/>\n",
       "     <use x=\"158.59375\" xlink:href=\"#DejaVuSans-100\"/>\n",
       "     <use x=\"222.070312\" xlink:href=\"#DejaVuSans-101\"/>\n",
       "     <use x=\"283.59375\" xlink:href=\"#DejaVuSans-108\"/>\n",
       "     <use x=\"311.376953\" xlink:href=\"#DejaVuSans-32\"/>\n",
       "     <use x=\"343.164062\" xlink:href=\"#DejaVuSans-108\"/>\n",
       "     <use x=\"370.947266\" xlink:href=\"#DejaVuSans-111\"/>\n",
       "     <use x=\"432.128906\" xlink:href=\"#DejaVuSans-115\"/>\n",
       "     <use x=\"484.228516\" xlink:href=\"#DejaVuSans-115\"/>\n",
       "    </g>\n",
       "   </g>\n",
       "   <g id=\"legend_1\">\n",
       "    <g id=\"patch_7\">\n",
       "     <path d=\"M 293.53125 59.674375 \n",
       "L 374.765625 59.674375 \n",
       "Q 376.765625 59.674375 376.765625 57.674375 \n",
       "L 376.765625 29.318125 \n",
       "Q 376.765625 27.318125 374.765625 27.318125 \n",
       "L 293.53125 27.318125 \n",
       "Q 291.53125 27.318125 291.53125 29.318125 \n",
       "L 291.53125 57.674375 \n",
       "Q 291.53125 59.674375 293.53125 59.674375 \n",
       "z\n",
       "\" style=\"fill:#ffffff;opacity:0.8;stroke:#cccccc;stroke-linejoin:miter;\"/>\n",
       "    </g>\n",
       "    <g id=\"line2d_17\">\n",
       "     <path d=\"M 295.53125 35.416562 \n",
       "L 315.53125 35.416562 \n",
       "\" style=\"fill:none;stroke:#1f77b4;stroke-linecap:square;stroke-width:1.5;\"/>\n",
       "    </g>\n",
       "    <g id=\"line2d_18\"/>\n",
       "    <g id=\"text_18\">\n",
       "     <!-- train -->\n",
       "     <g transform=\"translate(323.53125 38.916562)scale(0.1 -0.1)\">\n",
       "      <defs>\n",
       "       <path d=\"M 18.3125 70.21875 \n",
       "L 18.3125 54.6875 \n",
       "L 36.8125 54.6875 \n",
       "L 36.8125 47.703125 \n",
       "L 18.3125 47.703125 \n",
       "L 18.3125 18.015625 \n",
       "Q 18.3125 11.328125 20.140625 9.421875 \n",
       "Q 21.96875 7.515625 27.59375 7.515625 \n",
       "L 36.8125 7.515625 \n",
       "L 36.8125 0 \n",
       "L 27.59375 0 \n",
       "Q 17.1875 0 13.234375 3.875 \n",
       "Q 9.28125 7.765625 9.28125 18.015625 \n",
       "L 9.28125 47.703125 \n",
       "L 2.6875 47.703125 \n",
       "L 2.6875 54.6875 \n",
       "L 9.28125 54.6875 \n",
       "L 9.28125 70.21875 \n",
       "z\n",
       "\" id=\"DejaVuSans-116\"/>\n",
       "       <path d=\"M 41.109375 46.296875 \n",
       "Q 39.59375 47.171875 37.8125 47.578125 \n",
       "Q 36.03125 48 33.890625 48 \n",
       "Q 26.265625 48 22.1875 43.046875 \n",
       "Q 18.109375 38.09375 18.109375 28.8125 \n",
       "L 18.109375 0 \n",
       "L 9.078125 0 \n",
       "L 9.078125 54.6875 \n",
       "L 18.109375 54.6875 \n",
       "L 18.109375 46.1875 \n",
       "Q 20.953125 51.171875 25.484375 53.578125 \n",
       "Q 30.03125 56 36.53125 56 \n",
       "Q 37.453125 56 38.578125 55.875 \n",
       "Q 39.703125 55.765625 41.0625 55.515625 \n",
       "z\n",
       "\" id=\"DejaVuSans-114\"/>\n",
       "       <path d=\"M 34.28125 27.484375 \n",
       "Q 23.390625 27.484375 19.1875 25 \n",
       "Q 14.984375 22.515625 14.984375 16.5 \n",
       "Q 14.984375 11.71875 18.140625 8.90625 \n",
       "Q 21.296875 6.109375 26.703125 6.109375 \n",
       "Q 34.1875 6.109375 38.703125 11.40625 \n",
       "Q 43.21875 16.703125 43.21875 25.484375 \n",
       "L 43.21875 27.484375 \n",
       "z\n",
       "M 52.203125 31.203125 \n",
       "L 52.203125 0 \n",
       "L 43.21875 0 \n",
       "L 43.21875 8.296875 \n",
       "Q 40.140625 3.328125 35.546875 0.953125 \n",
       "Q 30.953125 -1.421875 24.3125 -1.421875 \n",
       "Q 15.921875 -1.421875 10.953125 3.296875 \n",
       "Q 6 8.015625 6 15.921875 \n",
       "Q 6 25.140625 12.171875 29.828125 \n",
       "Q 18.359375 34.515625 30.609375 34.515625 \n",
       "L 43.21875 34.515625 \n",
       "L 43.21875 35.40625 \n",
       "Q 43.21875 41.609375 39.140625 45 \n",
       "Q 35.0625 48.390625 27.6875 48.390625 \n",
       "Q 23 48.390625 18.546875 47.265625 \n",
       "Q 14.109375 46.140625 10.015625 43.890625 \n",
       "L 10.015625 52.203125 \n",
       "Q 14.9375 54.109375 19.578125 55.046875 \n",
       "Q 24.21875 56 28.609375 56 \n",
       "Q 40.484375 56 46.34375 49.84375 \n",
       "Q 52.203125 43.703125 52.203125 31.203125 \n",
       "z\n",
       "\" id=\"DejaVuSans-97\"/>\n",
       "       <path d=\"M 9.421875 54.6875 \n",
       "L 18.40625 54.6875 \n",
       "L 18.40625 0 \n",
       "L 9.421875 0 \n",
       "z\n",
       "M 9.421875 75.984375 \n",
       "L 18.40625 75.984375 \n",
       "L 18.40625 64.59375 \n",
       "L 9.421875 64.59375 \n",
       "z\n",
       "\" id=\"DejaVuSans-105\"/>\n",
       "       <path d=\"M 54.890625 33.015625 \n",
       "L 54.890625 0 \n",
       "L 45.90625 0 \n",
       "L 45.90625 32.71875 \n",
       "Q 45.90625 40.484375 42.875 44.328125 \n",
       "Q 39.84375 48.1875 33.796875 48.1875 \n",
       "Q 26.515625 48.1875 22.3125 43.546875 \n",
       "Q 18.109375 38.921875 18.109375 30.90625 \n",
       "L 18.109375 0 \n",
       "L 9.078125 0 \n",
       "L 9.078125 54.6875 \n",
       "L 18.109375 54.6875 \n",
       "L 18.109375 46.1875 \n",
       "Q 21.34375 51.125 25.703125 53.5625 \n",
       "Q 30.078125 56 35.796875 56 \n",
       "Q 45.21875 56 50.046875 50.171875 \n",
       "Q 54.890625 44.34375 54.890625 33.015625 \n",
       "z\n",
       "\" id=\"DejaVuSans-110\"/>\n",
       "      </defs>\n",
       "      <use xlink:href=\"#DejaVuSans-116\"/>\n",
       "      <use x=\"39.208984\" xlink:href=\"#DejaVuSans-114\"/>\n",
       "      <use x=\"80.322266\" xlink:href=\"#DejaVuSans-97\"/>\n",
       "      <use x=\"141.601562\" xlink:href=\"#DejaVuSans-105\"/>\n",
       "      <use x=\"169.384766\" xlink:href=\"#DejaVuSans-110\"/>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"line2d_19\">\n",
       "     <path d=\"M 295.53125 50.094687 \n",
       "L 315.53125 50.094687 \n",
       "\" style=\"fill:none;stroke:#ff7f0e;stroke-linecap:square;stroke-width:1.5;\"/>\n",
       "    </g>\n",
       "    <g id=\"line2d_20\"/>\n",
       "    <g id=\"text_19\">\n",
       "     <!-- validation -->\n",
       "     <g transform=\"translate(323.53125 53.594687)scale(0.1 -0.1)\">\n",
       "      <defs>\n",
       "       <path d=\"M 2.984375 54.6875 \n",
       "L 12.5 54.6875 \n",
       "L 29.59375 8.796875 \n",
       "L 46.6875 54.6875 \n",
       "L 56.203125 54.6875 \n",
       "L 35.6875 0 \n",
       "L 23.484375 0 \n",
       "z\n",
       "\" id=\"DejaVuSans-118\"/>\n",
       "      </defs>\n",
       "      <use xlink:href=\"#DejaVuSans-118\"/>\n",
       "      <use x=\"59.179688\" xlink:href=\"#DejaVuSans-97\"/>\n",
       "      <use x=\"120.458984\" xlink:href=\"#DejaVuSans-108\"/>\n",
       "      <use x=\"148.242188\" xlink:href=\"#DejaVuSans-105\"/>\n",
       "      <use x=\"176.025391\" xlink:href=\"#DejaVuSans-100\"/>\n",
       "      <use x=\"239.501953\" xlink:href=\"#DejaVuSans-97\"/>\n",
       "      <use x=\"300.78125\" xlink:href=\"#DejaVuSans-116\"/>\n",
       "      <use x=\"339.990234\" xlink:href=\"#DejaVuSans-105\"/>\n",
       "      <use x=\"367.773438\" xlink:href=\"#DejaVuSans-111\"/>\n",
       "      <use x=\"428.955078\" xlink:href=\"#DejaVuSans-110\"/>\n",
       "     </g>\n",
       "    </g>\n",
       "   </g>\n",
       "  </g>\n",
       " </g>\n",
       " <defs>\n",
       "  <clipPath id=\"p62fb7c4089\">\n",
       "   <rect height=\"217.44\" width=\"334.8\" x=\"46.965625\" y=\"22.318125\"/>\n",
       "  </clipPath>\n",
       " </defs>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_loss(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"utf-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       "  \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Created with matplotlib (https://matplotlib.org/) -->\n",
       "<svg height=\"277.314375pt\" version=\"1.1\" viewBox=\"0 0 392.14375 277.314375\" width=\"392.14375pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       " <metadata>\n",
       "  <rdf:RDF xmlns:cc=\"http://creativecommons.org/ns#\" xmlns:dc=\"http://purl.org/dc/elements/1.1/\" xmlns:rdf=\"http://www.w3.org/1999/02/22-rdf-syntax-ns#\">\n",
       "   <cc:Work>\n",
       "    <dc:type rdf:resource=\"http://purl.org/dc/dcmitype/StillImage\"/>\n",
       "    <dc:date>2022-04-13T09:00:01.669416</dc:date>\n",
       "    <dc:format>image/svg+xml</dc:format>\n",
       "    <dc:creator>\n",
       "     <cc:Agent>\n",
       "      <dc:title>Matplotlib v3.3.4, https://matplotlib.org/</dc:title>\n",
       "     </cc:Agent>\n",
       "    </dc:creator>\n",
       "   </cc:Work>\n",
       "  </rdf:RDF>\n",
       " </metadata>\n",
       " <defs>\n",
       "  <style type=\"text/css\">*{stroke-linecap:butt;stroke-linejoin:round;}</style>\n",
       " </defs>\n",
       " <g id=\"figure_1\">\n",
       "  <g id=\"patch_1\">\n",
       "   <path d=\"M 0 277.314375 \n",
       "L 392.14375 277.314375 \n",
       "L 392.14375 0 \n",
       "L 0 0 \n",
       "z\n",
       "\" style=\"fill:none;\"/>\n",
       "  </g>\n",
       "  <g id=\"axes_1\">\n",
       "   <g id=\"patch_2\">\n",
       "    <path d=\"M 50.14375 239.758125 \n",
       "L 384.94375 239.758125 \n",
       "L 384.94375 22.318125 \n",
       "L 50.14375 22.318125 \n",
       "z\n",
       "\" style=\"fill:#ffffff;\"/>\n",
       "   </g>\n",
       "   <g id=\"matplotlib.axis_1\">\n",
       "    <g id=\"xtick_1\">\n",
       "     <g id=\"line2d_1\">\n",
       "      <defs>\n",
       "       <path d=\"M 0 0 \n",
       "L 0 3.5 \n",
       "\" id=\"mdec01dc89a\" style=\"stroke:#000000;stroke-width:0.8;\"/>\n",
       "      </defs>\n",
       "      <g>\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"65.361932\" xlink:href=\"#mdec01dc89a\" y=\"239.758125\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_1\">\n",
       "      <!-- 0 -->\n",
       "      <g transform=\"translate(62.180682 254.356562)scale(0.1 -0.1)\">\n",
       "       <defs>\n",
       "        <path d=\"M 31.78125 66.40625 \n",
       "Q 24.171875 66.40625 20.328125 58.90625 \n",
       "Q 16.5 51.421875 16.5 36.375 \n",
       "Q 16.5 21.390625 20.328125 13.890625 \n",
       "Q 24.171875 6.390625 31.78125 6.390625 \n",
       "Q 39.453125 6.390625 43.28125 13.890625 \n",
       "Q 47.125 21.390625 47.125 36.375 \n",
       "Q 47.125 51.421875 43.28125 58.90625 \n",
       "Q 39.453125 66.40625 31.78125 66.40625 \n",
       "z\n",
       "M 31.78125 74.21875 \n",
       "Q 44.046875 74.21875 50.515625 64.515625 \n",
       "Q 56.984375 54.828125 56.984375 36.375 \n",
       "Q 56.984375 17.96875 50.515625 8.265625 \n",
       "Q 44.046875 -1.421875 31.78125 -1.421875 \n",
       "Q 19.53125 -1.421875 13.0625 8.265625 \n",
       "Q 6.59375 17.96875 6.59375 36.375 \n",
       "Q 6.59375 54.828125 13.0625 64.515625 \n",
       "Q 19.53125 74.21875 31.78125 74.21875 \n",
       "z\n",
       "\" id=\"DejaVuSans-48\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#DejaVuSans-48\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_2\">\n",
       "     <g id=\"line2d_2\">\n",
       "      <g>\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"126.295593\" xlink:href=\"#mdec01dc89a\" y=\"239.758125\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_2\">\n",
       "      <!-- 200 -->\n",
       "      <g transform=\"translate(116.751843 254.356562)scale(0.1 -0.1)\">\n",
       "       <defs>\n",
       "        <path d=\"M 19.1875 8.296875 \n",
       "L 53.609375 8.296875 \n",
       "L 53.609375 0 \n",
       "L 7.328125 0 \n",
       "L 7.328125 8.296875 \n",
       "Q 12.9375 14.109375 22.625 23.890625 \n",
       "Q 32.328125 33.6875 34.8125 36.53125 \n",
       "Q 39.546875 41.84375 41.421875 45.53125 \n",
       "Q 43.3125 49.21875 43.3125 52.78125 \n",
       "Q 43.3125 58.59375 39.234375 62.25 \n",
       "Q 35.15625 65.921875 28.609375 65.921875 \n",
       "Q 23.96875 65.921875 18.8125 64.3125 \n",
       "Q 13.671875 62.703125 7.8125 59.421875 \n",
       "L 7.8125 69.390625 \n",
       "Q 13.765625 71.78125 18.9375 73 \n",
       "Q 24.125 74.21875 28.421875 74.21875 \n",
       "Q 39.75 74.21875 46.484375 68.546875 \n",
       "Q 53.21875 62.890625 53.21875 53.421875 \n",
       "Q 53.21875 48.921875 51.53125 44.890625 \n",
       "Q 49.859375 40.875 45.40625 35.40625 \n",
       "Q 44.1875 33.984375 37.640625 27.21875 \n",
       "Q 31.109375 20.453125 19.1875 8.296875 \n",
       "z\n",
       "\" id=\"DejaVuSans-50\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#DejaVuSans-50\"/>\n",
       "       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n",
       "       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_3\">\n",
       "     <g id=\"line2d_3\">\n",
       "      <g>\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"187.229254\" xlink:href=\"#mdec01dc89a\" y=\"239.758125\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_3\">\n",
       "      <!-- 400 -->\n",
       "      <g transform=\"translate(177.685504 254.356562)scale(0.1 -0.1)\">\n",
       "       <defs>\n",
       "        <path d=\"M 37.796875 64.3125 \n",
       "L 12.890625 25.390625 \n",
       "L 37.796875 25.390625 \n",
       "z\n",
       "M 35.203125 72.90625 \n",
       "L 47.609375 72.90625 \n",
       "L 47.609375 25.390625 \n",
       "L 58.015625 25.390625 \n",
       "L 58.015625 17.1875 \n",
       "L 47.609375 17.1875 \n",
       "L 47.609375 0 \n",
       "L 37.796875 0 \n",
       "L 37.796875 17.1875 \n",
       "L 4.890625 17.1875 \n",
       "L 4.890625 26.703125 \n",
       "z\n",
       "\" id=\"DejaVuSans-52\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#DejaVuSans-52\"/>\n",
       "       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n",
       "       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_4\">\n",
       "     <g id=\"line2d_4\">\n",
       "      <g>\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"248.162915\" xlink:href=\"#mdec01dc89a\" y=\"239.758125\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_4\">\n",
       "      <!-- 600 -->\n",
       "      <g transform=\"translate(238.619165 254.356562)scale(0.1 -0.1)\">\n",
       "       <defs>\n",
       "        <path d=\"M 33.015625 40.375 \n",
       "Q 26.375 40.375 22.484375 35.828125 \n",
       "Q 18.609375 31.296875 18.609375 23.390625 \n",
       "Q 18.609375 15.53125 22.484375 10.953125 \n",
       "Q 26.375 6.390625 33.015625 6.390625 \n",
       "Q 39.65625 6.390625 43.53125 10.953125 \n",
       "Q 47.40625 15.53125 47.40625 23.390625 \n",
       "Q 47.40625 31.296875 43.53125 35.828125 \n",
       "Q 39.65625 40.375 33.015625 40.375 \n",
       "z\n",
       "M 52.59375 71.296875 \n",
       "L 52.59375 62.3125 \n",
       "Q 48.875 64.0625 45.09375 64.984375 \n",
       "Q 41.3125 65.921875 37.59375 65.921875 \n",
       "Q 27.828125 65.921875 22.671875 59.328125 \n",
       "Q 17.53125 52.734375 16.796875 39.40625 \n",
       "Q 19.671875 43.65625 24.015625 45.921875 \n",
       "Q 28.375 48.1875 33.59375 48.1875 \n",
       "Q 44.578125 48.1875 50.953125 41.515625 \n",
       "Q 57.328125 34.859375 57.328125 23.390625 \n",
       "Q 57.328125 12.15625 50.6875 5.359375 \n",
       "Q 44.046875 -1.421875 33.015625 -1.421875 \n",
       "Q 20.359375 -1.421875 13.671875 8.265625 \n",
       "Q 6.984375 17.96875 6.984375 36.375 \n",
       "Q 6.984375 53.65625 15.1875 63.9375 \n",
       "Q 23.390625 74.21875 37.203125 74.21875 \n",
       "Q 40.921875 74.21875 44.703125 73.484375 \n",
       "Q 48.484375 72.75 52.59375 71.296875 \n",
       "z\n",
       "\" id=\"DejaVuSans-54\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#DejaVuSans-54\"/>\n",
       "       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n",
       "       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_5\">\n",
       "     <g id=\"line2d_5\">\n",
       "      <g>\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"309.096576\" xlink:href=\"#mdec01dc89a\" y=\"239.758125\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_5\">\n",
       "      <!-- 800 -->\n",
       "      <g transform=\"translate(299.552826 254.356562)scale(0.1 -0.1)\">\n",
       "       <defs>\n",
       "        <path d=\"M 31.78125 34.625 \n",
       "Q 24.75 34.625 20.71875 30.859375 \n",
       "Q 16.703125 27.09375 16.703125 20.515625 \n",
       "Q 16.703125 13.921875 20.71875 10.15625 \n",
       "Q 24.75 6.390625 31.78125 6.390625 \n",
       "Q 38.8125 6.390625 42.859375 10.171875 \n",
       "Q 46.921875 13.96875 46.921875 20.515625 \n",
       "Q 46.921875 27.09375 42.890625 30.859375 \n",
       "Q 38.875 34.625 31.78125 34.625 \n",
       "z\n",
       "M 21.921875 38.8125 \n",
       "Q 15.578125 40.375 12.03125 44.71875 \n",
       "Q 8.5 49.078125 8.5 55.328125 \n",
       "Q 8.5 64.0625 14.71875 69.140625 \n",
       "Q 20.953125 74.21875 31.78125 74.21875 \n",
       "Q 42.671875 74.21875 48.875 69.140625 \n",
       "Q 55.078125 64.0625 55.078125 55.328125 \n",
       "Q 55.078125 49.078125 51.53125 44.71875 \n",
       "Q 48 40.375 41.703125 38.8125 \n",
       "Q 48.828125 37.15625 52.796875 32.3125 \n",
       "Q 56.78125 27.484375 56.78125 20.515625 \n",
       "Q 56.78125 9.90625 50.3125 4.234375 \n",
       "Q 43.84375 -1.421875 31.78125 -1.421875 \n",
       "Q 19.734375 -1.421875 13.25 4.234375 \n",
       "Q 6.78125 9.90625 6.78125 20.515625 \n",
       "Q 6.78125 27.484375 10.78125 32.3125 \n",
       "Q 14.796875 37.15625 21.921875 38.8125 \n",
       "z\n",
       "M 18.3125 54.390625 \n",
       "Q 18.3125 48.734375 21.84375 45.5625 \n",
       "Q 25.390625 42.390625 31.78125 42.390625 \n",
       "Q 38.140625 42.390625 41.71875 45.5625 \n",
       "Q 45.3125 48.734375 45.3125 54.390625 \n",
       "Q 45.3125 60.0625 41.71875 63.234375 \n",
       "Q 38.140625 66.40625 31.78125 66.40625 \n",
       "Q 25.390625 66.40625 21.84375 63.234375 \n",
       "Q 18.3125 60.0625 18.3125 54.390625 \n",
       "z\n",
       "\" id=\"DejaVuSans-56\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#DejaVuSans-56\"/>\n",
       "       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n",
       "       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_6\">\n",
       "     <g id=\"line2d_6\">\n",
       "      <g>\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"370.030236\" xlink:href=\"#mdec01dc89a\" y=\"239.758125\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_6\">\n",
       "      <!-- 1000 -->\n",
       "      <g transform=\"translate(357.305236 254.356562)scale(0.1 -0.1)\">\n",
       "       <defs>\n",
       "        <path d=\"M 12.40625 8.296875 \n",
       "L 28.515625 8.296875 \n",
       "L 28.515625 63.921875 \n",
       "L 10.984375 60.40625 \n",
       "L 10.984375 69.390625 \n",
       "L 28.421875 72.90625 \n",
       "L 38.28125 72.90625 \n",
       "L 38.28125 8.296875 \n",
       "L 54.390625 8.296875 \n",
       "L 54.390625 0 \n",
       "L 12.40625 0 \n",
       "z\n",
       "\" id=\"DejaVuSans-49\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#DejaVuSans-49\"/>\n",
       "       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n",
       "       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\n",
       "       <use x=\"190.869141\" xlink:href=\"#DejaVuSans-48\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"text_7\">\n",
       "     <!-- epoch -->\n",
       "     <g transform=\"translate(202.315625 268.034687)scale(0.1 -0.1)\">\n",
       "      <defs>\n",
       "       <path d=\"M 56.203125 29.59375 \n",
       "L 56.203125 25.203125 \n",
       "L 14.890625 25.203125 \n",
       "Q 15.484375 15.921875 20.484375 11.0625 \n",
       "Q 25.484375 6.203125 34.421875 6.203125 \n",
       "Q 39.59375 6.203125 44.453125 7.46875 \n",
       "Q 49.3125 8.734375 54.109375 11.28125 \n",
       "L 54.109375 2.78125 \n",
       "Q 49.265625 0.734375 44.1875 -0.34375 \n",
       "Q 39.109375 -1.421875 33.890625 -1.421875 \n",
       "Q 20.796875 -1.421875 13.15625 6.1875 \n",
       "Q 5.515625 13.8125 5.515625 26.8125 \n",
       "Q 5.515625 40.234375 12.765625 48.109375 \n",
       "Q 20.015625 56 32.328125 56 \n",
       "Q 43.359375 56 49.78125 48.890625 \n",
       "Q 56.203125 41.796875 56.203125 29.59375 \n",
       "z\n",
       "M 47.21875 32.234375 \n",
       "Q 47.125 39.59375 43.09375 43.984375 \n",
       "Q 39.0625 48.390625 32.421875 48.390625 \n",
       "Q 24.90625 48.390625 20.390625 44.140625 \n",
       "Q 15.875 39.890625 15.1875 32.171875 \n",
       "z\n",
       "\" id=\"DejaVuSans-101\"/>\n",
       "       <path d=\"M 18.109375 8.203125 \n",
       "L 18.109375 -20.796875 \n",
       "L 9.078125 -20.796875 \n",
       "L 9.078125 54.6875 \n",
       "L 18.109375 54.6875 \n",
       "L 18.109375 46.390625 \n",
       "Q 20.953125 51.265625 25.265625 53.625 \n",
       "Q 29.59375 56 35.59375 56 \n",
       "Q 45.5625 56 51.78125 48.09375 \n",
       "Q 58.015625 40.1875 58.015625 27.296875 \n",
       "Q 58.015625 14.40625 51.78125 6.484375 \n",
       "Q 45.5625 -1.421875 35.59375 -1.421875 \n",
       "Q 29.59375 -1.421875 25.265625 0.953125 \n",
       "Q 20.953125 3.328125 18.109375 8.203125 \n",
       "z\n",
       "M 48.6875 27.296875 \n",
       "Q 48.6875 37.203125 44.609375 42.84375 \n",
       "Q 40.53125 48.484375 33.40625 48.484375 \n",
       "Q 26.265625 48.484375 22.1875 42.84375 \n",
       "Q 18.109375 37.203125 18.109375 27.296875 \n",
       "Q 18.109375 17.390625 22.1875 11.75 \n",
       "Q 26.265625 6.109375 33.40625 6.109375 \n",
       "Q 40.53125 6.109375 44.609375 11.75 \n",
       "Q 48.6875 17.390625 48.6875 27.296875 \n",
       "z\n",
       "\" id=\"DejaVuSans-112\"/>\n",
       "       <path d=\"M 30.609375 48.390625 \n",
       "Q 23.390625 48.390625 19.1875 42.75 \n",
       "Q 14.984375 37.109375 14.984375 27.296875 \n",
       "Q 14.984375 17.484375 19.15625 11.84375 \n",
       "Q 23.34375 6.203125 30.609375 6.203125 \n",
       "Q 37.796875 6.203125 41.984375 11.859375 \n",
       "Q 46.1875 17.53125 46.1875 27.296875 \n",
       "Q 46.1875 37.015625 41.984375 42.703125 \n",
       "Q 37.796875 48.390625 30.609375 48.390625 \n",
       "z\n",
       "M 30.609375 56 \n",
       "Q 42.328125 56 49.015625 48.375 \n",
       "Q 55.71875 40.765625 55.71875 27.296875 \n",
       "Q 55.71875 13.875 49.015625 6.21875 \n",
       "Q 42.328125 -1.421875 30.609375 -1.421875 \n",
       "Q 18.84375 -1.421875 12.171875 6.21875 \n",
       "Q 5.515625 13.875 5.515625 27.296875 \n",
       "Q 5.515625 40.765625 12.171875 48.375 \n",
       "Q 18.84375 56 30.609375 56 \n",
       "z\n",
       "\" id=\"DejaVuSans-111\"/>\n",
       "       <path d=\"M 48.78125 52.59375 \n",
       "L 48.78125 44.1875 \n",
       "Q 44.96875 46.296875 41.140625 47.34375 \n",
       "Q 37.3125 48.390625 33.40625 48.390625 \n",
       "Q 24.65625 48.390625 19.8125 42.84375 \n",
       "Q 14.984375 37.3125 14.984375 27.296875 \n",
       "Q 14.984375 17.28125 19.8125 11.734375 \n",
       "Q 24.65625 6.203125 33.40625 6.203125 \n",
       "Q 37.3125 6.203125 41.140625 7.25 \n",
       "Q 44.96875 8.296875 48.78125 10.40625 \n",
       "L 48.78125 2.09375 \n",
       "Q 45.015625 0.34375 40.984375 -0.53125 \n",
       "Q 36.96875 -1.421875 32.421875 -1.421875 \n",
       "Q 20.0625 -1.421875 12.78125 6.34375 \n",
       "Q 5.515625 14.109375 5.515625 27.296875 \n",
       "Q 5.515625 40.671875 12.859375 48.328125 \n",
       "Q 20.21875 56 33.015625 56 \n",
       "Q 37.15625 56 41.109375 55.140625 \n",
       "Q 45.0625 54.296875 48.78125 52.59375 \n",
       "z\n",
       "\" id=\"DejaVuSans-99\"/>\n",
       "       <path d=\"M 54.890625 33.015625 \n",
       "L 54.890625 0 \n",
       "L 45.90625 0 \n",
       "L 45.90625 32.71875 \n",
       "Q 45.90625 40.484375 42.875 44.328125 \n",
       "Q 39.84375 48.1875 33.796875 48.1875 \n",
       "Q 26.515625 48.1875 22.3125 43.546875 \n",
       "Q 18.109375 38.921875 18.109375 30.90625 \n",
       "L 18.109375 0 \n",
       "L 9.078125 0 \n",
       "L 9.078125 75.984375 \n",
       "L 18.109375 75.984375 \n",
       "L 18.109375 46.1875 \n",
       "Q 21.34375 51.125 25.703125 53.5625 \n",
       "Q 30.078125 56 35.796875 56 \n",
       "Q 45.21875 56 50.046875 50.171875 \n",
       "Q 54.890625 44.34375 54.890625 33.015625 \n",
       "z\n",
       "\" id=\"DejaVuSans-104\"/>\n",
       "      </defs>\n",
       "      <use xlink:href=\"#DejaVuSans-101\"/>\n",
       "      <use x=\"61.523438\" xlink:href=\"#DejaVuSans-112\"/>\n",
       "      <use x=\"125\" xlink:href=\"#DejaVuSans-111\"/>\n",
       "      <use x=\"186.181641\" xlink:href=\"#DejaVuSans-99\"/>\n",
       "      <use x=\"241.162109\" xlink:href=\"#DejaVuSans-104\"/>\n",
       "     </g>\n",
       "    </g>\n",
       "   </g>\n",
       "   <g id=\"matplotlib.axis_2\">\n",
       "    <g id=\"ytick_1\">\n",
       "     <g id=\"line2d_7\">\n",
       "      <defs>\n",
       "       <path d=\"M 0 0 \n",
       "L -3.5 0 \n",
       "\" id=\"md9ba7103e1\" style=\"stroke:#000000;stroke-width:0.8;\"/>\n",
       "      </defs>\n",
       "      <g>\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"50.14375\" xlink:href=\"#md9ba7103e1\" y=\"211.88918\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_8\">\n",
       "      <!-- 0.90 -->\n",
       "      <g transform=\"translate(20.878125 215.688398)scale(0.1 -0.1)\">\n",
       "       <defs>\n",
       "        <path d=\"M 10.6875 12.40625 \n",
       "L 21 12.40625 \n",
       "L 21 0 \n",
       "L 10.6875 0 \n",
       "z\n",
       "\" id=\"DejaVuSans-46\"/>\n",
       "        <path d=\"M 10.984375 1.515625 \n",
       "L 10.984375 10.5 \n",
       "Q 14.703125 8.734375 18.5 7.8125 \n",
       "Q 22.3125 6.890625 25.984375 6.890625 \n",
       "Q 35.75 6.890625 40.890625 13.453125 \n",
       "Q 46.046875 20.015625 46.78125 33.40625 \n",
       "Q 43.953125 29.203125 39.59375 26.953125 \n",
       "Q 35.25 24.703125 29.984375 24.703125 \n",
       "Q 19.046875 24.703125 12.671875 31.3125 \n",
       "Q 6.296875 37.9375 6.296875 49.421875 \n",
       "Q 6.296875 60.640625 12.9375 67.421875 \n",
       "Q 19.578125 74.21875 30.609375 74.21875 \n",
       "Q 43.265625 74.21875 49.921875 64.515625 \n",
       "Q 56.59375 54.828125 56.59375 36.375 \n",
       "Q 56.59375 19.140625 48.40625 8.859375 \n",
       "Q 40.234375 -1.421875 26.421875 -1.421875 \n",
       "Q 22.703125 -1.421875 18.890625 -0.6875 \n",
       "Q 15.09375 0.046875 10.984375 1.515625 \n",
       "z\n",
       "M 30.609375 32.421875 \n",
       "Q 37.25 32.421875 41.125 36.953125 \n",
       "Q 45.015625 41.5 45.015625 49.421875 \n",
       "Q 45.015625 57.28125 41.125 61.84375 \n",
       "Q 37.25 66.40625 30.609375 66.40625 \n",
       "Q 23.96875 66.40625 20.09375 61.84375 \n",
       "Q 16.21875 57.28125 16.21875 49.421875 \n",
       "Q 16.21875 41.5 20.09375 36.953125 \n",
       "Q 23.96875 32.421875 30.609375 32.421875 \n",
       "z\n",
       "\" id=\"DejaVuSans-57\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#DejaVuSans-48\"/>\n",
       "       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n",
       "       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-57\"/>\n",
       "       <use x=\"159.033203\" xlink:href=\"#DejaVuSans-48\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_2\">\n",
       "     <g id=\"line2d_8\">\n",
       "      <g>\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"50.14375\" xlink:href=\"#md9ba7103e1\" y=\"174.093489\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_9\">\n",
       "      <!-- 0.91 -->\n",
       "      <g transform=\"translate(20.878125 177.892707)scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-48\"/>\n",
       "       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n",
       "       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-57\"/>\n",
       "       <use x=\"159.033203\" xlink:href=\"#DejaVuSans-49\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_3\">\n",
       "     <g id=\"line2d_9\">\n",
       "      <g>\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"50.14375\" xlink:href=\"#md9ba7103e1\" y=\"136.297797\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_10\">\n",
       "      <!-- 0.92 -->\n",
       "      <g transform=\"translate(20.878125 140.097016)scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-48\"/>\n",
       "       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n",
       "       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-57\"/>\n",
       "       <use x=\"159.033203\" xlink:href=\"#DejaVuSans-50\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_4\">\n",
       "     <g id=\"line2d_10\">\n",
       "      <g>\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"50.14375\" xlink:href=\"#md9ba7103e1\" y=\"98.502106\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_11\">\n",
       "      <!-- 0.93 -->\n",
       "      <g transform=\"translate(20.878125 102.301325)scale(0.1 -0.1)\">\n",
       "       <defs>\n",
       "        <path d=\"M 40.578125 39.3125 \n",
       "Q 47.65625 37.796875 51.625 33 \n",
       "Q 55.609375 28.21875 55.609375 21.1875 \n",
       "Q 55.609375 10.40625 48.1875 4.484375 \n",
       "Q 40.765625 -1.421875 27.09375 -1.421875 \n",
       "Q 22.515625 -1.421875 17.65625 -0.515625 \n",
       "Q 12.796875 0.390625 7.625 2.203125 \n",
       "L 7.625 11.71875 \n",
       "Q 11.71875 9.328125 16.59375 8.109375 \n",
       "Q 21.484375 6.890625 26.8125 6.890625 \n",
       "Q 36.078125 6.890625 40.9375 10.546875 \n",
       "Q 45.796875 14.203125 45.796875 21.1875 \n",
       "Q 45.796875 27.640625 41.28125 31.265625 \n",
       "Q 36.765625 34.90625 28.71875 34.90625 \n",
       "L 20.21875 34.90625 \n",
       "L 20.21875 43.015625 \n",
       "L 29.109375 43.015625 \n",
       "Q 36.375 43.015625 40.234375 45.921875 \n",
       "Q 44.09375 48.828125 44.09375 54.296875 \n",
       "Q 44.09375 59.90625 40.109375 62.90625 \n",
       "Q 36.140625 65.921875 28.71875 65.921875 \n",
       "Q 24.65625 65.921875 20.015625 65.03125 \n",
       "Q 15.375 64.15625 9.8125 62.3125 \n",
       "L 9.8125 71.09375 \n",
       "Q 15.4375 72.65625 20.34375 73.4375 \n",
       "Q 25.25 74.21875 29.59375 74.21875 \n",
       "Q 40.828125 74.21875 47.359375 69.109375 \n",
       "Q 53.90625 64.015625 53.90625 55.328125 \n",
       "Q 53.90625 49.265625 50.4375 45.09375 \n",
       "Q 46.96875 40.921875 40.578125 39.3125 \n",
       "z\n",
       "\" id=\"DejaVuSans-51\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#DejaVuSans-48\"/>\n",
       "       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n",
       "       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-57\"/>\n",
       "       <use x=\"159.033203\" xlink:href=\"#DejaVuSans-51\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_5\">\n",
       "     <g id=\"line2d_11\">\n",
       "      <g>\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"50.14375\" xlink:href=\"#md9ba7103e1\" y=\"60.706415\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_12\">\n",
       "      <!-- 0.94 -->\n",
       "      <g transform=\"translate(20.878125 64.505634)scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-48\"/>\n",
       "       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n",
       "       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-57\"/>\n",
       "       <use x=\"159.033203\" xlink:href=\"#DejaVuSans-52\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_6\">\n",
       "     <g id=\"line2d_12\">\n",
       "      <g>\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"50.14375\" xlink:href=\"#md9ba7103e1\" y=\"22.910724\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_13\">\n",
       "      <!-- 0.95 -->\n",
       "      <g transform=\"translate(20.878125 26.709942)scale(0.1 -0.1)\">\n",
       "       <defs>\n",
       "        <path d=\"M 10.796875 72.90625 \n",
       "L 49.515625 72.90625 \n",
       "L 49.515625 64.59375 \n",
       "L 19.828125 64.59375 \n",
       "L 19.828125 46.734375 \n",
       "Q 21.96875 47.46875 24.109375 47.828125 \n",
       "Q 26.265625 48.1875 28.421875 48.1875 \n",
       "Q 40.625 48.1875 47.75 41.5 \n",
       "Q 54.890625 34.8125 54.890625 23.390625 \n",
       "Q 54.890625 11.625 47.5625 5.09375 \n",
       "Q 40.234375 -1.421875 26.90625 -1.421875 \n",
       "Q 22.3125 -1.421875 17.546875 -0.640625 \n",
       "Q 12.796875 0.140625 7.71875 1.703125 \n",
       "L 7.71875 11.625 \n",
       "Q 12.109375 9.234375 16.796875 8.0625 \n",
       "Q 21.484375 6.890625 26.703125 6.890625 \n",
       "Q 35.15625 6.890625 40.078125 11.328125 \n",
       "Q 45.015625 15.765625 45.015625 23.390625 \n",
       "Q 45.015625 31 40.078125 35.4375 \n",
       "Q 35.15625 39.890625 26.703125 39.890625 \n",
       "Q 22.75 39.890625 18.8125 39.015625 \n",
       "Q 14.890625 38.140625 10.796875 36.28125 \n",
       "z\n",
       "\" id=\"DejaVuSans-53\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#DejaVuSans-48\"/>\n",
       "       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n",
       "       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-57\"/>\n",
       "       <use x=\"159.033203\" xlink:href=\"#DejaVuSans-53\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"text_14\">\n",
       "     <!-- accuracy -->\n",
       "     <g transform=\"translate(14.798438 153.5975)rotate(-90)scale(0.1 -0.1)\">\n",
       "      <defs>\n",
       "       <path d=\"M 34.28125 27.484375 \n",
       "Q 23.390625 27.484375 19.1875 25 \n",
       "Q 14.984375 22.515625 14.984375 16.5 \n",
       "Q 14.984375 11.71875 18.140625 8.90625 \n",
       "Q 21.296875 6.109375 26.703125 6.109375 \n",
       "Q 34.1875 6.109375 38.703125 11.40625 \n",
       "Q 43.21875 16.703125 43.21875 25.484375 \n",
       "L 43.21875 27.484375 \n",
       "z\n",
       "M 52.203125 31.203125 \n",
       "L 52.203125 0 \n",
       "L 43.21875 0 \n",
       "L 43.21875 8.296875 \n",
       "Q 40.140625 3.328125 35.546875 0.953125 \n",
       "Q 30.953125 -1.421875 24.3125 -1.421875 \n",
       "Q 15.921875 -1.421875 10.953125 3.296875 \n",
       "Q 6 8.015625 6 15.921875 \n",
       "Q 6 25.140625 12.171875 29.828125 \n",
       "Q 18.359375 34.515625 30.609375 34.515625 \n",
       "L 43.21875 34.515625 \n",
       "L 43.21875 35.40625 \n",
       "Q 43.21875 41.609375 39.140625 45 \n",
       "Q 35.0625 48.390625 27.6875 48.390625 \n",
       "Q 23 48.390625 18.546875 47.265625 \n",
       "Q 14.109375 46.140625 10.015625 43.890625 \n",
       "L 10.015625 52.203125 \n",
       "Q 14.9375 54.109375 19.578125 55.046875 \n",
       "Q 24.21875 56 28.609375 56 \n",
       "Q 40.484375 56 46.34375 49.84375 \n",
       "Q 52.203125 43.703125 52.203125 31.203125 \n",
       "z\n",
       "\" id=\"DejaVuSans-97\"/>\n",
       "       <path d=\"M 8.5 21.578125 \n",
       "L 8.5 54.6875 \n",
       "L 17.484375 54.6875 \n",
       "L 17.484375 21.921875 \n",
       "Q 17.484375 14.15625 20.5 10.265625 \n",
       "Q 23.53125 6.390625 29.59375 6.390625 \n",
       "Q 36.859375 6.390625 41.078125 11.03125 \n",
       "Q 45.3125 15.671875 45.3125 23.6875 \n",
       "L 45.3125 54.6875 \n",
       "L 54.296875 54.6875 \n",
       "L 54.296875 0 \n",
       "L 45.3125 0 \n",
       "L 45.3125 8.40625 \n",
       "Q 42.046875 3.421875 37.71875 1 \n",
       "Q 33.40625 -1.421875 27.6875 -1.421875 \n",
       "Q 18.265625 -1.421875 13.375 4.4375 \n",
       "Q 8.5 10.296875 8.5 21.578125 \n",
       "z\n",
       "M 31.109375 56 \n",
       "z\n",
       "\" id=\"DejaVuSans-117\"/>\n",
       "       <path d=\"M 41.109375 46.296875 \n",
       "Q 39.59375 47.171875 37.8125 47.578125 \n",
       "Q 36.03125 48 33.890625 48 \n",
       "Q 26.265625 48 22.1875 43.046875 \n",
       "Q 18.109375 38.09375 18.109375 28.8125 \n",
       "L 18.109375 0 \n",
       "L 9.078125 0 \n",
       "L 9.078125 54.6875 \n",
       "L 18.109375 54.6875 \n",
       "L 18.109375 46.1875 \n",
       "Q 20.953125 51.171875 25.484375 53.578125 \n",
       "Q 30.03125 56 36.53125 56 \n",
       "Q 37.453125 56 38.578125 55.875 \n",
       "Q 39.703125 55.765625 41.0625 55.515625 \n",
       "z\n",
       "\" id=\"DejaVuSans-114\"/>\n",
       "       <path d=\"M 32.171875 -5.078125 \n",
       "Q 28.375 -14.84375 24.75 -17.8125 \n",
       "Q 21.140625 -20.796875 15.09375 -20.796875 \n",
       "L 7.90625 -20.796875 \n",
       "L 7.90625 -13.28125 \n",
       "L 13.1875 -13.28125 \n",
       "Q 16.890625 -13.28125 18.9375 -11.515625 \n",
       "Q 21 -9.765625 23.484375 -3.21875 \n",
       "L 25.09375 0.875 \n",
       "L 2.984375 54.6875 \n",
       "L 12.5 54.6875 \n",
       "L 29.59375 11.921875 \n",
       "L 46.6875 54.6875 \n",
       "L 56.203125 54.6875 \n",
       "z\n",
       "\" id=\"DejaVuSans-121\"/>\n",
       "      </defs>\n",
       "      <use xlink:href=\"#DejaVuSans-97\"/>\n",
       "      <use x=\"61.279297\" xlink:href=\"#DejaVuSans-99\"/>\n",
       "      <use x=\"116.259766\" xlink:href=\"#DejaVuSans-99\"/>\n",
       "      <use x=\"171.240234\" xlink:href=\"#DejaVuSans-117\"/>\n",
       "      <use x=\"234.619141\" xlink:href=\"#DejaVuSans-114\"/>\n",
       "      <use x=\"275.732422\" xlink:href=\"#DejaVuSans-97\"/>\n",
       "      <use x=\"337.011719\" xlink:href=\"#DejaVuSans-99\"/>\n",
       "      <use x=\"391.992188\" xlink:href=\"#DejaVuSans-121\"/>\n",
       "     </g>\n",
       "    </g>\n",
       "   </g>\n",
       "   <g id=\"line2d_13\">\n",
       "    <path clip-path=\"url(#p96e24a3f24)\" d=\"M 65.361932 215.868614 \n",
       "L 65.6666 229.874489 \n",
       "L 65.971268 209.643905 \n",
       "L 66.275937 199.417325 \n",
       "L 66.580605 74.476656 \n",
       "L 67.189942 51.133606 \n",
       "L 67.49461 51.578083 \n",
       "L 67.799278 51.355957 \n",
       "L 68.103947 41.351729 \n",
       "L 68.408615 40.240198 \n",
       "L 68.713283 52.911966 \n",
       "L 69.017951 41.129378 \n",
       "L 69.32262 43.352439 \n",
       "L 69.627288 43.797142 \n",
       "L 69.931956 41.129378 \n",
       "L 70.541293 49.355022 \n",
       "L 70.845961 49.355022 \n",
       "L 71.15063 50.244201 \n",
       "L 71.455298 45.131024 \n",
       "L 71.759966 53.80137 \n",
       "L 72.064635 50.466552 \n",
       "L 72.369303 54.69055 \n",
       "L 72.673971 61.804663 \n",
       "L 72.978639 61.582312 \n",
       "L 73.283308 84.258308 \n",
       "L 73.587976 73.587251 \n",
       "L 73.892644 73.587251 \n",
       "L 74.197313 72.031018 \n",
       "L 74.501981 77.811249 \n",
       "L 74.806649 39.128667 \n",
       "L 75.111318 38.683964 \n",
       "L 75.415986 39.350793 \n",
       "L 75.720654 39.128667 \n",
       "L 76.025322 40.240198 \n",
       "L 76.329991 39.128667 \n",
       "L 76.634659 39.128667 \n",
       "L 76.939327 39.573144 \n",
       "L 77.243996 38.906316 \n",
       "L 77.853332 38.906316 \n",
       "L 78.158001 40.462549 \n",
       "L 78.462669 38.683964 \n",
       "L 78.767337 38.239262 \n",
       "L 79.072006 39.573144 \n",
       "L 79.376674 38.683964 \n",
       "L 79.681342 38.683964 \n",
       "L 79.98601 38.906316 \n",
       "L 80.290679 39.795495 \n",
       "L 80.595347 38.461613 \n",
       "L 80.900015 39.128667 \n",
       "L 81.204684 39.128667 \n",
       "L 81.509352 42.685611 \n",
       "L 81.81402 38.906316 \n",
       "L 82.118689 40.240198 \n",
       "L 82.423357 40.240198 \n",
       "L 82.728025 38.683964 \n",
       "L 83.032693 38.461613 \n",
       "L 83.337362 39.128667 \n",
       "L 83.64203 38.906316 \n",
       "L 83.946698 38.906316 \n",
       "L 84.251367 38.683964 \n",
       "L 84.556035 39.573144 \n",
       "L 84.860703 38.461613 \n",
       "L 85.165372 39.350793 \n",
       "L 85.47004 38.683964 \n",
       "L 85.774708 40.240198 \n",
       "L 86.384045 38.683964 \n",
       "L 86.688713 40.462549 \n",
       "L 86.993381 38.461613 \n",
       "L 87.29805 38.461613 \n",
       "L 87.602718 38.683964 \n",
       "L 87.907386 38.461613 \n",
       "L 88.212055 38.461613 \n",
       "L 88.516723 38.683964 \n",
       "L 88.821391 38.461613 \n",
       "L 89.12606 38.461613 \n",
       "L 89.430728 38.683964 \n",
       "L 89.735396 38.683964 \n",
       "L 90.040064 38.906316 \n",
       "L 90.344733 38.461613 \n",
       "L 91.868074 38.461613 \n",
       "L 92.172743 38.683964 \n",
       "L 92.477411 38.461613 \n",
       "L 93.391416 38.461613 \n",
       "L 93.696084 38.683964 \n",
       "L 94.000752 38.683964 \n",
       "L 94.305421 38.461613 \n",
       "L 369.725568 38.461613 \n",
       "L 369.725568 38.461613 \n",
       "\" style=\"fill:none;stroke:#1f77b4;stroke-linecap:square;stroke-width:1.5;\"/>\n",
       "   </g>\n",
       "   <g id=\"line2d_14\">\n",
       "    <path clip-path=\"url(#p96e24a3f24)\" d=\"M 65.361932 32.201761 \n",
       "L 65.6666 41.092882 \n",
       "L 65.971268 32.201761 \n",
       "L 369.725568 32.201761 \n",
       "L 369.725568 32.201761 \n",
       "\" style=\"fill:none;stroke:#ff7f0e;stroke-linecap:square;stroke-width:1.5;\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_3\">\n",
       "    <path d=\"M 50.14375 239.758125 \n",
       "L 50.14375 22.318125 \n",
       "\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_4\">\n",
       "    <path d=\"M 384.94375 239.758125 \n",
       "L 384.94375 22.318125 \n",
       "\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_5\">\n",
       "    <path d=\"M 50.14375 239.758125 \n",
       "L 384.94375 239.758125 \n",
       "\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_6\">\n",
       "    <path d=\"M 50.14375 22.318125 \n",
       "L 384.94375 22.318125 \n",
       "\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n",
       "   </g>\n",
       "   <g id=\"text_15\">\n",
       "    <!-- model accuracy -->\n",
       "    <g transform=\"translate(169.882188 16.318125)scale(0.12 -0.12)\">\n",
       "     <defs>\n",
       "      <path d=\"M 52 44.1875 \n",
       "Q 55.375 50.25 60.0625 53.125 \n",
       "Q 64.75 56 71.09375 56 \n",
       "Q 79.640625 56 84.28125 50.015625 \n",
       "Q 88.921875 44.046875 88.921875 33.015625 \n",
       "L 88.921875 0 \n",
       "L 79.890625 0 \n",
       "L 79.890625 32.71875 \n",
       "Q 79.890625 40.578125 77.09375 44.375 \n",
       "Q 74.3125 48.1875 68.609375 48.1875 \n",
       "Q 61.625 48.1875 57.5625 43.546875 \n",
       "Q 53.515625 38.921875 53.515625 30.90625 \n",
       "L 53.515625 0 \n",
       "L 44.484375 0 \n",
       "L 44.484375 32.71875 \n",
       "Q 44.484375 40.625 41.703125 44.40625 \n",
       "Q 38.921875 48.1875 33.109375 48.1875 \n",
       "Q 26.21875 48.1875 22.15625 43.53125 \n",
       "Q 18.109375 38.875 18.109375 30.90625 \n",
       "L 18.109375 0 \n",
       "L 9.078125 0 \n",
       "L 9.078125 54.6875 \n",
       "L 18.109375 54.6875 \n",
       "L 18.109375 46.1875 \n",
       "Q 21.1875 51.21875 25.484375 53.609375 \n",
       "Q 29.78125 56 35.6875 56 \n",
       "Q 41.65625 56 45.828125 52.96875 \n",
       "Q 50 49.953125 52 44.1875 \n",
       "z\n",
       "\" id=\"DejaVuSans-109\"/>\n",
       "      <path d=\"M 45.40625 46.390625 \n",
       "L 45.40625 75.984375 \n",
       "L 54.390625 75.984375 \n",
       "L 54.390625 0 \n",
       "L 45.40625 0 \n",
       "L 45.40625 8.203125 \n",
       "Q 42.578125 3.328125 38.25 0.953125 \n",
       "Q 33.9375 -1.421875 27.875 -1.421875 \n",
       "Q 17.96875 -1.421875 11.734375 6.484375 \n",
       "Q 5.515625 14.40625 5.515625 27.296875 \n",
       "Q 5.515625 40.1875 11.734375 48.09375 \n",
       "Q 17.96875 56 27.875 56 \n",
       "Q 33.9375 56 38.25 53.625 \n",
       "Q 42.578125 51.265625 45.40625 46.390625 \n",
       "z\n",
       "M 14.796875 27.296875 \n",
       "Q 14.796875 17.390625 18.875 11.75 \n",
       "Q 22.953125 6.109375 30.078125 6.109375 \n",
       "Q 37.203125 6.109375 41.296875 11.75 \n",
       "Q 45.40625 17.390625 45.40625 27.296875 \n",
       "Q 45.40625 37.203125 41.296875 42.84375 \n",
       "Q 37.203125 48.484375 30.078125 48.484375 \n",
       "Q 22.953125 48.484375 18.875 42.84375 \n",
       "Q 14.796875 37.203125 14.796875 27.296875 \n",
       "z\n",
       "\" id=\"DejaVuSans-100\"/>\n",
       "      <path d=\"M 9.421875 75.984375 \n",
       "L 18.40625 75.984375 \n",
       "L 18.40625 0 \n",
       "L 9.421875 0 \n",
       "z\n",
       "\" id=\"DejaVuSans-108\"/>\n",
       "      <path id=\"DejaVuSans-32\"/>\n",
       "     </defs>\n",
       "     <use xlink:href=\"#DejaVuSans-109\"/>\n",
       "     <use x=\"97.412109\" xlink:href=\"#DejaVuSans-111\"/>\n",
       "     <use x=\"158.59375\" xlink:href=\"#DejaVuSans-100\"/>\n",
       "     <use x=\"222.070312\" xlink:href=\"#DejaVuSans-101\"/>\n",
       "     <use x=\"283.59375\" xlink:href=\"#DejaVuSans-108\"/>\n",
       "     <use x=\"311.376953\" xlink:href=\"#DejaVuSans-32\"/>\n",
       "     <use x=\"343.164062\" xlink:href=\"#DejaVuSans-97\"/>\n",
       "     <use x=\"404.443359\" xlink:href=\"#DejaVuSans-99\"/>\n",
       "     <use x=\"459.423828\" xlink:href=\"#DejaVuSans-99\"/>\n",
       "     <use x=\"514.404297\" xlink:href=\"#DejaVuSans-117\"/>\n",
       "     <use x=\"577.783203\" xlink:href=\"#DejaVuSans-114\"/>\n",
       "     <use x=\"618.896484\" xlink:href=\"#DejaVuSans-97\"/>\n",
       "     <use x=\"680.175781\" xlink:href=\"#DejaVuSans-99\"/>\n",
       "     <use x=\"735.15625\" xlink:href=\"#DejaVuSans-121\"/>\n",
       "    </g>\n",
       "   </g>\n",
       "   <g id=\"legend_1\">\n",
       "    <g id=\"patch_7\">\n",
       "     <path d=\"M 296.709375 234.758125 \n",
       "L 377.94375 234.758125 \n",
       "Q 379.94375 234.758125 379.94375 232.758125 \n",
       "L 379.94375 204.401875 \n",
       "Q 379.94375 202.401875 377.94375 202.401875 \n",
       "L 296.709375 202.401875 \n",
       "Q 294.709375 202.401875 294.709375 204.401875 \n",
       "L 294.709375 232.758125 \n",
       "Q 294.709375 234.758125 296.709375 234.758125 \n",
       "z\n",
       "\" style=\"fill:#ffffff;opacity:0.8;stroke:#cccccc;stroke-linejoin:miter;\"/>\n",
       "    </g>\n",
       "    <g id=\"line2d_15\">\n",
       "     <path d=\"M 298.709375 210.500312 \n",
       "L 318.709375 210.500312 \n",
       "\" style=\"fill:none;stroke:#1f77b4;stroke-linecap:square;stroke-width:1.5;\"/>\n",
       "    </g>\n",
       "    <g id=\"line2d_16\"/>\n",
       "    <g id=\"text_16\">\n",
       "     <!-- train -->\n",
       "     <g transform=\"translate(326.709375 214.000312)scale(0.1 -0.1)\">\n",
       "      <defs>\n",
       "       <path d=\"M 18.3125 70.21875 \n",
       "L 18.3125 54.6875 \n",
       "L 36.8125 54.6875 \n",
       "L 36.8125 47.703125 \n",
       "L 18.3125 47.703125 \n",
       "L 18.3125 18.015625 \n",
       "Q 18.3125 11.328125 20.140625 9.421875 \n",
       "Q 21.96875 7.515625 27.59375 7.515625 \n",
       "L 36.8125 7.515625 \n",
       "L 36.8125 0 \n",
       "L 27.59375 0 \n",
       "Q 17.1875 0 13.234375 3.875 \n",
       "Q 9.28125 7.765625 9.28125 18.015625 \n",
       "L 9.28125 47.703125 \n",
       "L 2.6875 47.703125 \n",
       "L 2.6875 54.6875 \n",
       "L 9.28125 54.6875 \n",
       "L 9.28125 70.21875 \n",
       "z\n",
       "\" id=\"DejaVuSans-116\"/>\n",
       "       <path d=\"M 9.421875 54.6875 \n",
       "L 18.40625 54.6875 \n",
       "L 18.40625 0 \n",
       "L 9.421875 0 \n",
       "z\n",
       "M 9.421875 75.984375 \n",
       "L 18.40625 75.984375 \n",
       "L 18.40625 64.59375 \n",
       "L 9.421875 64.59375 \n",
       "z\n",
       "\" id=\"DejaVuSans-105\"/>\n",
       "       <path d=\"M 54.890625 33.015625 \n",
       "L 54.890625 0 \n",
       "L 45.90625 0 \n",
       "L 45.90625 32.71875 \n",
       "Q 45.90625 40.484375 42.875 44.328125 \n",
       "Q 39.84375 48.1875 33.796875 48.1875 \n",
       "Q 26.515625 48.1875 22.3125 43.546875 \n",
       "Q 18.109375 38.921875 18.109375 30.90625 \n",
       "L 18.109375 0 \n",
       "L 9.078125 0 \n",
       "L 9.078125 54.6875 \n",
       "L 18.109375 54.6875 \n",
       "L 18.109375 46.1875 \n",
       "Q 21.34375 51.125 25.703125 53.5625 \n",
       "Q 30.078125 56 35.796875 56 \n",
       "Q 45.21875 56 50.046875 50.171875 \n",
       "Q 54.890625 44.34375 54.890625 33.015625 \n",
       "z\n",
       "\" id=\"DejaVuSans-110\"/>\n",
       "      </defs>\n",
       "      <use xlink:href=\"#DejaVuSans-116\"/>\n",
       "      <use x=\"39.208984\" xlink:href=\"#DejaVuSans-114\"/>\n",
       "      <use x=\"80.322266\" xlink:href=\"#DejaVuSans-97\"/>\n",
       "      <use x=\"141.601562\" xlink:href=\"#DejaVuSans-105\"/>\n",
       "      <use x=\"169.384766\" xlink:href=\"#DejaVuSans-110\"/>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"line2d_17\">\n",
       "     <path d=\"M 298.709375 225.178437 \n",
       "L 318.709375 225.178437 \n",
       "\" style=\"fill:none;stroke:#ff7f0e;stroke-linecap:square;stroke-width:1.5;\"/>\n",
       "    </g>\n",
       "    <g id=\"line2d_18\"/>\n",
       "    <g id=\"text_17\">\n",
       "     <!-- validation -->\n",
       "     <g transform=\"translate(326.709375 228.678437)scale(0.1 -0.1)\">\n",
       "      <defs>\n",
       "       <path d=\"M 2.984375 54.6875 \n",
       "L 12.5 54.6875 \n",
       "L 29.59375 8.796875 \n",
       "L 46.6875 54.6875 \n",
       "L 56.203125 54.6875 \n",
       "L 35.6875 0 \n",
       "L 23.484375 0 \n",
       "z\n",
       "\" id=\"DejaVuSans-118\"/>\n",
       "      </defs>\n",
       "      <use xlink:href=\"#DejaVuSans-118\"/>\n",
       "      <use x=\"59.179688\" xlink:href=\"#DejaVuSans-97\"/>\n",
       "      <use x=\"120.458984\" xlink:href=\"#DejaVuSans-108\"/>\n",
       "      <use x=\"148.242188\" xlink:href=\"#DejaVuSans-105\"/>\n",
       "      <use x=\"176.025391\" xlink:href=\"#DejaVuSans-100\"/>\n",
       "      <use x=\"239.501953\" xlink:href=\"#DejaVuSans-97\"/>\n",
       "      <use x=\"300.78125\" xlink:href=\"#DejaVuSans-116\"/>\n",
       "      <use x=\"339.990234\" xlink:href=\"#DejaVuSans-105\"/>\n",
       "      <use x=\"367.773438\" xlink:href=\"#DejaVuSans-111\"/>\n",
       "      <use x=\"428.955078\" xlink:href=\"#DejaVuSans-110\"/>\n",
       "     </g>\n",
       "    </g>\n",
       "   </g>\n",
       "  </g>\n",
       " </g>\n",
       " <defs>\n",
       "  <clipPath id=\"p96e24a3f24\">\n",
       "   <rect height=\"217.44\" width=\"334.8\" x=\"50.14375\" y=\"22.318125\"/>\n",
       "  </clipPath>\n",
       " </defs>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_hist(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train_Loss: 0.192, Train_Acc: 0.946\n",
      "Test_Loss: 0.191, Test_Acc: 0.948\n"
     ]
    }
   ],
   "source": [
    "# evaluate the model\n",
    "train_loss, train_acc = model.evaluate([X_img_train, X_audio_train], y_train, verbose=0)\n",
    "test_loss, test_acc = model.evaluate([X_img_test, X_audio_test], y_test, verbose=0)\n",
    "print('Train_Loss: %.3f, Train_Acc: %.3f' % (train_loss, train_acc))\n",
    "print('Test_Loss: %.3f, Test_Acc: %.3f' % (test_loss, test_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model.predict([X_img_test, X_audio_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = (model.predict([X_img_test, X_audio_test]) > 0.5)*1    #.astype(\"int32\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score: 0.9475417548812044\n",
      "Precision: 0.0\n",
      "Recall: 0.0\n",
      "F1_score: 0.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, classification_report, confusion_matrix\n",
    "score = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test,y_pred)\n",
    "recall = recall_score(y_test,y_pred)\n",
    "f1 = f1_score(y_test,y_pred)\n",
    "print(\"score:\", score)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"F1_score:\", f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix : \n",
      " [[4028    0]\n",
      " [ 223    0]]\n"
     ]
    }
   ],
   "source": [
    "# confusion matrix\n",
    "matrix = confusion_matrix(y_test, y_pred, labels=[0,1])\n",
    "print('Confusion matrix : \\n',matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report : \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      1.00      0.97      4028\n",
      "           1       0.00      0.00      0.00       223\n",
      "\n",
      "    accuracy                           0.95      4251\n",
      "   macro avg       0.47      0.50      0.49      4251\n",
      "weighted avg       0.90      0.95      0.92      4251\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# classification report for precision, recall f1-score and accuracy\n",
    "matrix = classification_report(y_test, y_pred, labels=[0,1])\n",
    "print('Classification report : \\n',matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Outcome values : \n",
      " 4028 0 223 0\n"
     ]
    }
   ],
   "source": [
    "# outcome values order in sklearn\n",
    "tp, fn, fp, tn = confusion_matrix(y_test, y_pred,labels=[0,1]).reshape(-1)\n",
    "print('Outcome values : \\n', tp, fn, fp, tn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
