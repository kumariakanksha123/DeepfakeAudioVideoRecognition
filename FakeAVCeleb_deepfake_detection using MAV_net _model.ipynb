{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import os\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import (Activation, Dropout, Flatten, Dense, GlobalMaxPooling2D,\n",
    "                          BatchNormalization, Input, Conv2D, GlobalAveragePooling2D,concatenate,Concatenate,multiply, LocallyConnected2D, Lambda)\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras import metrics\n",
    "from keras import backend as K\n",
    "import keras\n",
    "from keras.models import Model\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.applications import EfficientNetB7\n",
    "import skimage.io\n",
    "from skimage.transform import resize\n",
    "\n",
    "from tqdm import tqdm\n",
    "import PIL\n",
    "from PIL import Image, ImageOps\n",
    "import cv2\n",
    "from sklearn.utils import class_weight, shuffle\n",
    "from keras.losses import binary_crossentropy, categorical_crossentropy\n",
    "#from keras.applications.resnet50 import preprocess_input\n",
    "from keras.applications.densenet import DenseNet121,DenseNet169,preprocess_input\n",
    "import keras.backend as K\n",
    "import tensorflow as tf\n",
    "from sklearn.metrics import f1_score, fbeta_score, cohen_kappa_score\n",
    "\n",
    "import keras.callbacks as callbacks\n",
    "from keras.callbacks import Callback\n",
    "get_ipython().run_line_magic('config', 'InlineBackend.figure_format=\"svg\"')\n",
    "get_ipython().run_line_magic('matplotlib', 'inline')\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "SIZE = 224\n",
    "NUM_CLASSES = 2\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Model, load_model\n",
    "from keras.layers import Embedding, LSTM, Dropout, Dense, Input, Bidirectional, Flatten, Conv2D, MaxPooling2D, concatenate, Conv1D, MaxPooling1D\n",
    "import keras.backend as K\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.optimizers import Adam, RMSprop\n",
    "from keras.callbacks import ModelCheckpoint, CSVLogger, EarlyStopping\n",
    "from keras.layers import Conv2D, MaxPooling2D, Input, Dense, Flatten, concatenate\n",
    "from keras.models import Model\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "\n",
    "\n",
    "def get_num_input():\n",
    "    df = pd.read_csv('Ad.csv')\n",
    "    df = df.drop(['filename'],axis=1)\n",
    "    columns = list(df.columns)\n",
    "    features = columns[:-1]\n",
    "    cls_name = columns[-1]\n",
    "    X = np.zeros((len(df), len(features)))\n",
    "    Y = list()\n",
    "    for i, row in df.iterrows():\n",
    "        X[i] = row[features]                    \n",
    "        Y.append(row[cls_name])\n",
    "\n",
    "    return (X, Y)\n",
    "X_num, Y = get_num_input()\n",
    "encoder = LabelEncoder()\n",
    "Y = encoder.fit_transform(Y)\n",
    "X_audio_train, X_audio_test, y_audio_train, y_audio_test = train_test_split( X_num, Y, test_size=0.2,random_state=42)\n",
    "#Scaling the Feature columns\n",
    "#scaler = StandardScaler()\n",
    "#X = scaler.fit_transform(np.array(data.iloc[:, :-1], dtype = float)\n",
    "\n",
    "#def get_img_input():\n",
    "    #df = pd.read_csv('/DATA/akanksha_2021cs39/visualdata.csv')\n",
    "    #X_img = np.zeros((len(df), 224, 224)) # change as per image size\n",
    "    #Y = list()\n",
    "    #for i, row in df.iterrows():\n",
    "        #X_img[i] = np.array(Image.open(row['X_img']))\n",
    "        #Y.append(row['class'])\n",
    "\n",
    "    #return (X_img, Y)\n",
    "    \n",
    "#X_img, Y_img = get_img_input() # use one of the Ys\n",
    "# X feature normalization, convert Y to one-hot representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df = pd.read_csv('/DATA/akanksha_2021cs39/fakeAV_audio.csv')\n",
    "#df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df = df.drop(21253)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.to_csv('Ad.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df2 = pd.read_csv('/DATA/akanksha_2021cs39/fakeAV_visual.csv')\n",
    "#df2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df2 = df2.drop([0 , 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df2.to_csv('Vd.csv', header=None, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_img_input():\n",
    "    df = pd.read_csv('Vd.csv')\n",
    "    columns = list(df.columns)\n",
    "    features = columns[:-1]\n",
    "    cls_name = columns[-1]\n",
    "    X = np.zeros((len(df), len(features)))\n",
    "    Y = list()\n",
    "    for i, row in df.iterrows():\n",
    "        X[i] = row[features]                    \n",
    "        Y.append(row[cls_name])\n",
    "\n",
    "    return (X, Y)\n",
    "X_img, Y_img = get_img_input()\n",
    "encoder = LabelEncoder()\n",
    "Y_img = encoder.fit_transform(Y_img)\n",
    "X_img_train, X_img_test, y_img_train, y_img_test = train_test_split( X_img, Y_img, test_size=0.2,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train=y_audio_train # both audio and video samples are synchronized so both have same levels that is why \n",
    "                                                     #initialized here with one (audio or video) label.\n",
    "y_test=y_audio_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(17001, 133)\n",
      "(17001, 50176)\n",
      "(4251, 133)\n",
      "(4251, 50176)\n",
      "(17001,)\n",
      "(17001,)\n",
      "(4251,)\n",
      "(4251,)\n"
     ]
    }
   ],
   "source": [
    "print(X_audio_train.shape)\n",
    "print(X_img_train.shape)\n",
    "print(X_audio_test.shape)\n",
    "print(X_img_test.shape)\n",
    "print(y_audio_train.shape)\n",
    "print(y_img_train.shape)\n",
    "print(y_audio_test.shape)\n",
    "print(y_img_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Conv2D, MaxPooling2D, Input, Dense, Flatten, concatenate\n",
    "from keras.models import Model\n",
    "import numpy as np\n",
    "from keras import regularizers\n",
    "from keras.layers import Dropout \n",
    "def compile_model():\n",
    "    img_input = Input(shape=(50176,)) \n",
    "    ## branch 1 with image input\n",
    "    x = Dense(1024, activation='relu', kernel_regularizer=regularizers.l2(0.01))(img_input)\n",
    "    x = Dropout(0.3)(x)\n",
    "    x = Dense(512, activation='relu', kernel_regularizer=regularizers.l2(0.01))(x)\n",
    "    x = Dropout(0.3)(x)\n",
    "    x = Dense(256, activation='relu', kernel_regularizer=regularizers.l2(0.01))(x)\n",
    "    x = Dropout(0.3)(x)\n",
    "    x = Dense(128, activation='relu', kernel_regularizer=regularizers.l2(0.01))(x)\n",
    "    x = Dropout(0.3)(x)\n",
    "    x = Dense(64, activation='relu', kernel_regularizer=regularizers.l2(0.01))(x)\n",
    "    x = Dropout(0.3)(x)\n",
    "    out_a = Dense(32, activation='relu', kernel_regularizer=regularizers.l2(0.01))(x)\n",
    "    \n",
    "    #x = MaxPooling2D((2, 2))(x)\n",
    "    #x = Flatten()(x)\n",
    "    #out_a = Dense(64)(x)\n",
    "\n",
    "    num_input = Input(shape=(133,))        ## branch 2 with numerical input\n",
    "    x1 = Dense(1024, activation='relu', kernel_regularizer=regularizers.l2(0.01))(num_input)\n",
    "    x1 = Dropout(0.3)(x1)\n",
    "    x1 = Dense(512, activation='relu', kernel_regularizer=regularizers.l2(0.01))(x1)\n",
    "    x1 = Dropout(0.3)(x1)\n",
    "    x1 = Dense(256, activation='relu', kernel_regularizer=regularizers.l2(0.01))(x1)\n",
    "    x1 = Dropout(0.3)(x1)\n",
    "    x1 = Dense(128, activation='relu', kernel_regularizer=regularizers.l2(0.01))(x1)\n",
    "    x1 = Dropout(0.3)(x1)\n",
    "    x1 = Dense(64, activation='relu', kernel_regularizer=regularizers.l2(0.01))(x1)\n",
    "    x1 = Dropout(0.3)(x1)\n",
    "    out_b = Dense(32, activation='relu', kernel_regularizer=regularizers.l2(0.01))(x1)\n",
    "\n",
    "    concatenated = concatenate([out_a, out_b])    ## concatenate the two branches\n",
    "    out = Dense(1, activation='sigmoid')(concatenated)\n",
    "    model = Model([img_input, num_input], out)\n",
    "    adam = Adam(lr=0.001, decay=1e-5)\n",
    "    print(model.summary())\n",
    "    model.compile(loss=\"binary_crossentropy\", optimizer=adam, metrics=[\"accuracy\"])\n",
    "    return model\n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "### Just for sanity check\n",
    "\n",
    "#print(model.predict(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 50176)]      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            [(None, 133)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 1024)         51381248    input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_6 (Dense)                 (None, 1024)         137216      input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 1024)         0           dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_5 (Dropout)             (None, 1024)         0           dense_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 512)          524800      dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_7 (Dense)                 (None, 512)          524800      dropout_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 512)          0           dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_6 (Dropout)             (None, 512)          0           dense_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 256)          131328      dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_8 (Dense)                 (None, 256)          131328      dropout_6[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 256)          0           dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_7 (Dropout)             (None, 256)          0           dense_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 128)          32896       dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_9 (Dense)                 (None, 128)          32896       dropout_7[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 128)          0           dense_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_8 (Dropout)             (None, 128)          0           dense_9[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 64)           8256        dropout_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_10 (Dense)                (None, 64)           8256        dropout_8[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)             (None, 64)           0           dense_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_9 (Dropout)             (None, 64)           0           dense_10[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_5 (Dense)                 (None, 32)           2080        dropout_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_11 (Dense)                (None, 32)           2080        dropout_9[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 64)           0           dense_5[0][0]                    \n",
      "                                                                 dense_11[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_12 (Dense)                (None, 1)            65          concatenate[0][0]                \n",
      "==================================================================================================\n",
      "Total params: 52,917,249\n",
      "Trainable params: 52,917,249\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model = compile_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "67/67 [==============================] - 28s 378ms/step - loss: 150.4507 - accuracy: 0.8929 - val_loss: 40.3865 - val_accuracy: 0.9475\n",
      "Epoch 2/1000\n",
      "67/67 [==============================] - 24s 361ms/step - loss: 43.4981 - accuracy: 0.8992 - val_loss: 30.1836 - val_accuracy: 0.8360\n",
      "Epoch 3/1000\n",
      "67/67 [==============================] - 25s 367ms/step - loss: 29.8672 - accuracy: 0.8925 - val_loss: 24.8246 - val_accuracy: 0.9475\n",
      "Epoch 4/1000\n",
      "67/67 [==============================] - 24s 361ms/step - loss: 23.0324 - accuracy: 0.9204 - val_loss: 21.1139 - val_accuracy: 0.9475\n",
      "Epoch 5/1000\n",
      "67/67 [==============================] - 25s 365ms/step - loss: 19.7425 - accuracy: 0.9389 - val_loss: 18.3699 - val_accuracy: 0.9475\n",
      "Epoch 6/1000\n",
      "67/67 [==============================] - 24s 351ms/step - loss: 17.4807 - accuracy: 0.9398 - val_loss: 16.3385 - val_accuracy: 0.9475\n",
      "Epoch 7/1000\n",
      "67/67 [==============================] - 24s 363ms/step - loss: 15.5255 - accuracy: 0.9448 - val_loss: 14.6790 - val_accuracy: 0.9475\n",
      "Epoch 8/1000\n",
      "67/67 [==============================] - 24s 361ms/step - loss: 14.1067 - accuracy: 0.9445 - val_loss: 13.4920 - val_accuracy: 0.9475\n",
      "Epoch 9/1000\n",
      "67/67 [==============================] - 24s 361ms/step - loss: 13.0210 - accuracy: 0.9448 - val_loss: 12.5066 - val_accuracy: 0.9475\n",
      "Epoch 10/1000\n",
      "67/67 [==============================] - 24s 361ms/step - loss: 12.2607 - accuracy: 0.9427 - val_loss: 11.7536 - val_accuracy: 0.9475\n",
      "Epoch 11/1000\n",
      "67/67 [==============================] - 24s 365ms/step - loss: 11.5278 - accuracy: 0.9441 - val_loss: 11.3634 - val_accuracy: 0.9475\n",
      "Epoch 12/1000\n",
      "67/67 [==============================] - 24s 363ms/step - loss: 11.1277 - accuracy: 0.9418 - val_loss: 10.6522 - val_accuracy: 0.9475\n",
      "Epoch 13/1000\n",
      "67/67 [==============================] - 24s 366ms/step - loss: 10.4352 - accuracy: 0.9450 - val_loss: 10.2421 - val_accuracy: 0.9475\n",
      "Epoch 14/1000\n",
      "67/67 [==============================] - 24s 364ms/step - loss: 9.9749 - accuracy: 0.9448 - val_loss: 9.7603 - val_accuracy: 0.9475\n",
      "Epoch 15/1000\n",
      "67/67 [==============================] - 24s 363ms/step - loss: 9.6457 - accuracy: 0.9451 - val_loss: 9.3757 - val_accuracy: 0.9475\n",
      "Epoch 16/1000\n",
      "67/67 [==============================] - 24s 364ms/step - loss: 9.4776 - accuracy: 0.9434 - val_loss: 9.2483 - val_accuracy: 0.9475\n",
      "Epoch 17/1000\n",
      "67/67 [==============================] - 25s 368ms/step - loss: 9.2127 - accuracy: 0.9430 - val_loss: 9.1840 - val_accuracy: 0.9475\n",
      "Epoch 18/1000\n",
      "67/67 [==============================] - 24s 365ms/step - loss: 8.9419 - accuracy: 0.9432 - val_loss: 8.8152 - val_accuracy: 0.9475\n",
      "Epoch 19/1000\n",
      "67/67 [==============================] - 24s 365ms/step - loss: 8.7379 - accuracy: 0.9429 - val_loss: 8.5383 - val_accuracy: 0.9475\n",
      "Epoch 20/1000\n",
      "67/67 [==============================] - 24s 364ms/step - loss: 8.3684 - accuracy: 0.9441 - val_loss: 8.1598 - val_accuracy: 0.9475\n",
      "Epoch 21/1000\n",
      "67/67 [==============================] - 24s 360ms/step - loss: 8.2272 - accuracy: 0.9419 - val_loss: 8.1081 - val_accuracy: 0.9475\n",
      "Epoch 22/1000\n",
      "67/67 [==============================] - 24s 359ms/step - loss: 7.9894 - accuracy: 0.9443 - val_loss: 7.7364 - val_accuracy: 0.9475\n",
      "Epoch 23/1000\n",
      "67/67 [==============================] - 24s 361ms/step - loss: 7.8772 - accuracy: 0.9411 - val_loss: 8.0498 - val_accuracy: 0.9475\n",
      "Epoch 24/1000\n",
      "67/67 [==============================] - 24s 363ms/step - loss: 7.7243 - accuracy: 0.9428 - val_loss: 7.7352 - val_accuracy: 0.9475\n",
      "Epoch 25/1000\n",
      "67/67 [==============================] - 24s 360ms/step - loss: 7.5680 - accuracy: 0.9416 - val_loss: 7.4013 - val_accuracy: 0.9475\n",
      "Epoch 26/1000\n",
      "67/67 [==============================] - 24s 364ms/step - loss: 7.6265 - accuracy: 0.9372 - val_loss: 7.4566 - val_accuracy: 0.9475\n",
      "Epoch 27/1000\n",
      "67/67 [==============================] - 24s 360ms/step - loss: 7.6612 - accuracy: 0.9344 - val_loss: 7.2332 - val_accuracy: 0.9475\n",
      "Epoch 28/1000\n",
      "67/67 [==============================] - 24s 361ms/step - loss: 7.0987 - accuracy: 0.9431 - val_loss: 6.9740 - val_accuracy: 0.9475\n",
      "Epoch 29/1000\n",
      "67/67 [==============================] - 24s 364ms/step - loss: 6.8744 - accuracy: 0.9447 - val_loss: 6.6426 - val_accuracy: 0.9475\n",
      "Epoch 30/1000\n",
      "67/67 [==============================] - 24s 362ms/step - loss: 6.7988 - accuracy: 0.9409 - val_loss: 6.6081 - val_accuracy: 0.9475\n",
      "Epoch 31/1000\n",
      "67/67 [==============================] - 24s 361ms/step - loss: 6.5900 - accuracy: 0.9421 - val_loss: 6.5156 - val_accuracy: 0.9475\n",
      "Epoch 32/1000\n",
      "67/67 [==============================] - 24s 363ms/step - loss: 6.6180 - accuracy: 0.9417 - val_loss: 6.4843 - val_accuracy: 0.9475\n",
      "Epoch 33/1000\n",
      "67/67 [==============================] - 24s 355ms/step - loss: 6.4003 - accuracy: 0.9419 - val_loss: 6.2490 - val_accuracy: 0.9475\n",
      "Epoch 34/1000\n",
      "67/67 [==============================] - 24s 361ms/step - loss: 6.5267 - accuracy: 0.9345 - val_loss: 6.3252 - val_accuracy: 0.9475\n",
      "Epoch 35/1000\n",
      "67/67 [==============================] - 24s 361ms/step - loss: 6.7636 - accuracy: 0.9351 - val_loss: 6.4128 - val_accuracy: 0.9475\n",
      "Epoch 36/1000\n",
      "67/67 [==============================] - 24s 363ms/step - loss: 6.9867 - accuracy: 0.9404 - val_loss: 6.5171 - val_accuracy: 0.9475\n",
      "Epoch 37/1000\n",
      "67/67 [==============================] - 24s 362ms/step - loss: 6.5964 - accuracy: 0.9416 - val_loss: 6.2892 - val_accuracy: 0.9475\n",
      "Epoch 38/1000\n",
      "67/67 [==============================] - 24s 360ms/step - loss: 6.7727 - accuracy: 0.9423 - val_loss: 6.2047 - val_accuracy: 0.9475\n",
      "Epoch 39/1000\n",
      "67/67 [==============================] - 24s 363ms/step - loss: 6.3720 - accuracy: 0.9409 - val_loss: 6.0646 - val_accuracy: 0.9475\n",
      "Epoch 40/1000\n",
      "67/67 [==============================] - 25s 368ms/step - loss: 6.2247 - accuracy: 0.9410 - val_loss: 5.8927 - val_accuracy: 0.9475\n",
      "Epoch 41/1000\n",
      "67/67 [==============================] - 24s 365ms/step - loss: 6.1478 - accuracy: 0.9414 - val_loss: 5.7699 - val_accuracy: 0.9475\n",
      "Epoch 42/1000\n",
      "67/67 [==============================] - 24s 363ms/step - loss: 5.9418 - accuracy: 0.9424 - val_loss: 5.6440 - val_accuracy: 0.9475\n",
      "Epoch 43/1000\n",
      "67/67 [==============================] - 24s 359ms/step - loss: 5.6499 - accuracy: 0.9427 - val_loss: 5.4408 - val_accuracy: 0.9475\n",
      "Epoch 44/1000\n",
      "67/67 [==============================] - 24s 366ms/step - loss: 5.5035 - accuracy: 0.9432 - val_loss: 5.2583 - val_accuracy: 0.9475\n",
      "Epoch 45/1000\n",
      "67/67 [==============================] - 24s 362ms/step - loss: 5.2238 - accuracy: 0.9435 - val_loss: 5.1105 - val_accuracy: 0.9475\n",
      "Epoch 46/1000\n",
      "67/67 [==============================] - 25s 366ms/step - loss: 5.1044 - accuracy: 0.9439 - val_loss: 4.9575 - val_accuracy: 0.9475\n",
      "Epoch 47/1000\n",
      "67/67 [==============================] - 25s 367ms/step - loss: 4.8910 - accuracy: 0.9456 - val_loss: 4.7936 - val_accuracy: 0.9475\n",
      "Epoch 48/1000\n",
      "67/67 [==============================] - 24s 360ms/step - loss: 4.7968 - accuracy: 0.9445 - val_loss: 4.6857 - val_accuracy: 0.9475\n",
      "Epoch 49/1000\n",
      "67/67 [==============================] - 24s 360ms/step - loss: 4.6612 - accuracy: 0.9444 - val_loss: 4.5652 - val_accuracy: 0.9475\n",
      "Epoch 50/1000\n",
      "67/67 [==============================] - 24s 358ms/step - loss: 4.5421 - accuracy: 0.9446 - val_loss: 4.4429 - val_accuracy: 0.9475\n",
      "Epoch 51/1000\n",
      "67/67 [==============================] - 24s 364ms/step - loss: 4.4640 - accuracy: 0.9442 - val_loss: 4.3679 - val_accuracy: 0.9475\n",
      "Epoch 52/1000\n",
      "67/67 [==============================] - 24s 360ms/step - loss: 4.3149 - accuracy: 0.9450 - val_loss: 4.1951 - val_accuracy: 0.9475\n",
      "Epoch 53/1000\n",
      "67/67 [==============================] - 24s 362ms/step - loss: 4.1391 - accuracy: 0.9449 - val_loss: 4.1002 - val_accuracy: 0.9475\n",
      "Epoch 54/1000\n",
      "67/67 [==============================] - 24s 359ms/step - loss: 4.0338 - accuracy: 0.9453 - val_loss: 3.9481 - val_accuracy: 0.9475\n",
      "Epoch 55/1000\n",
      "67/67 [==============================] - 24s 363ms/step - loss: 3.9357 - accuracy: 0.9452 - val_loss: 3.8698 - val_accuracy: 0.9475\n",
      "Epoch 56/1000\n",
      "67/67 [==============================] - 24s 359ms/step - loss: 3.7974 - accuracy: 0.9458 - val_loss: 3.7217 - val_accuracy: 0.9475\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/1000\n",
      "67/67 [==============================] - 24s 363ms/step - loss: 3.6851 - accuracy: 0.9456 - val_loss: 3.6273 - val_accuracy: 0.9475\n",
      "Epoch 58/1000\n",
      "67/67 [==============================] - 24s 360ms/step - loss: 3.5897 - accuracy: 0.9458 - val_loss: 3.5384 - val_accuracy: 0.9475\n",
      "Epoch 59/1000\n",
      "67/67 [==============================] - 24s 358ms/step - loss: 3.4949 - accuracy: 0.9457 - val_loss: 3.4269 - val_accuracy: 0.9475\n",
      "Epoch 60/1000\n",
      "67/67 [==============================] - 24s 357ms/step - loss: 3.3894 - accuracy: 0.9458 - val_loss: 3.3273 - val_accuracy: 0.9475\n",
      "Epoch 61/1000\n",
      "67/67 [==============================] - 24s 358ms/step - loss: 3.2906 - accuracy: 0.9458 - val_loss: 3.2337 - val_accuracy: 0.9475\n",
      "Epoch 62/1000\n",
      "67/67 [==============================] - 24s 360ms/step - loss: 3.2085 - accuracy: 0.9456 - val_loss: 3.1530 - val_accuracy: 0.9475\n",
      "Epoch 63/1000\n",
      "67/67 [==============================] - 24s 365ms/step - loss: 3.1426 - accuracy: 0.9458 - val_loss: 3.0869 - val_accuracy: 0.9475\n",
      "Epoch 64/1000\n",
      "67/67 [==============================] - 24s 361ms/step - loss: 3.0497 - accuracy: 0.9456 - val_loss: 2.9805 - val_accuracy: 0.9475\n",
      "Epoch 65/1000\n",
      "67/67 [==============================] - 25s 369ms/step - loss: 2.9562 - accuracy: 0.9457 - val_loss: 2.9024 - val_accuracy: 0.9475\n",
      "Epoch 66/1000\n",
      "67/67 [==============================] - 24s 366ms/step - loss: 2.8687 - accuracy: 0.9459 - val_loss: 2.8257 - val_accuracy: 0.9475\n",
      "Epoch 67/1000\n",
      "67/67 [==============================] - 24s 363ms/step - loss: 2.7967 - accuracy: 0.9459 - val_loss: 2.7312 - val_accuracy: 0.9475\n",
      "Epoch 68/1000\n",
      "67/67 [==============================] - 24s 363ms/step - loss: 2.7132 - accuracy: 0.9455 - val_loss: 2.6592 - val_accuracy: 0.9475\n",
      "Epoch 69/1000\n",
      "67/67 [==============================] - 24s 358ms/step - loss: 2.6420 - accuracy: 0.9458 - val_loss: 2.5862 - val_accuracy: 0.9475\n",
      "Epoch 70/1000\n",
      "67/67 [==============================] - 24s 363ms/step - loss: 2.5632 - accuracy: 0.9457 - val_loss: 2.5401 - val_accuracy: 0.9475\n",
      "Epoch 71/1000\n",
      "67/67 [==============================] - 24s 364ms/step - loss: 2.5008 - accuracy: 0.9457 - val_loss: 2.4894 - val_accuracy: 0.9475\n",
      "Epoch 72/1000\n",
      "67/67 [==============================] - 24s 358ms/step - loss: 2.4463 - accuracy: 0.9455 - val_loss: 2.3791 - val_accuracy: 0.9475\n",
      "Epoch 73/1000\n",
      "67/67 [==============================] - 24s 358ms/step - loss: 2.3524 - accuracy: 0.9458 - val_loss: 2.2954 - val_accuracy: 0.9475\n",
      "Epoch 74/1000\n",
      "67/67 [==============================] - 24s 353ms/step - loss: 2.2650 - accuracy: 0.9459 - val_loss: 2.2112 - val_accuracy: 0.9475\n",
      "Epoch 75/1000\n",
      "67/67 [==============================] - 24s 359ms/step - loss: 2.1845 - accuracy: 0.9459 - val_loss: 2.1437 - val_accuracy: 0.9475\n",
      "Epoch 76/1000\n",
      "67/67 [==============================] - 25s 368ms/step - loss: 2.1186 - accuracy: 0.9459 - val_loss: 2.0791 - val_accuracy: 0.9475\n",
      "Epoch 77/1000\n",
      "67/67 [==============================] - 24s 365ms/step - loss: 2.0637 - accuracy: 0.9458 - val_loss: 2.0198 - val_accuracy: 0.9475\n",
      "Epoch 78/1000\n",
      "67/67 [==============================] - 24s 367ms/step - loss: 1.9907 - accuracy: 0.9459 - val_loss: 1.9524 - val_accuracy: 0.9475\n",
      "Epoch 79/1000\n",
      "67/67 [==============================] - 24s 366ms/step - loss: 1.9425 - accuracy: 0.9459 - val_loss: 1.9009 - val_accuracy: 0.9475\n",
      "Epoch 80/1000\n",
      "67/67 [==============================] - 24s 364ms/step - loss: 1.8797 - accuracy: 0.9457 - val_loss: 1.8334 - val_accuracy: 0.9475\n",
      "Epoch 81/1000\n",
      "67/67 [==============================] - 24s 363ms/step - loss: 1.8172 - accuracy: 0.9459 - val_loss: 1.7772 - val_accuracy: 0.9475\n",
      "Epoch 82/1000\n",
      "67/67 [==============================] - 24s 359ms/step - loss: 1.7534 - accuracy: 0.9459 - val_loss: 1.7243 - val_accuracy: 0.9475\n",
      "Epoch 83/1000\n",
      "67/67 [==============================] - 24s 362ms/step - loss: 1.7127 - accuracy: 0.9459 - val_loss: 1.6694 - val_accuracy: 0.9475\n",
      "Epoch 84/1000\n",
      "67/67 [==============================] - 24s 357ms/step - loss: 1.6627 - accuracy: 0.9457 - val_loss: 1.6357 - val_accuracy: 0.9475\n",
      "Epoch 85/1000\n",
      "67/67 [==============================] - 26s 387ms/step - loss: 1.6087 - accuracy: 0.9459 - val_loss: 1.5657 - val_accuracy: 0.9475\n",
      "Epoch 86/1000\n",
      "67/67 [==============================] - 26s 388ms/step - loss: 1.5645 - accuracy: 0.9458 - val_loss: 1.5116 - val_accuracy: 0.9475\n",
      "Epoch 87/1000\n",
      "67/67 [==============================] - 26s 390ms/step - loss: 1.5219 - accuracy: 0.9457 - val_loss: 1.4792 - val_accuracy: 0.9475\n",
      "Epoch 88/1000\n",
      "67/67 [==============================] - 27s 398ms/step - loss: 1.4538 - accuracy: 0.9458 - val_loss: 1.4108 - val_accuracy: 0.9475\n",
      "Epoch 89/1000\n",
      "67/67 [==============================] - 26s 383ms/step - loss: 1.3916 - accuracy: 0.9459 - val_loss: 1.3597 - val_accuracy: 0.9475\n",
      "Epoch 90/1000\n",
      "67/67 [==============================] - 26s 394ms/step - loss: 1.3395 - accuracy: 0.9459 - val_loss: 1.3068 - val_accuracy: 0.9475\n",
      "Epoch 91/1000\n",
      "67/67 [==============================] - 26s 388ms/step - loss: 1.2902 - accuracy: 0.9459 - val_loss: 1.2722 - val_accuracy: 0.9475\n",
      "Epoch 92/1000\n",
      "67/67 [==============================] - 24s 360ms/step - loss: 1.2487 - accuracy: 0.9459 - val_loss: 1.2244 - val_accuracy: 0.9475\n",
      "Epoch 93/1000\n",
      "67/67 [==============================] - 24s 358ms/step - loss: 1.2184 - accuracy: 0.9458 - val_loss: 1.1948 - val_accuracy: 0.9475\n",
      "Epoch 94/1000\n",
      "67/67 [==============================] - 25s 369ms/step - loss: 1.1868 - accuracy: 0.9459 - val_loss: 1.1711 - val_accuracy: 0.9475\n",
      "Epoch 95/1000\n",
      "67/67 [==============================] - 24s 359ms/step - loss: 1.1589 - accuracy: 0.9459 - val_loss: 1.1191 - val_accuracy: 0.9475\n",
      "Epoch 96/1000\n",
      "67/67 [==============================] - 24s 355ms/step - loss: 1.1014 - accuracy: 0.9459 - val_loss: 1.0643 - val_accuracy: 0.9475\n",
      "Epoch 97/1000\n",
      "67/67 [==============================] - 24s 362ms/step - loss: 1.0493 - accuracy: 0.9459 - val_loss: 1.0204 - val_accuracy: 0.9475\n",
      "Epoch 98/1000\n",
      "67/67 [==============================] - 24s 361ms/step - loss: 1.0130 - accuracy: 0.9459 - val_loss: 0.9933 - val_accuracy: 0.9475\n",
      "Epoch 99/1000\n",
      "67/67 [==============================] - 24s 363ms/step - loss: 0.9835 - accuracy: 0.9458 - val_loss: 0.9580 - val_accuracy: 0.9475\n",
      "Epoch 100/1000\n",
      "67/67 [==============================] - 24s 366ms/step - loss: 0.9445 - accuracy: 0.9459 - val_loss: 0.9183 - val_accuracy: 0.9475\n",
      "Epoch 101/1000\n",
      "67/67 [==============================] - 24s 364ms/step - loss: 0.9218 - accuracy: 0.9457 - val_loss: 0.9261 - val_accuracy: 0.9475\n",
      "Epoch 102/1000\n",
      "67/67 [==============================] - 24s 360ms/step - loss: 0.9122 - accuracy: 0.9458 - val_loss: 0.8733 - val_accuracy: 0.9475\n",
      "Epoch 103/1000\n",
      "67/67 [==============================] - 25s 368ms/step - loss: 0.8591 - accuracy: 0.9459 - val_loss: 0.8397 - val_accuracy: 0.9475\n",
      "Epoch 104/1000\n",
      "67/67 [==============================] - 24s 362ms/step - loss: 0.8286 - accuracy: 0.9459 - val_loss: 0.7957 - val_accuracy: 0.9475\n",
      "Epoch 105/1000\n",
      "67/67 [==============================] - 24s 358ms/step - loss: 0.7855 - accuracy: 0.9459 - val_loss: 0.7646 - val_accuracy: 0.9475\n",
      "Epoch 106/1000\n",
      "67/67 [==============================] - 24s 364ms/step - loss: 0.7554 - accuracy: 0.9459 - val_loss: 0.7371 - val_accuracy: 0.9475\n",
      "Epoch 107/1000\n",
      "67/67 [==============================] - 23s 349ms/step - loss: 0.7448 - accuracy: 0.9458 - val_loss: 0.7191 - val_accuracy: 0.9475\n",
      "Epoch 108/1000\n",
      "67/67 [==============================] - 24s 356ms/step - loss: 0.7086 - accuracy: 0.9459 - val_loss: 0.6844 - val_accuracy: 0.9475\n",
      "Epoch 109/1000\n",
      "67/67 [==============================] - 24s 358ms/step - loss: 0.6761 - accuracy: 0.9459 - val_loss: 0.6591 - val_accuracy: 0.9475\n",
      "Epoch 110/1000\n",
      "67/67 [==============================] - 24s 365ms/step - loss: 0.6520 - accuracy: 0.9459 - val_loss: 0.6317 - val_accuracy: 0.9475\n",
      "Epoch 111/1000\n",
      "67/67 [==============================] - 24s 364ms/step - loss: 0.6273 - accuracy: 0.9459 - val_loss: 0.6082 - val_accuracy: 0.9475\n",
      "Epoch 112/1000\n",
      "67/67 [==============================] - 24s 363ms/step - loss: 0.6049 - accuracy: 0.9459 - val_loss: 0.5882 - val_accuracy: 0.9475\n",
      "Epoch 113/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "67/67 [==============================] - 24s 360ms/step - loss: 0.5859 - accuracy: 0.9459 - val_loss: 0.5683 - val_accuracy: 0.9475\n",
      "Epoch 114/1000\n",
      "67/67 [==============================] - 24s 361ms/step - loss: 0.5670 - accuracy: 0.9459 - val_loss: 0.5551 - val_accuracy: 0.9475\n",
      "Epoch 115/1000\n",
      "67/67 [==============================] - 24s 365ms/step - loss: 0.5560 - accuracy: 0.9459 - val_loss: 0.5425 - val_accuracy: 0.9475\n",
      "Epoch 116/1000\n",
      "67/67 [==============================] - 24s 364ms/step - loss: 0.5372 - accuracy: 0.9459 - val_loss: 0.5174 - val_accuracy: 0.9475\n",
      "Epoch 117/1000\n",
      "67/67 [==============================] - 24s 366ms/step - loss: 0.5102 - accuracy: 0.9459 - val_loss: 0.4943 - val_accuracy: 0.9475\n",
      "Epoch 118/1000\n",
      "67/67 [==============================] - 24s 365ms/step - loss: 0.4913 - accuracy: 0.9459 - val_loss: 0.4781 - val_accuracy: 0.9475\n",
      "Epoch 119/1000\n",
      "67/67 [==============================] - 24s 361ms/step - loss: 0.4772 - accuracy: 0.9459 - val_loss: 0.4759 - val_accuracy: 0.9475\n",
      "Epoch 120/1000\n",
      "67/67 [==============================] - 24s 354ms/step - loss: 0.4665 - accuracy: 0.9459 - val_loss: 0.4481 - val_accuracy: 0.9475\n",
      "Epoch 121/1000\n",
      "67/67 [==============================] - 24s 359ms/step - loss: 0.4463 - accuracy: 0.9459 - val_loss: 0.4340 - val_accuracy: 0.9475\n",
      "Epoch 122/1000\n",
      "67/67 [==============================] - 24s 357ms/step - loss: 0.4296 - accuracy: 0.9459 - val_loss: 0.4160 - val_accuracy: 0.9475\n",
      "Epoch 123/1000\n",
      "67/67 [==============================] - 24s 355ms/step - loss: 0.4161 - accuracy: 0.9459 - val_loss: 0.4032 - val_accuracy: 0.9475\n",
      "Epoch 124/1000\n",
      "67/67 [==============================] - 24s 366ms/step - loss: 0.4056 - accuracy: 0.9459 - val_loss: 0.3922 - val_accuracy: 0.9475\n",
      "Epoch 125/1000\n",
      "67/67 [==============================] - 24s 366ms/step - loss: 0.3908 - accuracy: 0.9459 - val_loss: 0.3797 - val_accuracy: 0.9475\n",
      "Epoch 126/1000\n",
      "67/67 [==============================] - 24s 364ms/step - loss: 0.3822 - accuracy: 0.9459 - val_loss: 0.3690 - val_accuracy: 0.9475\n",
      "Epoch 127/1000\n",
      "67/67 [==============================] - 24s 363ms/step - loss: 0.3694 - accuracy: 0.9459 - val_loss: 0.3587 - val_accuracy: 0.9475\n",
      "Epoch 128/1000\n",
      "67/67 [==============================] - 24s 361ms/step - loss: 0.3615 - accuracy: 0.9459 - val_loss: 0.3486 - val_accuracy: 0.9475\n",
      "Epoch 129/1000\n",
      "67/67 [==============================] - 24s 362ms/step - loss: 0.3521 - accuracy: 0.9459 - val_loss: 0.3473 - val_accuracy: 0.9475\n",
      "Epoch 130/1000\n",
      "67/67 [==============================] - 25s 367ms/step - loss: 0.3413 - accuracy: 0.9459 - val_loss: 0.3298 - val_accuracy: 0.9475\n",
      "Epoch 131/1000\n",
      "67/67 [==============================] - 24s 365ms/step - loss: 0.3320 - accuracy: 0.9459 - val_loss: 0.3222 - val_accuracy: 0.9475\n",
      "Epoch 132/1000\n",
      "67/67 [==============================] - 24s 361ms/step - loss: 0.3245 - accuracy: 0.9459 - val_loss: 0.3155 - val_accuracy: 0.9475\n",
      "Epoch 133/1000\n",
      "67/67 [==============================] - 24s 363ms/step - loss: 0.3183 - accuracy: 0.9459 - val_loss: 0.3110 - val_accuracy: 0.9475\n",
      "Epoch 134/1000\n",
      "67/67 [==============================] - 23s 350ms/step - loss: 0.3107 - accuracy: 0.9459 - val_loss: 0.3016 - val_accuracy: 0.9475\n",
      "Epoch 135/1000\n",
      "67/67 [==============================] - 24s 357ms/step - loss: 0.3017 - accuracy: 0.9459 - val_loss: 0.3002 - val_accuracy: 0.9475\n",
      "Epoch 136/1000\n",
      "67/67 [==============================] - 24s 359ms/step - loss: 0.2967 - accuracy: 0.9459 - val_loss: 0.2876 - val_accuracy: 0.9475\n",
      "Epoch 137/1000\n",
      "67/67 [==============================] - 24s 365ms/step - loss: 0.2905 - accuracy: 0.9459 - val_loss: 0.2819 - val_accuracy: 0.9475\n",
      "Epoch 138/1000\n",
      "67/67 [==============================] - 24s 363ms/step - loss: 0.2841 - accuracy: 0.9459 - val_loss: 0.2749 - val_accuracy: 0.9475\n",
      "Epoch 139/1000\n",
      "67/67 [==============================] - 24s 363ms/step - loss: 0.2787 - accuracy: 0.9459 - val_loss: 0.2731 - val_accuracy: 0.9475\n",
      "Epoch 140/1000\n",
      "67/67 [==============================] - 24s 361ms/step - loss: 0.2755 - accuracy: 0.9459 - val_loss: 0.2644 - val_accuracy: 0.9475\n",
      "Epoch 141/1000\n",
      "67/67 [==============================] - 24s 362ms/step - loss: 0.2694 - accuracy: 0.9459 - val_loss: 0.2618 - val_accuracy: 0.9475\n",
      "Epoch 142/1000\n",
      "67/67 [==============================] - 25s 368ms/step - loss: 0.2650 - accuracy: 0.9459 - val_loss: 0.2552 - val_accuracy: 0.9475\n",
      "Epoch 143/1000\n",
      "67/67 [==============================] - 24s 365ms/step - loss: 0.2603 - accuracy: 0.9459 - val_loss: 0.2600 - val_accuracy: 0.9475\n",
      "Epoch 144/1000\n",
      "67/67 [==============================] - 24s 366ms/step - loss: 0.2581 - accuracy: 0.9459 - val_loss: 0.2481 - val_accuracy: 0.9475\n",
      "Epoch 145/1000\n",
      "67/67 [==============================] - 24s 361ms/step - loss: 0.2547 - accuracy: 0.9459 - val_loss: 0.2476 - val_accuracy: 0.9475\n",
      "Epoch 146/1000\n",
      "67/67 [==============================] - 24s 364ms/step - loss: 0.2502 - accuracy: 0.9459 - val_loss: 0.2420 - val_accuracy: 0.9475\n",
      "Epoch 147/1000\n",
      "67/67 [==============================] - 25s 368ms/step - loss: 0.2463 - accuracy: 0.9459 - val_loss: 0.2389 - val_accuracy: 0.9475\n",
      "Epoch 148/1000\n",
      "67/67 [==============================] - 24s 367ms/step - loss: 0.2437 - accuracy: 0.9459 - val_loss: 0.2355 - val_accuracy: 0.9475\n",
      "Epoch 149/1000\n",
      "67/67 [==============================] - 24s 356ms/step - loss: 0.2402 - accuracy: 0.9459 - val_loss: 0.2364 - val_accuracy: 0.9475\n",
      "Epoch 150/1000\n",
      "67/67 [==============================] - 24s 354ms/step - loss: 0.2385 - accuracy: 0.9459 - val_loss: 0.2343 - val_accuracy: 0.9475\n",
      "Epoch 151/1000\n",
      "67/67 [==============================] - 24s 362ms/step - loss: 0.2352 - accuracy: 0.9459 - val_loss: 0.2276 - val_accuracy: 0.9475\n",
      "Epoch 152/1000\n",
      "67/67 [==============================] - 24s 366ms/step - loss: 0.2336 - accuracy: 0.9459 - val_loss: 0.2260 - val_accuracy: 0.9475\n",
      "Epoch 153/1000\n",
      "67/67 [==============================] - 24s 360ms/step - loss: 0.2337 - accuracy: 0.9459 - val_loss: 0.2233 - val_accuracy: 0.9475\n",
      "Epoch 154/1000\n",
      "67/67 [==============================] - 24s 365ms/step - loss: 0.2290 - accuracy: 0.9459 - val_loss: 0.2227 - val_accuracy: 0.9475\n",
      "Epoch 155/1000\n",
      "67/67 [==============================] - 24s 368ms/step - loss: 0.2296 - accuracy: 0.9459 - val_loss: 0.2206 - val_accuracy: 0.9475\n",
      "Epoch 156/1000\n",
      "67/67 [==============================] - 24s 362ms/step - loss: 0.2264 - accuracy: 0.9459 - val_loss: 0.2193 - val_accuracy: 0.9475\n",
      "Epoch 157/1000\n",
      "67/67 [==============================] - 24s 364ms/step - loss: 0.2249 - accuracy: 0.9459 - val_loss: 0.2177 - val_accuracy: 0.9475\n",
      "Epoch 158/1000\n",
      "67/67 [==============================] - 24s 361ms/step - loss: 0.2233 - accuracy: 0.9459 - val_loss: 0.2177 - val_accuracy: 0.9475\n",
      "Epoch 159/1000\n",
      "67/67 [==============================] - 24s 365ms/step - loss: 0.2217 - accuracy: 0.9459 - val_loss: 0.2190 - val_accuracy: 0.9475\n",
      "Epoch 160/1000\n",
      "67/67 [==============================] - 24s 364ms/step - loss: 0.2210 - accuracy: 0.9459 - val_loss: 0.2144 - val_accuracy: 0.9475\n",
      "Epoch 161/1000\n",
      "67/67 [==============================] - 24s 365ms/step - loss: 0.2193 - accuracy: 0.9459 - val_loss: 0.2120 - val_accuracy: 0.9475\n",
      "Epoch 162/1000\n",
      "67/67 [==============================] - 24s 358ms/step - loss: 0.2195 - accuracy: 0.9459 - val_loss: 0.2162 - val_accuracy: 0.9475\n",
      "Epoch 163/1000\n",
      "67/67 [==============================] - 24s 362ms/step - loss: 0.2186 - accuracy: 0.9459 - val_loss: 0.2105 - val_accuracy: 0.9475\n",
      "Epoch 164/1000\n",
      "67/67 [==============================] - 25s 368ms/step - loss: 0.2165 - accuracy: 0.9459 - val_loss: 0.2091 - val_accuracy: 0.9475\n",
      "Epoch 165/1000\n",
      "67/67 [==============================] - 24s 366ms/step - loss: 0.2142 - accuracy: 0.9459 - val_loss: 0.2089 - val_accuracy: 0.9475\n",
      "Epoch 166/1000\n",
      "67/67 [==============================] - 24s 366ms/step - loss: 0.2164 - accuracy: 0.9459 - val_loss: 0.2093 - val_accuracy: 0.9475\n",
      "Epoch 167/1000\n",
      "67/67 [==============================] - 24s 366ms/step - loss: 0.2132 - accuracy: 0.9459 - val_loss: 0.2101 - val_accuracy: 0.9475\n",
      "Epoch 168/1000\n",
      "67/67 [==============================] - 24s 366ms/step - loss: 0.2153 - accuracy: 0.9459 - val_loss: 0.2076 - val_accuracy: 0.9475\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 169/1000\n",
      "67/67 [==============================] - 24s 358ms/step - loss: 0.2161 - accuracy: 0.9459 - val_loss: 0.2096 - val_accuracy: 0.9475\n",
      "Epoch 170/1000\n",
      "67/67 [==============================] - 25s 365ms/step - loss: 0.2132 - accuracy: 0.9459 - val_loss: 0.2077 - val_accuracy: 0.9475\n",
      "Epoch 171/1000\n",
      "67/67 [==============================] - 24s 361ms/step - loss: 0.2127 - accuracy: 0.9459 - val_loss: 0.2090 - val_accuracy: 0.9475\n",
      "Epoch 172/1000\n",
      "67/67 [==============================] - 24s 363ms/step - loss: 0.2131 - accuracy: 0.9459 - val_loss: 0.2044 - val_accuracy: 0.9475\n",
      "Epoch 173/1000\n",
      "67/67 [==============================] - 23s 350ms/step - loss: 0.2116 - accuracy: 0.9459 - val_loss: 0.2065 - val_accuracy: 0.9475\n",
      "Epoch 174/1000\n",
      "67/67 [==============================] - 24s 361ms/step - loss: 0.2108 - accuracy: 0.9459 - val_loss: 0.2045 - val_accuracy: 0.9475\n",
      "Epoch 175/1000\n",
      "67/67 [==============================] - 24s 361ms/step - loss: 0.2113 - accuracy: 0.9459 - val_loss: 0.2038 - val_accuracy: 0.9475\n",
      "Epoch 176/1000\n",
      "67/67 [==============================] - 24s 365ms/step - loss: 0.2099 - accuracy: 0.9459 - val_loss: 0.2042 - val_accuracy: 0.9475\n",
      "Epoch 177/1000\n",
      "67/67 [==============================] - 24s 364ms/step - loss: 0.2093 - accuracy: 0.9459 - val_loss: 0.2033 - val_accuracy: 0.9475\n",
      "Epoch 178/1000\n",
      "67/67 [==============================] - 24s 365ms/step - loss: 0.2101 - accuracy: 0.9459 - val_loss: 0.2026 - val_accuracy: 0.9475\n",
      "Epoch 179/1000\n",
      "67/67 [==============================] - 24s 364ms/step - loss: 0.2090 - accuracy: 0.9459 - val_loss: 0.2039 - val_accuracy: 0.9475\n",
      "Epoch 180/1000\n",
      "67/67 [==============================] - 24s 364ms/step - loss: 0.2091 - accuracy: 0.9459 - val_loss: 0.2021 - val_accuracy: 0.9475\n",
      "Epoch 181/1000\n",
      "67/67 [==============================] - 24s 363ms/step - loss: 0.2089 - accuracy: 0.9459 - val_loss: 0.2040 - val_accuracy: 0.9475\n",
      "Epoch 182/1000\n",
      "67/67 [==============================] - 24s 359ms/step - loss: 0.2089 - accuracy: 0.9459 - val_loss: 0.2015 - val_accuracy: 0.9475\n",
      "Epoch 183/1000\n",
      "67/67 [==============================] - 24s 362ms/step - loss: 0.2077 - accuracy: 0.9459 - val_loss: 0.2012 - val_accuracy: 0.9475\n",
      "Epoch 184/1000\n",
      "67/67 [==============================] - 25s 368ms/step - loss: 0.2086 - accuracy: 0.9459 - val_loss: 0.2010 - val_accuracy: 0.9475\n",
      "Epoch 185/1000\n",
      "67/67 [==============================] - 24s 361ms/step - loss: 0.2075 - accuracy: 0.9459 - val_loss: 0.2026 - val_accuracy: 0.9475\n",
      "Epoch 186/1000\n",
      "67/67 [==============================] - 24s 353ms/step - loss: 0.2096 - accuracy: 0.9459 - val_loss: 0.2030 - val_accuracy: 0.9475\n",
      "Epoch 187/1000\n",
      "67/67 [==============================] - 24s 357ms/step - loss: 0.2073 - accuracy: 0.9459 - val_loss: 0.2019 - val_accuracy: 0.9475\n",
      "Epoch 188/1000\n",
      "67/67 [==============================] - 24s 358ms/step - loss: 0.2078 - accuracy: 0.9459 - val_loss: 0.2003 - val_accuracy: 0.9475\n",
      "Epoch 189/1000\n",
      "67/67 [==============================] - 24s 365ms/step - loss: 0.2076 - accuracy: 0.9459 - val_loss: 0.2008 - val_accuracy: 0.9475\n",
      "Epoch 190/1000\n",
      "67/67 [==============================] - 24s 366ms/step - loss: 0.2081 - accuracy: 0.9459 - val_loss: 0.2008 - val_accuracy: 0.9475\n",
      "Epoch 191/1000\n",
      "67/67 [==============================] - 24s 363ms/step - loss: 0.2073 - accuracy: 0.9459 - val_loss: 0.2048 - val_accuracy: 0.9475\n",
      "Epoch 192/1000\n",
      "67/67 [==============================] - 24s 361ms/step - loss: 0.2099 - accuracy: 0.9459 - val_loss: 0.2008 - val_accuracy: 0.9475\n",
      "Epoch 193/1000\n",
      "67/67 [==============================] - 24s 358ms/step - loss: 0.2067 - accuracy: 0.9459 - val_loss: 0.2007 - val_accuracy: 0.9475\n",
      "Epoch 194/1000\n",
      "67/67 [==============================] - 24s 362ms/step - loss: 0.2090 - accuracy: 0.9459 - val_loss: 0.2020 - val_accuracy: 0.9475\n",
      "Epoch 195/1000\n",
      "67/67 [==============================] - 24s 363ms/step - loss: 0.2073 - accuracy: 0.9459 - val_loss: 0.2029 - val_accuracy: 0.9475\n",
      "Epoch 196/1000\n",
      "67/67 [==============================] - 25s 367ms/step - loss: 0.2061 - accuracy: 0.9459 - val_loss: 0.2008 - val_accuracy: 0.9475\n",
      "Epoch 197/1000\n",
      "67/67 [==============================] - 24s 366ms/step - loss: 0.2061 - accuracy: 0.9459 - val_loss: 0.2019 - val_accuracy: 0.9475\n",
      "Epoch 198/1000\n",
      "67/67 [==============================] - 24s 365ms/step - loss: 0.2064 - accuracy: 0.9459 - val_loss: 0.1991 - val_accuracy: 0.9475\n",
      "Epoch 199/1000\n",
      "67/67 [==============================] - 24s 361ms/step - loss: 0.2061 - accuracy: 0.9459 - val_loss: 0.1994 - val_accuracy: 0.9475\n",
      "Epoch 200/1000\n",
      "67/67 [==============================] - 24s 366ms/step - loss: 0.2070 - accuracy: 0.9459 - val_loss: 0.2039 - val_accuracy: 0.9475\n",
      "Epoch 201/1000\n",
      "67/67 [==============================] - 24s 365ms/step - loss: 0.2072 - accuracy: 0.9459 - val_loss: 0.2013 - val_accuracy: 0.9475\n",
      "Epoch 202/1000\n",
      "67/67 [==============================] - 24s 365ms/step - loss: 0.2086 - accuracy: 0.9459 - val_loss: 0.2013 - val_accuracy: 0.9475\n",
      "Epoch 203/1000\n",
      "67/67 [==============================] - 24s 366ms/step - loss: 0.2064 - accuracy: 0.9459 - val_loss: 0.2021 - val_accuracy: 0.9475\n",
      "Epoch 204/1000\n",
      "67/67 [==============================] - 24s 366ms/step - loss: 0.2069 - accuracy: 0.9459 - val_loss: 0.2002 - val_accuracy: 0.9475\n",
      "Epoch 205/1000\n",
      "67/67 [==============================] - 24s 365ms/step - loss: 0.2073 - accuracy: 0.9459 - val_loss: 0.1994 - val_accuracy: 0.9475\n",
      "Epoch 206/1000\n",
      "67/67 [==============================] - 24s 366ms/step - loss: 0.2071 - accuracy: 0.9459 - val_loss: 0.2008 - val_accuracy: 0.9475\n",
      "Epoch 207/1000\n",
      "67/67 [==============================] - 24s 360ms/step - loss: 0.2063 - accuracy: 0.9459 - val_loss: 0.1991 - val_accuracy: 0.9475\n",
      "Epoch 208/1000\n",
      "67/67 [==============================] - 24s 357ms/step - loss: 0.2057 - accuracy: 0.9459 - val_loss: 0.2037 - val_accuracy: 0.9475\n",
      "Epoch 209/1000\n",
      "67/67 [==============================] - 24s 364ms/step - loss: 0.2075 - accuracy: 0.9459 - val_loss: 0.1995 - val_accuracy: 0.9475\n",
      "Epoch 210/1000\n",
      "67/67 [==============================] - 26s 389ms/step - loss: 0.2056 - accuracy: 0.9459 - val_loss: 0.1994 - val_accuracy: 0.9475\n",
      "Epoch 211/1000\n",
      "67/67 [==============================] - 26s 389ms/step - loss: 0.2057 - accuracy: 0.9459 - val_loss: 0.2017 - val_accuracy: 0.9475\n",
      "Epoch 212/1000\n",
      "67/67 [==============================] - 26s 394ms/step - loss: 0.2058 - accuracy: 0.9459 - val_loss: 0.2001 - val_accuracy: 0.9475\n",
      "Epoch 213/1000\n",
      "67/67 [==============================] - 27s 395ms/step - loss: 0.2062 - accuracy: 0.9459 - val_loss: 0.2050 - val_accuracy: 0.9475\n",
      "Epoch 214/1000\n",
      "67/67 [==============================] - 26s 385ms/step - loss: 0.2093 - accuracy: 0.9459 - val_loss: 0.2032 - val_accuracy: 0.9475\n",
      "Epoch 215/1000\n",
      "67/67 [==============================] - 26s 395ms/step - loss: 0.2053 - accuracy: 0.9459 - val_loss: 0.1983 - val_accuracy: 0.9475\n",
      "Epoch 216/1000\n",
      "67/67 [==============================] - 24s 365ms/step - loss: 0.2063 - accuracy: 0.9459 - val_loss: 0.1992 - val_accuracy: 0.9475\n",
      "Epoch 217/1000\n",
      "67/67 [==============================] - 24s 357ms/step - loss: 0.2055 - accuracy: 0.9459 - val_loss: 0.1995 - val_accuracy: 0.9475\n",
      "Epoch 218/1000\n",
      "67/67 [==============================] - 25s 367ms/step - loss: 0.2056 - accuracy: 0.9459 - val_loss: 0.2022 - val_accuracy: 0.9475\n",
      "Epoch 219/1000\n",
      "67/67 [==============================] - 24s 357ms/step - loss: 0.2055 - accuracy: 0.9459 - val_loss: 0.1985 - val_accuracy: 0.9475\n",
      "Epoch 220/1000\n",
      "67/67 [==============================] - 24s 362ms/step - loss: 0.2048 - accuracy: 0.9459 - val_loss: 0.1984 - val_accuracy: 0.9475\n",
      "Epoch 221/1000\n",
      "67/67 [==============================] - 24s 362ms/step - loss: 0.2035 - accuracy: 0.9459 - val_loss: 0.1996 - val_accuracy: 0.9475\n",
      "Epoch 222/1000\n",
      "67/67 [==============================] - 24s 363ms/step - loss: 0.2046 - accuracy: 0.9459 - val_loss: 0.1986 - val_accuracy: 0.9475\n",
      "Epoch 223/1000\n",
      "67/67 [==============================] - 25s 367ms/step - loss: 0.2060 - accuracy: 0.9459 - val_loss: 0.1986 - val_accuracy: 0.9475\n",
      "Epoch 224/1000\n",
      "67/67 [==============================] - 24s 360ms/step - loss: 0.2045 - accuracy: 0.9459 - val_loss: 0.1999 - val_accuracy: 0.9475\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 225/1000\n",
      "67/67 [==============================] - 24s 363ms/step - loss: 0.2065 - accuracy: 0.9459 - val_loss: 0.2015 - val_accuracy: 0.9475\n",
      "Epoch 226/1000\n",
      "67/67 [==============================] - 25s 367ms/step - loss: 0.2066 - accuracy: 0.9459 - val_loss: 0.1992 - val_accuracy: 0.9475\n",
      "Epoch 227/1000\n",
      "67/67 [==============================] - 24s 363ms/step - loss: 0.2056 - accuracy: 0.9459 - val_loss: 0.2001 - val_accuracy: 0.9475\n",
      "Epoch 228/1000\n",
      "67/67 [==============================] - 24s 360ms/step - loss: 0.2046 - accuracy: 0.9459 - val_loss: 0.1994 - val_accuracy: 0.9475\n",
      "Epoch 229/1000\n",
      "67/67 [==============================] - 24s 366ms/step - loss: 0.2070 - accuracy: 0.9459 - val_loss: 0.1998 - val_accuracy: 0.9475\n",
      "Epoch 230/1000\n",
      "67/67 [==============================] - 24s 367ms/step - loss: 0.2055 - accuracy: 0.9459 - val_loss: 0.1985 - val_accuracy: 0.9475\n",
      "Epoch 231/1000\n",
      "67/67 [==============================] - 24s 363ms/step - loss: 0.2045 - accuracy: 0.9459 - val_loss: 0.1995 - val_accuracy: 0.9475\n",
      "Epoch 232/1000\n",
      "67/67 [==============================] - 24s 361ms/step - loss: 0.2044 - accuracy: 0.9459 - val_loss: 0.1983 - val_accuracy: 0.9475\n",
      "Epoch 233/1000\n",
      "67/67 [==============================] - 24s 353ms/step - loss: 0.2077 - accuracy: 0.9459 - val_loss: 0.2041 - val_accuracy: 0.9475\n",
      "Epoch 234/1000\n",
      "67/67 [==============================] - 24s 362ms/step - loss: 0.2051 - accuracy: 0.9459 - val_loss: 0.2053 - val_accuracy: 0.9475\n",
      "Epoch 235/1000\n",
      "67/67 [==============================] - 24s 359ms/step - loss: 0.2067 - accuracy: 0.9459 - val_loss: 0.1980 - val_accuracy: 0.9475\n",
      "Epoch 236/1000\n",
      "67/67 [==============================] - 24s 364ms/step - loss: 0.2043 - accuracy: 0.9459 - val_loss: 0.1982 - val_accuracy: 0.9475\n",
      "Epoch 237/1000\n",
      "67/67 [==============================] - 24s 363ms/step - loss: 0.2047 - accuracy: 0.9459 - val_loss: 0.1993 - val_accuracy: 0.9475\n",
      "Epoch 238/1000\n",
      "67/67 [==============================] - 24s 366ms/step - loss: 0.2047 - accuracy: 0.9459 - val_loss: 0.2044 - val_accuracy: 0.9475\n",
      "Epoch 239/1000\n",
      "67/67 [==============================] - 24s 367ms/step - loss: 0.2057 - accuracy: 0.9459 - val_loss: 0.2075 - val_accuracy: 0.9475\n",
      "Epoch 240/1000\n",
      "67/67 [==============================] - 24s 362ms/step - loss: 0.2048 - accuracy: 0.9459 - val_loss: 0.1992 - val_accuracy: 0.9475\n",
      "Epoch 241/1000\n",
      "67/67 [==============================] - 24s 363ms/step - loss: 0.2048 - accuracy: 0.9459 - val_loss: 0.1985 - val_accuracy: 0.9475\n",
      "Epoch 242/1000\n",
      "67/67 [==============================] - 24s 360ms/step - loss: 0.2048 - accuracy: 0.9459 - val_loss: 0.1999 - val_accuracy: 0.9475\n",
      "Epoch 243/1000\n",
      "67/67 [==============================] - 24s 364ms/step - loss: 0.2052 - accuracy: 0.9459 - val_loss: 0.1992 - val_accuracy: 0.9475\n",
      "Epoch 244/1000\n",
      "67/67 [==============================] - 24s 361ms/step - loss: 0.2044 - accuracy: 0.9459 - val_loss: 0.1990 - val_accuracy: 0.9475\n",
      "Epoch 245/1000\n",
      "67/67 [==============================] - 24s 361ms/step - loss: 0.2049 - accuracy: 0.9459 - val_loss: 0.1988 - val_accuracy: 0.9475\n",
      "Epoch 246/1000\n",
      "67/67 [==============================] - 24s 357ms/step - loss: 0.2030 - accuracy: 0.9459 - val_loss: 0.1994 - val_accuracy: 0.9475\n",
      "Epoch 247/1000\n",
      "67/67 [==============================] - 24s 361ms/step - loss: 0.2038 - accuracy: 0.9459 - val_loss: 0.1987 - val_accuracy: 0.9475\n",
      "Epoch 248/1000\n",
      "67/67 [==============================] - 24s 357ms/step - loss: 0.2056 - accuracy: 0.9459 - val_loss: 0.2001 - val_accuracy: 0.9475\n",
      "Epoch 249/1000\n",
      "67/67 [==============================] - 24s 357ms/step - loss: 0.2053 - accuracy: 0.9459 - val_loss: 0.1988 - val_accuracy: 0.9475\n",
      "Epoch 250/1000\n",
      "67/67 [==============================] - 24s 358ms/step - loss: 0.2044 - accuracy: 0.9459 - val_loss: 0.1977 - val_accuracy: 0.9475\n",
      "Epoch 251/1000\n",
      "67/67 [==============================] - 24s 364ms/step - loss: 0.2036 - accuracy: 0.9459 - val_loss: 0.1987 - val_accuracy: 0.9475\n",
      "Epoch 252/1000\n",
      "67/67 [==============================] - 24s 358ms/step - loss: 0.2044 - accuracy: 0.9459 - val_loss: 0.2044 - val_accuracy: 0.9475\n",
      "Epoch 253/1000\n",
      "67/67 [==============================] - 24s 362ms/step - loss: 0.2026 - accuracy: 0.9459 - val_loss: 0.1989 - val_accuracy: 0.9475\n",
      "Epoch 254/1000\n",
      "67/67 [==============================] - 25s 368ms/step - loss: 0.2075 - accuracy: 0.9459 - val_loss: 0.2004 - val_accuracy: 0.9475\n",
      "Epoch 255/1000\n",
      "67/67 [==============================] - 24s 362ms/step - loss: 0.2055 - accuracy: 0.9459 - val_loss: 0.2010 - val_accuracy: 0.9475\n",
      "Epoch 256/1000\n",
      "67/67 [==============================] - 24s 366ms/step - loss: 0.2052 - accuracy: 0.9459 - val_loss: 0.1979 - val_accuracy: 0.9475\n",
      "Epoch 257/1000\n",
      "67/67 [==============================] - 24s 363ms/step - loss: 0.2074 - accuracy: 0.9459 - val_loss: 0.2008 - val_accuracy: 0.9475\n",
      "Epoch 258/1000\n",
      "67/67 [==============================] - 24s 360ms/step - loss: 0.2063 - accuracy: 0.9459 - val_loss: 0.2107 - val_accuracy: 0.9475\n",
      "Epoch 259/1000\n",
      "67/67 [==============================] - 24s 361ms/step - loss: 0.2042 - accuracy: 0.9459 - val_loss: 0.1976 - val_accuracy: 0.9475\n",
      "Epoch 260/1000\n",
      "67/67 [==============================] - 24s 365ms/step - loss: 0.2033 - accuracy: 0.9459 - val_loss: 0.1974 - val_accuracy: 0.9475\n",
      "Epoch 261/1000\n",
      "67/67 [==============================] - 24s 365ms/step - loss: 0.2036 - accuracy: 0.9459 - val_loss: 0.1994 - val_accuracy: 0.9475\n",
      "Epoch 262/1000\n",
      "67/67 [==============================] - 25s 367ms/step - loss: 0.2041 - accuracy: 0.9459 - val_loss: 0.1987 - val_accuracy: 0.9475\n",
      "Epoch 263/1000\n",
      "67/67 [==============================] - 24s 361ms/step - loss: 0.2032 - accuracy: 0.9459 - val_loss: 0.1980 - val_accuracy: 0.9475\n",
      "Epoch 264/1000\n",
      "67/67 [==============================] - 24s 363ms/step - loss: 0.2047 - accuracy: 0.9459 - val_loss: 0.1999 - val_accuracy: 0.9475\n",
      "Epoch 265/1000\n",
      "67/67 [==============================] - 24s 359ms/step - loss: 0.2042 - accuracy: 0.9459 - val_loss: 0.1981 - val_accuracy: 0.9475\n",
      "Epoch 266/1000\n",
      "67/67 [==============================] - 24s 355ms/step - loss: 0.2023 - accuracy: 0.9459 - val_loss: 0.2004 - val_accuracy: 0.9475\n",
      "Epoch 267/1000\n",
      "67/67 [==============================] - 24s 359ms/step - loss: 0.2039 - accuracy: 0.9459 - val_loss: 0.1983 - val_accuracy: 0.9475\n",
      "Epoch 268/1000\n",
      "67/67 [==============================] - 24s 359ms/step - loss: 0.2064 - accuracy: 0.9459 - val_loss: 0.1975 - val_accuracy: 0.9475\n",
      "Epoch 269/1000\n",
      "67/67 [==============================] - 24s 365ms/step - loss: 0.2045 - accuracy: 0.9459 - val_loss: 0.1983 - val_accuracy: 0.9475\n",
      "Epoch 270/1000\n",
      "67/67 [==============================] - 24s 360ms/step - loss: 0.2047 - accuracy: 0.9459 - val_loss: 0.1973 - val_accuracy: 0.9475\n",
      "Epoch 271/1000\n",
      "67/67 [==============================] - 24s 365ms/step - loss: 0.2038 - accuracy: 0.9459 - val_loss: 0.1980 - val_accuracy: 0.9475\n",
      "Epoch 272/1000\n",
      "67/67 [==============================] - 24s 365ms/step - loss: 0.2046 - accuracy: 0.9459 - val_loss: 0.1984 - val_accuracy: 0.9475\n",
      "Epoch 273/1000\n",
      "67/67 [==============================] - 24s 365ms/step - loss: 0.2040 - accuracy: 0.9459 - val_loss: 0.1980 - val_accuracy: 0.9475\n",
      "Epoch 274/1000\n",
      "67/67 [==============================] - 24s 363ms/step - loss: 0.2039 - accuracy: 0.9459 - val_loss: 0.1974 - val_accuracy: 0.9475\n",
      "Epoch 275/1000\n",
      "67/67 [==============================] - 24s 365ms/step - loss: 0.2036 - accuracy: 0.9459 - val_loss: 0.1985 - val_accuracy: 0.9475\n",
      "Epoch 276/1000\n",
      "67/67 [==============================] - 24s 360ms/step - loss: 0.2055 - accuracy: 0.9459 - val_loss: 0.1985 - val_accuracy: 0.9475\n",
      "Epoch 277/1000\n",
      "67/67 [==============================] - 24s 359ms/step - loss: 0.2035 - accuracy: 0.9459 - val_loss: 0.1980 - val_accuracy: 0.9475\n",
      "Epoch 278/1000\n",
      "67/67 [==============================] - 24s 362ms/step - loss: 0.2034 - accuracy: 0.9459 - val_loss: 0.1977 - val_accuracy: 0.9475\n",
      "Epoch 279/1000\n",
      "67/67 [==============================] - 24s 361ms/step - loss: 0.2048 - accuracy: 0.9459 - val_loss: 0.1982 - val_accuracy: 0.9475\n",
      "Epoch 280/1000\n",
      "67/67 [==============================] - 24s 356ms/step - loss: 0.2037 - accuracy: 0.9459 - val_loss: 0.1976 - val_accuracy: 0.9475\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 281/1000\n",
      "67/67 [==============================] - 24s 356ms/step - loss: 0.2042 - accuracy: 0.9459 - val_loss: 0.1979 - val_accuracy: 0.9475\n",
      "Epoch 282/1000\n",
      "67/67 [==============================] - 24s 359ms/step - loss: 0.2048 - accuracy: 0.9459 - val_loss: 0.1995 - val_accuracy: 0.9475\n",
      "Epoch 283/1000\n",
      "67/67 [==============================] - 24s 363ms/step - loss: 0.2044 - accuracy: 0.9459 - val_loss: 0.1972 - val_accuracy: 0.9475\n",
      "Epoch 284/1000\n",
      "67/67 [==============================] - 24s 363ms/step - loss: 0.2045 - accuracy: 0.9459 - val_loss: 0.1972 - val_accuracy: 0.9475\n",
      "Epoch 285/1000\n",
      "67/67 [==============================] - 24s 361ms/step - loss: 0.2044 - accuracy: 0.9459 - val_loss: 0.1972 - val_accuracy: 0.9475\n",
      "Epoch 286/1000\n",
      "67/67 [==============================] - 24s 365ms/step - loss: 0.2040 - accuracy: 0.9459 - val_loss: 0.1999 - val_accuracy: 0.9475\n",
      "Epoch 287/1000\n",
      "67/67 [==============================] - 24s 363ms/step - loss: 0.2039 - accuracy: 0.9459 - val_loss: 0.1984 - val_accuracy: 0.9475\n",
      "Epoch 288/1000\n",
      "67/67 [==============================] - 24s 362ms/step - loss: 0.2061 - accuracy: 0.9459 - val_loss: 0.1977 - val_accuracy: 0.9475\n",
      "Epoch 289/1000\n",
      "67/67 [==============================] - 24s 362ms/step - loss: 0.2049 - accuracy: 0.9459 - val_loss: 0.1975 - val_accuracy: 0.9475\n",
      "Epoch 290/1000\n",
      "67/67 [==============================] - 24s 363ms/step - loss: 0.2046 - accuracy: 0.9459 - val_loss: 0.1997 - val_accuracy: 0.9475\n",
      "Epoch 291/1000\n",
      "67/67 [==============================] - 25s 367ms/step - loss: 0.2040 - accuracy: 0.9459 - val_loss: 0.1973 - val_accuracy: 0.9475\n",
      "Epoch 292/1000\n",
      "67/67 [==============================] - 24s 361ms/step - loss: 0.2036 - accuracy: 0.9459 - val_loss: 0.1986 - val_accuracy: 0.9475\n",
      "Epoch 293/1000\n",
      "67/67 [==============================] - 24s 363ms/step - loss: 0.2050 - accuracy: 0.9459 - val_loss: 0.1975 - val_accuracy: 0.9475\n",
      "Epoch 294/1000\n",
      "67/67 [==============================] - 24s 357ms/step - loss: 0.2033 - accuracy: 0.9459 - val_loss: 0.1969 - val_accuracy: 0.9475\n",
      "Epoch 295/1000\n",
      "67/67 [==============================] - 24s 358ms/step - loss: 0.2055 - accuracy: 0.9459 - val_loss: 0.1975 - val_accuracy: 0.9475\n",
      "Epoch 296/1000\n",
      "67/67 [==============================] - 24s 359ms/step - loss: 0.2042 - accuracy: 0.9459 - val_loss: 0.1992 - val_accuracy: 0.9475\n",
      "Epoch 297/1000\n",
      "67/67 [==============================] - 24s 357ms/step - loss: 0.2037 - accuracy: 0.9459 - val_loss: 0.1970 - val_accuracy: 0.9475\n",
      "Epoch 298/1000\n",
      "67/67 [==============================] - 24s 362ms/step - loss: 0.2039 - accuracy: 0.9459 - val_loss: 0.1980 - val_accuracy: 0.9475\n",
      "Epoch 299/1000\n",
      "67/67 [==============================] - 24s 365ms/step - loss: 0.2031 - accuracy: 0.9459 - val_loss: 0.1973 - val_accuracy: 0.9475\n",
      "Epoch 300/1000\n",
      "67/67 [==============================] - 24s 361ms/step - loss: 0.2027 - accuracy: 0.9459 - val_loss: 0.1974 - val_accuracy: 0.9475\n",
      "Epoch 301/1000\n",
      "67/67 [==============================] - 24s 363ms/step - loss: 0.2040 - accuracy: 0.9459 - val_loss: 0.1977 - val_accuracy: 0.9475\n",
      "Epoch 302/1000\n",
      "67/67 [==============================] - 25s 369ms/step - loss: 0.2048 - accuracy: 0.9459 - val_loss: 0.1969 - val_accuracy: 0.9475\n",
      "Epoch 303/1000\n",
      "67/67 [==============================] - 24s 363ms/step - loss: 0.2048 - accuracy: 0.9459 - val_loss: 0.2013 - val_accuracy: 0.9475\n",
      "Epoch 304/1000\n",
      "67/67 [==============================] - 24s 361ms/step - loss: 0.2038 - accuracy: 0.9459 - val_loss: 0.1970 - val_accuracy: 0.9475\n",
      "Epoch 305/1000\n",
      "67/67 [==============================] - 24s 360ms/step - loss: 0.2034 - accuracy: 0.9459 - val_loss: 0.1966 - val_accuracy: 0.9475\n",
      "Epoch 306/1000\n",
      "67/67 [==============================] - 25s 367ms/step - loss: 0.2034 - accuracy: 0.9459 - val_loss: 0.1986 - val_accuracy: 0.9475\n",
      "Epoch 307/1000\n",
      "67/67 [==============================] - 24s 363ms/step - loss: 0.2032 - accuracy: 0.9459 - val_loss: 0.1971 - val_accuracy: 0.9475\n",
      "Epoch 308/1000\n",
      "67/67 [==============================] - 24s 365ms/step - loss: 0.2033 - accuracy: 0.9459 - val_loss: 0.1974 - val_accuracy: 0.9475\n",
      "Epoch 309/1000\n",
      "67/67 [==============================] - 24s 363ms/step - loss: 0.2015 - accuracy: 0.9459 - val_loss: 0.1975 - val_accuracy: 0.9475\n",
      "Epoch 310/1000\n",
      "67/67 [==============================] - 24s 363ms/step - loss: 0.2037 - accuracy: 0.9459 - val_loss: 0.1993 - val_accuracy: 0.9475\n",
      "Epoch 311/1000\n",
      "67/67 [==============================] - 24s 365ms/step - loss: 0.2068 - accuracy: 0.9459 - val_loss: 0.2019 - val_accuracy: 0.9475\n",
      "Epoch 312/1000\n",
      "67/67 [==============================] - 24s 362ms/step - loss: 0.2036 - accuracy: 0.9459 - val_loss: 0.1963 - val_accuracy: 0.9475\n",
      "Epoch 313/1000\n",
      "67/67 [==============================] - 24s 354ms/step - loss: 0.2037 - accuracy: 0.9459 - val_loss: 0.1997 - val_accuracy: 0.9475\n",
      "Epoch 314/1000\n",
      "67/67 [==============================] - 24s 355ms/step - loss: 0.2027 - accuracy: 0.9459 - val_loss: 0.1973 - val_accuracy: 0.9475\n",
      "Epoch 315/1000\n",
      "67/67 [==============================] - 24s 357ms/step - loss: 0.2039 - accuracy: 0.9459 - val_loss: 0.1978 - val_accuracy: 0.9475\n",
      "Epoch 316/1000\n",
      "67/67 [==============================] - 24s 363ms/step - loss: 0.2060 - accuracy: 0.9459 - val_loss: 0.1985 - val_accuracy: 0.9475\n",
      "Epoch 317/1000\n",
      "67/67 [==============================] - 24s 358ms/step - loss: 0.2040 - accuracy: 0.9459 - val_loss: 0.1986 - val_accuracy: 0.9475\n",
      "Epoch 318/1000\n",
      "67/67 [==============================] - 24s 366ms/step - loss: 0.2039 - accuracy: 0.9459 - val_loss: 0.1985 - val_accuracy: 0.9475\n",
      "Epoch 319/1000\n",
      "67/67 [==============================] - 24s 366ms/step - loss: 0.2023 - accuracy: 0.9459 - val_loss: 0.1976 - val_accuracy: 0.9475\n",
      "Epoch 320/1000\n",
      "67/67 [==============================] - 24s 362ms/step - loss: 0.2026 - accuracy: 0.9459 - val_loss: 0.1970 - val_accuracy: 0.9475\n",
      "Epoch 321/1000\n",
      "67/67 [==============================] - 24s 361ms/step - loss: 0.2037 - accuracy: 0.9459 - val_loss: 0.1966 - val_accuracy: 0.9475\n",
      "Epoch 322/1000\n",
      "67/67 [==============================] - 24s 360ms/step - loss: 0.2026 - accuracy: 0.9459 - val_loss: 0.1972 - val_accuracy: 0.9475\n",
      "Epoch 323/1000\n",
      "67/67 [==============================] - 24s 361ms/step - loss: 0.2039 - accuracy: 0.9459 - val_loss: 0.1973 - val_accuracy: 0.9475\n",
      "Epoch 324/1000\n",
      "67/67 [==============================] - 23s 349ms/step - loss: 0.2028 - accuracy: 0.9459 - val_loss: 0.1980 - val_accuracy: 0.9475\n",
      "Epoch 325/1000\n",
      "67/67 [==============================] - 24s 360ms/step - loss: 0.2029 - accuracy: 0.9459 - val_loss: 0.1969 - val_accuracy: 0.9475\n",
      "Epoch 326/1000\n",
      "67/67 [==============================] - 24s 362ms/step - loss: 0.2030 - accuracy: 0.9459 - val_loss: 0.1962 - val_accuracy: 0.9475\n",
      "Epoch 327/1000\n",
      "67/67 [==============================] - 25s 366ms/step - loss: 0.2026 - accuracy: 0.9459 - val_loss: 0.2039 - val_accuracy: 0.9475\n",
      "Epoch 328/1000\n",
      "67/67 [==============================] - 24s 363ms/step - loss: 0.2044 - accuracy: 0.9459 - val_loss: 0.1983 - val_accuracy: 0.9475\n",
      "Epoch 329/1000\n",
      "67/67 [==============================] - 25s 368ms/step - loss: 0.2027 - accuracy: 0.9459 - val_loss: 0.1965 - val_accuracy: 0.9475\n",
      "Epoch 330/1000\n",
      "67/67 [==============================] - 24s 360ms/step - loss: 0.2035 - accuracy: 0.9459 - val_loss: 0.1961 - val_accuracy: 0.9475\n",
      "Epoch 331/1000\n",
      "67/67 [==============================] - 24s 359ms/step - loss: 0.2022 - accuracy: 0.9459 - val_loss: 0.1966 - val_accuracy: 0.9475\n",
      "Epoch 332/1000\n",
      "67/67 [==============================] - 24s 363ms/step - loss: 0.2023 - accuracy: 0.9459 - val_loss: 0.1974 - val_accuracy: 0.9475\n",
      "Epoch 333/1000\n",
      "67/67 [==============================] - 24s 365ms/step - loss: 0.2033 - accuracy: 0.9459 - val_loss: 0.1968 - val_accuracy: 0.9475\n",
      "Epoch 334/1000\n",
      "67/67 [==============================] - 26s 382ms/step - loss: 0.2024 - accuracy: 0.9459 - val_loss: 0.1967 - val_accuracy: 0.9475\n",
      "Epoch 335/1000\n",
      "67/67 [==============================] - 26s 387ms/step - loss: 0.2013 - accuracy: 0.9459 - val_loss: 0.1971 - val_accuracy: 0.9475\n",
      "Epoch 336/1000\n",
      "67/67 [==============================] - 26s 386ms/step - loss: 0.2038 - accuracy: 0.9459 - val_loss: 0.2033 - val_accuracy: 0.9475\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 337/1000\n",
      "67/67 [==============================] - 26s 393ms/step - loss: 0.2032 - accuracy: 0.9459 - val_loss: 0.1968 - val_accuracy: 0.9475\n",
      "Epoch 338/1000\n",
      "67/67 [==============================] - 26s 387ms/step - loss: 0.2051 - accuracy: 0.9459 - val_loss: 0.2018 - val_accuracy: 0.9475\n",
      "Epoch 339/1000\n",
      "67/67 [==============================] - 26s 394ms/step - loss: 0.2053 - accuracy: 0.9459 - val_loss: 0.1980 - val_accuracy: 0.9475\n",
      "Epoch 340/1000\n",
      "67/67 [==============================] - 26s 388ms/step - loss: 0.2037 - accuracy: 0.9459 - val_loss: 0.1979 - val_accuracy: 0.9475\n",
      "Epoch 341/1000\n",
      "67/67 [==============================] - 24s 365ms/step - loss: 0.2040 - accuracy: 0.9459 - val_loss: 0.1961 - val_accuracy: 0.9475\n",
      "Epoch 342/1000\n",
      "67/67 [==============================] - 25s 369ms/step - loss: 0.2016 - accuracy: 0.9459 - val_loss: 0.1982 - val_accuracy: 0.9475\n",
      "Epoch 343/1000\n",
      "67/67 [==============================] - 25s 367ms/step - loss: 0.2048 - accuracy: 0.9459 - val_loss: 0.1974 - val_accuracy: 0.9475\n",
      "Epoch 344/1000\n",
      "67/67 [==============================] - 24s 362ms/step - loss: 0.2028 - accuracy: 0.9459 - val_loss: 0.2013 - val_accuracy: 0.9475\n",
      "Epoch 345/1000\n",
      "67/67 [==============================] - 25s 366ms/step - loss: 0.2032 - accuracy: 0.9459 - val_loss: 0.1963 - val_accuracy: 0.9475\n",
      "Epoch 346/1000\n",
      "67/67 [==============================] - 24s 361ms/step - loss: 0.2040 - accuracy: 0.9459 - val_loss: 0.1982 - val_accuracy: 0.9475\n",
      "Epoch 347/1000\n",
      "67/67 [==============================] - 24s 365ms/step - loss: 0.2034 - accuracy: 0.9459 - val_loss: 0.1963 - val_accuracy: 0.9475\n",
      "Epoch 348/1000\n",
      "67/67 [==============================] - 24s 365ms/step - loss: 0.2033 - accuracy: 0.9459 - val_loss: 0.1980 - val_accuracy: 0.9475\n",
      "Epoch 349/1000\n",
      "67/67 [==============================] - 24s 357ms/step - loss: 0.2050 - accuracy: 0.9459 - val_loss: 0.1970 - val_accuracy: 0.9475\n",
      "Epoch 350/1000\n",
      "67/67 [==============================] - 24s 361ms/step - loss: 0.2029 - accuracy: 0.9459 - val_loss: 0.1986 - val_accuracy: 0.9475\n",
      "Epoch 351/1000\n",
      "67/67 [==============================] - 24s 363ms/step - loss: 0.2028 - accuracy: 0.9459 - val_loss: 0.1975 - val_accuracy: 0.9475\n",
      "Epoch 352/1000\n",
      "67/67 [==============================] - 24s 367ms/step - loss: 0.2043 - accuracy: 0.9459 - val_loss: 0.2001 - val_accuracy: 0.9475\n",
      "Epoch 353/1000\n",
      "67/67 [==============================] - 25s 366ms/step - loss: 0.2031 - accuracy: 0.9459 - val_loss: 0.1964 - val_accuracy: 0.9475\n",
      "Epoch 354/1000\n",
      "67/67 [==============================] - 24s 363ms/step - loss: 0.2038 - accuracy: 0.9459 - val_loss: 0.1967 - val_accuracy: 0.9475\n",
      "Epoch 355/1000\n",
      "67/67 [==============================] - 24s 367ms/step - loss: 0.2034 - accuracy: 0.9459 - val_loss: 0.2016 - val_accuracy: 0.9475\n",
      "Epoch 356/1000\n",
      "67/67 [==============================] - 24s 366ms/step - loss: 0.2037 - accuracy: 0.9459 - val_loss: 0.1997 - val_accuracy: 0.9475\n",
      "Epoch 357/1000\n",
      "67/67 [==============================] - 24s 365ms/step - loss: 0.2030 - accuracy: 0.9459 - val_loss: 0.2014 - val_accuracy: 0.9475\n",
      "Epoch 358/1000\n",
      "67/67 [==============================] - 24s 363ms/step - loss: 0.2021 - accuracy: 0.9459 - val_loss: 0.1967 - val_accuracy: 0.9475\n",
      "Epoch 359/1000\n",
      "67/67 [==============================] - 24s 366ms/step - loss: 0.2022 - accuracy: 0.9459 - val_loss: 0.1965 - val_accuracy: 0.9475\n",
      "Epoch 360/1000\n",
      "67/67 [==============================] - 24s 367ms/step - loss: 0.2026 - accuracy: 0.9459 - val_loss: 0.1970 - val_accuracy: 0.9475\n",
      "Epoch 361/1000\n",
      "67/67 [==============================] - 23s 351ms/step - loss: 0.2026 - accuracy: 0.9459 - val_loss: 0.1960 - val_accuracy: 0.9475\n",
      "Epoch 362/1000\n",
      "67/67 [==============================] - 24s 357ms/step - loss: 0.2031 - accuracy: 0.9459 - val_loss: 0.1981 - val_accuracy: 0.9475\n",
      "Epoch 363/1000\n",
      "67/67 [==============================] - 24s 362ms/step - loss: 0.2032 - accuracy: 0.9459 - val_loss: 0.1987 - val_accuracy: 0.9475\n",
      "Epoch 364/1000\n",
      "67/67 [==============================] - 24s 357ms/step - loss: 0.2024 - accuracy: 0.9459 - val_loss: 0.1992 - val_accuracy: 0.9475\n",
      "Epoch 365/1000\n",
      "67/67 [==============================] - 24s 366ms/step - loss: 0.2039 - accuracy: 0.9459 - val_loss: 0.1963 - val_accuracy: 0.9475\n",
      "Epoch 366/1000\n",
      "67/67 [==============================] - 24s 365ms/step - loss: 0.2031 - accuracy: 0.9459 - val_loss: 0.1970 - val_accuracy: 0.9475\n",
      "Epoch 367/1000\n",
      "67/67 [==============================] - 24s 363ms/step - loss: 0.2022 - accuracy: 0.9459 - val_loss: 0.1986 - val_accuracy: 0.9475\n",
      "Epoch 368/1000\n",
      "67/67 [==============================] - 24s 362ms/step - loss: 0.2036 - accuracy: 0.9459 - val_loss: 0.2004 - val_accuracy: 0.9475\n",
      "Epoch 369/1000\n",
      "67/67 [==============================] - 24s 365ms/step - loss: 0.2036 - accuracy: 0.9459 - val_loss: 0.2006 - val_accuracy: 0.9475\n",
      "Epoch 370/1000\n",
      "67/67 [==============================] - 24s 359ms/step - loss: 0.2018 - accuracy: 0.9459 - val_loss: 0.1973 - val_accuracy: 0.9475\n",
      "Epoch 371/1000\n",
      "67/67 [==============================] - 24s 364ms/step - loss: 0.2024 - accuracy: 0.9459 - val_loss: 0.1961 - val_accuracy: 0.9475\n",
      "Epoch 372/1000\n",
      "67/67 [==============================] - 24s 366ms/step - loss: 0.2027 - accuracy: 0.9459 - val_loss: 0.1979 - val_accuracy: 0.9475\n",
      "Epoch 373/1000\n",
      "67/67 [==============================] - 24s 357ms/step - loss: 0.2021 - accuracy: 0.9459 - val_loss: 0.1964 - val_accuracy: 0.9475\n",
      "Epoch 374/1000\n",
      "67/67 [==============================] - 25s 367ms/step - loss: 0.2033 - accuracy: 0.9459 - val_loss: 0.1968 - val_accuracy: 0.9475\n",
      "Epoch 375/1000\n",
      "67/67 [==============================] - 24s 357ms/step - loss: 0.2024 - accuracy: 0.9459 - val_loss: 0.1966 - val_accuracy: 0.9475\n",
      "Epoch 376/1000\n",
      "67/67 [==============================] - 23s 346ms/step - loss: 0.2019 - accuracy: 0.9459 - val_loss: 0.2019 - val_accuracy: 0.9475\n",
      "Epoch 377/1000\n",
      "67/67 [==============================] - 24s 358ms/step - loss: 0.2029 - accuracy: 0.9459 - val_loss: 0.1973 - val_accuracy: 0.9475\n",
      "Epoch 378/1000\n",
      "67/67 [==============================] - 25s 369ms/step - loss: 0.2032 - accuracy: 0.9459 - val_loss: 0.1967 - val_accuracy: 0.9475\n",
      "Epoch 379/1000\n",
      "67/67 [==============================] - 24s 364ms/step - loss: 0.2034 - accuracy: 0.9459 - val_loss: 0.1989 - val_accuracy: 0.9475\n",
      "Epoch 380/1000\n",
      "67/67 [==============================] - 24s 366ms/step - loss: 0.2034 - accuracy: 0.9459 - val_loss: 0.1964 - val_accuracy: 0.9475\n",
      "Epoch 381/1000\n",
      "67/67 [==============================] - 24s 355ms/step - loss: 0.2041 - accuracy: 0.9459 - val_loss: 0.1993 - val_accuracy: 0.9475\n",
      "Epoch 382/1000\n",
      "67/67 [==============================] - 24s 360ms/step - loss: 0.2016 - accuracy: 0.9459 - val_loss: 0.1962 - val_accuracy: 0.9475\n",
      "Epoch 383/1000\n",
      "67/67 [==============================] - 24s 364ms/step - loss: 0.2027 - accuracy: 0.9459 - val_loss: 0.2019 - val_accuracy: 0.9475\n",
      "Epoch 384/1000\n",
      "67/67 [==============================] - 24s 365ms/step - loss: 0.2038 - accuracy: 0.9459 - val_loss: 0.2012 - val_accuracy: 0.9475\n",
      "Epoch 385/1000\n",
      "67/67 [==============================] - 24s 363ms/step - loss: 0.2028 - accuracy: 0.9459 - val_loss: 0.1955 - val_accuracy: 0.9475\n",
      "Epoch 386/1000\n",
      "67/67 [==============================] - 24s 362ms/step - loss: 0.2039 - accuracy: 0.9459 - val_loss: 0.1966 - val_accuracy: 0.9475\n",
      "Epoch 387/1000\n",
      "67/67 [==============================] - 25s 366ms/step - loss: 0.2020 - accuracy: 0.9459 - val_loss: 0.1957 - val_accuracy: 0.9475\n",
      "Epoch 388/1000\n",
      "67/67 [==============================] - 24s 363ms/step - loss: 0.2043 - accuracy: 0.9459 - val_loss: 0.1971 - val_accuracy: 0.9475\n",
      "Epoch 389/1000\n",
      "67/67 [==============================] - 24s 364ms/step - loss: 0.2027 - accuracy: 0.9459 - val_loss: 0.1996 - val_accuracy: 0.9475\n",
      "Epoch 390/1000\n",
      "67/67 [==============================] - 24s 362ms/step - loss: 0.2026 - accuracy: 0.9459 - val_loss: 0.1962 - val_accuracy: 0.9475\n",
      "Epoch 391/1000\n",
      "67/67 [==============================] - 24s 359ms/step - loss: 0.2026 - accuracy: 0.9459 - val_loss: 0.1996 - val_accuracy: 0.9475\n",
      "Epoch 392/1000\n",
      "67/67 [==============================] - 24s 361ms/step - loss: 0.2021 - accuracy: 0.9459 - val_loss: 0.1961 - val_accuracy: 0.9475\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 393/1000\n",
      "67/67 [==============================] - 24s 359ms/step - loss: 0.2034 - accuracy: 0.9459 - val_loss: 0.1958 - val_accuracy: 0.9475\n",
      "Epoch 394/1000\n",
      "67/67 [==============================] - 24s 352ms/step - loss: 0.2039 - accuracy: 0.9459 - val_loss: 0.1989 - val_accuracy: 0.9475\n",
      "Epoch 395/1000\n",
      "67/67 [==============================] - 24s 357ms/step - loss: 0.2025 - accuracy: 0.9459 - val_loss: 0.1969 - val_accuracy: 0.9475\n",
      "Epoch 396/1000\n",
      "67/67 [==============================] - 24s 365ms/step - loss: 0.2020 - accuracy: 0.9459 - val_loss: 0.1998 - val_accuracy: 0.9475\n",
      "Epoch 397/1000\n",
      "67/67 [==============================] - 24s 365ms/step - loss: 0.2025 - accuracy: 0.9459 - val_loss: 0.1957 - val_accuracy: 0.9475\n",
      "Epoch 398/1000\n",
      "67/67 [==============================] - 24s 365ms/step - loss: 0.2028 - accuracy: 0.9459 - val_loss: 0.1970 - val_accuracy: 0.9475\n",
      "Epoch 399/1000\n",
      "67/67 [==============================] - 24s 362ms/step - loss: 0.2027 - accuracy: 0.9459 - val_loss: 0.1995 - val_accuracy: 0.9475\n",
      "Epoch 400/1000\n",
      "67/67 [==============================] - 24s 359ms/step - loss: 0.2049 - accuracy: 0.9459 - val_loss: 0.1983 - val_accuracy: 0.9475\n",
      "Epoch 401/1000\n",
      "67/67 [==============================] - 24s 363ms/step - loss: 0.2032 - accuracy: 0.9459 - val_loss: 0.1963 - val_accuracy: 0.9475\n",
      "Epoch 402/1000\n",
      "67/67 [==============================] - 24s 363ms/step - loss: 0.2027 - accuracy: 0.9459 - val_loss: 0.2051 - val_accuracy: 0.9475\n",
      "Epoch 403/1000\n",
      "67/67 [==============================] - 24s 366ms/step - loss: 0.2047 - accuracy: 0.9459 - val_loss: 0.1980 - val_accuracy: 0.9475\n",
      "Epoch 404/1000\n",
      "67/67 [==============================] - 24s 362ms/step - loss: 0.2021 - accuracy: 0.9459 - val_loss: 0.1957 - val_accuracy: 0.9475\n",
      "Epoch 405/1000\n",
      "67/67 [==============================] - 24s 362ms/step - loss: 0.2026 - accuracy: 0.9459 - val_loss: 0.1974 - val_accuracy: 0.9475\n",
      "Epoch 406/1000\n",
      "67/67 [==============================] - 25s 371ms/step - loss: 0.2022 - accuracy: 0.9459 - val_loss: 0.1961 - val_accuracy: 0.9475\n",
      "Epoch 407/1000\n",
      "67/67 [==============================] - 24s 363ms/step - loss: 0.2017 - accuracy: 0.9459 - val_loss: 0.1973 - val_accuracy: 0.9475\n",
      "Epoch 408/1000\n",
      "67/67 [==============================] - 24s 360ms/step - loss: 0.2034 - accuracy: 0.9459 - val_loss: 0.1968 - val_accuracy: 0.9475\n",
      "Epoch 409/1000\n",
      "67/67 [==============================] - 24s 365ms/step - loss: 0.2024 - accuracy: 0.9459 - val_loss: 0.1978 - val_accuracy: 0.9475\n",
      "Epoch 410/1000\n",
      "67/67 [==============================] - 24s 355ms/step - loss: 0.2028 - accuracy: 0.9459 - val_loss: 0.1984 - val_accuracy: 0.9475\n",
      "Epoch 411/1000\n",
      "67/67 [==============================] - 24s 361ms/step - loss: 0.2037 - accuracy: 0.9459 - val_loss: 0.2023 - val_accuracy: 0.9475\n",
      "Epoch 412/1000\n",
      "67/67 [==============================] - 24s 357ms/step - loss: 0.2051 - accuracy: 0.9459 - val_loss: 0.1966 - val_accuracy: 0.9475\n",
      "Epoch 413/1000\n",
      "67/67 [==============================] - 24s 358ms/step - loss: 0.2014 - accuracy: 0.9459 - val_loss: 0.1958 - val_accuracy: 0.9475\n",
      "Epoch 414/1000\n",
      "67/67 [==============================] - 24s 361ms/step - loss: 0.2035 - accuracy: 0.9459 - val_loss: 0.1963 - val_accuracy: 0.9475\n",
      "Epoch 415/1000\n",
      "67/67 [==============================] - 24s 367ms/step - loss: 0.2021 - accuracy: 0.9459 - val_loss: 0.1968 - val_accuracy: 0.9475\n",
      "Epoch 416/1000\n",
      "67/67 [==============================] - 24s 365ms/step - loss: 0.2021 - accuracy: 0.9459 - val_loss: 0.1958 - val_accuracy: 0.9475\n",
      "Epoch 417/1000\n",
      "67/67 [==============================] - 24s 365ms/step - loss: 0.2024 - accuracy: 0.9459 - val_loss: 0.1963 - val_accuracy: 0.9475\n",
      "Epoch 418/1000\n",
      "67/67 [==============================] - 24s 363ms/step - loss: 0.2029 - accuracy: 0.9459 - val_loss: 0.1964 - val_accuracy: 0.9475\n",
      "Epoch 419/1000\n",
      "67/67 [==============================] - 24s 359ms/step - loss: 0.2017 - accuracy: 0.9459 - val_loss: 0.1980 - val_accuracy: 0.9475\n",
      "Epoch 420/1000\n",
      "67/67 [==============================] - 24s 361ms/step - loss: 0.2016 - accuracy: 0.9459 - val_loss: 0.2075 - val_accuracy: 0.9475\n",
      "Epoch 421/1000\n",
      "67/67 [==============================] - 24s 363ms/step - loss: 0.2019 - accuracy: 0.9459 - val_loss: 0.1952 - val_accuracy: 0.9475\n",
      "Epoch 422/1000\n",
      "67/67 [==============================] - 24s 357ms/step - loss: 0.2025 - accuracy: 0.9459 - val_loss: 0.1990 - val_accuracy: 0.9475\n",
      "Epoch 423/1000\n",
      "67/67 [==============================] - 24s 352ms/step - loss: 0.2022 - accuracy: 0.9459 - val_loss: 0.1985 - val_accuracy: 0.9475\n",
      "Epoch 424/1000\n",
      "67/67 [==============================] - 24s 364ms/step - loss: 0.2013 - accuracy: 0.9459 - val_loss: 0.1968 - val_accuracy: 0.9475\n",
      "Epoch 425/1000\n",
      "67/67 [==============================] - 24s 361ms/step - loss: 0.2006 - accuracy: 0.9459 - val_loss: 0.1961 - val_accuracy: 0.9475\n",
      "Epoch 426/1000\n",
      "67/67 [==============================] - 24s 365ms/step - loss: 0.2025 - accuracy: 0.9459 - val_loss: 0.1962 - val_accuracy: 0.9475\n",
      "Epoch 427/1000\n",
      "67/67 [==============================] - 24s 363ms/step - loss: 0.2016 - accuracy: 0.9459 - val_loss: 0.1973 - val_accuracy: 0.9475\n",
      "Epoch 428/1000\n",
      "67/67 [==============================] - 24s 366ms/step - loss: 0.2026 - accuracy: 0.9459 - val_loss: 0.1949 - val_accuracy: 0.9475\n",
      "Epoch 429/1000\n",
      "67/67 [==============================] - 24s 360ms/step - loss: 0.2031 - accuracy: 0.9459 - val_loss: 0.1978 - val_accuracy: 0.9475\n",
      "Epoch 430/1000\n",
      "67/67 [==============================] - 24s 362ms/step - loss: 0.2037 - accuracy: 0.9459 - val_loss: 0.1972 - val_accuracy: 0.9475\n",
      "Epoch 431/1000\n",
      "67/67 [==============================] - 24s 361ms/step - loss: 0.2038 - accuracy: 0.9459 - val_loss: 0.1958 - val_accuracy: 0.9475\n",
      "Epoch 432/1000\n",
      "67/67 [==============================] - 24s 365ms/step - loss: 0.2028 - accuracy: 0.9459 - val_loss: 0.1959 - val_accuracy: 0.9475\n",
      "Epoch 433/1000\n",
      "67/67 [==============================] - 25s 367ms/step - loss: 0.2028 - accuracy: 0.9459 - val_loss: 0.1963 - val_accuracy: 0.9475\n",
      "Epoch 434/1000\n",
      "67/67 [==============================] - 24s 362ms/step - loss: 0.2014 - accuracy: 0.9459 - val_loss: 0.1947 - val_accuracy: 0.9475\n",
      "Epoch 435/1000\n",
      "67/67 [==============================] - 24s 365ms/step - loss: 0.2035 - accuracy: 0.9459 - val_loss: 0.1955 - val_accuracy: 0.9475\n",
      "Epoch 436/1000\n",
      "67/67 [==============================] - 24s 364ms/step - loss: 0.2018 - accuracy: 0.9459 - val_loss: 0.1955 - val_accuracy: 0.9475\n",
      "Epoch 437/1000\n",
      "67/67 [==============================] - 24s 358ms/step - loss: 0.2017 - accuracy: 0.9459 - val_loss: 0.1992 - val_accuracy: 0.9475\n",
      "Epoch 438/1000\n",
      "67/67 [==============================] - 24s 354ms/step - loss: 0.2037 - accuracy: 0.9459 - val_loss: 0.1972 - val_accuracy: 0.9475\n",
      "Epoch 439/1000\n",
      "67/67 [==============================] - 24s 362ms/step - loss: 0.2043 - accuracy: 0.9459 - val_loss: 0.1958 - val_accuracy: 0.9475\n",
      "Epoch 440/1000\n",
      "67/67 [==============================] - 24s 357ms/step - loss: 0.2017 - accuracy: 0.9459 - val_loss: 0.1955 - val_accuracy: 0.9475\n",
      "Epoch 441/1000\n",
      "67/67 [==============================] - 24s 360ms/step - loss: 0.2021 - accuracy: 0.9459 - val_loss: 0.1953 - val_accuracy: 0.9475\n",
      "Epoch 442/1000\n",
      "67/67 [==============================] - 24s 364ms/step - loss: 0.2008 - accuracy: 0.9459 - val_loss: 0.1950 - val_accuracy: 0.9475\n",
      "Epoch 443/1000\n",
      "67/67 [==============================] - 24s 366ms/step - loss: 0.2019 - accuracy: 0.9459 - val_loss: 0.1958 - val_accuracy: 0.9475\n",
      "Epoch 444/1000\n",
      "67/67 [==============================] - 24s 363ms/step - loss: 0.2025 - accuracy: 0.9459 - val_loss: 0.1972 - val_accuracy: 0.9475\n",
      "Epoch 445/1000\n",
      "67/67 [==============================] - 24s 363ms/step - loss: 0.2015 - accuracy: 0.9459 - val_loss: 0.2003 - val_accuracy: 0.9475\n",
      "Epoch 446/1000\n",
      "67/67 [==============================] - 24s 364ms/step - loss: 0.2027 - accuracy: 0.9459 - val_loss: 0.2009 - val_accuracy: 0.9475\n",
      "Epoch 447/1000\n",
      "67/67 [==============================] - 24s 364ms/step - loss: 0.2024 - accuracy: 0.9459 - val_loss: 0.1961 - val_accuracy: 0.9475\n",
      "Epoch 448/1000\n",
      "67/67 [==============================] - 24s 363ms/step - loss: 0.2007 - accuracy: 0.9459 - val_loss: 0.1954 - val_accuracy: 0.9475\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 449/1000\n",
      "67/67 [==============================] - 24s 362ms/step - loss: 0.2028 - accuracy: 0.9459 - val_loss: 0.1950 - val_accuracy: 0.9475\n",
      "Epoch 450/1000\n",
      "67/67 [==============================] - 24s 360ms/step - loss: 0.2021 - accuracy: 0.9459 - val_loss: 0.2025 - val_accuracy: 0.9475\n",
      "Epoch 451/1000\n",
      "67/67 [==============================] - 24s 359ms/step - loss: 0.2038 - accuracy: 0.9459 - val_loss: 0.1958 - val_accuracy: 0.9475\n",
      "Epoch 452/1000\n",
      "67/67 [==============================] - 24s 359ms/step - loss: 0.2009 - accuracy: 0.9459 - val_loss: 0.1965 - val_accuracy: 0.9475\n",
      "Epoch 453/1000\n",
      "67/67 [==============================] - 24s 360ms/step - loss: 0.2014 - accuracy: 0.9459 - val_loss: 0.1981 - val_accuracy: 0.9475\n",
      "Epoch 454/1000\n",
      "67/67 [==============================] - 25s 367ms/step - loss: 0.2014 - accuracy: 0.9459 - val_loss: 0.1975 - val_accuracy: 0.9475\n",
      "Epoch 455/1000\n",
      "67/67 [==============================] - 24s 361ms/step - loss: 0.2041 - accuracy: 0.9459 - val_loss: 0.1965 - val_accuracy: 0.9475\n",
      "Epoch 456/1000\n",
      "67/67 [==============================] - 24s 358ms/step - loss: 0.2032 - accuracy: 0.9459 - val_loss: 0.1958 - val_accuracy: 0.9475\n",
      "Epoch 457/1000\n",
      "67/67 [==============================] - 24s 357ms/step - loss: 0.2022 - accuracy: 0.9459 - val_loss: 0.1965 - val_accuracy: 0.9475\n",
      "Epoch 458/1000\n",
      "67/67 [==============================] - 25s 370ms/step - loss: 0.2031 - accuracy: 0.9459 - val_loss: 0.1951 - val_accuracy: 0.9475\n",
      "Epoch 459/1000\n",
      "67/67 [==============================] - 27s 397ms/step - loss: 0.2021 - accuracy: 0.9459 - val_loss: 0.1964 - val_accuracy: 0.9475\n",
      "Epoch 460/1000\n",
      "67/67 [==============================] - 26s 396ms/step - loss: 0.2026 - accuracy: 0.9459 - val_loss: 0.1953 - val_accuracy: 0.9475\n",
      "Epoch 461/1000\n",
      "67/67 [==============================] - 26s 387ms/step - loss: 0.2023 - accuracy: 0.9459 - val_loss: 0.1974 - val_accuracy: 0.9475\n",
      "Epoch 462/1000\n",
      "67/67 [==============================] - 26s 393ms/step - loss: 0.2016 - accuracy: 0.9459 - val_loss: 0.1952 - val_accuracy: 0.9475\n",
      "Epoch 463/1000\n",
      "67/67 [==============================] - 26s 387ms/step - loss: 0.2018 - accuracy: 0.9459 - val_loss: 0.1975 - val_accuracy: 0.9475\n",
      "Epoch 464/1000\n",
      "67/67 [==============================] - 26s 392ms/step - loss: 0.2035 - accuracy: 0.9459 - val_loss: 0.1957 - val_accuracy: 0.9475\n",
      "Epoch 465/1000\n",
      "67/67 [==============================] - 24s 366ms/step - loss: 0.2024 - accuracy: 0.9459 - val_loss: 0.1955 - val_accuracy: 0.9475\n",
      "Epoch 466/1000\n",
      "67/67 [==============================] - 24s 357ms/step - loss: 0.2049 - accuracy: 0.9459 - val_loss: 0.2013 - val_accuracy: 0.9475\n",
      "Epoch 467/1000\n",
      "67/67 [==============================] - 24s 359ms/step - loss: 0.2022 - accuracy: 0.9459 - val_loss: 0.1957 - val_accuracy: 0.9475\n",
      "Epoch 468/1000\n",
      "67/67 [==============================] - 24s 359ms/step - loss: 0.2011 - accuracy: 0.9459 - val_loss: 0.1949 - val_accuracy: 0.9475\n",
      "Epoch 469/1000\n",
      "67/67 [==============================] - 24s 361ms/step - loss: 0.2015 - accuracy: 0.9459 - val_loss: 0.1948 - val_accuracy: 0.9475\n",
      "Epoch 470/1000\n",
      "67/67 [==============================] - 24s 361ms/step - loss: 0.2012 - accuracy: 0.9459 - val_loss: 0.1961 - val_accuracy: 0.9475\n",
      "Epoch 471/1000\n",
      "67/67 [==============================] - 24s 362ms/step - loss: 0.2022 - accuracy: 0.9459 - val_loss: 0.2022 - val_accuracy: 0.9475\n",
      "Epoch 472/1000\n",
      "67/67 [==============================] - 24s 364ms/step - loss: 0.2028 - accuracy: 0.9459 - val_loss: 0.1965 - val_accuracy: 0.9475\n",
      "Epoch 473/1000\n",
      "67/67 [==============================] - 24s 365ms/step - loss: 0.2013 - accuracy: 0.9459 - val_loss: 0.1953 - val_accuracy: 0.9475\n",
      "Epoch 474/1000\n",
      "67/67 [==============================] - 24s 365ms/step - loss: 0.2025 - accuracy: 0.9459 - val_loss: 0.1960 - val_accuracy: 0.9475\n",
      "Epoch 475/1000\n",
      "67/67 [==============================] - 24s 361ms/step - loss: 0.2026 - accuracy: 0.9459 - val_loss: 0.1950 - val_accuracy: 0.9475\n",
      "Epoch 476/1000\n",
      "67/67 [==============================] - 25s 367ms/step - loss: 0.2028 - accuracy: 0.9459 - val_loss: 0.1953 - val_accuracy: 0.9475\n",
      "Epoch 477/1000\n",
      "67/67 [==============================] - 24s 364ms/step - loss: 0.2036 - accuracy: 0.9459 - val_loss: 0.1951 - val_accuracy: 0.9475\n",
      "Epoch 478/1000\n",
      "67/67 [==============================] - 24s 362ms/step - loss: 0.2012 - accuracy: 0.9459 - val_loss: 0.1981 - val_accuracy: 0.9475\n",
      "Epoch 479/1000\n",
      "67/67 [==============================] - 25s 367ms/step - loss: 0.2025 - accuracy: 0.9459 - val_loss: 0.1953 - val_accuracy: 0.9475\n",
      "Epoch 480/1000\n",
      "67/67 [==============================] - 25s 369ms/step - loss: 0.2017 - accuracy: 0.9459 - val_loss: 0.1962 - val_accuracy: 0.9475\n",
      "Epoch 481/1000\n",
      "67/67 [==============================] - 24s 363ms/step - loss: 0.2019 - accuracy: 0.9459 - val_loss: 0.1972 - val_accuracy: 0.9475\n",
      "Epoch 482/1000\n",
      "67/67 [==============================] - 24s 359ms/step - loss: 0.2019 - accuracy: 0.9459 - val_loss: 0.1963 - val_accuracy: 0.9475\n",
      "Epoch 483/1000\n",
      "67/67 [==============================] - 24s 365ms/step - loss: 0.2023 - accuracy: 0.9459 - val_loss: 0.1952 - val_accuracy: 0.9475\n",
      "Epoch 484/1000\n",
      "67/67 [==============================] - 24s 365ms/step - loss: 0.2024 - accuracy: 0.9459 - val_loss: 0.1965 - val_accuracy: 0.9475\n",
      "Epoch 485/1000\n",
      "67/67 [==============================] - 24s 366ms/step - loss: 0.2026 - accuracy: 0.9459 - val_loss: 0.1977 - val_accuracy: 0.9475\n",
      "Epoch 486/1000\n",
      "67/67 [==============================] - 25s 368ms/step - loss: 0.2024 - accuracy: 0.9459 - val_loss: 0.1963 - val_accuracy: 0.9475\n",
      "Epoch 487/1000\n",
      "67/67 [==============================] - 24s 357ms/step - loss: 0.2017 - accuracy: 0.9459 - val_loss: 0.1952 - val_accuracy: 0.9475\n",
      "Epoch 488/1000\n",
      "67/67 [==============================] - 24s 357ms/step - loss: 0.2012 - accuracy: 0.9459 - val_loss: 0.1968 - val_accuracy: 0.9475\n",
      "Epoch 489/1000\n",
      "67/67 [==============================] - 24s 356ms/step - loss: 0.2019 - accuracy: 0.9459 - val_loss: 0.1951 - val_accuracy: 0.9475\n",
      "Epoch 490/1000\n",
      "67/67 [==============================] - 24s 355ms/step - loss: 0.2015 - accuracy: 0.9459 - val_loss: 0.1949 - val_accuracy: 0.9475\n",
      "Epoch 491/1000\n",
      "67/67 [==============================] - 24s 359ms/step - loss: 0.2022 - accuracy: 0.9459 - val_loss: 0.1955 - val_accuracy: 0.9475\n",
      "Epoch 492/1000\n",
      "67/67 [==============================] - 24s 363ms/step - loss: 0.2010 - accuracy: 0.9459 - val_loss: 0.1969 - val_accuracy: 0.9475\n",
      "Epoch 493/1000\n",
      "67/67 [==============================] - 24s 366ms/step - loss: 0.2030 - accuracy: 0.9459 - val_loss: 0.1959 - val_accuracy: 0.9475\n",
      "Epoch 494/1000\n",
      "67/67 [==============================] - 24s 365ms/step - loss: 0.2010 - accuracy: 0.9459 - val_loss: 0.2002 - val_accuracy: 0.9475\n",
      "Epoch 495/1000\n",
      "67/67 [==============================] - 24s 362ms/step - loss: 0.2020 - accuracy: 0.9459 - val_loss: 0.1948 - val_accuracy: 0.9475\n",
      "Epoch 496/1000\n",
      "67/67 [==============================] - 24s 365ms/step - loss: 0.2015 - accuracy: 0.9459 - val_loss: 0.2149 - val_accuracy: 0.9475\n",
      "Epoch 497/1000\n",
      "67/67 [==============================] - 24s 365ms/step - loss: 0.2044 - accuracy: 0.9459 - val_loss: 0.1953 - val_accuracy: 0.9475\n",
      "Epoch 498/1000\n",
      "67/67 [==============================] - 24s 364ms/step - loss: 0.2012 - accuracy: 0.9459 - val_loss: 0.2052 - val_accuracy: 0.9475\n",
      "Epoch 499/1000\n",
      "67/67 [==============================] - 25s 367ms/step - loss: 0.2024 - accuracy: 0.9459 - val_loss: 0.1976 - val_accuracy: 0.9475\n",
      "Epoch 500/1000\n",
      "67/67 [==============================] - 24s 360ms/step - loss: 0.2025 - accuracy: 0.9459 - val_loss: 0.1960 - val_accuracy: 0.9475\n",
      "Epoch 501/1000\n",
      "67/67 [==============================] - 24s 362ms/step - loss: 0.2012 - accuracy: 0.9459 - val_loss: 0.1946 - val_accuracy: 0.9475\n",
      "Epoch 502/1000\n",
      "67/67 [==============================] - 24s 360ms/step - loss: 0.2024 - accuracy: 0.9459 - val_loss: 0.1949 - val_accuracy: 0.9475\n",
      "Epoch 503/1000\n",
      "67/67 [==============================] - 25s 367ms/step - loss: 0.2013 - accuracy: 0.9459 - val_loss: 0.1954 - val_accuracy: 0.9475\n",
      "Epoch 504/1000\n",
      "67/67 [==============================] - 24s 362ms/step - loss: 0.2024 - accuracy: 0.9459 - val_loss: 0.1970 - val_accuracy: 0.9475\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 505/1000\n",
      "67/67 [==============================] - 24s 365ms/step - loss: 0.2016 - accuracy: 0.9459 - val_loss: 0.1970 - val_accuracy: 0.9475\n",
      "Epoch 506/1000\n",
      "67/67 [==============================] - 24s 364ms/step - loss: 0.2033 - accuracy: 0.9459 - val_loss: 0.1961 - val_accuracy: 0.9475\n",
      "Epoch 507/1000\n",
      "67/67 [==============================] - 24s 366ms/step - loss: 0.2045 - accuracy: 0.9459 - val_loss: 0.1951 - val_accuracy: 0.9475\n",
      "Epoch 508/1000\n",
      "67/67 [==============================] - 24s 361ms/step - loss: 0.2039 - accuracy: 0.9459 - val_loss: 0.1967 - val_accuracy: 0.9475\n",
      "Epoch 509/1000\n",
      "67/67 [==============================] - 24s 354ms/step - loss: 0.2026 - accuracy: 0.9459 - val_loss: 0.1964 - val_accuracy: 0.9475\n",
      "Epoch 510/1000\n",
      "67/67 [==============================] - 24s 352ms/step - loss: 0.2029 - accuracy: 0.9459 - val_loss: 0.1967 - val_accuracy: 0.9475\n",
      "Epoch 511/1000\n",
      "67/67 [==============================] - 24s 359ms/step - loss: 0.2024 - accuracy: 0.9459 - val_loss: 0.1952 - val_accuracy: 0.9475\n",
      "Epoch 512/1000\n",
      "67/67 [==============================] - 24s 366ms/step - loss: 0.2021 - accuracy: 0.9459 - val_loss: 0.1952 - val_accuracy: 0.9475\n",
      "Epoch 513/1000\n",
      "67/67 [==============================] - 24s 364ms/step - loss: 0.2034 - accuracy: 0.9459 - val_loss: 0.1953 - val_accuracy: 0.9475\n",
      "Epoch 514/1000\n",
      "67/67 [==============================] - 24s 365ms/step - loss: 0.2010 - accuracy: 0.9459 - val_loss: 0.1982 - val_accuracy: 0.9475\n",
      "Epoch 515/1000\n",
      "67/67 [==============================] - 24s 362ms/step - loss: 0.2009 - accuracy: 0.9459 - val_loss: 0.1962 - val_accuracy: 0.9475\n",
      "Epoch 516/1000\n",
      "67/67 [==============================] - 25s 367ms/step - loss: 0.2031 - accuracy: 0.9459 - val_loss: 0.1962 - val_accuracy: 0.9475\n",
      "Epoch 517/1000\n",
      "67/67 [==============================] - 24s 362ms/step - loss: 0.2014 - accuracy: 0.9459 - val_loss: 0.1956 - val_accuracy: 0.9475\n",
      "Epoch 518/1000\n",
      "67/67 [==============================] - 24s 364ms/step - loss: 0.2017 - accuracy: 0.9459 - val_loss: 0.2014 - val_accuracy: 0.9475\n",
      "Epoch 519/1000\n",
      "67/67 [==============================] - 24s 359ms/step - loss: 0.2027 - accuracy: 0.9459 - val_loss: 0.1996 - val_accuracy: 0.9475\n",
      "Epoch 520/1000\n",
      "67/67 [==============================] - 24s 359ms/step - loss: 0.2005 - accuracy: 0.9459 - val_loss: 0.1976 - val_accuracy: 0.9475\n",
      "Epoch 521/1000\n",
      "67/67 [==============================] - 25s 370ms/step - loss: 0.2017 - accuracy: 0.9459 - val_loss: 0.1986 - val_accuracy: 0.9475\n",
      "Epoch 522/1000\n",
      "67/67 [==============================] - 24s 363ms/step - loss: 0.2019 - accuracy: 0.9459 - val_loss: 0.1951 - val_accuracy: 0.9475\n",
      "Epoch 523/1000\n",
      "67/67 [==============================] - 24s 364ms/step - loss: 0.2007 - accuracy: 0.9459 - val_loss: 0.1975 - val_accuracy: 0.9475\n",
      "Epoch 524/1000\n",
      "67/67 [==============================] - 24s 362ms/step - loss: 0.2063 - accuracy: 0.9459 - val_loss: 0.1955 - val_accuracy: 0.9475\n",
      "Epoch 525/1000\n",
      "67/67 [==============================] - 24s 367ms/step - loss: 0.2015 - accuracy: 0.9459 - val_loss: 0.1963 - val_accuracy: 0.9475\n",
      "Epoch 526/1000\n",
      "67/67 [==============================] - 24s 366ms/step - loss: 0.2022 - accuracy: 0.9459 - val_loss: 0.1962 - val_accuracy: 0.9475\n",
      "Epoch 527/1000\n",
      "67/67 [==============================] - 25s 370ms/step - loss: 0.2034 - accuracy: 0.9459 - val_loss: 0.1986 - val_accuracy: 0.9475\n",
      "Epoch 528/1000\n",
      "67/67 [==============================] - 24s 365ms/step - loss: 0.2035 - accuracy: 0.9459 - val_loss: 0.1960 - val_accuracy: 0.9475\n",
      "Epoch 529/1000\n",
      "67/67 [==============================] - 24s 362ms/step - loss: 0.2024 - accuracy: 0.9459 - val_loss: 0.1958 - val_accuracy: 0.9475\n",
      "Epoch 530/1000\n",
      "67/67 [==============================] - 24s 358ms/step - loss: 0.2016 - accuracy: 0.9459 - val_loss: 0.1956 - val_accuracy: 0.9475\n",
      "Epoch 531/1000\n",
      "67/67 [==============================] - 24s 363ms/step - loss: 0.2023 - accuracy: 0.9459 - val_loss: 0.1964 - val_accuracy: 0.9475\n",
      "Epoch 532/1000\n",
      "67/67 [==============================] - 24s 355ms/step - loss: 0.2029 - accuracy: 0.9459 - val_loss: 0.1991 - val_accuracy: 0.9475\n",
      "Epoch 533/1000\n",
      "67/67 [==============================] - 24s 355ms/step - loss: 0.2027 - accuracy: 0.9459 - val_loss: 0.2013 - val_accuracy: 0.9475\n",
      "Epoch 534/1000\n",
      "67/67 [==============================] - 24s 358ms/step - loss: 0.2040 - accuracy: 0.9459 - val_loss: 0.2021 - val_accuracy: 0.9475\n",
      "Epoch 535/1000\n",
      "67/67 [==============================] - 24s 365ms/step - loss: 0.2034 - accuracy: 0.9459 - val_loss: 0.1952 - val_accuracy: 0.9475\n",
      "Epoch 536/1000\n",
      "67/67 [==============================] - 24s 360ms/step - loss: 0.2021 - accuracy: 0.9459 - val_loss: 0.2075 - val_accuracy: 0.9475\n",
      "Epoch 537/1000\n",
      "67/67 [==============================] - 24s 361ms/step - loss: 0.2039 - accuracy: 0.9459 - val_loss: 0.1946 - val_accuracy: 0.9475\n",
      "Epoch 538/1000\n",
      "67/67 [==============================] - 24s 363ms/step - loss: 0.2024 - accuracy: 0.9459 - val_loss: 0.1960 - val_accuracy: 0.9475\n",
      "Epoch 539/1000\n",
      "67/67 [==============================] - 24s 359ms/step - loss: 0.2024 - accuracy: 0.9459 - val_loss: 0.1967 - val_accuracy: 0.9475\n",
      "Epoch 540/1000\n",
      "67/67 [==============================] - 24s 362ms/step - loss: 0.2014 - accuracy: 0.9459 - val_loss: 0.1954 - val_accuracy: 0.9475\n",
      "Epoch 541/1000\n",
      "67/67 [==============================] - 25s 368ms/step - loss: 0.2018 - accuracy: 0.9459 - val_loss: 0.1946 - val_accuracy: 0.9475\n",
      "Epoch 542/1000\n",
      "67/67 [==============================] - 25s 366ms/step - loss: 0.2035 - accuracy: 0.9459 - val_loss: 0.1974 - val_accuracy: 0.9475\n",
      "Epoch 543/1000\n",
      "67/67 [==============================] - 24s 364ms/step - loss: 0.2011 - accuracy: 0.9459 - val_loss: 0.1951 - val_accuracy: 0.9475\n",
      "Epoch 544/1000\n",
      "67/67 [==============================] - 24s 361ms/step - loss: 0.2015 - accuracy: 0.9459 - val_loss: 0.1964 - val_accuracy: 0.9475\n",
      "Epoch 545/1000\n",
      "67/67 [==============================] - 25s 367ms/step - loss: 0.2072 - accuracy: 0.9459 - val_loss: 0.2011 - val_accuracy: 0.9475\n",
      "Epoch 546/1000\n",
      "67/67 [==============================] - 24s 364ms/step - loss: 0.2063 - accuracy: 0.9459 - val_loss: 0.1977 - val_accuracy: 0.9475\n",
      "Epoch 547/1000\n",
      "67/67 [==============================] - 24s 363ms/step - loss: 0.2023 - accuracy: 0.9459 - val_loss: 0.2005 - val_accuracy: 0.9475\n",
      "Epoch 548/1000\n",
      "67/67 [==============================] - 24s 365ms/step - loss: 0.2034 - accuracy: 0.9459 - val_loss: 0.1941 - val_accuracy: 0.9475\n",
      "Epoch 549/1000\n",
      "67/67 [==============================] - 24s 359ms/step - loss: 0.2020 - accuracy: 0.9459 - val_loss: 0.1947 - val_accuracy: 0.9475\n",
      "Epoch 550/1000\n",
      "67/67 [==============================] - 24s 355ms/step - loss: 0.2033 - accuracy: 0.9459 - val_loss: 0.1977 - val_accuracy: 0.9475\n",
      "Epoch 551/1000\n",
      "67/67 [==============================] - 24s 357ms/step - loss: 0.2032 - accuracy: 0.9459 - val_loss: 0.1959 - val_accuracy: 0.9475\n",
      "Epoch 552/1000\n",
      "67/67 [==============================] - 24s 360ms/step - loss: 0.2016 - accuracy: 0.9459 - val_loss: 0.1952 - val_accuracy: 0.9475\n",
      "Epoch 553/1000\n",
      "67/67 [==============================] - 24s 364ms/step - loss: 0.2018 - accuracy: 0.9459 - val_loss: 0.1970 - val_accuracy: 0.9475\n",
      "Epoch 554/1000\n",
      "67/67 [==============================] - 24s 361ms/step - loss: 0.2023 - accuracy: 0.9459 - val_loss: 0.1962 - val_accuracy: 0.9475\n",
      "Epoch 555/1000\n",
      "67/67 [==============================] - 24s 361ms/step - loss: 0.2018 - accuracy: 0.9459 - val_loss: 0.1960 - val_accuracy: 0.9475\n",
      "Epoch 556/1000\n",
      "67/67 [==============================] - 24s 362ms/step - loss: 0.2014 - accuracy: 0.9459 - val_loss: 0.1953 - val_accuracy: 0.9475\n",
      "Epoch 557/1000\n",
      "67/67 [==============================] - 24s 363ms/step - loss: 0.2019 - accuracy: 0.9459 - val_loss: 0.1962 - val_accuracy: 0.9475\n",
      "Epoch 558/1000\n",
      "67/67 [==============================] - 25s 368ms/step - loss: 0.2022 - accuracy: 0.9459 - val_loss: 0.1982 - val_accuracy: 0.9475\n",
      "Epoch 559/1000\n",
      "67/67 [==============================] - 24s 364ms/step - loss: 0.2027 - accuracy: 0.9459 - val_loss: 0.1980 - val_accuracy: 0.9475\n",
      "Epoch 560/1000\n",
      "67/67 [==============================] - 25s 366ms/step - loss: 0.2050 - accuracy: 0.9459 - val_loss: 0.2026 - val_accuracy: 0.9475\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 561/1000\n",
      "67/67 [==============================] - 24s 365ms/step - loss: 0.2029 - accuracy: 0.9459 - val_loss: 0.1945 - val_accuracy: 0.9475\n",
      "Epoch 562/1000\n",
      "67/67 [==============================] - 24s 363ms/step - loss: 0.2038 - accuracy: 0.9459 - val_loss: 0.1946 - val_accuracy: 0.9475\n",
      "Epoch 563/1000\n",
      "67/67 [==============================] - 24s 363ms/step - loss: 0.2021 - accuracy: 0.9459 - val_loss: 0.1972 - val_accuracy: 0.9475\n",
      "Epoch 564/1000\n",
      "67/67 [==============================] - 24s 359ms/step - loss: 0.2012 - accuracy: 0.9459 - val_loss: 0.1950 - val_accuracy: 0.9475\n",
      "Epoch 565/1000\n",
      "67/67 [==============================] - 24s 365ms/step - loss: 0.2008 - accuracy: 0.9459 - val_loss: 0.1949 - val_accuracy: 0.9475\n",
      "Epoch 566/1000\n",
      "67/67 [==============================] - 24s 365ms/step - loss: 0.2005 - accuracy: 0.9459 - val_loss: 0.1946 - val_accuracy: 0.9475\n",
      "Epoch 567/1000\n",
      "67/67 [==============================] - 24s 362ms/step - loss: 0.2018 - accuracy: 0.9459 - val_loss: 0.1978 - val_accuracy: 0.9475\n",
      "Epoch 568/1000\n",
      "67/67 [==============================] - 25s 368ms/step - loss: 0.2012 - accuracy: 0.9459 - val_loss: 0.1983 - val_accuracy: 0.9475\n",
      "Epoch 569/1000\n",
      "67/67 [==============================] - 24s 366ms/step - loss: 0.2031 - accuracy: 0.9459 - val_loss: 0.2002 - val_accuracy: 0.9475\n",
      "Epoch 570/1000\n",
      "67/67 [==============================] - 24s 366ms/step - loss: 0.2021 - accuracy: 0.9459 - val_loss: 0.1944 - val_accuracy: 0.9475\n",
      "Epoch 571/1000\n",
      "67/67 [==============================] - 24s 356ms/step - loss: 0.2023 - accuracy: 0.9459 - val_loss: 0.1946 - val_accuracy: 0.9475\n",
      "Epoch 572/1000\n",
      "67/67 [==============================] - 24s 357ms/step - loss: 0.2006 - accuracy: 0.9459 - val_loss: 0.1950 - val_accuracy: 0.9475\n",
      "Epoch 573/1000\n",
      "67/67 [==============================] - 24s 357ms/step - loss: 0.2023 - accuracy: 0.9459 - val_loss: 0.1943 - val_accuracy: 0.9475\n",
      "Epoch 574/1000\n",
      "67/67 [==============================] - 24s 362ms/step - loss: 0.2009 - accuracy: 0.9459 - val_loss: 0.1939 - val_accuracy: 0.9475\n",
      "Epoch 575/1000\n",
      "67/67 [==============================] - 24s 366ms/step - loss: 0.2015 - accuracy: 0.9459 - val_loss: 0.1948 - val_accuracy: 0.9475\n",
      "Epoch 576/1000\n",
      "67/67 [==============================] - 24s 364ms/step - loss: 0.2023 - accuracy: 0.9459 - val_loss: 0.1939 - val_accuracy: 0.9475\n",
      "Epoch 577/1000\n",
      "67/67 [==============================] - 24s 359ms/step - loss: 0.2020 - accuracy: 0.9459 - val_loss: 0.1969 - val_accuracy: 0.9475\n",
      "Epoch 578/1000\n",
      "67/67 [==============================] - 24s 363ms/step - loss: 0.2023 - accuracy: 0.9459 - val_loss: 0.1956 - val_accuracy: 0.9475\n",
      "Epoch 579/1000\n",
      "67/67 [==============================] - 24s 363ms/step - loss: 0.2032 - accuracy: 0.9459 - val_loss: 0.1992 - val_accuracy: 0.9475\n",
      "Epoch 580/1000\n",
      "67/67 [==============================] - 24s 365ms/step - loss: 0.2022 - accuracy: 0.9459 - val_loss: 0.1947 - val_accuracy: 0.9475\n",
      "Epoch 581/1000\n",
      "67/67 [==============================] - 24s 364ms/step - loss: 0.2024 - accuracy: 0.9459 - val_loss: 0.1945 - val_accuracy: 0.9475\n",
      "Epoch 582/1000\n",
      "67/67 [==============================] - 24s 363ms/step - loss: 0.2010 - accuracy: 0.9459 - val_loss: 0.1963 - val_accuracy: 0.9475\n",
      "Epoch 583/1000\n",
      "67/67 [==============================] - 26s 391ms/step - loss: 0.2020 - accuracy: 0.9459 - val_loss: 0.1947 - val_accuracy: 0.9475\n",
      "Epoch 584/1000\n",
      "67/67 [==============================] - 26s 389ms/step - loss: 0.2027 - accuracy: 0.9459 - val_loss: 0.1970 - val_accuracy: 0.9475\n",
      "Epoch 585/1000\n",
      "67/67 [==============================] - 26s 393ms/step - loss: 0.2024 - accuracy: 0.9459 - val_loss: 0.1957 - val_accuracy: 0.9475\n",
      "Epoch 586/1000\n",
      "67/67 [==============================] - 26s 389ms/step - loss: 0.2020 - accuracy: 0.9459 - val_loss: 0.1943 - val_accuracy: 0.9475\n",
      "Epoch 587/1000\n",
      "67/67 [==============================] - 26s 395ms/step - loss: 0.2004 - accuracy: 0.9459 - val_loss: 0.1942 - val_accuracy: 0.9475\n",
      "Epoch 588/1000\n",
      "67/67 [==============================] - 26s 391ms/step - loss: 0.2013 - accuracy: 0.9459 - val_loss: 0.1942 - val_accuracy: 0.9475\n",
      "Epoch 589/1000\n",
      "67/67 [==============================] - 26s 391ms/step - loss: 0.2037 - accuracy: 0.9459 - val_loss: 0.1939 - val_accuracy: 0.9475\n",
      "Epoch 590/1000\n",
      "67/67 [==============================] - 24s 364ms/step - loss: 0.2008 - accuracy: 0.9459 - val_loss: 0.1975 - val_accuracy: 0.9475\n",
      "Epoch 591/1000\n",
      "67/67 [==============================] - 24s 364ms/step - loss: 0.2033 - accuracy: 0.9459 - val_loss: 0.1941 - val_accuracy: 0.9475\n",
      "Epoch 592/1000\n",
      "67/67 [==============================] - 24s 364ms/step - loss: 0.2015 - accuracy: 0.9459 - val_loss: 0.2005 - val_accuracy: 0.9475\n",
      "Epoch 593/1000\n",
      "67/67 [==============================] - 24s 359ms/step - loss: 0.2037 - accuracy: 0.9459 - val_loss: 0.2050 - val_accuracy: 0.9475\n",
      "Epoch 594/1000\n",
      "67/67 [==============================] - 24s 364ms/step - loss: 0.2023 - accuracy: 0.9459 - val_loss: 0.1948 - val_accuracy: 0.9475\n",
      "Epoch 595/1000\n",
      "67/67 [==============================] - 24s 365ms/step - loss: 0.2025 - accuracy: 0.9459 - val_loss: 0.1949 - val_accuracy: 0.9475\n",
      "Epoch 596/1000\n",
      "67/67 [==============================] - 24s 365ms/step - loss: 0.2018 - accuracy: 0.9459 - val_loss: 0.1957 - val_accuracy: 0.9475\n",
      "Epoch 597/1000\n",
      "67/67 [==============================] - 24s 362ms/step - loss: 0.2012 - accuracy: 0.9459 - val_loss: 0.1953 - val_accuracy: 0.9475\n",
      "Epoch 598/1000\n",
      "67/67 [==============================] - 24s 363ms/step - loss: 0.2031 - accuracy: 0.9459 - val_loss: 0.1942 - val_accuracy: 0.9475\n",
      "Epoch 599/1000\n",
      "67/67 [==============================] - 25s 367ms/step - loss: 0.2024 - accuracy: 0.9459 - val_loss: 0.1943 - val_accuracy: 0.9475\n",
      "Epoch 600/1000\n",
      "67/67 [==============================] - 24s 362ms/step - loss: 0.2014 - accuracy: 0.9459 - val_loss: 0.1940 - val_accuracy: 0.9475\n",
      "Epoch 601/1000\n",
      "67/67 [==============================] - 24s 365ms/step - loss: 0.2025 - accuracy: 0.9459 - val_loss: 0.1979 - val_accuracy: 0.9475\n",
      "Epoch 602/1000\n",
      "67/67 [==============================] - 24s 365ms/step - loss: 0.2021 - accuracy: 0.9459 - val_loss: 0.1939 - val_accuracy: 0.9475\n",
      "Epoch 603/1000\n",
      "67/67 [==============================] - 24s 366ms/step - loss: 0.2005 - accuracy: 0.9459 - val_loss: 0.1937 - val_accuracy: 0.9475\n",
      "Epoch 604/1000\n",
      "67/67 [==============================] - 24s 361ms/step - loss: 0.2013 - accuracy: 0.9459 - val_loss: 0.1975 - val_accuracy: 0.9475\n",
      "Epoch 605/1000\n",
      "67/67 [==============================] - 24s 354ms/step - loss: 0.2012 - accuracy: 0.9459 - val_loss: 0.1935 - val_accuracy: 0.9475\n",
      "Epoch 606/1000\n",
      "67/67 [==============================] - 24s 357ms/step - loss: 0.2012 - accuracy: 0.9459 - val_loss: 0.1949 - val_accuracy: 0.9475\n",
      "Epoch 607/1000\n",
      "67/67 [==============================] - 24s 358ms/step - loss: 0.2016 - accuracy: 0.9459 - val_loss: 0.1957 - val_accuracy: 0.9475\n",
      "Epoch 608/1000\n",
      "67/67 [==============================] - 24s 362ms/step - loss: 0.2011 - accuracy: 0.9459 - val_loss: 0.1946 - val_accuracy: 0.9475\n",
      "Epoch 609/1000\n",
      "67/67 [==============================] - 24s 366ms/step - loss: 0.2010 - accuracy: 0.9459 - val_loss: 0.1958 - val_accuracy: 0.9475\n",
      "Epoch 610/1000\n",
      "67/67 [==============================] - 25s 367ms/step - loss: 0.2026 - accuracy: 0.9459 - val_loss: 0.1976 - val_accuracy: 0.9475\n",
      "Epoch 611/1000\n",
      "67/67 [==============================] - 24s 365ms/step - loss: 0.2018 - accuracy: 0.9459 - val_loss: 0.1940 - val_accuracy: 0.9475\n",
      "Epoch 612/1000\n",
      "67/67 [==============================] - 24s 364ms/step - loss: 0.2023 - accuracy: 0.9459 - val_loss: 0.1941 - val_accuracy: 0.9475\n",
      "Epoch 613/1000\n",
      "67/67 [==============================] - 24s 363ms/step - loss: 0.2017 - accuracy: 0.9459 - val_loss: 0.1938 - val_accuracy: 0.9475\n",
      "Epoch 614/1000\n",
      "67/67 [==============================] - 24s 360ms/step - loss: 0.2029 - accuracy: 0.9459 - val_loss: 0.1965 - val_accuracy: 0.9475\n",
      "Epoch 615/1000\n",
      "67/67 [==============================] - 25s 367ms/step - loss: 0.2005 - accuracy: 0.9459 - val_loss: 0.1948 - val_accuracy: 0.9475\n",
      "Epoch 616/1000\n",
      "67/67 [==============================] - 24s 362ms/step - loss: 0.2027 - accuracy: 0.9459 - val_loss: 0.1946 - val_accuracy: 0.9475\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 617/1000\n",
      "67/67 [==============================] - 24s 364ms/step - loss: 0.2005 - accuracy: 0.9459 - val_loss: 0.1949 - val_accuracy: 0.9475\n",
      "Epoch 618/1000\n",
      "67/67 [==============================] - 24s 363ms/step - loss: 0.2019 - accuracy: 0.9459 - val_loss: 0.1938 - val_accuracy: 0.9475\n",
      "Epoch 619/1000\n",
      "67/67 [==============================] - 24s 364ms/step - loss: 0.2016 - accuracy: 0.9459 - val_loss: 0.1946 - val_accuracy: 0.9475\n",
      "Epoch 620/1000\n",
      "67/67 [==============================] - 25s 367ms/step - loss: 0.2022 - accuracy: 0.9459 - val_loss: 0.1960 - val_accuracy: 0.9475\n",
      "Epoch 621/1000\n",
      "67/67 [==============================] - 24s 360ms/step - loss: 0.2005 - accuracy: 0.9459 - val_loss: 0.1980 - val_accuracy: 0.9475\n",
      "Epoch 622/1000\n",
      "67/67 [==============================] - 24s 362ms/step - loss: 0.2019 - accuracy: 0.9459 - val_loss: 0.1932 - val_accuracy: 0.9475\n",
      "Epoch 623/1000\n",
      "67/67 [==============================] - 24s 362ms/step - loss: 0.2016 - accuracy: 0.9459 - val_loss: 0.1941 - val_accuracy: 0.9475\n",
      "Epoch 624/1000\n",
      "67/67 [==============================] - 24s 364ms/step - loss: 0.2031 - accuracy: 0.9459 - val_loss: 0.1961 - val_accuracy: 0.9475\n",
      "Epoch 625/1000\n",
      "67/67 [==============================] - 24s 355ms/step - loss: 0.2003 - accuracy: 0.9459 - val_loss: 0.2000 - val_accuracy: 0.9475\n",
      "Epoch 626/1000\n",
      "67/67 [==============================] - 24s 358ms/step - loss: 0.2040 - accuracy: 0.9459 - val_loss: 0.1945 - val_accuracy: 0.9475\n",
      "Epoch 627/1000\n",
      "67/67 [==============================] - 24s 356ms/step - loss: 0.2008 - accuracy: 0.9459 - val_loss: 0.1945 - val_accuracy: 0.9475\n",
      "Epoch 628/1000\n",
      "67/67 [==============================] - 24s 360ms/step - loss: 0.2008 - accuracy: 0.9459 - val_loss: 0.1935 - val_accuracy: 0.9475\n",
      "Epoch 629/1000\n",
      "67/67 [==============================] - 24s 364ms/step - loss: 0.2001 - accuracy: 0.9459 - val_loss: 0.1969 - val_accuracy: 0.9475\n",
      "Epoch 630/1000\n",
      "67/67 [==============================] - 24s 364ms/step - loss: 0.2016 - accuracy: 0.9459 - val_loss: 0.1957 - val_accuracy: 0.9475\n",
      "Epoch 631/1000\n",
      "67/67 [==============================] - 24s 362ms/step - loss: 0.2033 - accuracy: 0.9459 - val_loss: 0.1961 - val_accuracy: 0.9475\n",
      "Epoch 632/1000\n",
      "67/67 [==============================] - 24s 365ms/step - loss: 0.2036 - accuracy: 0.9459 - val_loss: 0.1939 - val_accuracy: 0.9475\n",
      "Epoch 633/1000\n",
      "67/67 [==============================] - 24s 359ms/step - loss: 0.2009 - accuracy: 0.9459 - val_loss: 0.1933 - val_accuracy: 0.9475\n",
      "Epoch 634/1000\n",
      "67/67 [==============================] - 25s 366ms/step - loss: 0.2006 - accuracy: 0.9459 - val_loss: 0.1931 - val_accuracy: 0.9475\n",
      "Epoch 635/1000\n",
      "67/67 [==============================] - 24s 364ms/step - loss: 0.2006 - accuracy: 0.9459 - val_loss: 0.1948 - val_accuracy: 0.9475\n",
      "Epoch 636/1000\n",
      "67/67 [==============================] - 24s 358ms/step - loss: 0.2003 - accuracy: 0.9459 - val_loss: 0.1963 - val_accuracy: 0.9475\n",
      "Epoch 637/1000\n",
      "67/67 [==============================] - 25s 367ms/step - loss: 0.2016 - accuracy: 0.9459 - val_loss: 0.1941 - val_accuracy: 0.9475\n",
      "Epoch 638/1000\n",
      "67/67 [==============================] - 24s 362ms/step - loss: 0.2014 - accuracy: 0.9459 - val_loss: 0.1997 - val_accuracy: 0.9475\n",
      "Epoch 639/1000\n",
      "67/67 [==============================] - 24s 363ms/step - loss: 0.2036 - accuracy: 0.9459 - val_loss: 0.1942 - val_accuracy: 0.9475\n",
      "Epoch 640/1000\n",
      "67/67 [==============================] - 24s 363ms/step - loss: 0.2026 - accuracy: 0.9459 - val_loss: 0.1943 - val_accuracy: 0.9475\n",
      "Epoch 641/1000\n",
      "67/67 [==============================] - 24s 354ms/step - loss: 0.2033 - accuracy: 0.9459 - val_loss: 0.1967 - val_accuracy: 0.9475\n",
      "Epoch 642/1000\n",
      "67/67 [==============================] - 25s 368ms/step - loss: 0.2016 - accuracy: 0.9459 - val_loss: 0.1945 - val_accuracy: 0.9475\n",
      "Epoch 643/1000\n",
      "67/67 [==============================] - 24s 350ms/step - loss: 0.2013 - accuracy: 0.9459 - val_loss: 0.1938 - val_accuracy: 0.9475\n",
      "Epoch 644/1000\n",
      "67/67 [==============================] - 24s 358ms/step - loss: 0.2010 - accuracy: 0.9459 - val_loss: 0.1966 - val_accuracy: 0.9475\n",
      "Epoch 645/1000\n",
      "67/67 [==============================] - 24s 360ms/step - loss: 0.2006 - accuracy: 0.9459 - val_loss: 0.1947 - val_accuracy: 0.9475\n",
      "Epoch 646/1000\n",
      "67/67 [==============================] - 24s 360ms/step - loss: 0.2017 - accuracy: 0.9459 - val_loss: 0.1956 - val_accuracy: 0.9475\n",
      "Epoch 647/1000\n",
      "67/67 [==============================] - 24s 361ms/step - loss: 0.2013 - accuracy: 0.9459 - val_loss: 0.1946 - val_accuracy: 0.9475\n",
      "Epoch 648/1000\n",
      "67/67 [==============================] - 24s 361ms/step - loss: 0.2022 - accuracy: 0.9459 - val_loss: 0.1950 - val_accuracy: 0.9475\n",
      "Epoch 649/1000\n",
      "67/67 [==============================] - 24s 362ms/step - loss: 0.2026 - accuracy: 0.9459 - val_loss: 0.1939 - val_accuracy: 0.9475\n",
      "Epoch 650/1000\n",
      "67/67 [==============================] - 24s 363ms/step - loss: 0.2016 - accuracy: 0.9459 - val_loss: 0.1953 - val_accuracy: 0.9475\n",
      "Epoch 651/1000\n",
      "67/67 [==============================] - 25s 368ms/step - loss: 0.2041 - accuracy: 0.9459 - val_loss: 0.1984 - val_accuracy: 0.9475\n",
      "Epoch 652/1000\n",
      "67/67 [==============================] - 25s 369ms/step - loss: 0.2022 - accuracy: 0.9459 - val_loss: 0.1938 - val_accuracy: 0.9475\n",
      "Epoch 653/1000\n",
      "67/67 [==============================] - 24s 366ms/step - loss: 0.2013 - accuracy: 0.9459 - val_loss: 0.2007 - val_accuracy: 0.9475\n",
      "Epoch 654/1000\n",
      "67/67 [==============================] - 24s 365ms/step - loss: 0.2030 - accuracy: 0.9459 - val_loss: 0.1955 - val_accuracy: 0.9475\n",
      "Epoch 655/1000\n",
      "67/67 [==============================] - 24s 363ms/step - loss: 0.2006 - accuracy: 0.9459 - val_loss: 0.1951 - val_accuracy: 0.9475\n",
      "Epoch 656/1000\n",
      "67/67 [==============================] - 24s 364ms/step - loss: 0.2003 - accuracy: 0.9459 - val_loss: 0.1942 - val_accuracy: 0.9475\n",
      "Epoch 657/1000\n",
      "67/67 [==============================] - 24s 361ms/step - loss: 0.2014 - accuracy: 0.9459 - val_loss: 0.1938 - val_accuracy: 0.9475\n",
      "Epoch 658/1000\n",
      "67/67 [==============================] - 24s 352ms/step - loss: 0.2010 - accuracy: 0.9459 - val_loss: 0.1946 - val_accuracy: 0.9475\n",
      "Epoch 659/1000\n",
      "67/67 [==============================] - 24s 360ms/step - loss: 0.1997 - accuracy: 0.9459 - val_loss: 0.1937 - val_accuracy: 0.9475\n",
      "Epoch 660/1000\n",
      "67/67 [==============================] - 24s 359ms/step - loss: 0.2008 - accuracy: 0.9459 - val_loss: 0.1952 - val_accuracy: 0.9475\n",
      "Epoch 661/1000\n",
      "67/67 [==============================] - 24s 364ms/step - loss: 0.2000 - accuracy: 0.9459 - val_loss: 0.1955 - val_accuracy: 0.9475\n",
      "Epoch 662/1000\n",
      "67/67 [==============================] - 24s 366ms/step - loss: 0.2013 - accuracy: 0.9459 - val_loss: 0.1990 - val_accuracy: 0.9475\n",
      "Epoch 663/1000\n",
      "67/67 [==============================] - 24s 365ms/step - loss: 0.2016 - accuracy: 0.9459 - val_loss: 0.1946 - val_accuracy: 0.9475\n",
      "Epoch 664/1000\n",
      "67/67 [==============================] - 24s 359ms/step - loss: 0.2011 - accuracy: 0.9459 - val_loss: 0.1941 - val_accuracy: 0.9475\n",
      "Epoch 665/1000\n",
      "67/67 [==============================] - 24s 361ms/step - loss: 0.2004 - accuracy: 0.9459 - val_loss: 0.1939 - val_accuracy: 0.9475\n",
      "Epoch 666/1000\n",
      "67/67 [==============================] - 24s 362ms/step - loss: 0.2002 - accuracy: 0.9459 - val_loss: 0.1950 - val_accuracy: 0.9475\n",
      "Epoch 667/1000\n",
      "67/67 [==============================] - 24s 366ms/step - loss: 0.2019 - accuracy: 0.9459 - val_loss: 0.1959 - val_accuracy: 0.9475\n",
      "Epoch 668/1000\n",
      "67/67 [==============================] - 25s 369ms/step - loss: 0.2011 - accuracy: 0.9459 - val_loss: 0.1936 - val_accuracy: 0.9475\n",
      "Epoch 669/1000\n",
      "67/67 [==============================] - 24s 363ms/step - loss: 0.2026 - accuracy: 0.9459 - val_loss: 0.1950 - val_accuracy: 0.9475\n",
      "Epoch 670/1000\n",
      "67/67 [==============================] - 24s 365ms/step - loss: 0.2018 - accuracy: 0.9459 - val_loss: 0.1943 - val_accuracy: 0.9475\n",
      "Epoch 671/1000\n",
      "67/67 [==============================] - 24s 362ms/step - loss: 0.2016 - accuracy: 0.9459 - val_loss: 0.1952 - val_accuracy: 0.9475\n",
      "Epoch 672/1000\n",
      "67/67 [==============================] - 24s 366ms/step - loss: 0.2019 - accuracy: 0.9459 - val_loss: 0.1942 - val_accuracy: 0.9475\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 673/1000\n",
      "67/67 [==============================] - 24s 352ms/step - loss: 0.2036 - accuracy: 0.9459 - val_loss: 0.1939 - val_accuracy: 0.9475\n",
      "Epoch 674/1000\n",
      "67/67 [==============================] - 24s 363ms/step - loss: 0.2010 - accuracy: 0.9459 - val_loss: 0.1945 - val_accuracy: 0.9475\n",
      "Epoch 675/1000\n",
      "67/67 [==============================] - 24s 363ms/step - loss: 0.2014 - accuracy: 0.9459 - val_loss: 0.1952 - val_accuracy: 0.9475\n",
      "Epoch 676/1000\n",
      "67/67 [==============================] - 24s 357ms/step - loss: 0.2023 - accuracy: 0.9459 - val_loss: 0.1977 - val_accuracy: 0.9475\n",
      "Epoch 677/1000\n",
      "67/67 [==============================] - 24s 362ms/step - loss: 0.2012 - accuracy: 0.9459 - val_loss: 0.1945 - val_accuracy: 0.9475\n",
      "Epoch 678/1000\n",
      "67/67 [==============================] - 24s 364ms/step - loss: 0.2004 - accuracy: 0.9459 - val_loss: 0.1964 - val_accuracy: 0.9475\n",
      "Epoch 679/1000\n",
      "67/67 [==============================] - 24s 361ms/step - loss: 0.2011 - accuracy: 0.9459 - val_loss: 0.1961 - val_accuracy: 0.9475\n",
      "Epoch 680/1000\n",
      "67/67 [==============================] - 24s 360ms/step - loss: 0.2001 - accuracy: 0.9459 - val_loss: 0.1933 - val_accuracy: 0.9475\n",
      "Epoch 681/1000\n",
      "67/67 [==============================] - 24s 365ms/step - loss: 0.2012 - accuracy: 0.9459 - val_loss: 0.1952 - val_accuracy: 0.9475\n",
      "Epoch 682/1000\n",
      "67/67 [==============================] - 24s 361ms/step - loss: 0.2019 - accuracy: 0.9459 - val_loss: 0.1963 - val_accuracy: 0.9475\n",
      "Epoch 683/1000\n",
      "67/67 [==============================] - 24s 360ms/step - loss: 0.2026 - accuracy: 0.9459 - val_loss: 0.1937 - val_accuracy: 0.9475\n",
      "Epoch 684/1000\n",
      "67/67 [==============================] - 24s 362ms/step - loss: 0.2019 - accuracy: 0.9459 - val_loss: 0.1954 - val_accuracy: 0.9475\n",
      "Epoch 685/1000\n",
      "67/67 [==============================] - 24s 361ms/step - loss: 0.2011 - accuracy: 0.9459 - val_loss: 0.1940 - val_accuracy: 0.9475\n",
      "Epoch 686/1000\n",
      "67/67 [==============================] - 24s 366ms/step - loss: 0.2009 - accuracy: 0.9459 - val_loss: 0.1940 - val_accuracy: 0.9475\n",
      "Epoch 687/1000\n",
      "67/67 [==============================] - 25s 367ms/step - loss: 0.2015 - accuracy: 0.9459 - val_loss: 0.1944 - val_accuracy: 0.9475\n",
      "Epoch 688/1000\n",
      "67/67 [==============================] - 24s 362ms/step - loss: 0.2018 - accuracy: 0.9459 - val_loss: 0.1955 - val_accuracy: 0.9475\n",
      "Epoch 689/1000\n",
      "67/67 [==============================] - 24s 362ms/step - loss: 0.2021 - accuracy: 0.9459 - val_loss: 0.1973 - val_accuracy: 0.9475\n",
      "Epoch 690/1000\n",
      "67/67 [==============================] - 24s 356ms/step - loss: 0.2027 - accuracy: 0.9459 - val_loss: 0.1938 - val_accuracy: 0.9475\n",
      "Epoch 691/1000\n",
      "67/67 [==============================] - 24s 358ms/step - loss: 0.2025 - accuracy: 0.9459 - val_loss: 0.1952 - val_accuracy: 0.9475\n",
      "Epoch 692/1000\n",
      "67/67 [==============================] - 24s 364ms/step - loss: 0.2028 - accuracy: 0.9459 - val_loss: 0.1944 - val_accuracy: 0.9475\n",
      "Epoch 693/1000\n",
      "67/67 [==============================] - 24s 365ms/step - loss: 0.2008 - accuracy: 0.9459 - val_loss: 0.1939 - val_accuracy: 0.9475\n",
      "Epoch 694/1000\n",
      "67/67 [==============================] - 24s 363ms/step - loss: 0.2018 - accuracy: 0.9459 - val_loss: 0.1942 - val_accuracy: 0.9475\n",
      "Epoch 695/1000\n",
      "67/67 [==============================] - 24s 360ms/step - loss: 0.2011 - accuracy: 0.9459 - val_loss: 0.1938 - val_accuracy: 0.9475\n",
      "Epoch 696/1000\n",
      "67/67 [==============================] - 24s 363ms/step - loss: 0.2011 - accuracy: 0.9459 - val_loss: 0.1936 - val_accuracy: 0.9475\n",
      "Epoch 697/1000\n",
      "67/67 [==============================] - 24s 366ms/step - loss: 0.2016 - accuracy: 0.9459 - val_loss: 0.1957 - val_accuracy: 0.9475\n",
      "Epoch 698/1000\n",
      "67/67 [==============================] - 24s 366ms/step - loss: 0.2007 - accuracy: 0.9459 - val_loss: 0.1936 - val_accuracy: 0.9475\n",
      "Epoch 699/1000\n",
      "67/67 [==============================] - 24s 362ms/step - loss: 0.2015 - accuracy: 0.9459 - val_loss: 0.1955 - val_accuracy: 0.9475\n",
      "Epoch 700/1000\n",
      "67/67 [==============================] - 24s 365ms/step - loss: 0.2014 - accuracy: 0.9459 - val_loss: 0.1947 - val_accuracy: 0.9475\n",
      "Epoch 701/1000\n",
      "67/67 [==============================] - 24s 363ms/step - loss: 0.2021 - accuracy: 0.9459 - val_loss: 0.1950 - val_accuracy: 0.9475\n",
      "Epoch 702/1000\n",
      "67/67 [==============================] - 24s 364ms/step - loss: 0.2001 - accuracy: 0.9459 - val_loss: 0.1947 - val_accuracy: 0.9475\n",
      "Epoch 703/1000\n",
      "67/67 [==============================] - 24s 361ms/step - loss: 0.2008 - accuracy: 0.9459 - val_loss: 0.1951 - val_accuracy: 0.9475\n",
      "Epoch 704/1000\n",
      "67/67 [==============================] - 24s 360ms/step - loss: 0.2014 - accuracy: 0.9459 - val_loss: 0.1946 - val_accuracy: 0.9475\n",
      "Epoch 705/1000\n",
      "67/67 [==============================] - 24s 367ms/step - loss: 0.2011 - accuracy: 0.9459 - val_loss: 0.1943 - val_accuracy: 0.9475\n",
      "Epoch 706/1000\n",
      "67/67 [==============================] - 24s 362ms/step - loss: 0.2025 - accuracy: 0.9459 - val_loss: 0.1957 - val_accuracy: 0.9475\n",
      "Epoch 707/1000\n",
      "67/67 [==============================] - 26s 391ms/step - loss: 0.1996 - accuracy: 0.9459 - val_loss: 0.1938 - val_accuracy: 0.9475\n",
      "Epoch 708/1000\n",
      "67/67 [==============================] - 26s 390ms/step - loss: 0.2010 - accuracy: 0.9459 - val_loss: 0.1976 - val_accuracy: 0.9475\n",
      "Epoch 709/1000\n",
      "67/67 [==============================] - 26s 389ms/step - loss: 0.2027 - accuracy: 0.9459 - val_loss: 0.1936 - val_accuracy: 0.9475\n",
      "Epoch 710/1000\n",
      "67/67 [==============================] - 26s 396ms/step - loss: 0.2007 - accuracy: 0.9459 - val_loss: 0.1947 - val_accuracy: 0.9475\n",
      "Epoch 711/1000\n",
      "67/67 [==============================] - 26s 396ms/step - loss: 0.2001 - accuracy: 0.9459 - val_loss: 0.1939 - val_accuracy: 0.9475\n",
      "Epoch 712/1000\n",
      "67/67 [==============================] - 27s 398ms/step - loss: 0.2007 - accuracy: 0.9459 - val_loss: 0.1972 - val_accuracy: 0.9475\n",
      "Epoch 713/1000\n",
      "67/67 [==============================] - 25s 381ms/step - loss: 0.2018 - accuracy: 0.9459 - val_loss: 0.2004 - val_accuracy: 0.9475\n",
      "Epoch 714/1000\n",
      "67/67 [==============================] - 24s 361ms/step - loss: 0.2019 - accuracy: 0.9459 - val_loss: 0.1946 - val_accuracy: 0.9475\n",
      "Epoch 715/1000\n",
      "67/67 [==============================] - 24s 364ms/step - loss: 0.2010 - accuracy: 0.9459 - val_loss: 0.1947 - val_accuracy: 0.9475\n",
      "Epoch 716/1000\n",
      "67/67 [==============================] - 24s 363ms/step - loss: 0.2001 - accuracy: 0.9459 - val_loss: 0.1943 - val_accuracy: 0.9475\n",
      "Epoch 717/1000\n",
      "67/67 [==============================] - 24s 361ms/step - loss: 0.2011 - accuracy: 0.9459 - val_loss: 0.1989 - val_accuracy: 0.9475\n",
      "Epoch 718/1000\n",
      "67/67 [==============================] - 24s 363ms/step - loss: 0.2032 - accuracy: 0.9459 - val_loss: 0.1948 - val_accuracy: 0.9475\n",
      "Epoch 719/1000\n",
      "67/67 [==============================] - 25s 367ms/step - loss: 0.2004 - accuracy: 0.9459 - val_loss: 0.1929 - val_accuracy: 0.9475\n",
      "Epoch 720/1000\n",
      "67/67 [==============================] - 24s 365ms/step - loss: 0.2012 - accuracy: 0.9459 - val_loss: 0.1938 - val_accuracy: 0.9475\n",
      "Epoch 721/1000\n",
      "67/67 [==============================] - 24s 365ms/step - loss: 0.2005 - accuracy: 0.9459 - val_loss: 0.1933 - val_accuracy: 0.9475\n",
      "Epoch 722/1000\n",
      "67/67 [==============================] - 25s 367ms/step - loss: 0.2009 - accuracy: 0.9459 - val_loss: 0.1940 - val_accuracy: 0.9475\n",
      "Epoch 723/1000\n",
      "67/67 [==============================] - 24s 366ms/step - loss: 0.2004 - accuracy: 0.9459 - val_loss: 0.1966 - val_accuracy: 0.9475\n",
      "Epoch 724/1000\n",
      "67/67 [==============================] - 24s 362ms/step - loss: 0.2006 - accuracy: 0.9459 - val_loss: 0.1944 - val_accuracy: 0.9475\n",
      "Epoch 725/1000\n",
      "67/67 [==============================] - 25s 367ms/step - loss: 0.2005 - accuracy: 0.9459 - val_loss: 0.1938 - val_accuracy: 0.9475\n",
      "Epoch 726/1000\n",
      "67/67 [==============================] - 24s 364ms/step - loss: 0.2011 - accuracy: 0.9459 - val_loss: 0.1956 - val_accuracy: 0.9475\n",
      "Epoch 727/1000\n",
      "67/67 [==============================] - 24s 365ms/step - loss: 0.2030 - accuracy: 0.9459 - val_loss: 0.1945 - val_accuracy: 0.9475\n",
      "Epoch 728/1000\n",
      "67/67 [==============================] - 25s 368ms/step - loss: 0.2007 - accuracy: 0.9459 - val_loss: 0.1931 - val_accuracy: 0.9475\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 729/1000\n",
      "67/67 [==============================] - 24s 365ms/step - loss: 0.2000 - accuracy: 0.9459 - val_loss: 0.1941 - val_accuracy: 0.9475\n",
      "Epoch 730/1000\n",
      "67/67 [==============================] - 24s 359ms/step - loss: 0.2018 - accuracy: 0.9459 - val_loss: 0.1941 - val_accuracy: 0.9475\n",
      "Epoch 731/1000\n",
      "67/67 [==============================] - 25s 366ms/step - loss: 0.2001 - accuracy: 0.9459 - val_loss: 0.1942 - val_accuracy: 0.9475\n",
      "Epoch 732/1000\n",
      "67/67 [==============================] - 24s 360ms/step - loss: 0.1999 - accuracy: 0.9459 - val_loss: 0.1936 - val_accuracy: 0.9475\n",
      "Epoch 733/1000\n",
      "67/67 [==============================] - 24s 361ms/step - loss: 0.2021 - accuracy: 0.9459 - val_loss: 0.1946 - val_accuracy: 0.9475\n",
      "Epoch 734/1000\n",
      "67/67 [==============================] - 24s 360ms/step - loss: 0.2024 - accuracy: 0.9459 - val_loss: 0.1946 - val_accuracy: 0.9475\n",
      "Epoch 735/1000\n",
      "67/67 [==============================] - 24s 355ms/step - loss: 0.2016 - accuracy: 0.9459 - val_loss: 0.1941 - val_accuracy: 0.9475\n",
      "Epoch 736/1000\n",
      "67/67 [==============================] - 24s 357ms/step - loss: 0.2012 - accuracy: 0.9459 - val_loss: 0.1931 - val_accuracy: 0.9475\n",
      "Epoch 737/1000\n",
      "67/67 [==============================] - 24s 363ms/step - loss: 0.2026 - accuracy: 0.9459 - val_loss: 0.1962 - val_accuracy: 0.9475\n",
      "Epoch 738/1000\n",
      "67/67 [==============================] - 24s 364ms/step - loss: 0.2012 - accuracy: 0.9459 - val_loss: 0.1950 - val_accuracy: 0.9475\n",
      "Epoch 739/1000\n",
      "67/67 [==============================] - 24s 361ms/step - loss: 0.2002 - accuracy: 0.9459 - val_loss: 0.1952 - val_accuracy: 0.9475\n",
      "Epoch 740/1000\n",
      "67/67 [==============================] - 24s 360ms/step - loss: 0.1995 - accuracy: 0.9459 - val_loss: 0.1946 - val_accuracy: 0.9475\n",
      "Epoch 741/1000\n",
      "67/67 [==============================] - 24s 366ms/step - loss: 0.2006 - accuracy: 0.9459 - val_loss: 0.1979 - val_accuracy: 0.9475\n",
      "Epoch 742/1000\n",
      "67/67 [==============================] - 24s 359ms/step - loss: 0.2019 - accuracy: 0.9459 - val_loss: 0.1981 - val_accuracy: 0.9475\n",
      "Epoch 743/1000\n",
      "67/67 [==============================] - 24s 363ms/step - loss: 0.2015 - accuracy: 0.9459 - val_loss: 0.1952 - val_accuracy: 0.9475\n",
      "Epoch 744/1000\n",
      "67/67 [==============================] - 24s 359ms/step - loss: 0.2002 - accuracy: 0.9459 - val_loss: 0.1930 - val_accuracy: 0.9475\n",
      "Epoch 745/1000\n",
      "67/67 [==============================] - 24s 351ms/step - loss: 0.1997 - accuracy: 0.9459 - val_loss: 0.1970 - val_accuracy: 0.9475\n",
      "Epoch 746/1000\n",
      "67/67 [==============================] - 24s 358ms/step - loss: 0.2005 - accuracy: 0.9459 - val_loss: 0.1932 - val_accuracy: 0.9475\n",
      "Epoch 747/1000\n",
      "67/67 [==============================] - 24s 359ms/step - loss: 0.2002 - accuracy: 0.9459 - val_loss: 0.1935 - val_accuracy: 0.9475\n",
      "Epoch 748/1000\n",
      "67/67 [==============================] - 24s 366ms/step - loss: 0.2009 - accuracy: 0.9459 - val_loss: 0.1938 - val_accuracy: 0.9475\n",
      "Epoch 749/1000\n",
      "67/67 [==============================] - 24s 363ms/step - loss: 0.2007 - accuracy: 0.9459 - val_loss: 0.1963 - val_accuracy: 0.9475\n",
      "Epoch 750/1000\n",
      "67/67 [==============================] - 24s 362ms/step - loss: 0.2014 - accuracy: 0.9459 - val_loss: 0.1928 - val_accuracy: 0.9475\n",
      "Epoch 751/1000\n",
      "67/67 [==============================] - 24s 364ms/step - loss: 0.1992 - accuracy: 0.9459 - val_loss: 0.1954 - val_accuracy: 0.9475\n",
      "Epoch 752/1000\n",
      "67/67 [==============================] - 24s 360ms/step - loss: 0.2011 - accuracy: 0.9459 - val_loss: 0.1933 - val_accuracy: 0.9475\n",
      "Epoch 753/1000\n",
      "67/67 [==============================] - 24s 361ms/step - loss: 0.2022 - accuracy: 0.9459 - val_loss: 0.1937 - val_accuracy: 0.9475\n",
      "Epoch 754/1000\n",
      "67/67 [==============================] - 24s 359ms/step - loss: 0.2023 - accuracy: 0.9459 - val_loss: 0.1932 - val_accuracy: 0.9475\n",
      "Epoch 755/1000\n",
      "67/67 [==============================] - 24s 366ms/step - loss: 0.2011 - accuracy: 0.9459 - val_loss: 0.1938 - val_accuracy: 0.9475\n",
      "Epoch 756/1000\n",
      "67/67 [==============================] - 24s 366ms/step - loss: 0.2005 - accuracy: 0.9459 - val_loss: 0.1931 - val_accuracy: 0.9475\n",
      "Epoch 757/1000\n",
      "67/67 [==============================] - 24s 366ms/step - loss: 0.2014 - accuracy: 0.9459 - val_loss: 0.1944 - val_accuracy: 0.9475\n",
      "Epoch 758/1000\n",
      "67/67 [==============================] - 24s 359ms/step - loss: 0.2010 - accuracy: 0.9459 - val_loss: 0.1934 - val_accuracy: 0.9475\n",
      "Epoch 759/1000\n",
      "67/67 [==============================] - 24s 363ms/step - loss: 0.2005 - accuracy: 0.9459 - val_loss: 0.1941 - val_accuracy: 0.9475\n",
      "Epoch 760/1000\n",
      "67/67 [==============================] - 24s 353ms/step - loss: 0.2008 - accuracy: 0.9459 - val_loss: 0.1946 - val_accuracy: 0.9475\n",
      "Epoch 761/1000\n",
      "67/67 [==============================] - 24s 353ms/step - loss: 0.2006 - accuracy: 0.9459 - val_loss: 0.1983 - val_accuracy: 0.9475\n",
      "Epoch 762/1000\n",
      "67/67 [==============================] - 24s 360ms/step - loss: 0.2024 - accuracy: 0.9459 - val_loss: 0.1941 - val_accuracy: 0.9475\n",
      "Epoch 763/1000\n",
      "67/67 [==============================] - 24s 361ms/step - loss: 0.2004 - accuracy: 0.9459 - val_loss: 0.1953 - val_accuracy: 0.9475\n",
      "Epoch 764/1000\n",
      "67/67 [==============================] - 24s 361ms/step - loss: 0.2011 - accuracy: 0.9459 - val_loss: 0.1939 - val_accuracy: 0.9475\n",
      "Epoch 765/1000\n",
      "67/67 [==============================] - 24s 361ms/step - loss: 0.2010 - accuracy: 0.9459 - val_loss: 0.1938 - val_accuracy: 0.9475\n",
      "Epoch 766/1000\n",
      "67/67 [==============================] - 24s 363ms/step - loss: 0.2009 - accuracy: 0.9459 - val_loss: 0.1937 - val_accuracy: 0.9475\n",
      "Epoch 767/1000\n",
      "67/67 [==============================] - 25s 368ms/step - loss: 0.2013 - accuracy: 0.9459 - val_loss: 0.1975 - val_accuracy: 0.9475\n",
      "Epoch 768/1000\n",
      "67/67 [==============================] - 24s 366ms/step - loss: 0.2010 - accuracy: 0.9459 - val_loss: 0.1928 - val_accuracy: 0.9475\n",
      "Epoch 769/1000\n",
      "67/67 [==============================] - 24s 364ms/step - loss: 0.2014 - accuracy: 0.9459 - val_loss: 0.1950 - val_accuracy: 0.9475\n",
      "Epoch 770/1000\n",
      "67/67 [==============================] - 24s 365ms/step - loss: 0.2006 - accuracy: 0.9459 - val_loss: 0.1939 - val_accuracy: 0.9475\n",
      "Epoch 771/1000\n",
      "67/67 [==============================] - 24s 364ms/step - loss: 0.2006 - accuracy: 0.9459 - val_loss: 0.1993 - val_accuracy: 0.9475\n",
      "Epoch 772/1000\n",
      "67/67 [==============================] - 24s 363ms/step - loss: 0.2010 - accuracy: 0.9459 - val_loss: 0.1946 - val_accuracy: 0.9475\n",
      "Epoch 773/1000\n",
      "67/67 [==============================] - 24s 363ms/step - loss: 0.1999 - accuracy: 0.9459 - val_loss: 0.1944 - val_accuracy: 0.9475\n",
      "Epoch 774/1000\n",
      "67/67 [==============================] - 24s 364ms/step - loss: 0.1998 - accuracy: 0.9459 - val_loss: 0.1965 - val_accuracy: 0.9475\n",
      "Epoch 775/1000\n",
      "67/67 [==============================] - 24s 360ms/step - loss: 0.2000 - accuracy: 0.9459 - val_loss: 0.1929 - val_accuracy: 0.9475\n",
      "Epoch 776/1000\n",
      "67/67 [==============================] - 25s 367ms/step - loss: 0.2004 - accuracy: 0.9459 - val_loss: 0.1928 - val_accuracy: 0.9475\n",
      "Epoch 777/1000\n",
      "67/67 [==============================] - 25s 366ms/step - loss: 0.2009 - accuracy: 0.9459 - val_loss: 0.1958 - val_accuracy: 0.9475\n",
      "Epoch 778/1000\n",
      "67/67 [==============================] - 24s 361ms/step - loss: 0.2016 - accuracy: 0.9459 - val_loss: 0.1934 - val_accuracy: 0.9475\n",
      "Epoch 779/1000\n",
      "67/67 [==============================] - 24s 361ms/step - loss: 0.1999 - accuracy: 0.9459 - val_loss: 0.1934 - val_accuracy: 0.9475\n",
      "Epoch 780/1000\n",
      "67/67 [==============================] - 25s 369ms/step - loss: 0.2011 - accuracy: 0.9459 - val_loss: 0.1937 - val_accuracy: 0.9475\n",
      "Epoch 781/1000\n",
      "67/67 [==============================] - 24s 365ms/step - loss: 0.1997 - accuracy: 0.9459 - val_loss: 0.1957 - val_accuracy: 0.9475\n",
      "Epoch 782/1000\n",
      "67/67 [==============================] - 24s 355ms/step - loss: 0.2009 - accuracy: 0.9459 - val_loss: 0.1932 - val_accuracy: 0.9475\n",
      "Epoch 783/1000\n",
      "67/67 [==============================] - 24s 363ms/step - loss: 0.1991 - accuracy: 0.9459 - val_loss: 0.2001 - val_accuracy: 0.9475\n",
      "Epoch 784/1000\n",
      "67/67 [==============================] - 24s 365ms/step - loss: 0.1999 - accuracy: 0.9459 - val_loss: 0.1935 - val_accuracy: 0.9475\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 785/1000\n",
      "67/67 [==============================] - 24s 351ms/step - loss: 0.2007 - accuracy: 0.9459 - val_loss: 0.1995 - val_accuracy: 0.9475\n",
      "Epoch 786/1000\n",
      "67/67 [==============================] - 24s 360ms/step - loss: 0.2021 - accuracy: 0.9459 - val_loss: 0.1996 - val_accuracy: 0.9475\n",
      "Epoch 787/1000\n",
      "67/67 [==============================] - 24s 364ms/step - loss: 0.2028 - accuracy: 0.9459 - val_loss: 0.1950 - val_accuracy: 0.9475\n",
      "Epoch 788/1000\n",
      "67/67 [==============================] - 24s 366ms/step - loss: 0.2016 - accuracy: 0.9459 - val_loss: 0.2014 - val_accuracy: 0.9475\n",
      "Epoch 789/1000\n",
      "67/67 [==============================] - 24s 363ms/step - loss: 0.2017 - accuracy: 0.9459 - val_loss: 0.1953 - val_accuracy: 0.9475\n",
      "Epoch 790/1000\n",
      "67/67 [==============================] - 24s 362ms/step - loss: 0.1998 - accuracy: 0.9459 - val_loss: 0.1940 - val_accuracy: 0.9475\n",
      "Epoch 791/1000\n",
      "67/67 [==============================] - 24s 364ms/step - loss: 0.1996 - accuracy: 0.9459 - val_loss: 0.1938 - val_accuracy: 0.9475\n",
      "Epoch 792/1000\n",
      "67/67 [==============================] - 24s 359ms/step - loss: 0.2019 - accuracy: 0.9459 - val_loss: 0.1955 - val_accuracy: 0.9475\n",
      "Epoch 793/1000\n",
      "67/67 [==============================] - 25s 366ms/step - loss: 0.2021 - accuracy: 0.9459 - val_loss: 0.1935 - val_accuracy: 0.9475\n",
      "Epoch 794/1000\n",
      "67/67 [==============================] - 24s 359ms/step - loss: 0.2000 - accuracy: 0.9459 - val_loss: 0.1933 - val_accuracy: 0.9475\n",
      "Epoch 795/1000\n",
      "67/67 [==============================] - 24s 363ms/step - loss: 0.1994 - accuracy: 0.9459 - val_loss: 0.1933 - val_accuracy: 0.9475\n",
      "Epoch 796/1000\n",
      "67/67 [==============================] - 24s 363ms/step - loss: 0.2011 - accuracy: 0.9459 - val_loss: 0.1932 - val_accuracy: 0.9475\n",
      "Epoch 797/1000\n",
      "67/67 [==============================] - 24s 355ms/step - loss: 0.1993 - accuracy: 0.9459 - val_loss: 0.1982 - val_accuracy: 0.9475\n",
      "Epoch 798/1000\n",
      "67/67 [==============================] - 24s 362ms/step - loss: 0.2030 - accuracy: 0.9459 - val_loss: 0.1951 - val_accuracy: 0.9475\n",
      "Epoch 799/1000\n",
      "67/67 [==============================] - 24s 351ms/step - loss: 0.2013 - accuracy: 0.9459 - val_loss: 0.1953 - val_accuracy: 0.9475\n",
      "Epoch 800/1000\n",
      "67/67 [==============================] - 24s 358ms/step - loss: 0.2019 - accuracy: 0.9459 - val_loss: 0.1953 - val_accuracy: 0.9475\n",
      "Epoch 801/1000\n",
      "67/67 [==============================] - 24s 363ms/step - loss: 0.1989 - accuracy: 0.9459 - val_loss: 0.1933 - val_accuracy: 0.9475\n",
      "Epoch 802/1000\n",
      "67/67 [==============================] - 24s 365ms/step - loss: 0.2005 - accuracy: 0.9459 - val_loss: 0.1941 - val_accuracy: 0.9475\n",
      "Epoch 803/1000\n",
      "67/67 [==============================] - 24s 359ms/step - loss: 0.2005 - accuracy: 0.9459 - val_loss: 0.1957 - val_accuracy: 0.9475\n",
      "Epoch 804/1000\n",
      "67/67 [==============================] - 24s 361ms/step - loss: 0.2012 - accuracy: 0.9459 - val_loss: 0.1962 - val_accuracy: 0.9475\n",
      "Epoch 805/1000\n",
      "67/67 [==============================] - 24s 363ms/step - loss: 0.2003 - accuracy: 0.9459 - val_loss: 0.1940 - val_accuracy: 0.9475\n",
      "Epoch 806/1000\n",
      "67/67 [==============================] - 23s 351ms/step - loss: 0.2003 - accuracy: 0.9459 - val_loss: 0.1933 - val_accuracy: 0.9475\n",
      "Epoch 807/1000\n",
      "67/67 [==============================] - 24s 356ms/step - loss: 0.1994 - accuracy: 0.9459 - val_loss: 0.1935 - val_accuracy: 0.9475\n",
      "Epoch 808/1000\n",
      "67/67 [==============================] - 24s 359ms/step - loss: 0.1998 - accuracy: 0.9459 - val_loss: 0.1940 - val_accuracy: 0.9475\n",
      "Epoch 809/1000\n",
      "67/67 [==============================] - 24s 364ms/step - loss: 0.2012 - accuracy: 0.9459 - val_loss: 0.1958 - val_accuracy: 0.9475\n",
      "Epoch 810/1000\n",
      "67/67 [==============================] - 24s 361ms/step - loss: 0.1997 - accuracy: 0.9459 - val_loss: 0.1938 - val_accuracy: 0.9475\n",
      "Epoch 811/1000\n",
      "67/67 [==============================] - 24s 364ms/step - loss: 0.1997 - accuracy: 0.9459 - val_loss: 0.1935 - val_accuracy: 0.9475\n",
      "Epoch 812/1000\n",
      "67/67 [==============================] - 24s 361ms/step - loss: 0.1995 - accuracy: 0.9459 - val_loss: 0.1940 - val_accuracy: 0.9475\n",
      "Epoch 813/1000\n",
      "67/67 [==============================] - 24s 359ms/step - loss: 0.1997 - accuracy: 0.9459 - val_loss: 0.1941 - val_accuracy: 0.9475\n",
      "Epoch 814/1000\n",
      "67/67 [==============================] - 24s 363ms/step - loss: 0.2001 - accuracy: 0.9459 - val_loss: 0.1969 - val_accuracy: 0.9475\n",
      "Epoch 815/1000\n",
      "67/67 [==============================] - 24s 366ms/step - loss: 0.2035 - accuracy: 0.9459 - val_loss: 0.1942 - val_accuracy: 0.9475\n",
      "Epoch 816/1000\n",
      "67/67 [==============================] - 24s 366ms/step - loss: 0.1998 - accuracy: 0.9459 - val_loss: 0.1949 - val_accuracy: 0.9475\n",
      "Epoch 817/1000\n",
      "67/67 [==============================] - 24s 362ms/step - loss: 0.2004 - accuracy: 0.9459 - val_loss: 0.1968 - val_accuracy: 0.9475\n",
      "Epoch 818/1000\n",
      "67/67 [==============================] - 24s 361ms/step - loss: 0.2003 - accuracy: 0.9459 - val_loss: 0.1949 - val_accuracy: 0.9475\n",
      "Epoch 819/1000\n",
      "67/67 [==============================] - 24s 361ms/step - loss: 0.2005 - accuracy: 0.9459 - val_loss: 0.1937 - val_accuracy: 0.9475\n",
      "Epoch 820/1000\n",
      "67/67 [==============================] - 24s 360ms/step - loss: 0.1995 - accuracy: 0.9459 - val_loss: 0.1958 - val_accuracy: 0.9475\n",
      "Epoch 821/1000\n",
      "67/67 [==============================] - 24s 356ms/step - loss: 0.2007 - accuracy: 0.9459 - val_loss: 0.1953 - val_accuracy: 0.9475\n",
      "Epoch 822/1000\n",
      "67/67 [==============================] - 24s 359ms/step - loss: 0.2006 - accuracy: 0.9459 - val_loss: 0.1954 - val_accuracy: 0.9475\n",
      "Epoch 823/1000\n",
      "67/67 [==============================] - 24s 358ms/step - loss: 0.2034 - accuracy: 0.9459 - val_loss: 0.1972 - val_accuracy: 0.9475\n",
      "Epoch 824/1000\n",
      "67/67 [==============================] - 24s 365ms/step - loss: 0.2006 - accuracy: 0.9459 - val_loss: 0.1928 - val_accuracy: 0.9475\n",
      "Epoch 825/1000\n",
      "67/67 [==============================] - 24s 368ms/step - loss: 0.2006 - accuracy: 0.9459 - val_loss: 0.1938 - val_accuracy: 0.9475\n",
      "Epoch 826/1000\n",
      "67/67 [==============================] - 24s 367ms/step - loss: 0.2006 - accuracy: 0.9459 - val_loss: 0.1963 - val_accuracy: 0.9475\n",
      "Epoch 827/1000\n",
      "67/67 [==============================] - 24s 365ms/step - loss: 0.2034 - accuracy: 0.9459 - val_loss: 0.1952 - val_accuracy: 0.9475\n",
      "Epoch 828/1000\n",
      "67/67 [==============================] - 24s 367ms/step - loss: 0.2002 - accuracy: 0.9459 - val_loss: 0.1931 - val_accuracy: 0.9475\n",
      "Epoch 829/1000\n",
      "67/67 [==============================] - 24s 363ms/step - loss: 0.1999 - accuracy: 0.9459 - val_loss: 0.1939 - val_accuracy: 0.9475\n",
      "Epoch 830/1000\n",
      "67/67 [==============================] - 24s 363ms/step - loss: 0.1993 - accuracy: 0.9459 - val_loss: 0.1935 - val_accuracy: 0.9475\n",
      "Epoch 831/1000\n",
      "67/67 [==============================] - 25s 376ms/step - loss: 0.2013 - accuracy: 0.9459 - val_loss: 0.1938 - val_accuracy: 0.9475\n",
      "Epoch 832/1000\n",
      "67/67 [==============================] - 26s 389ms/step - loss: 0.2005 - accuracy: 0.9459 - val_loss: 0.1944 - val_accuracy: 0.9475\n",
      "Epoch 833/1000\n",
      "67/67 [==============================] - 26s 389ms/step - loss: 0.1998 - accuracy: 0.9459 - val_loss: 0.1942 - val_accuracy: 0.9475\n",
      "Epoch 834/1000\n",
      "67/67 [==============================] - 26s 393ms/step - loss: 0.2001 - accuracy: 0.9459 - val_loss: 0.1948 - val_accuracy: 0.9475\n",
      "Epoch 835/1000\n",
      "67/67 [==============================] - 26s 391ms/step - loss: 0.1999 - accuracy: 0.9459 - val_loss: 0.1946 - val_accuracy: 0.9475\n",
      "Epoch 836/1000\n",
      "67/67 [==============================] - 26s 391ms/step - loss: 0.2017 - accuracy: 0.9459 - val_loss: 0.1964 - val_accuracy: 0.9475\n",
      "Epoch 837/1000\n",
      "67/67 [==============================] - 26s 390ms/step - loss: 0.2000 - accuracy: 0.9459 - val_loss: 0.1935 - val_accuracy: 0.9475\n",
      "Epoch 838/1000\n",
      "67/67 [==============================] - 25s 368ms/step - loss: 0.1997 - accuracy: 0.9459 - val_loss: 0.1929 - val_accuracy: 0.9475\n",
      "Epoch 839/1000\n",
      "67/67 [==============================] - 24s 362ms/step - loss: 0.2002 - accuracy: 0.9459 - val_loss: 0.1932 - val_accuracy: 0.9475\n",
      "Epoch 840/1000\n",
      "67/67 [==============================] - 24s 362ms/step - loss: 0.2008 - accuracy: 0.9459 - val_loss: 0.1958 - val_accuracy: 0.9475\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 841/1000\n",
      "67/67 [==============================] - 24s 360ms/step - loss: 0.2015 - accuracy: 0.9459 - val_loss: 0.1930 - val_accuracy: 0.9475\n",
      "Epoch 842/1000\n",
      "67/67 [==============================] - 25s 371ms/step - loss: 0.1994 - accuracy: 0.9459 - val_loss: 0.1954 - val_accuracy: 0.9475\n",
      "Epoch 843/1000\n",
      "67/67 [==============================] - 24s 365ms/step - loss: 0.2006 - accuracy: 0.9459 - val_loss: 0.1949 - val_accuracy: 0.9475\n",
      "Epoch 844/1000\n",
      "67/67 [==============================] - 25s 369ms/step - loss: 0.2009 - accuracy: 0.9459 - val_loss: 0.1953 - val_accuracy: 0.9475\n",
      "Epoch 845/1000\n",
      "67/67 [==============================] - 24s 357ms/step - loss: 0.2005 - accuracy: 0.9459 - val_loss: 0.1964 - val_accuracy: 0.9475\n",
      "Epoch 846/1000\n",
      "67/67 [==============================] - 24s 357ms/step - loss: 0.2000 - accuracy: 0.9459 - val_loss: 0.1931 - val_accuracy: 0.9475\n",
      "Epoch 847/1000\n",
      "67/67 [==============================] - 24s 353ms/step - loss: 0.1988 - accuracy: 0.9459 - val_loss: 0.1938 - val_accuracy: 0.9475\n",
      "Epoch 848/1000\n",
      "67/67 [==============================] - 24s 359ms/step - loss: 0.1994 - accuracy: 0.9459 - val_loss: 0.1929 - val_accuracy: 0.9475\n",
      "Epoch 849/1000\n",
      "67/67 [==============================] - 24s 359ms/step - loss: 0.1994 - accuracy: 0.9459 - val_loss: 0.2026 - val_accuracy: 0.9475\n",
      "Epoch 850/1000\n",
      "67/67 [==============================] - 24s 367ms/step - loss: 0.2014 - accuracy: 0.9459 - val_loss: 0.1974 - val_accuracy: 0.9475\n",
      "Epoch 851/1000\n",
      "67/67 [==============================] - 24s 362ms/step - loss: 0.2001 - accuracy: 0.9459 - val_loss: 0.2035 - val_accuracy: 0.9475\n",
      "Epoch 852/1000\n",
      "67/67 [==============================] - 24s 363ms/step - loss: 0.2021 - accuracy: 0.9459 - val_loss: 0.1938 - val_accuracy: 0.9475\n",
      "Epoch 853/1000\n",
      "67/67 [==============================] - 24s 363ms/step - loss: 0.2011 - accuracy: 0.9459 - val_loss: 0.2017 - val_accuracy: 0.9475\n",
      "Epoch 854/1000\n",
      "67/67 [==============================] - 24s 362ms/step - loss: 0.2000 - accuracy: 0.9459 - val_loss: 0.1953 - val_accuracy: 0.9475\n",
      "Epoch 855/1000\n",
      "67/67 [==============================] - 24s 362ms/step - loss: 0.2014 - accuracy: 0.9459 - val_loss: 0.1930 - val_accuracy: 0.9475\n",
      "Epoch 856/1000\n",
      "67/67 [==============================] - 25s 368ms/step - loss: 0.2014 - accuracy: 0.9459 - val_loss: 0.1941 - val_accuracy: 0.9475\n",
      "Epoch 857/1000\n",
      "67/67 [==============================] - 24s 364ms/step - loss: 0.2010 - accuracy: 0.9459 - val_loss: 0.1957 - val_accuracy: 0.9475\n",
      "Epoch 858/1000\n",
      "67/67 [==============================] - 24s 364ms/step - loss: 0.1998 - accuracy: 0.9459 - val_loss: 0.1931 - val_accuracy: 0.9475\n",
      "Epoch 859/1000\n",
      "67/67 [==============================] - 24s 363ms/step - loss: 0.2014 - accuracy: 0.9459 - val_loss: 0.1925 - val_accuracy: 0.9475\n",
      "Epoch 860/1000\n",
      "67/67 [==============================] - 24s 362ms/step - loss: 0.1996 - accuracy: 0.9459 - val_loss: 0.1935 - val_accuracy: 0.9475\n",
      "Epoch 861/1000\n",
      "67/67 [==============================] - 24s 360ms/step - loss: 0.1997 - accuracy: 0.9459 - val_loss: 0.1966 - val_accuracy: 0.9475\n",
      "Epoch 862/1000\n",
      "67/67 [==============================] - 24s 359ms/step - loss: 0.2012 - accuracy: 0.9459 - val_loss: 0.1934 - val_accuracy: 0.9475\n",
      "Epoch 863/1000\n",
      "67/67 [==============================] - 24s 359ms/step - loss: 0.2003 - accuracy: 0.9459 - val_loss: 0.1985 - val_accuracy: 0.9475\n",
      "Epoch 864/1000\n",
      "67/67 [==============================] - 24s 355ms/step - loss: 0.2012 - accuracy: 0.9459 - val_loss: 0.1938 - val_accuracy: 0.9475\n",
      "Epoch 865/1000\n",
      "67/67 [==============================] - 24s 366ms/step - loss: 0.2004 - accuracy: 0.9459 - val_loss: 0.1958 - val_accuracy: 0.9475\n",
      "Epoch 866/1000\n",
      "67/67 [==============================] - 24s 361ms/step - loss: 0.1994 - accuracy: 0.9459 - val_loss: 0.1931 - val_accuracy: 0.9475\n",
      "Epoch 867/1000\n",
      "67/67 [==============================] - 24s 358ms/step - loss: 0.2019 - accuracy: 0.9459 - val_loss: 0.1947 - val_accuracy: 0.9475\n",
      "Epoch 868/1000\n",
      "67/67 [==============================] - 24s 366ms/step - loss: 0.1996 - accuracy: 0.9459 - val_loss: 0.1941 - val_accuracy: 0.9475\n",
      "Epoch 869/1000\n",
      "67/67 [==============================] - 24s 362ms/step - loss: 0.1999 - accuracy: 0.9459 - val_loss: 0.1932 - val_accuracy: 0.9475\n",
      "Epoch 870/1000\n",
      "67/67 [==============================] - 24s 363ms/step - loss: 0.2020 - accuracy: 0.9459 - val_loss: 0.1941 - val_accuracy: 0.9475\n",
      "Epoch 871/1000\n",
      "67/67 [==============================] - 25s 368ms/step - loss: 0.2015 - accuracy: 0.9459 - val_loss: 0.1967 - val_accuracy: 0.9475\n",
      "Epoch 872/1000\n",
      "67/67 [==============================] - 24s 363ms/step - loss: 0.2010 - accuracy: 0.9459 - val_loss: 0.1947 - val_accuracy: 0.9475\n",
      "Epoch 873/1000\n",
      "67/67 [==============================] - 24s 362ms/step - loss: 0.2001 - accuracy: 0.9459 - val_loss: 0.1936 - val_accuracy: 0.9475\n",
      "Epoch 874/1000\n",
      "67/67 [==============================] - 25s 367ms/step - loss: 0.2013 - accuracy: 0.9459 - val_loss: 0.1955 - val_accuracy: 0.9475\n",
      "Epoch 875/1000\n",
      "67/67 [==============================] - 24s 365ms/step - loss: 0.2002 - accuracy: 0.9459 - val_loss: 0.1946 - val_accuracy: 0.9475\n",
      "Epoch 876/1000\n",
      "67/67 [==============================] - 24s 362ms/step - loss: 0.1999 - accuracy: 0.9459 - val_loss: 0.1939 - val_accuracy: 0.9475\n",
      "Epoch 877/1000\n",
      "67/67 [==============================] - 25s 368ms/step - loss: 0.2006 - accuracy: 0.9459 - val_loss: 0.1929 - val_accuracy: 0.9475\n",
      "Epoch 878/1000\n",
      "67/67 [==============================] - 24s 362ms/step - loss: 0.2000 - accuracy: 0.9459 - val_loss: 0.1943 - val_accuracy: 0.9475\n",
      "Epoch 879/1000\n",
      "67/67 [==============================] - 24s 363ms/step - loss: 0.2019 - accuracy: 0.9459 - val_loss: 0.1934 - val_accuracy: 0.9475\n",
      "Epoch 880/1000\n",
      "67/67 [==============================] - 24s 363ms/step - loss: 0.2003 - accuracy: 0.9459 - val_loss: 0.1929 - val_accuracy: 0.9475\n",
      "Epoch 881/1000\n",
      "67/67 [==============================] - 24s 359ms/step - loss: 0.2004 - accuracy: 0.9459 - val_loss: 0.1925 - val_accuracy: 0.9475\n",
      "Epoch 882/1000\n",
      "67/67 [==============================] - 24s 363ms/step - loss: 0.1994 - accuracy: 0.9459 - val_loss: 0.1928 - val_accuracy: 0.9475\n",
      "Epoch 883/1000\n",
      "67/67 [==============================] - 24s 363ms/step - loss: 0.1992 - accuracy: 0.9459 - val_loss: 0.1952 - val_accuracy: 0.9475\n",
      "Epoch 884/1000\n",
      "67/67 [==============================] - 24s 366ms/step - loss: 0.2012 - accuracy: 0.9459 - val_loss: 0.1945 - val_accuracy: 0.9475\n",
      "Epoch 885/1000\n",
      "67/67 [==============================] - 24s 365ms/step - loss: 0.1992 - accuracy: 0.9459 - val_loss: 0.1932 - val_accuracy: 0.9475\n",
      "Epoch 886/1000\n",
      "67/67 [==============================] - 24s 366ms/step - loss: 0.2001 - accuracy: 0.9459 - val_loss: 0.1963 - val_accuracy: 0.9475\n",
      "Epoch 887/1000\n",
      "67/67 [==============================] - 24s 367ms/step - loss: 0.1998 - accuracy: 0.9459 - val_loss: 0.1943 - val_accuracy: 0.9475\n",
      "Epoch 888/1000\n",
      "67/67 [==============================] - 25s 367ms/step - loss: 0.2003 - accuracy: 0.9459 - val_loss: 0.1928 - val_accuracy: 0.9475\n",
      "Epoch 889/1000\n",
      "67/67 [==============================] - 24s 365ms/step - loss: 0.1999 - accuracy: 0.9459 - val_loss: 0.1927 - val_accuracy: 0.9475\n",
      "Epoch 890/1000\n",
      "67/67 [==============================] - 24s 363ms/step - loss: 0.2001 - accuracy: 0.9459 - val_loss: 0.1941 - val_accuracy: 0.9475\n",
      "Epoch 891/1000\n",
      "67/67 [==============================] - 24s 366ms/step - loss: 0.1996 - accuracy: 0.9459 - val_loss: 0.1956 - val_accuracy: 0.9475\n",
      "Epoch 892/1000\n",
      "67/67 [==============================] - 24s 367ms/step - loss: 0.2003 - accuracy: 0.9459 - val_loss: 0.1940 - val_accuracy: 0.9475\n",
      "Epoch 893/1000\n",
      "67/67 [==============================] - 24s 366ms/step - loss: 0.2002 - accuracy: 0.9459 - val_loss: 0.1929 - val_accuracy: 0.9475\n",
      "Epoch 894/1000\n",
      "67/67 [==============================] - 24s 365ms/step - loss: 0.1995 - accuracy: 0.9459 - val_loss: 0.1925 - val_accuracy: 0.9475\n",
      "Epoch 895/1000\n",
      "67/67 [==============================] - 24s 363ms/step - loss: 0.1998 - accuracy: 0.9459 - val_loss: 0.1927 - val_accuracy: 0.9475\n",
      "Epoch 896/1000\n",
      "67/67 [==============================] - 24s 364ms/step - loss: 0.1999 - accuracy: 0.9459 - val_loss: 0.1940 - val_accuracy: 0.9475\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 897/1000\n",
      "67/67 [==============================] - 24s 366ms/step - loss: 0.1998 - accuracy: 0.9459 - val_loss: 0.1934 - val_accuracy: 0.9475\n",
      "Epoch 898/1000\n",
      "67/67 [==============================] - 24s 367ms/step - loss: 0.2004 - accuracy: 0.9459 - val_loss: 0.1943 - val_accuracy: 0.9475\n",
      "Epoch 899/1000\n",
      "67/67 [==============================] - 24s 365ms/step - loss: 0.2005 - accuracy: 0.9459 - val_loss: 0.1945 - val_accuracy: 0.9475\n",
      "Epoch 900/1000\n",
      "67/67 [==============================] - 24s 362ms/step - loss: 0.2002 - accuracy: 0.9459 - val_loss: 0.1932 - val_accuracy: 0.9475\n",
      "Epoch 901/1000\n",
      "67/67 [==============================] - 24s 358ms/step - loss: 0.1999 - accuracy: 0.9459 - val_loss: 0.2031 - val_accuracy: 0.9475\n",
      "Epoch 902/1000\n",
      "67/67 [==============================] - 24s 362ms/step - loss: 0.2014 - accuracy: 0.9459 - val_loss: 0.1981 - val_accuracy: 0.9475\n",
      "Epoch 903/1000\n",
      "67/67 [==============================] - 24s 356ms/step - loss: 0.1988 - accuracy: 0.9459 - val_loss: 0.1928 - val_accuracy: 0.9475\n",
      "Epoch 904/1000\n",
      "67/67 [==============================] - 24s 354ms/step - loss: 0.2011 - accuracy: 0.9459 - val_loss: 0.1969 - val_accuracy: 0.9475\n",
      "Epoch 905/1000\n",
      "67/67 [==============================] - 24s 361ms/step - loss: 0.2012 - accuracy: 0.9459 - val_loss: 0.1935 - val_accuracy: 0.9475\n",
      "Epoch 906/1000\n",
      "67/67 [==============================] - 24s 363ms/step - loss: 0.2006 - accuracy: 0.9459 - val_loss: 0.1928 - val_accuracy: 0.9475\n",
      "Epoch 907/1000\n",
      "67/67 [==============================] - 24s 362ms/step - loss: 0.2009 - accuracy: 0.9459 - val_loss: 0.1944 - val_accuracy: 0.9475\n",
      "Epoch 908/1000\n",
      "67/67 [==============================] - 24s 366ms/step - loss: 0.2012 - accuracy: 0.9459 - val_loss: 0.1965 - val_accuracy: 0.9475\n",
      "Epoch 909/1000\n",
      "67/67 [==============================] - 24s 365ms/step - loss: 0.2006 - accuracy: 0.9459 - val_loss: 0.1934 - val_accuracy: 0.9475\n",
      "Epoch 910/1000\n",
      "67/67 [==============================] - 25s 368ms/step - loss: 0.2005 - accuracy: 0.9459 - val_loss: 0.1933 - val_accuracy: 0.9475\n",
      "Epoch 911/1000\n",
      "67/67 [==============================] - 24s 363ms/step - loss: 0.1999 - accuracy: 0.9459 - val_loss: 0.1949 - val_accuracy: 0.9475\n",
      "Epoch 912/1000\n",
      "67/67 [==============================] - 24s 362ms/step - loss: 0.1992 - accuracy: 0.9459 - val_loss: 0.1935 - val_accuracy: 0.9475\n",
      "Epoch 913/1000\n",
      "67/67 [==============================] - 24s 361ms/step - loss: 0.1993 - accuracy: 0.9459 - val_loss: 0.1945 - val_accuracy: 0.9475\n",
      "Epoch 914/1000\n",
      "67/67 [==============================] - 24s 363ms/step - loss: 0.2027 - accuracy: 0.9459 - val_loss: 0.1943 - val_accuracy: 0.9475\n",
      "Epoch 915/1000\n",
      "67/67 [==============================] - 24s 361ms/step - loss: 0.1998 - accuracy: 0.9459 - val_loss: 0.1934 - val_accuracy: 0.9475\n",
      "Epoch 916/1000\n",
      "67/67 [==============================] - 24s 366ms/step - loss: 0.1995 - accuracy: 0.9459 - val_loss: 0.1957 - val_accuracy: 0.9475\n",
      "Epoch 917/1000\n",
      "67/67 [==============================] - 24s 366ms/step - loss: 0.2025 - accuracy: 0.9459 - val_loss: 0.1950 - val_accuracy: 0.9475\n",
      "Epoch 918/1000\n",
      "67/67 [==============================] - 24s 366ms/step - loss: 0.2007 - accuracy: 0.9459 - val_loss: 0.1944 - val_accuracy: 0.9475\n",
      "Epoch 919/1000\n",
      "67/67 [==============================] - 24s 365ms/step - loss: 0.1998 - accuracy: 0.9459 - val_loss: 0.1939 - val_accuracy: 0.9475\n",
      "Epoch 920/1000\n",
      "67/67 [==============================] - 24s 365ms/step - loss: 0.2010 - accuracy: 0.9459 - val_loss: 0.1931 - val_accuracy: 0.9475\n",
      "Epoch 921/1000\n",
      "67/67 [==============================] - 24s 358ms/step - loss: 0.2011 - accuracy: 0.9459 - val_loss: 0.1928 - val_accuracy: 0.9475\n",
      "Epoch 922/1000\n",
      "67/67 [==============================] - 24s 357ms/step - loss: 0.2021 - accuracy: 0.9459 - val_loss: 0.1947 - val_accuracy: 0.9475\n",
      "Epoch 923/1000\n",
      "67/67 [==============================] - 24s 356ms/step - loss: 0.1992 - accuracy: 0.9459 - val_loss: 0.1944 - val_accuracy: 0.9475\n",
      "Epoch 924/1000\n",
      "67/67 [==============================] - 24s 364ms/step - loss: 0.2002 - accuracy: 0.9459 - val_loss: 0.1969 - val_accuracy: 0.9475\n",
      "Epoch 925/1000\n",
      "67/67 [==============================] - 24s 366ms/step - loss: 0.2004 - accuracy: 0.9459 - val_loss: 0.1934 - val_accuracy: 0.9475\n",
      "Epoch 926/1000\n",
      "67/67 [==============================] - 24s 367ms/step - loss: 0.2003 - accuracy: 0.9459 - val_loss: 0.1922 - val_accuracy: 0.9475\n",
      "Epoch 927/1000\n",
      "67/67 [==============================] - 24s 360ms/step - loss: 0.2010 - accuracy: 0.9459 - val_loss: 0.1926 - val_accuracy: 0.9475\n",
      "Epoch 928/1000\n",
      "67/67 [==============================] - 24s 360ms/step - loss: 0.1997 - accuracy: 0.9459 - val_loss: 0.1928 - val_accuracy: 0.9475\n",
      "Epoch 929/1000\n",
      "67/67 [==============================] - 24s 362ms/step - loss: 0.2018 - accuracy: 0.9459 - val_loss: 0.1951 - val_accuracy: 0.9475\n",
      "Epoch 930/1000\n",
      "67/67 [==============================] - 24s 362ms/step - loss: 0.2008 - accuracy: 0.9459 - val_loss: 0.1939 - val_accuracy: 0.9475\n",
      "Epoch 931/1000\n",
      "67/67 [==============================] - 24s 353ms/step - loss: 0.2000 - accuracy: 0.9459 - val_loss: 0.1931 - val_accuracy: 0.9475\n",
      "Epoch 932/1000\n",
      "67/67 [==============================] - 24s 358ms/step - loss: 0.2006 - accuracy: 0.9459 - val_loss: 0.1933 - val_accuracy: 0.9475\n",
      "Epoch 933/1000\n",
      "67/67 [==============================] - 24s 362ms/step - loss: 0.1998 - accuracy: 0.9459 - val_loss: 0.1960 - val_accuracy: 0.9475\n",
      "Epoch 934/1000\n",
      "67/67 [==============================] - 24s 360ms/step - loss: 0.1995 - accuracy: 0.9459 - val_loss: 0.1934 - val_accuracy: 0.9475\n",
      "Epoch 935/1000\n",
      "67/67 [==============================] - 24s 363ms/step - loss: 0.2005 - accuracy: 0.9459 - val_loss: 0.1941 - val_accuracy: 0.9475\n",
      "Epoch 936/1000\n",
      "67/67 [==============================] - 24s 361ms/step - loss: 0.2000 - accuracy: 0.9459 - val_loss: 0.1930 - val_accuracy: 0.9475\n",
      "Epoch 937/1000\n",
      "67/67 [==============================] - 24s 362ms/step - loss: 0.1990 - accuracy: 0.9459 - val_loss: 0.1929 - val_accuracy: 0.9475\n",
      "Epoch 938/1000\n",
      "67/67 [==============================] - 25s 367ms/step - loss: 0.1990 - accuracy: 0.9459 - val_loss: 0.1929 - val_accuracy: 0.9475\n",
      "Epoch 939/1000\n",
      "67/67 [==============================] - 24s 360ms/step - loss: 0.1984 - accuracy: 0.9459 - val_loss: 0.1936 - val_accuracy: 0.9475\n",
      "Epoch 940/1000\n",
      "67/67 [==============================] - 24s 363ms/step - loss: 0.2003 - accuracy: 0.9459 - val_loss: 0.1925 - val_accuracy: 0.9475\n",
      "Epoch 941/1000\n",
      "67/67 [==============================] - 24s 355ms/step - loss: 0.1997 - accuracy: 0.9459 - val_loss: 0.1952 - val_accuracy: 0.9475\n",
      "Epoch 942/1000\n",
      "67/67 [==============================] - 24s 355ms/step - loss: 0.1999 - accuracy: 0.9459 - val_loss: 0.1930 - val_accuracy: 0.9475\n",
      "Epoch 943/1000\n",
      "67/67 [==============================] - 24s 362ms/step - loss: 0.1982 - accuracy: 0.9459 - val_loss: 0.1932 - val_accuracy: 0.9475\n",
      "Epoch 944/1000\n",
      "67/67 [==============================] - 24s 366ms/step - loss: 0.2022 - accuracy: 0.9459 - val_loss: 0.1956 - val_accuracy: 0.9475\n",
      "Epoch 945/1000\n",
      "67/67 [==============================] - 24s 365ms/step - loss: 0.1992 - accuracy: 0.9459 - val_loss: 0.1925 - val_accuracy: 0.9475\n",
      "Epoch 946/1000\n",
      "67/67 [==============================] - 24s 359ms/step - loss: 0.1999 - accuracy: 0.9459 - val_loss: 0.1931 - val_accuracy: 0.9475\n",
      "Epoch 947/1000\n",
      "67/67 [==============================] - 24s 361ms/step - loss: 0.2017 - accuracy: 0.9459 - val_loss: 0.1940 - val_accuracy: 0.9475\n",
      "Epoch 948/1000\n",
      "67/67 [==============================] - 24s 358ms/step - loss: 0.1999 - accuracy: 0.9459 - val_loss: 0.1966 - val_accuracy: 0.9475\n",
      "Epoch 949/1000\n",
      "67/67 [==============================] - 24s 365ms/step - loss: 0.2012 - accuracy: 0.9459 - val_loss: 0.1940 - val_accuracy: 0.9475\n",
      "Epoch 950/1000\n",
      "67/67 [==============================] - 24s 366ms/step - loss: 0.2007 - accuracy: 0.9459 - val_loss: 0.1930 - val_accuracy: 0.9475\n",
      "Epoch 951/1000\n",
      "67/67 [==============================] - 24s 366ms/step - loss: 0.2001 - accuracy: 0.9459 - val_loss: 0.1927 - val_accuracy: 0.9475\n",
      "Epoch 952/1000\n",
      "67/67 [==============================] - 24s 363ms/step - loss: 0.2010 - accuracy: 0.9459 - val_loss: 0.1931 - val_accuracy: 0.9475\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 953/1000\n",
      "67/67 [==============================] - 24s 362ms/step - loss: 0.2007 - accuracy: 0.9459 - val_loss: 0.1935 - val_accuracy: 0.9475\n",
      "Epoch 954/1000\n",
      "67/67 [==============================] - 24s 364ms/step - loss: 0.2008 - accuracy: 0.9459 - val_loss: 0.1929 - val_accuracy: 0.9475\n",
      "Epoch 955/1000\n",
      "67/67 [==============================] - 24s 363ms/step - loss: 0.1998 - accuracy: 0.9459 - val_loss: 0.1931 - val_accuracy: 0.9475\n",
      "Epoch 956/1000\n",
      "67/67 [==============================] - 26s 383ms/step - loss: 0.1991 - accuracy: 0.9459 - val_loss: 0.1929 - val_accuracy: 0.9475\n",
      "Epoch 957/1000\n",
      "67/67 [==============================] - 26s 382ms/step - loss: 0.2002 - accuracy: 0.9459 - val_loss: 0.1930 - val_accuracy: 0.9475\n",
      "Epoch 958/1000\n",
      "67/67 [==============================] - 26s 392ms/step - loss: 0.2000 - accuracy: 0.9459 - val_loss: 0.1936 - val_accuracy: 0.9475\n",
      "Epoch 959/1000\n",
      "67/67 [==============================] - 26s 383ms/step - loss: 0.2007 - accuracy: 0.9459 - val_loss: 0.1982 - val_accuracy: 0.9475\n",
      "Epoch 960/1000\n",
      "67/67 [==============================] - 26s 391ms/step - loss: 0.2007 - accuracy: 0.9459 - val_loss: 0.1926 - val_accuracy: 0.9475\n",
      "Epoch 961/1000\n",
      "67/67 [==============================] - 26s 392ms/step - loss: 0.2009 - accuracy: 0.9459 - val_loss: 0.1938 - val_accuracy: 0.9475\n",
      "Epoch 962/1000\n",
      "67/67 [==============================] - 25s 373ms/step - loss: 0.1997 - accuracy: 0.9459 - val_loss: 0.1922 - val_accuracy: 0.9475\n",
      "Epoch 963/1000\n",
      "67/67 [==============================] - 24s 363ms/step - loss: 0.1995 - accuracy: 0.9459 - val_loss: 0.1927 - val_accuracy: 0.9475\n",
      "Epoch 964/1000\n",
      "67/67 [==============================] - 25s 367ms/step - loss: 0.1998 - accuracy: 0.9459 - val_loss: 0.1969 - val_accuracy: 0.9475\n",
      "Epoch 965/1000\n",
      "67/67 [==============================] - 24s 366ms/step - loss: 0.2017 - accuracy: 0.9459 - val_loss: 0.1937 - val_accuracy: 0.9475\n",
      "Epoch 966/1000\n",
      "67/67 [==============================] - 24s 366ms/step - loss: 0.2002 - accuracy: 0.9459 - val_loss: 0.1931 - val_accuracy: 0.9475\n",
      "Epoch 967/1000\n",
      "67/67 [==============================] - 24s 361ms/step - loss: 0.1985 - accuracy: 0.9459 - val_loss: 0.1949 - val_accuracy: 0.9475\n",
      "Epoch 968/1000\n",
      "67/67 [==============================] - 24s 358ms/step - loss: 0.1997 - accuracy: 0.9459 - val_loss: 0.2009 - val_accuracy: 0.9475\n",
      "Epoch 969/1000\n",
      "67/67 [==============================] - 24s 360ms/step - loss: 0.1999 - accuracy: 0.9459 - val_loss: 0.1968 - val_accuracy: 0.9475\n",
      "Epoch 970/1000\n",
      "67/67 [==============================] - 24s 358ms/step - loss: 0.2002 - accuracy: 0.9459 - val_loss: 0.1940 - val_accuracy: 0.9475\n",
      "Epoch 971/1000\n",
      "67/67 [==============================] - 24s 362ms/step - loss: 0.1998 - accuracy: 0.9459 - val_loss: 0.1924 - val_accuracy: 0.9475\n",
      "Epoch 972/1000\n",
      "67/67 [==============================] - 24s 361ms/step - loss: 0.1996 - accuracy: 0.9459 - val_loss: 0.1935 - val_accuracy: 0.9475\n",
      "Epoch 973/1000\n",
      "67/67 [==============================] - 24s 361ms/step - loss: 0.2000 - accuracy: 0.9459 - val_loss: 0.1949 - val_accuracy: 0.9475\n",
      "Epoch 974/1000\n",
      "67/67 [==============================] - 24s 361ms/step - loss: 0.2012 - accuracy: 0.9459 - val_loss: 0.1952 - val_accuracy: 0.9475\n",
      "Epoch 975/1000\n",
      "67/67 [==============================] - 24s 365ms/step - loss: 0.2005 - accuracy: 0.9459 - val_loss: 0.1940 - val_accuracy: 0.9475\n",
      "Epoch 976/1000\n",
      "67/67 [==============================] - 24s 363ms/step - loss: 0.2020 - accuracy: 0.9459 - val_loss: 0.1994 - val_accuracy: 0.9475\n",
      "Epoch 977/1000\n",
      "67/67 [==============================] - 24s 360ms/step - loss: 0.2004 - accuracy: 0.9459 - val_loss: 0.1933 - val_accuracy: 0.9475\n",
      "Epoch 978/1000\n",
      "67/67 [==============================] - 24s 362ms/step - loss: 0.2008 - accuracy: 0.9459 - val_loss: 0.1933 - val_accuracy: 0.9475\n",
      "Epoch 979/1000\n",
      "67/67 [==============================] - 24s 366ms/step - loss: 0.1994 - accuracy: 0.9459 - val_loss: 0.1927 - val_accuracy: 0.9475\n",
      "Epoch 980/1000\n",
      "67/67 [==============================] - 25s 368ms/step - loss: 0.2002 - accuracy: 0.9459 - val_loss: 0.1949 - val_accuracy: 0.9475\n",
      "Epoch 981/1000\n",
      "67/67 [==============================] - 24s 359ms/step - loss: 0.1991 - accuracy: 0.9459 - val_loss: 0.1928 - val_accuracy: 0.9475\n",
      "Epoch 982/1000\n",
      "67/67 [==============================] - 24s 367ms/step - loss: 0.2006 - accuracy: 0.9459 - val_loss: 0.1944 - val_accuracy: 0.9475\n",
      "Epoch 983/1000\n",
      "67/67 [==============================] - 24s 365ms/step - loss: 0.2010 - accuracy: 0.9459 - val_loss: 0.1945 - val_accuracy: 0.9475\n",
      "Epoch 984/1000\n",
      "67/67 [==============================] - 25s 370ms/step - loss: 0.1999 - accuracy: 0.9459 - val_loss: 0.1939 - val_accuracy: 0.9475\n",
      "Epoch 985/1000\n",
      "67/67 [==============================] - 25s 366ms/step - loss: 0.1997 - accuracy: 0.9459 - val_loss: 0.1961 - val_accuracy: 0.9475\n",
      "Epoch 986/1000\n",
      "67/67 [==============================] - 24s 364ms/step - loss: 0.2001 - accuracy: 0.9459 - val_loss: 0.1959 - val_accuracy: 0.9475\n",
      "Epoch 987/1000\n",
      "67/67 [==============================] - 24s 365ms/step - loss: 0.2013 - accuracy: 0.9459 - val_loss: 0.1933 - val_accuracy: 0.9475\n",
      "Epoch 988/1000\n",
      "67/67 [==============================] - 24s 362ms/step - loss: 0.1987 - accuracy: 0.9459 - val_loss: 0.1925 - val_accuracy: 0.9475\n",
      "Epoch 989/1000\n",
      "67/67 [==============================] - 24s 364ms/step - loss: 0.2010 - accuracy: 0.9459 - val_loss: 0.1937 - val_accuracy: 0.9475\n",
      "Epoch 990/1000\n",
      "67/67 [==============================] - 25s 368ms/step - loss: 0.2018 - accuracy: 0.9459 - val_loss: 0.1927 - val_accuracy: 0.9475\n",
      "Epoch 991/1000\n",
      "67/67 [==============================] - 24s 365ms/step - loss: 0.1994 - accuracy: 0.9459 - val_loss: 0.1963 - val_accuracy: 0.9475\n",
      "Epoch 992/1000\n",
      "67/67 [==============================] - 24s 363ms/step - loss: 0.1995 - accuracy: 0.9459 - val_loss: 0.1930 - val_accuracy: 0.9475\n",
      "Epoch 993/1000\n",
      "67/67 [==============================] - 24s 367ms/step - loss: 0.1999 - accuracy: 0.9459 - val_loss: 0.1934 - val_accuracy: 0.9475\n",
      "Epoch 994/1000\n",
      "67/67 [==============================] - 25s 371ms/step - loss: 0.1994 - accuracy: 0.9459 - val_loss: 0.1927 - val_accuracy: 0.9475\n",
      "Epoch 995/1000\n",
      "67/67 [==============================] - 25s 366ms/step - loss: 0.1987 - accuracy: 0.9459 - val_loss: 0.1969 - val_accuracy: 0.9475\n",
      "Epoch 996/1000\n",
      "67/67 [==============================] - 25s 366ms/step - loss: 0.2004 - accuracy: 0.9459 - val_loss: 0.1973 - val_accuracy: 0.9475\n",
      "Epoch 997/1000\n",
      "67/67 [==============================] - 25s 368ms/step - loss: 0.2001 - accuracy: 0.9459 - val_loss: 0.1933 - val_accuracy: 0.9475\n",
      "Epoch 998/1000\n",
      "67/67 [==============================] - 24s 364ms/step - loss: 0.2006 - accuracy: 0.9459 - val_loss: 0.1969 - val_accuracy: 0.9475\n",
      "Epoch 999/1000\n",
      "67/67 [==============================] - 24s 361ms/step - loss: 0.1994 - accuracy: 0.9459 - val_loss: 0.1944 - val_accuracy: 0.9475\n",
      "Epoch 1000/1000\n",
      "67/67 [==============================] - 24s 364ms/step - loss: 0.1986 - accuracy: 0.9459 - val_loss: 0.1925 - val_accuracy: 0.9475\n"
     ]
    }
   ],
   "source": [
    "from keras.callbacks import EarlyStopping\n",
    "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=100)\n",
    "history=model.fit([X_img_train, X_audio_train], y_train, batch_size=256, epochs=1000,\n",
    "                            validation_data=([X_img_test, X_audio_test], y_test), callbacks=[es])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_hist(hist):\n",
    "    plt.plot(hist.history[\"accuracy\"])\n",
    "    plt.plot(hist.history[\"val_accuracy\"])\n",
    "    plt.title(\"model accuracy\")\n",
    "    plt.ylabel(\"accuracy\")\n",
    "    plt.xlabel(\"epoch\")\n",
    "    plt.legend([\"train\", \"validation\"], loc=\"lower right\")\n",
    "    plt.savefig('fakeav_combined_acc.eps', format='eps')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_loss(hist):\n",
    "    plt.plot(hist.history['loss'])\n",
    "    plt.plot(hist.history['val_loss'])\n",
    "    plt.title('model loss')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(['train', 'validation'], loc='upper right')\n",
    "    plt.savefig('fakeav_combined_loss.eps', format='eps')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The PostScript backend does not support transparency; partially transparent artists will be rendered opaque.\n",
      "The PostScript backend does not support transparency; partially transparent artists will be rendered opaque.\n"
     ]
    },
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"utf-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       "  \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Created with matplotlib (https://matplotlib.org/) -->\n",
       "<svg height=\"277.314375pt\" version=\"1.1\" viewBox=\"0 0 388.965625 277.314375\" width=\"388.965625pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       " <metadata>\n",
       "  <rdf:RDF xmlns:cc=\"http://creativecommons.org/ns#\" xmlns:dc=\"http://purl.org/dc/elements/1.1/\" xmlns:rdf=\"http://www.w3.org/1999/02/22-rdf-syntax-ns#\">\n",
       "   <cc:Work>\n",
       "    <dc:type rdf:resource=\"http://purl.org/dc/dcmitype/StillImage\"/>\n",
       "    <dc:date>2022-06-13T00:40:23.160655</dc:date>\n",
       "    <dc:format>image/svg+xml</dc:format>\n",
       "    <dc:creator>\n",
       "     <cc:Agent>\n",
       "      <dc:title>Matplotlib v3.3.4, https://matplotlib.org/</dc:title>\n",
       "     </cc:Agent>\n",
       "    </dc:creator>\n",
       "   </cc:Work>\n",
       "  </rdf:RDF>\n",
       " </metadata>\n",
       " <defs>\n",
       "  <style type=\"text/css\">*{stroke-linecap:butt;stroke-linejoin:round;}</style>\n",
       " </defs>\n",
       " <g id=\"figure_1\">\n",
       "  <g id=\"patch_1\">\n",
       "   <path d=\"M -0 277.314375 \n",
       "L 388.965625 277.314375 \n",
       "L 388.965625 0 \n",
       "L -0 0 \n",
       "z\n",
       "\" style=\"fill:none;\"/>\n",
       "  </g>\n",
       "  <g id=\"axes_1\">\n",
       "   <g id=\"patch_2\">\n",
       "    <path d=\"M 46.965625 239.758125 \n",
       "L 381.765625 239.758125 \n",
       "L 381.765625 22.318125 \n",
       "L 46.965625 22.318125 \n",
       "z\n",
       "\" style=\"fill:#ffffff;\"/>\n",
       "   </g>\n",
       "   <g id=\"matplotlib.axis_1\">\n",
       "    <g id=\"xtick_1\">\n",
       "     <g id=\"line2d_1\">\n",
       "      <defs>\n",
       "       <path d=\"M 0 0 \n",
       "L 0 3.5 \n",
       "\" id=\"m6f9e5888b6\" style=\"stroke:#000000;stroke-width:0.8;\"/>\n",
       "      </defs>\n",
       "      <g>\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"62.183807\" xlink:href=\"#m6f9e5888b6\" y=\"239.758125\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_1\">\n",
       "      <!-- 0 -->\n",
       "      <g transform=\"translate(59.002557 254.356562)scale(0.1 -0.1)\">\n",
       "       <defs>\n",
       "        <path d=\"M 31.78125 66.40625 \n",
       "Q 24.171875 66.40625 20.328125 58.90625 \n",
       "Q 16.5 51.421875 16.5 36.375 \n",
       "Q 16.5 21.390625 20.328125 13.890625 \n",
       "Q 24.171875 6.390625 31.78125 6.390625 \n",
       "Q 39.453125 6.390625 43.28125 13.890625 \n",
       "Q 47.125 21.390625 47.125 36.375 \n",
       "Q 47.125 51.421875 43.28125 58.90625 \n",
       "Q 39.453125 66.40625 31.78125 66.40625 \n",
       "z\n",
       "M 31.78125 74.21875 \n",
       "Q 44.046875 74.21875 50.515625 64.515625 \n",
       "Q 56.984375 54.828125 56.984375 36.375 \n",
       "Q 56.984375 17.96875 50.515625 8.265625 \n",
       "Q 44.046875 -1.421875 31.78125 -1.421875 \n",
       "Q 19.53125 -1.421875 13.0625 8.265625 \n",
       "Q 6.59375 17.96875 6.59375 36.375 \n",
       "Q 6.59375 54.828125 13.0625 64.515625 \n",
       "Q 19.53125 74.21875 31.78125 74.21875 \n",
       "z\n",
       "\" id=\"DejaVuSans-48\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#DejaVuSans-48\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_2\">\n",
       "     <g id=\"line2d_2\">\n",
       "      <g>\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"123.117468\" xlink:href=\"#m6f9e5888b6\" y=\"239.758125\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_2\">\n",
       "      <!-- 200 -->\n",
       "      <g transform=\"translate(113.573718 254.356562)scale(0.1 -0.1)\">\n",
       "       <defs>\n",
       "        <path d=\"M 19.1875 8.296875 \n",
       "L 53.609375 8.296875 \n",
       "L 53.609375 0 \n",
       "L 7.328125 0 \n",
       "L 7.328125 8.296875 \n",
       "Q 12.9375 14.109375 22.625 23.890625 \n",
       "Q 32.328125 33.6875 34.8125 36.53125 \n",
       "Q 39.546875 41.84375 41.421875 45.53125 \n",
       "Q 43.3125 49.21875 43.3125 52.78125 \n",
       "Q 43.3125 58.59375 39.234375 62.25 \n",
       "Q 35.15625 65.921875 28.609375 65.921875 \n",
       "Q 23.96875 65.921875 18.8125 64.3125 \n",
       "Q 13.671875 62.703125 7.8125 59.421875 \n",
       "L 7.8125 69.390625 \n",
       "Q 13.765625 71.78125 18.9375 73 \n",
       "Q 24.125 74.21875 28.421875 74.21875 \n",
       "Q 39.75 74.21875 46.484375 68.546875 \n",
       "Q 53.21875 62.890625 53.21875 53.421875 \n",
       "Q 53.21875 48.921875 51.53125 44.890625 \n",
       "Q 49.859375 40.875 45.40625 35.40625 \n",
       "Q 44.1875 33.984375 37.640625 27.21875 \n",
       "Q 31.109375 20.453125 19.1875 8.296875 \n",
       "z\n",
       "\" id=\"DejaVuSans-50\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#DejaVuSans-50\"/>\n",
       "       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n",
       "       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_3\">\n",
       "     <g id=\"line2d_3\">\n",
       "      <g>\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"184.051129\" xlink:href=\"#m6f9e5888b6\" y=\"239.758125\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_3\">\n",
       "      <!-- 400 -->\n",
       "      <g transform=\"translate(174.507379 254.356562)scale(0.1 -0.1)\">\n",
       "       <defs>\n",
       "        <path d=\"M 37.796875 64.3125 \n",
       "L 12.890625 25.390625 \n",
       "L 37.796875 25.390625 \n",
       "z\n",
       "M 35.203125 72.90625 \n",
       "L 47.609375 72.90625 \n",
       "L 47.609375 25.390625 \n",
       "L 58.015625 25.390625 \n",
       "L 58.015625 17.1875 \n",
       "L 47.609375 17.1875 \n",
       "L 47.609375 0 \n",
       "L 37.796875 0 \n",
       "L 37.796875 17.1875 \n",
       "L 4.890625 17.1875 \n",
       "L 4.890625 26.703125 \n",
       "z\n",
       "\" id=\"DejaVuSans-52\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#DejaVuSans-52\"/>\n",
       "       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n",
       "       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_4\">\n",
       "     <g id=\"line2d_4\">\n",
       "      <g>\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"244.98479\" xlink:href=\"#m6f9e5888b6\" y=\"239.758125\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_4\">\n",
       "      <!-- 600 -->\n",
       "      <g transform=\"translate(235.44104 254.356562)scale(0.1 -0.1)\">\n",
       "       <defs>\n",
       "        <path d=\"M 33.015625 40.375 \n",
       "Q 26.375 40.375 22.484375 35.828125 \n",
       "Q 18.609375 31.296875 18.609375 23.390625 \n",
       "Q 18.609375 15.53125 22.484375 10.953125 \n",
       "Q 26.375 6.390625 33.015625 6.390625 \n",
       "Q 39.65625 6.390625 43.53125 10.953125 \n",
       "Q 47.40625 15.53125 47.40625 23.390625 \n",
       "Q 47.40625 31.296875 43.53125 35.828125 \n",
       "Q 39.65625 40.375 33.015625 40.375 \n",
       "z\n",
       "M 52.59375 71.296875 \n",
       "L 52.59375 62.3125 \n",
       "Q 48.875 64.0625 45.09375 64.984375 \n",
       "Q 41.3125 65.921875 37.59375 65.921875 \n",
       "Q 27.828125 65.921875 22.671875 59.328125 \n",
       "Q 17.53125 52.734375 16.796875 39.40625 \n",
       "Q 19.671875 43.65625 24.015625 45.921875 \n",
       "Q 28.375 48.1875 33.59375 48.1875 \n",
       "Q 44.578125 48.1875 50.953125 41.515625 \n",
       "Q 57.328125 34.859375 57.328125 23.390625 \n",
       "Q 57.328125 12.15625 50.6875 5.359375 \n",
       "Q 44.046875 -1.421875 33.015625 -1.421875 \n",
       "Q 20.359375 -1.421875 13.671875 8.265625 \n",
       "Q 6.984375 17.96875 6.984375 36.375 \n",
       "Q 6.984375 53.65625 15.1875 63.9375 \n",
       "Q 23.390625 74.21875 37.203125 74.21875 \n",
       "Q 40.921875 74.21875 44.703125 73.484375 \n",
       "Q 48.484375 72.75 52.59375 71.296875 \n",
       "z\n",
       "\" id=\"DejaVuSans-54\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#DejaVuSans-54\"/>\n",
       "       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n",
       "       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_5\">\n",
       "     <g id=\"line2d_5\">\n",
       "      <g>\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"305.918451\" xlink:href=\"#m6f9e5888b6\" y=\"239.758125\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_5\">\n",
       "      <!-- 800 -->\n",
       "      <g transform=\"translate(296.374701 254.356562)scale(0.1 -0.1)\">\n",
       "       <defs>\n",
       "        <path d=\"M 31.78125 34.625 \n",
       "Q 24.75 34.625 20.71875 30.859375 \n",
       "Q 16.703125 27.09375 16.703125 20.515625 \n",
       "Q 16.703125 13.921875 20.71875 10.15625 \n",
       "Q 24.75 6.390625 31.78125 6.390625 \n",
       "Q 38.8125 6.390625 42.859375 10.171875 \n",
       "Q 46.921875 13.96875 46.921875 20.515625 \n",
       "Q 46.921875 27.09375 42.890625 30.859375 \n",
       "Q 38.875 34.625 31.78125 34.625 \n",
       "z\n",
       "M 21.921875 38.8125 \n",
       "Q 15.578125 40.375 12.03125 44.71875 \n",
       "Q 8.5 49.078125 8.5 55.328125 \n",
       "Q 8.5 64.0625 14.71875 69.140625 \n",
       "Q 20.953125 74.21875 31.78125 74.21875 \n",
       "Q 42.671875 74.21875 48.875 69.140625 \n",
       "Q 55.078125 64.0625 55.078125 55.328125 \n",
       "Q 55.078125 49.078125 51.53125 44.71875 \n",
       "Q 48 40.375 41.703125 38.8125 \n",
       "Q 48.828125 37.15625 52.796875 32.3125 \n",
       "Q 56.78125 27.484375 56.78125 20.515625 \n",
       "Q 56.78125 9.90625 50.3125 4.234375 \n",
       "Q 43.84375 -1.421875 31.78125 -1.421875 \n",
       "Q 19.734375 -1.421875 13.25 4.234375 \n",
       "Q 6.78125 9.90625 6.78125 20.515625 \n",
       "Q 6.78125 27.484375 10.78125 32.3125 \n",
       "Q 14.796875 37.15625 21.921875 38.8125 \n",
       "z\n",
       "M 18.3125 54.390625 \n",
       "Q 18.3125 48.734375 21.84375 45.5625 \n",
       "Q 25.390625 42.390625 31.78125 42.390625 \n",
       "Q 38.140625 42.390625 41.71875 45.5625 \n",
       "Q 45.3125 48.734375 45.3125 54.390625 \n",
       "Q 45.3125 60.0625 41.71875 63.234375 \n",
       "Q 38.140625 66.40625 31.78125 66.40625 \n",
       "Q 25.390625 66.40625 21.84375 63.234375 \n",
       "Q 18.3125 60.0625 18.3125 54.390625 \n",
       "z\n",
       "\" id=\"DejaVuSans-56\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#DejaVuSans-56\"/>\n",
       "       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n",
       "       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_6\">\n",
       "     <g id=\"line2d_6\">\n",
       "      <g>\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"366.852111\" xlink:href=\"#m6f9e5888b6\" y=\"239.758125\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_6\">\n",
       "      <!-- 1000 -->\n",
       "      <g transform=\"translate(354.127111 254.356562)scale(0.1 -0.1)\">\n",
       "       <defs>\n",
       "        <path d=\"M 12.40625 8.296875 \n",
       "L 28.515625 8.296875 \n",
       "L 28.515625 63.921875 \n",
       "L 10.984375 60.40625 \n",
       "L 10.984375 69.390625 \n",
       "L 28.421875 72.90625 \n",
       "L 38.28125 72.90625 \n",
       "L 38.28125 8.296875 \n",
       "L 54.390625 8.296875 \n",
       "L 54.390625 0 \n",
       "L 12.40625 0 \n",
       "z\n",
       "\" id=\"DejaVuSans-49\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#DejaVuSans-49\"/>\n",
       "       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n",
       "       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\n",
       "       <use x=\"190.869141\" xlink:href=\"#DejaVuSans-48\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"text_7\">\n",
       "     <!-- Epoch -->\n",
       "     <g transform=\"translate(199.054688 268.034687)scale(0.1 -0.1)\">\n",
       "      <defs>\n",
       "       <path d=\"M 9.8125 72.90625 \n",
       "L 55.90625 72.90625 \n",
       "L 55.90625 64.59375 \n",
       "L 19.671875 64.59375 \n",
       "L 19.671875 43.015625 \n",
       "L 54.390625 43.015625 \n",
       "L 54.390625 34.71875 \n",
       "L 19.671875 34.71875 \n",
       "L 19.671875 8.296875 \n",
       "L 56.78125 8.296875 \n",
       "L 56.78125 0 \n",
       "L 9.8125 0 \n",
       "z\n",
       "\" id=\"DejaVuSans-69\"/>\n",
       "       <path d=\"M 18.109375 8.203125 \n",
       "L 18.109375 -20.796875 \n",
       "L 9.078125 -20.796875 \n",
       "L 9.078125 54.6875 \n",
       "L 18.109375 54.6875 \n",
       "L 18.109375 46.390625 \n",
       "Q 20.953125 51.265625 25.265625 53.625 \n",
       "Q 29.59375 56 35.59375 56 \n",
       "Q 45.5625 56 51.78125 48.09375 \n",
       "Q 58.015625 40.1875 58.015625 27.296875 \n",
       "Q 58.015625 14.40625 51.78125 6.484375 \n",
       "Q 45.5625 -1.421875 35.59375 -1.421875 \n",
       "Q 29.59375 -1.421875 25.265625 0.953125 \n",
       "Q 20.953125 3.328125 18.109375 8.203125 \n",
       "z\n",
       "M 48.6875 27.296875 \n",
       "Q 48.6875 37.203125 44.609375 42.84375 \n",
       "Q 40.53125 48.484375 33.40625 48.484375 \n",
       "Q 26.265625 48.484375 22.1875 42.84375 \n",
       "Q 18.109375 37.203125 18.109375 27.296875 \n",
       "Q 18.109375 17.390625 22.1875 11.75 \n",
       "Q 26.265625 6.109375 33.40625 6.109375 \n",
       "Q 40.53125 6.109375 44.609375 11.75 \n",
       "Q 48.6875 17.390625 48.6875 27.296875 \n",
       "z\n",
       "\" id=\"DejaVuSans-112\"/>\n",
       "       <path d=\"M 30.609375 48.390625 \n",
       "Q 23.390625 48.390625 19.1875 42.75 \n",
       "Q 14.984375 37.109375 14.984375 27.296875 \n",
       "Q 14.984375 17.484375 19.15625 11.84375 \n",
       "Q 23.34375 6.203125 30.609375 6.203125 \n",
       "Q 37.796875 6.203125 41.984375 11.859375 \n",
       "Q 46.1875 17.53125 46.1875 27.296875 \n",
       "Q 46.1875 37.015625 41.984375 42.703125 \n",
       "Q 37.796875 48.390625 30.609375 48.390625 \n",
       "z\n",
       "M 30.609375 56 \n",
       "Q 42.328125 56 49.015625 48.375 \n",
       "Q 55.71875 40.765625 55.71875 27.296875 \n",
       "Q 55.71875 13.875 49.015625 6.21875 \n",
       "Q 42.328125 -1.421875 30.609375 -1.421875 \n",
       "Q 18.84375 -1.421875 12.171875 6.21875 \n",
       "Q 5.515625 13.875 5.515625 27.296875 \n",
       "Q 5.515625 40.765625 12.171875 48.375 \n",
       "Q 18.84375 56 30.609375 56 \n",
       "z\n",
       "\" id=\"DejaVuSans-111\"/>\n",
       "       <path d=\"M 48.78125 52.59375 \n",
       "L 48.78125 44.1875 \n",
       "Q 44.96875 46.296875 41.140625 47.34375 \n",
       "Q 37.3125 48.390625 33.40625 48.390625 \n",
       "Q 24.65625 48.390625 19.8125 42.84375 \n",
       "Q 14.984375 37.3125 14.984375 27.296875 \n",
       "Q 14.984375 17.28125 19.8125 11.734375 \n",
       "Q 24.65625 6.203125 33.40625 6.203125 \n",
       "Q 37.3125 6.203125 41.140625 7.25 \n",
       "Q 44.96875 8.296875 48.78125 10.40625 \n",
       "L 48.78125 2.09375 \n",
       "Q 45.015625 0.34375 40.984375 -0.53125 \n",
       "Q 36.96875 -1.421875 32.421875 -1.421875 \n",
       "Q 20.0625 -1.421875 12.78125 6.34375 \n",
       "Q 5.515625 14.109375 5.515625 27.296875 \n",
       "Q 5.515625 40.671875 12.859375 48.328125 \n",
       "Q 20.21875 56 33.015625 56 \n",
       "Q 37.15625 56 41.109375 55.140625 \n",
       "Q 45.0625 54.296875 48.78125 52.59375 \n",
       "z\n",
       "\" id=\"DejaVuSans-99\"/>\n",
       "       <path d=\"M 54.890625 33.015625 \n",
       "L 54.890625 0 \n",
       "L 45.90625 0 \n",
       "L 45.90625 32.71875 \n",
       "Q 45.90625 40.484375 42.875 44.328125 \n",
       "Q 39.84375 48.1875 33.796875 48.1875 \n",
       "Q 26.515625 48.1875 22.3125 43.546875 \n",
       "Q 18.109375 38.921875 18.109375 30.90625 \n",
       "L 18.109375 0 \n",
       "L 9.078125 0 \n",
       "L 9.078125 75.984375 \n",
       "L 18.109375 75.984375 \n",
       "L 18.109375 46.1875 \n",
       "Q 21.34375 51.125 25.703125 53.5625 \n",
       "Q 30.078125 56 35.796875 56 \n",
       "Q 45.21875 56 50.046875 50.171875 \n",
       "Q 54.890625 44.34375 54.890625 33.015625 \n",
       "z\n",
       "\" id=\"DejaVuSans-104\"/>\n",
       "      </defs>\n",
       "      <use xlink:href=\"#DejaVuSans-69\"/>\n",
       "      <use x=\"63.183594\" xlink:href=\"#DejaVuSans-112\"/>\n",
       "      <use x=\"126.660156\" xlink:href=\"#DejaVuSans-111\"/>\n",
       "      <use x=\"187.841797\" xlink:href=\"#DejaVuSans-99\"/>\n",
       "      <use x=\"242.822266\" xlink:href=\"#DejaVuSans-104\"/>\n",
       "     </g>\n",
       "    </g>\n",
       "   </g>\n",
       "   <g id=\"matplotlib.axis_2\">\n",
       "    <g id=\"ytick_1\">\n",
       "     <g id=\"line2d_7\">\n",
       "      <defs>\n",
       "       <path d=\"M 0 0 \n",
       "L -3.5 0 \n",
       "\" id=\"m66f7577633\" style=\"stroke:#000000;stroke-width:0.8;\"/>\n",
       "      </defs>\n",
       "      <g>\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"46.965625\" xlink:href=\"#m66f7577633\" y=\"230.127346\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_8\">\n",
       "      <!-- 0 -->\n",
       "      <g transform=\"translate(33.603125 233.926565)scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-48\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_2\">\n",
       "     <g id=\"line2d_8\">\n",
       "      <g>\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"46.965625\" xlink:href=\"#m66f7577633\" y=\"203.816321\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_9\">\n",
       "      <!-- 20 -->\n",
       "      <g transform=\"translate(27.240625 207.61554)scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-50\"/>\n",
       "       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_3\">\n",
       "     <g id=\"line2d_9\">\n",
       "      <g>\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"46.965625\" xlink:href=\"#m66f7577633\" y=\"177.505296\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_10\">\n",
       "      <!-- 40 -->\n",
       "      <g transform=\"translate(27.240625 181.304515)scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-52\"/>\n",
       "       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_4\">\n",
       "     <g id=\"line2d_10\">\n",
       "      <g>\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"46.965625\" xlink:href=\"#m66f7577633\" y=\"151.194271\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_11\">\n",
       "      <!-- 60 -->\n",
       "      <g transform=\"translate(27.240625 154.99349)scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-54\"/>\n",
       "       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_5\">\n",
       "     <g id=\"line2d_11\">\n",
       "      <g>\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"46.965625\" xlink:href=\"#m66f7577633\" y=\"124.883246\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_12\">\n",
       "      <!-- 80 -->\n",
       "      <g transform=\"translate(27.240625 128.682465)scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-56\"/>\n",
       "       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_6\">\n",
       "     <g id=\"line2d_12\">\n",
       "      <g>\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"46.965625\" xlink:href=\"#m66f7577633\" y=\"98.572221\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_13\">\n",
       "      <!-- 100 -->\n",
       "      <g transform=\"translate(20.878125 102.37144)scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-49\"/>\n",
       "       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n",
       "       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_7\">\n",
       "     <g id=\"line2d_13\">\n",
       "      <g>\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"46.965625\" xlink:href=\"#m66f7577633\" y=\"72.261196\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_14\">\n",
       "      <!-- 120 -->\n",
       "      <g transform=\"translate(20.878125 76.060415)scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-49\"/>\n",
       "       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-50\"/>\n",
       "       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_8\">\n",
       "     <g id=\"line2d_14\">\n",
       "      <g>\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"46.965625\" xlink:href=\"#m66f7577633\" y=\"45.950171\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_15\">\n",
       "      <!-- 140 -->\n",
       "      <g transform=\"translate(20.878125 49.74939)scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-49\"/>\n",
       "       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-52\"/>\n",
       "       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"text_16\">\n",
       "     <!-- Loss -->\n",
       "     <g transform=\"translate(14.798438 142.005312)rotate(-90)scale(0.1 -0.1)\">\n",
       "      <defs>\n",
       "       <path d=\"M 9.8125 72.90625 \n",
       "L 19.671875 72.90625 \n",
       "L 19.671875 8.296875 \n",
       "L 55.171875 8.296875 \n",
       "L 55.171875 0 \n",
       "L 9.8125 0 \n",
       "z\n",
       "\" id=\"DejaVuSans-76\"/>\n",
       "       <path d=\"M 44.28125 53.078125 \n",
       "L 44.28125 44.578125 \n",
       "Q 40.484375 46.53125 36.375 47.5 \n",
       "Q 32.28125 48.484375 27.875 48.484375 \n",
       "Q 21.1875 48.484375 17.84375 46.4375 \n",
       "Q 14.5 44.390625 14.5 40.28125 \n",
       "Q 14.5 37.15625 16.890625 35.375 \n",
       "Q 19.28125 33.59375 26.515625 31.984375 \n",
       "L 29.59375 31.296875 \n",
       "Q 39.15625 29.25 43.1875 25.515625 \n",
       "Q 47.21875 21.78125 47.21875 15.09375 \n",
       "Q 47.21875 7.46875 41.1875 3.015625 \n",
       "Q 35.15625 -1.421875 24.609375 -1.421875 \n",
       "Q 20.21875 -1.421875 15.453125 -0.5625 \n",
       "Q 10.6875 0.296875 5.421875 2 \n",
       "L 5.421875 11.28125 \n",
       "Q 10.40625 8.6875 15.234375 7.390625 \n",
       "Q 20.0625 6.109375 24.8125 6.109375 \n",
       "Q 31.15625 6.109375 34.5625 8.28125 \n",
       "Q 37.984375 10.453125 37.984375 14.40625 \n",
       "Q 37.984375 18.0625 35.515625 20.015625 \n",
       "Q 33.0625 21.96875 24.703125 23.78125 \n",
       "L 21.578125 24.515625 \n",
       "Q 13.234375 26.265625 9.515625 29.90625 \n",
       "Q 5.8125 33.546875 5.8125 39.890625 \n",
       "Q 5.8125 47.609375 11.28125 51.796875 \n",
       "Q 16.75 56 26.8125 56 \n",
       "Q 31.78125 56 36.171875 55.265625 \n",
       "Q 40.578125 54.546875 44.28125 53.078125 \n",
       "z\n",
       "\" id=\"DejaVuSans-115\"/>\n",
       "      </defs>\n",
       "      <use xlink:href=\"#DejaVuSans-76\"/>\n",
       "      <use x=\"53.962891\" xlink:href=\"#DejaVuSans-111\"/>\n",
       "      <use x=\"115.144531\" xlink:href=\"#DejaVuSans-115\"/>\n",
       "      <use x=\"167.244141\" xlink:href=\"#DejaVuSans-115\"/>\n",
       "     </g>\n",
       "    </g>\n",
       "   </g>\n",
       "   <g id=\"line2d_15\">\n",
       "    <path clip-path=\"url(#p76bd3a7ae4)\" d=\"M 62.183807 32.201761 \n",
       "L 62.488475 172.903326 \n",
       "L 62.793143 190.835545 \n",
       "L 63.097812 199.826981 \n",
       "L 63.707148 207.130638 \n",
       "L 64.316485 211.569306 \n",
       "L 64.925822 213.997763 \n",
       "L 65.23049 214.961984 \n",
       "L 65.535158 215.488308 \n",
       "L 66.144495 217.004788 \n",
       "L 66.449163 217.437963 \n",
       "L 67.0585 218.007619 \n",
       "L 68.277173 219.30402 \n",
       "L 68.581841 219.616831 \n",
       "L 69.800514 220.094234 \n",
       "L 70.105183 220.048708 \n",
       "L 70.409851 220.788614 \n",
       "L 70.714519 221.083667 \n",
       "L 71.019188 221.183211 \n",
       "L 71.323856 221.457883 \n",
       "L 71.628524 221.421035 \n",
       "L 71.933193 221.707481 \n",
       "L 72.237861 221.541187 \n",
       "L 72.847197 220.935924 \n",
       "L 73.151866 221.449387 \n",
       "L 73.456534 221.217559 \n",
       "L 73.761202 221.744592 \n",
       "L 74.675207 222.310539 \n",
       "L 74.979876 222.694567 \n",
       "L 75.284544 222.887234 \n",
       "L 75.589212 223.255218 \n",
       "L 77.72189 224.450845 \n",
       "L 78.331227 224.820653 \n",
       "L 82.901252 226.651658 \n",
       "L 85.947935 227.571872 \n",
       "L 88.994618 228.296634 \n",
       "L 91.431964 228.746879 \n",
       "L 95.392652 229.269547 \n",
       "L 99.048672 229.562235 \n",
       "L 104.228033 229.760645 \n",
       "L 118.852111 229.854606 \n",
       "L 174.301743 229.859451 \n",
       "L 188.316485 229.861469 \n",
       "L 366.547443 229.866115 \n",
       "L 366.547443 229.866115 \n",
       "\" style=\"fill:none;stroke:#1f77b4;stroke-linecap:square;stroke-width:1.5;\"/>\n",
       "   </g>\n",
       "   <g id=\"line2d_16\">\n",
       "    <path clip-path=\"url(#p76bd3a7ae4)\" d=\"M 62.183807 176.996864 \n",
       "L 62.488475 190.419279 \n",
       "L 63.097812 202.350915 \n",
       "L 63.707148 208.633183 \n",
       "L 64.316485 212.377898 \n",
       "L 64.925822 214.664868 \n",
       "L 65.23049 215.178157 \n",
       "L 65.535158 216.113868 \n",
       "L 66.449163 217.793101 \n",
       "L 67.0585 218.0453 \n",
       "L 67.972505 219.392707 \n",
       "L 68.277173 219.4607 \n",
       "L 68.581841 219.949732 \n",
       "L 68.88651 219.537367 \n",
       "L 69.495846 220.390558 \n",
       "L 69.800514 220.317825 \n",
       "L 70.409851 220.952724 \n",
       "L 70.714519 221.388643 \n",
       "L 71.628524 221.596874 \n",
       "L 71.933193 221.906481 \n",
       "L 72.847197 221.553741 \n",
       "L 73.151866 221.853584 \n",
       "L 73.761202 222.149021 \n",
       "L 76.198549 223.821146 \n",
       "L 78.635895 225.036471 \n",
       "L 79.245232 225.355421 \n",
       "L 83.20592 226.785672 \n",
       "L 83.815256 226.997471 \n",
       "L 85.643266 227.558854 \n",
       "L 91.736632 228.820553 \n",
       "L 95.69732 229.327208 \n",
       "L 100.876682 229.668776 \n",
       "L 106.360711 229.809002 \n",
       "L 118.242775 229.860753 \n",
       "L 189.839826 229.854317 \n",
       "L 191.972505 229.867813 \n",
       "L 202.635895 229.870583 \n",
       "L 213.603954 229.85736 \n",
       "L 217.259974 229.868532 \n",
       "L 234.321399 229.871347 \n",
       "L 242.547443 229.857692 \n",
       "L 245.289458 229.872203 \n",
       "L 364.719433 229.873881 \n",
       "L 366.547443 229.874095 \n",
       "L 366.547443 229.874095 \n",
       "\" style=\"fill:none;stroke:#ff7f0e;stroke-linecap:square;stroke-width:1.5;\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_3\">\n",
       "    <path d=\"M 46.965625 239.758125 \n",
       "L 46.965625 22.318125 \n",
       "\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_4\">\n",
       "    <path d=\"M 381.765625 239.758125 \n",
       "L 381.765625 22.318125 \n",
       "\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_5\">\n",
       "    <path d=\"M 46.965625 239.758125 \n",
       "L 381.765625 239.758125 \n",
       "\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_6\">\n",
       "    <path d=\"M 46.965625 22.318125 \n",
       "L 381.765625 22.318125 \n",
       "\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n",
       "   </g>\n",
       "   <g id=\"text_17\">\n",
       "    <!-- model loss -->\n",
       "    <g transform=\"translate(182.185938 16.318125)scale(0.12 -0.12)\">\n",
       "     <defs>\n",
       "      <path d=\"M 52 44.1875 \n",
       "Q 55.375 50.25 60.0625 53.125 \n",
       "Q 64.75 56 71.09375 56 \n",
       "Q 79.640625 56 84.28125 50.015625 \n",
       "Q 88.921875 44.046875 88.921875 33.015625 \n",
       "L 88.921875 0 \n",
       "L 79.890625 0 \n",
       "L 79.890625 32.71875 \n",
       "Q 79.890625 40.578125 77.09375 44.375 \n",
       "Q 74.3125 48.1875 68.609375 48.1875 \n",
       "Q 61.625 48.1875 57.5625 43.546875 \n",
       "Q 53.515625 38.921875 53.515625 30.90625 \n",
       "L 53.515625 0 \n",
       "L 44.484375 0 \n",
       "L 44.484375 32.71875 \n",
       "Q 44.484375 40.625 41.703125 44.40625 \n",
       "Q 38.921875 48.1875 33.109375 48.1875 \n",
       "Q 26.21875 48.1875 22.15625 43.53125 \n",
       "Q 18.109375 38.875 18.109375 30.90625 \n",
       "L 18.109375 0 \n",
       "L 9.078125 0 \n",
       "L 9.078125 54.6875 \n",
       "L 18.109375 54.6875 \n",
       "L 18.109375 46.1875 \n",
       "Q 21.1875 51.21875 25.484375 53.609375 \n",
       "Q 29.78125 56 35.6875 56 \n",
       "Q 41.65625 56 45.828125 52.96875 \n",
       "Q 50 49.953125 52 44.1875 \n",
       "z\n",
       "\" id=\"DejaVuSans-109\"/>\n",
       "      <path d=\"M 45.40625 46.390625 \n",
       "L 45.40625 75.984375 \n",
       "L 54.390625 75.984375 \n",
       "L 54.390625 0 \n",
       "L 45.40625 0 \n",
       "L 45.40625 8.203125 \n",
       "Q 42.578125 3.328125 38.25 0.953125 \n",
       "Q 33.9375 -1.421875 27.875 -1.421875 \n",
       "Q 17.96875 -1.421875 11.734375 6.484375 \n",
       "Q 5.515625 14.40625 5.515625 27.296875 \n",
       "Q 5.515625 40.1875 11.734375 48.09375 \n",
       "Q 17.96875 56 27.875 56 \n",
       "Q 33.9375 56 38.25 53.625 \n",
       "Q 42.578125 51.265625 45.40625 46.390625 \n",
       "z\n",
       "M 14.796875 27.296875 \n",
       "Q 14.796875 17.390625 18.875 11.75 \n",
       "Q 22.953125 6.109375 30.078125 6.109375 \n",
       "Q 37.203125 6.109375 41.296875 11.75 \n",
       "Q 45.40625 17.390625 45.40625 27.296875 \n",
       "Q 45.40625 37.203125 41.296875 42.84375 \n",
       "Q 37.203125 48.484375 30.078125 48.484375 \n",
       "Q 22.953125 48.484375 18.875 42.84375 \n",
       "Q 14.796875 37.203125 14.796875 27.296875 \n",
       "z\n",
       "\" id=\"DejaVuSans-100\"/>\n",
       "      <path d=\"M 56.203125 29.59375 \n",
       "L 56.203125 25.203125 \n",
       "L 14.890625 25.203125 \n",
       "Q 15.484375 15.921875 20.484375 11.0625 \n",
       "Q 25.484375 6.203125 34.421875 6.203125 \n",
       "Q 39.59375 6.203125 44.453125 7.46875 \n",
       "Q 49.3125 8.734375 54.109375 11.28125 \n",
       "L 54.109375 2.78125 \n",
       "Q 49.265625 0.734375 44.1875 -0.34375 \n",
       "Q 39.109375 -1.421875 33.890625 -1.421875 \n",
       "Q 20.796875 -1.421875 13.15625 6.1875 \n",
       "Q 5.515625 13.8125 5.515625 26.8125 \n",
       "Q 5.515625 40.234375 12.765625 48.109375 \n",
       "Q 20.015625 56 32.328125 56 \n",
       "Q 43.359375 56 49.78125 48.890625 \n",
       "Q 56.203125 41.796875 56.203125 29.59375 \n",
       "z\n",
       "M 47.21875 32.234375 \n",
       "Q 47.125 39.59375 43.09375 43.984375 \n",
       "Q 39.0625 48.390625 32.421875 48.390625 \n",
       "Q 24.90625 48.390625 20.390625 44.140625 \n",
       "Q 15.875 39.890625 15.1875 32.171875 \n",
       "z\n",
       "\" id=\"DejaVuSans-101\"/>\n",
       "      <path d=\"M 9.421875 75.984375 \n",
       "L 18.40625 75.984375 \n",
       "L 18.40625 0 \n",
       "L 9.421875 0 \n",
       "z\n",
       "\" id=\"DejaVuSans-108\"/>\n",
       "      <path id=\"DejaVuSans-32\"/>\n",
       "     </defs>\n",
       "     <use xlink:href=\"#DejaVuSans-109\"/>\n",
       "     <use x=\"97.412109\" xlink:href=\"#DejaVuSans-111\"/>\n",
       "     <use x=\"158.59375\" xlink:href=\"#DejaVuSans-100\"/>\n",
       "     <use x=\"222.070312\" xlink:href=\"#DejaVuSans-101\"/>\n",
       "     <use x=\"283.59375\" xlink:href=\"#DejaVuSans-108\"/>\n",
       "     <use x=\"311.376953\" xlink:href=\"#DejaVuSans-32\"/>\n",
       "     <use x=\"343.164062\" xlink:href=\"#DejaVuSans-108\"/>\n",
       "     <use x=\"370.947266\" xlink:href=\"#DejaVuSans-111\"/>\n",
       "     <use x=\"432.128906\" xlink:href=\"#DejaVuSans-115\"/>\n",
       "     <use x=\"484.228516\" xlink:href=\"#DejaVuSans-115\"/>\n",
       "    </g>\n",
       "   </g>\n",
       "   <g id=\"legend_1\">\n",
       "    <g id=\"patch_7\">\n",
       "     <path d=\"M 293.53125 59.674375 \n",
       "L 374.765625 59.674375 \n",
       "Q 376.765625 59.674375 376.765625 57.674375 \n",
       "L 376.765625 29.318125 \n",
       "Q 376.765625 27.318125 374.765625 27.318125 \n",
       "L 293.53125 27.318125 \n",
       "Q 291.53125 27.318125 291.53125 29.318125 \n",
       "L 291.53125 57.674375 \n",
       "Q 291.53125 59.674375 293.53125 59.674375 \n",
       "z\n",
       "\" style=\"fill:#ffffff;opacity:0.8;stroke:#cccccc;stroke-linejoin:miter;\"/>\n",
       "    </g>\n",
       "    <g id=\"line2d_17\">\n",
       "     <path d=\"M 295.53125 35.416562 \n",
       "L 315.53125 35.416562 \n",
       "\" style=\"fill:none;stroke:#1f77b4;stroke-linecap:square;stroke-width:1.5;\"/>\n",
       "    </g>\n",
       "    <g id=\"line2d_18\"/>\n",
       "    <g id=\"text_18\">\n",
       "     <!-- train -->\n",
       "     <g transform=\"translate(323.53125 38.916562)scale(0.1 -0.1)\">\n",
       "      <defs>\n",
       "       <path d=\"M 18.3125 70.21875 \n",
       "L 18.3125 54.6875 \n",
       "L 36.8125 54.6875 \n",
       "L 36.8125 47.703125 \n",
       "L 18.3125 47.703125 \n",
       "L 18.3125 18.015625 \n",
       "Q 18.3125 11.328125 20.140625 9.421875 \n",
       "Q 21.96875 7.515625 27.59375 7.515625 \n",
       "L 36.8125 7.515625 \n",
       "L 36.8125 0 \n",
       "L 27.59375 0 \n",
       "Q 17.1875 0 13.234375 3.875 \n",
       "Q 9.28125 7.765625 9.28125 18.015625 \n",
       "L 9.28125 47.703125 \n",
       "L 2.6875 47.703125 \n",
       "L 2.6875 54.6875 \n",
       "L 9.28125 54.6875 \n",
       "L 9.28125 70.21875 \n",
       "z\n",
       "\" id=\"DejaVuSans-116\"/>\n",
       "       <path d=\"M 41.109375 46.296875 \n",
       "Q 39.59375 47.171875 37.8125 47.578125 \n",
       "Q 36.03125 48 33.890625 48 \n",
       "Q 26.265625 48 22.1875 43.046875 \n",
       "Q 18.109375 38.09375 18.109375 28.8125 \n",
       "L 18.109375 0 \n",
       "L 9.078125 0 \n",
       "L 9.078125 54.6875 \n",
       "L 18.109375 54.6875 \n",
       "L 18.109375 46.1875 \n",
       "Q 20.953125 51.171875 25.484375 53.578125 \n",
       "Q 30.03125 56 36.53125 56 \n",
       "Q 37.453125 56 38.578125 55.875 \n",
       "Q 39.703125 55.765625 41.0625 55.515625 \n",
       "z\n",
       "\" id=\"DejaVuSans-114\"/>\n",
       "       <path d=\"M 34.28125 27.484375 \n",
       "Q 23.390625 27.484375 19.1875 25 \n",
       "Q 14.984375 22.515625 14.984375 16.5 \n",
       "Q 14.984375 11.71875 18.140625 8.90625 \n",
       "Q 21.296875 6.109375 26.703125 6.109375 \n",
       "Q 34.1875 6.109375 38.703125 11.40625 \n",
       "Q 43.21875 16.703125 43.21875 25.484375 \n",
       "L 43.21875 27.484375 \n",
       "z\n",
       "M 52.203125 31.203125 \n",
       "L 52.203125 0 \n",
       "L 43.21875 0 \n",
       "L 43.21875 8.296875 \n",
       "Q 40.140625 3.328125 35.546875 0.953125 \n",
       "Q 30.953125 -1.421875 24.3125 -1.421875 \n",
       "Q 15.921875 -1.421875 10.953125 3.296875 \n",
       "Q 6 8.015625 6 15.921875 \n",
       "Q 6 25.140625 12.171875 29.828125 \n",
       "Q 18.359375 34.515625 30.609375 34.515625 \n",
       "L 43.21875 34.515625 \n",
       "L 43.21875 35.40625 \n",
       "Q 43.21875 41.609375 39.140625 45 \n",
       "Q 35.0625 48.390625 27.6875 48.390625 \n",
       "Q 23 48.390625 18.546875 47.265625 \n",
       "Q 14.109375 46.140625 10.015625 43.890625 \n",
       "L 10.015625 52.203125 \n",
       "Q 14.9375 54.109375 19.578125 55.046875 \n",
       "Q 24.21875 56 28.609375 56 \n",
       "Q 40.484375 56 46.34375 49.84375 \n",
       "Q 52.203125 43.703125 52.203125 31.203125 \n",
       "z\n",
       "\" id=\"DejaVuSans-97\"/>\n",
       "       <path d=\"M 9.421875 54.6875 \n",
       "L 18.40625 54.6875 \n",
       "L 18.40625 0 \n",
       "L 9.421875 0 \n",
       "z\n",
       "M 9.421875 75.984375 \n",
       "L 18.40625 75.984375 \n",
       "L 18.40625 64.59375 \n",
       "L 9.421875 64.59375 \n",
       "z\n",
       "\" id=\"DejaVuSans-105\"/>\n",
       "       <path d=\"M 54.890625 33.015625 \n",
       "L 54.890625 0 \n",
       "L 45.90625 0 \n",
       "L 45.90625 32.71875 \n",
       "Q 45.90625 40.484375 42.875 44.328125 \n",
       "Q 39.84375 48.1875 33.796875 48.1875 \n",
       "Q 26.515625 48.1875 22.3125 43.546875 \n",
       "Q 18.109375 38.921875 18.109375 30.90625 \n",
       "L 18.109375 0 \n",
       "L 9.078125 0 \n",
       "L 9.078125 54.6875 \n",
       "L 18.109375 54.6875 \n",
       "L 18.109375 46.1875 \n",
       "Q 21.34375 51.125 25.703125 53.5625 \n",
       "Q 30.078125 56 35.796875 56 \n",
       "Q 45.21875 56 50.046875 50.171875 \n",
       "Q 54.890625 44.34375 54.890625 33.015625 \n",
       "z\n",
       "\" id=\"DejaVuSans-110\"/>\n",
       "      </defs>\n",
       "      <use xlink:href=\"#DejaVuSans-116\"/>\n",
       "      <use x=\"39.208984\" xlink:href=\"#DejaVuSans-114\"/>\n",
       "      <use x=\"80.322266\" xlink:href=\"#DejaVuSans-97\"/>\n",
       "      <use x=\"141.601562\" xlink:href=\"#DejaVuSans-105\"/>\n",
       "      <use x=\"169.384766\" xlink:href=\"#DejaVuSans-110\"/>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"line2d_19\">\n",
       "     <path d=\"M 295.53125 50.094687 \n",
       "L 315.53125 50.094687 \n",
       "\" style=\"fill:none;stroke:#ff7f0e;stroke-linecap:square;stroke-width:1.5;\"/>\n",
       "    </g>\n",
       "    <g id=\"line2d_20\"/>\n",
       "    <g id=\"text_19\">\n",
       "     <!-- validation -->\n",
       "     <g transform=\"translate(323.53125 53.594687)scale(0.1 -0.1)\">\n",
       "      <defs>\n",
       "       <path d=\"M 2.984375 54.6875 \n",
       "L 12.5 54.6875 \n",
       "L 29.59375 8.796875 \n",
       "L 46.6875 54.6875 \n",
       "L 56.203125 54.6875 \n",
       "L 35.6875 0 \n",
       "L 23.484375 0 \n",
       "z\n",
       "\" id=\"DejaVuSans-118\"/>\n",
       "      </defs>\n",
       "      <use xlink:href=\"#DejaVuSans-118\"/>\n",
       "      <use x=\"59.179688\" xlink:href=\"#DejaVuSans-97\"/>\n",
       "      <use x=\"120.458984\" xlink:href=\"#DejaVuSans-108\"/>\n",
       "      <use x=\"148.242188\" xlink:href=\"#DejaVuSans-105\"/>\n",
       "      <use x=\"176.025391\" xlink:href=\"#DejaVuSans-100\"/>\n",
       "      <use x=\"239.501953\" xlink:href=\"#DejaVuSans-97\"/>\n",
       "      <use x=\"300.78125\" xlink:href=\"#DejaVuSans-116\"/>\n",
       "      <use x=\"339.990234\" xlink:href=\"#DejaVuSans-105\"/>\n",
       "      <use x=\"367.773438\" xlink:href=\"#DejaVuSans-111\"/>\n",
       "      <use x=\"428.955078\" xlink:href=\"#DejaVuSans-110\"/>\n",
       "     </g>\n",
       "    </g>\n",
       "   </g>\n",
       "  </g>\n",
       " </g>\n",
       " <defs>\n",
       "  <clipPath id=\"p76bd3a7ae4\">\n",
       "   <rect height=\"217.44\" width=\"334.8\" x=\"46.965625\" y=\"22.318125\"/>\n",
       "  </clipPath>\n",
       " </defs>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_loss(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The PostScript backend does not support transparency; partially transparent artists will be rendered opaque.\n",
      "The PostScript backend does not support transparency; partially transparent artists will be rendered opaque.\n"
     ]
    },
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"utf-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       "  \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Created with matplotlib (https://matplotlib.org/) -->\n",
       "<svg height=\"277.314375pt\" version=\"1.1\" viewBox=\"0 0 392.14375 277.314375\" width=\"392.14375pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       " <metadata>\n",
       "  <rdf:RDF xmlns:cc=\"http://creativecommons.org/ns#\" xmlns:dc=\"http://purl.org/dc/elements/1.1/\" xmlns:rdf=\"http://www.w3.org/1999/02/22-rdf-syntax-ns#\">\n",
       "   <cc:Work>\n",
       "    <dc:type rdf:resource=\"http://purl.org/dc/dcmitype/StillImage\"/>\n",
       "    <dc:date>2022-06-13T00:40:23.907307</dc:date>\n",
       "    <dc:format>image/svg+xml</dc:format>\n",
       "    <dc:creator>\n",
       "     <cc:Agent>\n",
       "      <dc:title>Matplotlib v3.3.4, https://matplotlib.org/</dc:title>\n",
       "     </cc:Agent>\n",
       "    </dc:creator>\n",
       "   </cc:Work>\n",
       "  </rdf:RDF>\n",
       " </metadata>\n",
       " <defs>\n",
       "  <style type=\"text/css\">*{stroke-linecap:butt;stroke-linejoin:round;}</style>\n",
       " </defs>\n",
       " <g id=\"figure_1\">\n",
       "  <g id=\"patch_1\">\n",
       "   <path d=\"M 0 277.314375 \n",
       "L 392.14375 277.314375 \n",
       "L 392.14375 0 \n",
       "L 0 0 \n",
       "z\n",
       "\" style=\"fill:none;\"/>\n",
       "  </g>\n",
       "  <g id=\"axes_1\">\n",
       "   <g id=\"patch_2\">\n",
       "    <path d=\"M 50.14375 239.758125 \n",
       "L 384.94375 239.758125 \n",
       "L 384.94375 22.318125 \n",
       "L 50.14375 22.318125 \n",
       "z\n",
       "\" style=\"fill:#ffffff;\"/>\n",
       "   </g>\n",
       "   <g id=\"matplotlib.axis_1\">\n",
       "    <g id=\"xtick_1\">\n",
       "     <g id=\"line2d_1\">\n",
       "      <defs>\n",
       "       <path d=\"M 0 0 \n",
       "L 0 3.5 \n",
       "\" id=\"m97a3e45562\" style=\"stroke:#000000;stroke-width:0.8;\"/>\n",
       "      </defs>\n",
       "      <g>\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"65.361932\" xlink:href=\"#m97a3e45562\" y=\"239.758125\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_1\">\n",
       "      <!-- 0 -->\n",
       "      <g transform=\"translate(62.180682 254.356562)scale(0.1 -0.1)\">\n",
       "       <defs>\n",
       "        <path d=\"M 31.78125 66.40625 \n",
       "Q 24.171875 66.40625 20.328125 58.90625 \n",
       "Q 16.5 51.421875 16.5 36.375 \n",
       "Q 16.5 21.390625 20.328125 13.890625 \n",
       "Q 24.171875 6.390625 31.78125 6.390625 \n",
       "Q 39.453125 6.390625 43.28125 13.890625 \n",
       "Q 47.125 21.390625 47.125 36.375 \n",
       "Q 47.125 51.421875 43.28125 58.90625 \n",
       "Q 39.453125 66.40625 31.78125 66.40625 \n",
       "z\n",
       "M 31.78125 74.21875 \n",
       "Q 44.046875 74.21875 50.515625 64.515625 \n",
       "Q 56.984375 54.828125 56.984375 36.375 \n",
       "Q 56.984375 17.96875 50.515625 8.265625 \n",
       "Q 44.046875 -1.421875 31.78125 -1.421875 \n",
       "Q 19.53125 -1.421875 13.0625 8.265625 \n",
       "Q 6.59375 17.96875 6.59375 36.375 \n",
       "Q 6.59375 54.828125 13.0625 64.515625 \n",
       "Q 19.53125 74.21875 31.78125 74.21875 \n",
       "z\n",
       "\" id=\"DejaVuSans-48\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#DejaVuSans-48\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_2\">\n",
       "     <g id=\"line2d_2\">\n",
       "      <g>\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"126.295593\" xlink:href=\"#m97a3e45562\" y=\"239.758125\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_2\">\n",
       "      <!-- 200 -->\n",
       "      <g transform=\"translate(116.751843 254.356562)scale(0.1 -0.1)\">\n",
       "       <defs>\n",
       "        <path d=\"M 19.1875 8.296875 \n",
       "L 53.609375 8.296875 \n",
       "L 53.609375 0 \n",
       "L 7.328125 0 \n",
       "L 7.328125 8.296875 \n",
       "Q 12.9375 14.109375 22.625 23.890625 \n",
       "Q 32.328125 33.6875 34.8125 36.53125 \n",
       "Q 39.546875 41.84375 41.421875 45.53125 \n",
       "Q 43.3125 49.21875 43.3125 52.78125 \n",
       "Q 43.3125 58.59375 39.234375 62.25 \n",
       "Q 35.15625 65.921875 28.609375 65.921875 \n",
       "Q 23.96875 65.921875 18.8125 64.3125 \n",
       "Q 13.671875 62.703125 7.8125 59.421875 \n",
       "L 7.8125 69.390625 \n",
       "Q 13.765625 71.78125 18.9375 73 \n",
       "Q 24.125 74.21875 28.421875 74.21875 \n",
       "Q 39.75 74.21875 46.484375 68.546875 \n",
       "Q 53.21875 62.890625 53.21875 53.421875 \n",
       "Q 53.21875 48.921875 51.53125 44.890625 \n",
       "Q 49.859375 40.875 45.40625 35.40625 \n",
       "Q 44.1875 33.984375 37.640625 27.21875 \n",
       "Q 31.109375 20.453125 19.1875 8.296875 \n",
       "z\n",
       "\" id=\"DejaVuSans-50\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#DejaVuSans-50\"/>\n",
       "       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n",
       "       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_3\">\n",
       "     <g id=\"line2d_3\">\n",
       "      <g>\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"187.229254\" xlink:href=\"#m97a3e45562\" y=\"239.758125\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_3\">\n",
       "      <!-- 400 -->\n",
       "      <g transform=\"translate(177.685504 254.356562)scale(0.1 -0.1)\">\n",
       "       <defs>\n",
       "        <path d=\"M 37.796875 64.3125 \n",
       "L 12.890625 25.390625 \n",
       "L 37.796875 25.390625 \n",
       "z\n",
       "M 35.203125 72.90625 \n",
       "L 47.609375 72.90625 \n",
       "L 47.609375 25.390625 \n",
       "L 58.015625 25.390625 \n",
       "L 58.015625 17.1875 \n",
       "L 47.609375 17.1875 \n",
       "L 47.609375 0 \n",
       "L 37.796875 0 \n",
       "L 37.796875 17.1875 \n",
       "L 4.890625 17.1875 \n",
       "L 4.890625 26.703125 \n",
       "z\n",
       "\" id=\"DejaVuSans-52\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#DejaVuSans-52\"/>\n",
       "       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n",
       "       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_4\">\n",
       "     <g id=\"line2d_4\">\n",
       "      <g>\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"248.162915\" xlink:href=\"#m97a3e45562\" y=\"239.758125\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_4\">\n",
       "      <!-- 600 -->\n",
       "      <g transform=\"translate(238.619165 254.356562)scale(0.1 -0.1)\">\n",
       "       <defs>\n",
       "        <path d=\"M 33.015625 40.375 \n",
       "Q 26.375 40.375 22.484375 35.828125 \n",
       "Q 18.609375 31.296875 18.609375 23.390625 \n",
       "Q 18.609375 15.53125 22.484375 10.953125 \n",
       "Q 26.375 6.390625 33.015625 6.390625 \n",
       "Q 39.65625 6.390625 43.53125 10.953125 \n",
       "Q 47.40625 15.53125 47.40625 23.390625 \n",
       "Q 47.40625 31.296875 43.53125 35.828125 \n",
       "Q 39.65625 40.375 33.015625 40.375 \n",
       "z\n",
       "M 52.59375 71.296875 \n",
       "L 52.59375 62.3125 \n",
       "Q 48.875 64.0625 45.09375 64.984375 \n",
       "Q 41.3125 65.921875 37.59375 65.921875 \n",
       "Q 27.828125 65.921875 22.671875 59.328125 \n",
       "Q 17.53125 52.734375 16.796875 39.40625 \n",
       "Q 19.671875 43.65625 24.015625 45.921875 \n",
       "Q 28.375 48.1875 33.59375 48.1875 \n",
       "Q 44.578125 48.1875 50.953125 41.515625 \n",
       "Q 57.328125 34.859375 57.328125 23.390625 \n",
       "Q 57.328125 12.15625 50.6875 5.359375 \n",
       "Q 44.046875 -1.421875 33.015625 -1.421875 \n",
       "Q 20.359375 -1.421875 13.671875 8.265625 \n",
       "Q 6.984375 17.96875 6.984375 36.375 \n",
       "Q 6.984375 53.65625 15.1875 63.9375 \n",
       "Q 23.390625 74.21875 37.203125 74.21875 \n",
       "Q 40.921875 74.21875 44.703125 73.484375 \n",
       "Q 48.484375 72.75 52.59375 71.296875 \n",
       "z\n",
       "\" id=\"DejaVuSans-54\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#DejaVuSans-54\"/>\n",
       "       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n",
       "       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_5\">\n",
       "     <g id=\"line2d_5\">\n",
       "      <g>\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"309.096576\" xlink:href=\"#m97a3e45562\" y=\"239.758125\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_5\">\n",
       "      <!-- 800 -->\n",
       "      <g transform=\"translate(299.552826 254.356562)scale(0.1 -0.1)\">\n",
       "       <defs>\n",
       "        <path d=\"M 31.78125 34.625 \n",
       "Q 24.75 34.625 20.71875 30.859375 \n",
       "Q 16.703125 27.09375 16.703125 20.515625 \n",
       "Q 16.703125 13.921875 20.71875 10.15625 \n",
       "Q 24.75 6.390625 31.78125 6.390625 \n",
       "Q 38.8125 6.390625 42.859375 10.171875 \n",
       "Q 46.921875 13.96875 46.921875 20.515625 \n",
       "Q 46.921875 27.09375 42.890625 30.859375 \n",
       "Q 38.875 34.625 31.78125 34.625 \n",
       "z\n",
       "M 21.921875 38.8125 \n",
       "Q 15.578125 40.375 12.03125 44.71875 \n",
       "Q 8.5 49.078125 8.5 55.328125 \n",
       "Q 8.5 64.0625 14.71875 69.140625 \n",
       "Q 20.953125 74.21875 31.78125 74.21875 \n",
       "Q 42.671875 74.21875 48.875 69.140625 \n",
       "Q 55.078125 64.0625 55.078125 55.328125 \n",
       "Q 55.078125 49.078125 51.53125 44.71875 \n",
       "Q 48 40.375 41.703125 38.8125 \n",
       "Q 48.828125 37.15625 52.796875 32.3125 \n",
       "Q 56.78125 27.484375 56.78125 20.515625 \n",
       "Q 56.78125 9.90625 50.3125 4.234375 \n",
       "Q 43.84375 -1.421875 31.78125 -1.421875 \n",
       "Q 19.734375 -1.421875 13.25 4.234375 \n",
       "Q 6.78125 9.90625 6.78125 20.515625 \n",
       "Q 6.78125 27.484375 10.78125 32.3125 \n",
       "Q 14.796875 37.15625 21.921875 38.8125 \n",
       "z\n",
       "M 18.3125 54.390625 \n",
       "Q 18.3125 48.734375 21.84375 45.5625 \n",
       "Q 25.390625 42.390625 31.78125 42.390625 \n",
       "Q 38.140625 42.390625 41.71875 45.5625 \n",
       "Q 45.3125 48.734375 45.3125 54.390625 \n",
       "Q 45.3125 60.0625 41.71875 63.234375 \n",
       "Q 38.140625 66.40625 31.78125 66.40625 \n",
       "Q 25.390625 66.40625 21.84375 63.234375 \n",
       "Q 18.3125 60.0625 18.3125 54.390625 \n",
       "z\n",
       "\" id=\"DejaVuSans-56\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#DejaVuSans-56\"/>\n",
       "       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n",
       "       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_6\">\n",
       "     <g id=\"line2d_6\">\n",
       "      <g>\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"370.030236\" xlink:href=\"#m97a3e45562\" y=\"239.758125\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_6\">\n",
       "      <!-- 1000 -->\n",
       "      <g transform=\"translate(357.305236 254.356562)scale(0.1 -0.1)\">\n",
       "       <defs>\n",
       "        <path d=\"M 12.40625 8.296875 \n",
       "L 28.515625 8.296875 \n",
       "L 28.515625 63.921875 \n",
       "L 10.984375 60.40625 \n",
       "L 10.984375 69.390625 \n",
       "L 28.421875 72.90625 \n",
       "L 38.28125 72.90625 \n",
       "L 38.28125 8.296875 \n",
       "L 54.390625 8.296875 \n",
       "L 54.390625 0 \n",
       "L 12.40625 0 \n",
       "z\n",
       "\" id=\"DejaVuSans-49\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#DejaVuSans-49\"/>\n",
       "       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n",
       "       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\n",
       "       <use x=\"190.869141\" xlink:href=\"#DejaVuSans-48\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"text_7\">\n",
       "     <!-- epoch -->\n",
       "     <g transform=\"translate(202.315625 268.034687)scale(0.1 -0.1)\">\n",
       "      <defs>\n",
       "       <path d=\"M 56.203125 29.59375 \n",
       "L 56.203125 25.203125 \n",
       "L 14.890625 25.203125 \n",
       "Q 15.484375 15.921875 20.484375 11.0625 \n",
       "Q 25.484375 6.203125 34.421875 6.203125 \n",
       "Q 39.59375 6.203125 44.453125 7.46875 \n",
       "Q 49.3125 8.734375 54.109375 11.28125 \n",
       "L 54.109375 2.78125 \n",
       "Q 49.265625 0.734375 44.1875 -0.34375 \n",
       "Q 39.109375 -1.421875 33.890625 -1.421875 \n",
       "Q 20.796875 -1.421875 13.15625 6.1875 \n",
       "Q 5.515625 13.8125 5.515625 26.8125 \n",
       "Q 5.515625 40.234375 12.765625 48.109375 \n",
       "Q 20.015625 56 32.328125 56 \n",
       "Q 43.359375 56 49.78125 48.890625 \n",
       "Q 56.203125 41.796875 56.203125 29.59375 \n",
       "z\n",
       "M 47.21875 32.234375 \n",
       "Q 47.125 39.59375 43.09375 43.984375 \n",
       "Q 39.0625 48.390625 32.421875 48.390625 \n",
       "Q 24.90625 48.390625 20.390625 44.140625 \n",
       "Q 15.875 39.890625 15.1875 32.171875 \n",
       "z\n",
       "\" id=\"DejaVuSans-101\"/>\n",
       "       <path d=\"M 18.109375 8.203125 \n",
       "L 18.109375 -20.796875 \n",
       "L 9.078125 -20.796875 \n",
       "L 9.078125 54.6875 \n",
       "L 18.109375 54.6875 \n",
       "L 18.109375 46.390625 \n",
       "Q 20.953125 51.265625 25.265625 53.625 \n",
       "Q 29.59375 56 35.59375 56 \n",
       "Q 45.5625 56 51.78125 48.09375 \n",
       "Q 58.015625 40.1875 58.015625 27.296875 \n",
       "Q 58.015625 14.40625 51.78125 6.484375 \n",
       "Q 45.5625 -1.421875 35.59375 -1.421875 \n",
       "Q 29.59375 -1.421875 25.265625 0.953125 \n",
       "Q 20.953125 3.328125 18.109375 8.203125 \n",
       "z\n",
       "M 48.6875 27.296875 \n",
       "Q 48.6875 37.203125 44.609375 42.84375 \n",
       "Q 40.53125 48.484375 33.40625 48.484375 \n",
       "Q 26.265625 48.484375 22.1875 42.84375 \n",
       "Q 18.109375 37.203125 18.109375 27.296875 \n",
       "Q 18.109375 17.390625 22.1875 11.75 \n",
       "Q 26.265625 6.109375 33.40625 6.109375 \n",
       "Q 40.53125 6.109375 44.609375 11.75 \n",
       "Q 48.6875 17.390625 48.6875 27.296875 \n",
       "z\n",
       "\" id=\"DejaVuSans-112\"/>\n",
       "       <path d=\"M 30.609375 48.390625 \n",
       "Q 23.390625 48.390625 19.1875 42.75 \n",
       "Q 14.984375 37.109375 14.984375 27.296875 \n",
       "Q 14.984375 17.484375 19.15625 11.84375 \n",
       "Q 23.34375 6.203125 30.609375 6.203125 \n",
       "Q 37.796875 6.203125 41.984375 11.859375 \n",
       "Q 46.1875 17.53125 46.1875 27.296875 \n",
       "Q 46.1875 37.015625 41.984375 42.703125 \n",
       "Q 37.796875 48.390625 30.609375 48.390625 \n",
       "z\n",
       "M 30.609375 56 \n",
       "Q 42.328125 56 49.015625 48.375 \n",
       "Q 55.71875 40.765625 55.71875 27.296875 \n",
       "Q 55.71875 13.875 49.015625 6.21875 \n",
       "Q 42.328125 -1.421875 30.609375 -1.421875 \n",
       "Q 18.84375 -1.421875 12.171875 6.21875 \n",
       "Q 5.515625 13.875 5.515625 27.296875 \n",
       "Q 5.515625 40.765625 12.171875 48.375 \n",
       "Q 18.84375 56 30.609375 56 \n",
       "z\n",
       "\" id=\"DejaVuSans-111\"/>\n",
       "       <path d=\"M 48.78125 52.59375 \n",
       "L 48.78125 44.1875 \n",
       "Q 44.96875 46.296875 41.140625 47.34375 \n",
       "Q 37.3125 48.390625 33.40625 48.390625 \n",
       "Q 24.65625 48.390625 19.8125 42.84375 \n",
       "Q 14.984375 37.3125 14.984375 27.296875 \n",
       "Q 14.984375 17.28125 19.8125 11.734375 \n",
       "Q 24.65625 6.203125 33.40625 6.203125 \n",
       "Q 37.3125 6.203125 41.140625 7.25 \n",
       "Q 44.96875 8.296875 48.78125 10.40625 \n",
       "L 48.78125 2.09375 \n",
       "Q 45.015625 0.34375 40.984375 -0.53125 \n",
       "Q 36.96875 -1.421875 32.421875 -1.421875 \n",
       "Q 20.0625 -1.421875 12.78125 6.34375 \n",
       "Q 5.515625 14.109375 5.515625 27.296875 \n",
       "Q 5.515625 40.671875 12.859375 48.328125 \n",
       "Q 20.21875 56 33.015625 56 \n",
       "Q 37.15625 56 41.109375 55.140625 \n",
       "Q 45.0625 54.296875 48.78125 52.59375 \n",
       "z\n",
       "\" id=\"DejaVuSans-99\"/>\n",
       "       <path d=\"M 54.890625 33.015625 \n",
       "L 54.890625 0 \n",
       "L 45.90625 0 \n",
       "L 45.90625 32.71875 \n",
       "Q 45.90625 40.484375 42.875 44.328125 \n",
       "Q 39.84375 48.1875 33.796875 48.1875 \n",
       "Q 26.515625 48.1875 22.3125 43.546875 \n",
       "Q 18.109375 38.921875 18.109375 30.90625 \n",
       "L 18.109375 0 \n",
       "L 9.078125 0 \n",
       "L 9.078125 75.984375 \n",
       "L 18.109375 75.984375 \n",
       "L 18.109375 46.1875 \n",
       "Q 21.34375 51.125 25.703125 53.5625 \n",
       "Q 30.078125 56 35.796875 56 \n",
       "Q 45.21875 56 50.046875 50.171875 \n",
       "Q 54.890625 44.34375 54.890625 33.015625 \n",
       "z\n",
       "\" id=\"DejaVuSans-104\"/>\n",
       "      </defs>\n",
       "      <use xlink:href=\"#DejaVuSans-101\"/>\n",
       "      <use x=\"61.523438\" xlink:href=\"#DejaVuSans-112\"/>\n",
       "      <use x=\"125\" xlink:href=\"#DejaVuSans-111\"/>\n",
       "      <use x=\"186.181641\" xlink:href=\"#DejaVuSans-99\"/>\n",
       "      <use x=\"241.162109\" xlink:href=\"#DejaVuSans-104\"/>\n",
       "     </g>\n",
       "    </g>\n",
       "   </g>\n",
       "   <g id=\"matplotlib.axis_2\">\n",
       "    <g id=\"ytick_1\">\n",
       "     <g id=\"line2d_7\">\n",
       "      <defs>\n",
       "       <path d=\"M 0 0 \n",
       "L -3.5 0 \n",
       "\" id=\"m2499756918\" style=\"stroke:#000000;stroke-width:0.8;\"/>\n",
       "      </defs>\n",
       "      <g>\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"50.14375\" xlink:href=\"#m2499756918\" y=\"222.851704\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_8\">\n",
       "      <!-- 0.84 -->\n",
       "      <g transform=\"translate(20.878125 226.650923)scale(0.1 -0.1)\">\n",
       "       <defs>\n",
       "        <path d=\"M 10.6875 12.40625 \n",
       "L 21 12.40625 \n",
       "L 21 0 \n",
       "L 10.6875 0 \n",
       "z\n",
       "\" id=\"DejaVuSans-46\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#DejaVuSans-48\"/>\n",
       "       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n",
       "       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-56\"/>\n",
       "       <use x=\"159.033203\" xlink:href=\"#DejaVuSans-52\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_2\">\n",
       "     <g id=\"line2d_8\">\n",
       "      <g>\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"50.14375\" xlink:href=\"#m2499756918\" y=\"187.395725\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_9\">\n",
       "      <!-- 0.86 -->\n",
       "      <g transform=\"translate(20.878125 191.194944)scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-48\"/>\n",
       "       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n",
       "       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-56\"/>\n",
       "       <use x=\"159.033203\" xlink:href=\"#DejaVuSans-54\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_3\">\n",
       "     <g id=\"line2d_9\">\n",
       "      <g>\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"50.14375\" xlink:href=\"#m2499756918\" y=\"151.939746\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_10\">\n",
       "      <!-- 0.88 -->\n",
       "      <g transform=\"translate(20.878125 155.738965)scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-48\"/>\n",
       "       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n",
       "       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-56\"/>\n",
       "       <use x=\"159.033203\" xlink:href=\"#DejaVuSans-56\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_4\">\n",
       "     <g id=\"line2d_10\">\n",
       "      <g>\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"50.14375\" xlink:href=\"#m2499756918\" y=\"116.483767\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_11\">\n",
       "      <!-- 0.90 -->\n",
       "      <g transform=\"translate(20.878125 120.282986)scale(0.1 -0.1)\">\n",
       "       <defs>\n",
       "        <path d=\"M 10.984375 1.515625 \n",
       "L 10.984375 10.5 \n",
       "Q 14.703125 8.734375 18.5 7.8125 \n",
       "Q 22.3125 6.890625 25.984375 6.890625 \n",
       "Q 35.75 6.890625 40.890625 13.453125 \n",
       "Q 46.046875 20.015625 46.78125 33.40625 \n",
       "Q 43.953125 29.203125 39.59375 26.953125 \n",
       "Q 35.25 24.703125 29.984375 24.703125 \n",
       "Q 19.046875 24.703125 12.671875 31.3125 \n",
       "Q 6.296875 37.9375 6.296875 49.421875 \n",
       "Q 6.296875 60.640625 12.9375 67.421875 \n",
       "Q 19.578125 74.21875 30.609375 74.21875 \n",
       "Q 43.265625 74.21875 49.921875 64.515625 \n",
       "Q 56.59375 54.828125 56.59375 36.375 \n",
       "Q 56.59375 19.140625 48.40625 8.859375 \n",
       "Q 40.234375 -1.421875 26.421875 -1.421875 \n",
       "Q 22.703125 -1.421875 18.890625 -0.6875 \n",
       "Q 15.09375 0.046875 10.984375 1.515625 \n",
       "z\n",
       "M 30.609375 32.421875 \n",
       "Q 37.25 32.421875 41.125 36.953125 \n",
       "Q 45.015625 41.5 45.015625 49.421875 \n",
       "Q 45.015625 57.28125 41.125 61.84375 \n",
       "Q 37.25 66.40625 30.609375 66.40625 \n",
       "Q 23.96875 66.40625 20.09375 61.84375 \n",
       "Q 16.21875 57.28125 16.21875 49.421875 \n",
       "Q 16.21875 41.5 20.09375 36.953125 \n",
       "Q 23.96875 32.421875 30.609375 32.421875 \n",
       "z\n",
       "\" id=\"DejaVuSans-57\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#DejaVuSans-48\"/>\n",
       "       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n",
       "       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-57\"/>\n",
       "       <use x=\"159.033203\" xlink:href=\"#DejaVuSans-48\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_5\">\n",
       "     <g id=\"line2d_11\">\n",
       "      <g>\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"50.14375\" xlink:href=\"#m2499756918\" y=\"81.027788\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_12\">\n",
       "      <!-- 0.92 -->\n",
       "      <g transform=\"translate(20.878125 84.827007)scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-48\"/>\n",
       "       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n",
       "       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-57\"/>\n",
       "       <use x=\"159.033203\" xlink:href=\"#DejaVuSans-50\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_6\">\n",
       "     <g id=\"line2d_12\">\n",
       "      <g>\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"50.14375\" xlink:href=\"#m2499756918\" y=\"45.571809\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_13\">\n",
       "      <!-- 0.94 -->\n",
       "      <g transform=\"translate(20.878125 49.371028)scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-48\"/>\n",
       "       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n",
       "       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-57\"/>\n",
       "       <use x=\"159.033203\" xlink:href=\"#DejaVuSans-52\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"text_14\">\n",
       "     <!-- accuracy -->\n",
       "     <g transform=\"translate(14.798438 153.5975)rotate(-90)scale(0.1 -0.1)\">\n",
       "      <defs>\n",
       "       <path d=\"M 34.28125 27.484375 \n",
       "Q 23.390625 27.484375 19.1875 25 \n",
       "Q 14.984375 22.515625 14.984375 16.5 \n",
       "Q 14.984375 11.71875 18.140625 8.90625 \n",
       "Q 21.296875 6.109375 26.703125 6.109375 \n",
       "Q 34.1875 6.109375 38.703125 11.40625 \n",
       "Q 43.21875 16.703125 43.21875 25.484375 \n",
       "L 43.21875 27.484375 \n",
       "z\n",
       "M 52.203125 31.203125 \n",
       "L 52.203125 0 \n",
       "L 43.21875 0 \n",
       "L 43.21875 8.296875 \n",
       "Q 40.140625 3.328125 35.546875 0.953125 \n",
       "Q 30.953125 -1.421875 24.3125 -1.421875 \n",
       "Q 15.921875 -1.421875 10.953125 3.296875 \n",
       "Q 6 8.015625 6 15.921875 \n",
       "Q 6 25.140625 12.171875 29.828125 \n",
       "Q 18.359375 34.515625 30.609375 34.515625 \n",
       "L 43.21875 34.515625 \n",
       "L 43.21875 35.40625 \n",
       "Q 43.21875 41.609375 39.140625 45 \n",
       "Q 35.0625 48.390625 27.6875 48.390625 \n",
       "Q 23 48.390625 18.546875 47.265625 \n",
       "Q 14.109375 46.140625 10.015625 43.890625 \n",
       "L 10.015625 52.203125 \n",
       "Q 14.9375 54.109375 19.578125 55.046875 \n",
       "Q 24.21875 56 28.609375 56 \n",
       "Q 40.484375 56 46.34375 49.84375 \n",
       "Q 52.203125 43.703125 52.203125 31.203125 \n",
       "z\n",
       "\" id=\"DejaVuSans-97\"/>\n",
       "       <path d=\"M 8.5 21.578125 \n",
       "L 8.5 54.6875 \n",
       "L 17.484375 54.6875 \n",
       "L 17.484375 21.921875 \n",
       "Q 17.484375 14.15625 20.5 10.265625 \n",
       "Q 23.53125 6.390625 29.59375 6.390625 \n",
       "Q 36.859375 6.390625 41.078125 11.03125 \n",
       "Q 45.3125 15.671875 45.3125 23.6875 \n",
       "L 45.3125 54.6875 \n",
       "L 54.296875 54.6875 \n",
       "L 54.296875 0 \n",
       "L 45.3125 0 \n",
       "L 45.3125 8.40625 \n",
       "Q 42.046875 3.421875 37.71875 1 \n",
       "Q 33.40625 -1.421875 27.6875 -1.421875 \n",
       "Q 18.265625 -1.421875 13.375 4.4375 \n",
       "Q 8.5 10.296875 8.5 21.578125 \n",
       "z\n",
       "M 31.109375 56 \n",
       "z\n",
       "\" id=\"DejaVuSans-117\"/>\n",
       "       <path d=\"M 41.109375 46.296875 \n",
       "Q 39.59375 47.171875 37.8125 47.578125 \n",
       "Q 36.03125 48 33.890625 48 \n",
       "Q 26.265625 48 22.1875 43.046875 \n",
       "Q 18.109375 38.09375 18.109375 28.8125 \n",
       "L 18.109375 0 \n",
       "L 9.078125 0 \n",
       "L 9.078125 54.6875 \n",
       "L 18.109375 54.6875 \n",
       "L 18.109375 46.1875 \n",
       "Q 20.953125 51.171875 25.484375 53.578125 \n",
       "Q 30.03125 56 36.53125 56 \n",
       "Q 37.453125 56 38.578125 55.875 \n",
       "Q 39.703125 55.765625 41.0625 55.515625 \n",
       "z\n",
       "\" id=\"DejaVuSans-114\"/>\n",
       "       <path d=\"M 32.171875 -5.078125 \n",
       "Q 28.375 -14.84375 24.75 -17.8125 \n",
       "Q 21.140625 -20.796875 15.09375 -20.796875 \n",
       "L 7.90625 -20.796875 \n",
       "L 7.90625 -13.28125 \n",
       "L 13.1875 -13.28125 \n",
       "Q 16.890625 -13.28125 18.9375 -11.515625 \n",
       "Q 21 -9.765625 23.484375 -3.21875 \n",
       "L 25.09375 0.875 \n",
       "L 2.984375 54.6875 \n",
       "L 12.5 54.6875 \n",
       "L 29.59375 11.921875 \n",
       "L 46.6875 54.6875 \n",
       "L 56.203125 54.6875 \n",
       "z\n",
       "\" id=\"DejaVuSans-121\"/>\n",
       "      </defs>\n",
       "      <use xlink:href=\"#DejaVuSans-97\"/>\n",
       "      <use x=\"61.279297\" xlink:href=\"#DejaVuSans-99\"/>\n",
       "      <use x=\"116.259766\" xlink:href=\"#DejaVuSans-99\"/>\n",
       "      <use x=\"171.240234\" xlink:href=\"#DejaVuSans-117\"/>\n",
       "      <use x=\"234.619141\" xlink:href=\"#DejaVuSans-114\"/>\n",
       "      <use x=\"275.732422\" xlink:href=\"#DejaVuSans-97\"/>\n",
       "      <use x=\"337.011719\" xlink:href=\"#DejaVuSans-99\"/>\n",
       "      <use x=\"391.992188\" xlink:href=\"#DejaVuSans-121\"/>\n",
       "     </g>\n",
       "    </g>\n",
       "   </g>\n",
       "   <g id=\"line2d_13\">\n",
       "    <path clip-path=\"url(#p849050020c)\" d=\"M 65.361932 129.090734 \n",
       "L 65.6666 117.828951 \n",
       "L 65.971268 129.820682 \n",
       "L 66.580605 47.546836 \n",
       "L 66.885273 45.878354 \n",
       "L 67.189942 37.014896 \n",
       "L 67.49461 37.536257 \n",
       "L 67.799278 37.119189 \n",
       "L 68.103947 40.873117 \n",
       "L 68.408615 38.370498 \n",
       "L 68.713283 42.437306 \n",
       "L 69.017951 36.702121 \n",
       "L 69.32262 37.014896 \n",
       "L 69.627288 36.597828 \n",
       "L 69.931956 39.517514 \n",
       "L 70.236625 40.247462 \n",
       "L 70.541293 39.934688 \n",
       "L 70.845961 40.351755 \n",
       "L 71.15063 38.370498 \n",
       "L 71.455298 42.228719 \n",
       "L 71.759966 37.95343 \n",
       "L 72.064635 43.584322 \n",
       "L 72.369303 40.560342 \n",
       "L 72.673971 42.75008 \n",
       "L 72.978639 50.570816 \n",
       "L 73.283308 55.471759 \n",
       "L 73.587976 40.143169 \n",
       "L 73.892644 37.327776 \n",
       "L 74.197313 43.897096 \n",
       "L 74.501981 41.915839 \n",
       "L 74.806649 42.645787 \n",
       "L 75.111318 42.124426 \n",
       "L 75.415986 55.263278 \n",
       "L 75.720654 54.22045 \n",
       "L 76.025322 44.835631 \n",
       "L 76.329991 42.75008 \n",
       "L 76.634659 41.498771 \n",
       "L 76.939327 44.00139 \n",
       "L 77.243996 43.792909 \n",
       "L 77.548664 43.167148 \n",
       "L 77.853332 41.394478 \n",
       "L 78.158001 40.873117 \n",
       "L 78.462669 39.830394 \n",
       "L 78.767337 39.413221 \n",
       "L 79.072006 38.579085 \n",
       "L 79.376674 35.659293 \n",
       "L 79.681342 37.536257 \n",
       "L 79.98601 37.849137 \n",
       "L 80.290679 37.431963 \n",
       "L 80.595347 38.057618 \n",
       "L 80.900015 36.702121 \n",
       "L 81.204684 36.910602 \n",
       "L 81.509352 36.180654 \n",
       "L 81.81402 36.284948 \n",
       "L 82.118689 35.242225 \n",
       "L 82.423357 35.659293 \n",
       "L 82.728025 35.346518 \n",
       "L 83.032693 35.450812 \n",
       "L 83.337362 35.242225 \n",
       "L 83.64203 35.346518 \n",
       "L 83.946698 35.659293 \n",
       "L 84.251367 35.242225 \n",
       "L 84.556035 35.659293 \n",
       "L 84.860703 35.555 \n",
       "L 85.165372 35.137932 \n",
       "L 85.47004 35.137932 \n",
       "L 85.774708 35.763586 \n",
       "L 86.079377 35.346518 \n",
       "L 86.993381 35.763586 \n",
       "L 87.29805 35.346518 \n",
       "L 87.602718 35.137932 \n",
       "L 89.12606 35.137932 \n",
       "L 89.430728 35.450812 \n",
       "L 89.735396 35.137932 \n",
       "L 90.344733 35.137932 \n",
       "L 90.649401 35.555 \n",
       "L 90.954069 35.137932 \n",
       "L 91.563406 35.450812 \n",
       "L 92.172743 35.137932 \n",
       "L 93.086748 35.137932 \n",
       "L 93.391416 35.346518 \n",
       "L 93.696084 35.137932 \n",
       "L 95.524094 35.137932 \n",
       "L 95.828762 35.555 \n",
       "L 96.438099 35.137932 \n",
       "L 97.352104 35.137932 \n",
       "L 97.656772 35.346518 \n",
       "L 97.96144 35.137932 \n",
       "L 369.725568 35.137932 \n",
       "L 369.725568 35.137932 \n",
       "\" style=\"fill:none;stroke:#1f77b4;stroke-linecap:square;stroke-width:1.5;\"/>\n",
       "   </g>\n",
       "   <g id=\"line2d_14\">\n",
       "    <path clip-path=\"url(#p849050020c)\" d=\"M 65.361932 32.201761 \n",
       "L 65.6666 229.874489 \n",
       "L 65.971268 32.201761 \n",
       "L 369.725568 32.201761 \n",
       "L 369.725568 32.201761 \n",
       "\" style=\"fill:none;stroke:#ff7f0e;stroke-linecap:square;stroke-width:1.5;\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_3\">\n",
       "    <path d=\"M 50.14375 239.758125 \n",
       "L 50.14375 22.318125 \n",
       "\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_4\">\n",
       "    <path d=\"M 384.94375 239.758125 \n",
       "L 384.94375 22.318125 \n",
       "\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_5\">\n",
       "    <path d=\"M 50.14375 239.758125 \n",
       "L 384.94375 239.758125 \n",
       "\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_6\">\n",
       "    <path d=\"M 50.14375 22.318125 \n",
       "L 384.94375 22.318125 \n",
       "\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n",
       "   </g>\n",
       "   <g id=\"text_15\">\n",
       "    <!-- model accuracy -->\n",
       "    <g transform=\"translate(169.882188 16.318125)scale(0.12 -0.12)\">\n",
       "     <defs>\n",
       "      <path d=\"M 52 44.1875 \n",
       "Q 55.375 50.25 60.0625 53.125 \n",
       "Q 64.75 56 71.09375 56 \n",
       "Q 79.640625 56 84.28125 50.015625 \n",
       "Q 88.921875 44.046875 88.921875 33.015625 \n",
       "L 88.921875 0 \n",
       "L 79.890625 0 \n",
       "L 79.890625 32.71875 \n",
       "Q 79.890625 40.578125 77.09375 44.375 \n",
       "Q 74.3125 48.1875 68.609375 48.1875 \n",
       "Q 61.625 48.1875 57.5625 43.546875 \n",
       "Q 53.515625 38.921875 53.515625 30.90625 \n",
       "L 53.515625 0 \n",
       "L 44.484375 0 \n",
       "L 44.484375 32.71875 \n",
       "Q 44.484375 40.625 41.703125 44.40625 \n",
       "Q 38.921875 48.1875 33.109375 48.1875 \n",
       "Q 26.21875 48.1875 22.15625 43.53125 \n",
       "Q 18.109375 38.875 18.109375 30.90625 \n",
       "L 18.109375 0 \n",
       "L 9.078125 0 \n",
       "L 9.078125 54.6875 \n",
       "L 18.109375 54.6875 \n",
       "L 18.109375 46.1875 \n",
       "Q 21.1875 51.21875 25.484375 53.609375 \n",
       "Q 29.78125 56 35.6875 56 \n",
       "Q 41.65625 56 45.828125 52.96875 \n",
       "Q 50 49.953125 52 44.1875 \n",
       "z\n",
       "\" id=\"DejaVuSans-109\"/>\n",
       "      <path d=\"M 45.40625 46.390625 \n",
       "L 45.40625 75.984375 \n",
       "L 54.390625 75.984375 \n",
       "L 54.390625 0 \n",
       "L 45.40625 0 \n",
       "L 45.40625 8.203125 \n",
       "Q 42.578125 3.328125 38.25 0.953125 \n",
       "Q 33.9375 -1.421875 27.875 -1.421875 \n",
       "Q 17.96875 -1.421875 11.734375 6.484375 \n",
       "Q 5.515625 14.40625 5.515625 27.296875 \n",
       "Q 5.515625 40.1875 11.734375 48.09375 \n",
       "Q 17.96875 56 27.875 56 \n",
       "Q 33.9375 56 38.25 53.625 \n",
       "Q 42.578125 51.265625 45.40625 46.390625 \n",
       "z\n",
       "M 14.796875 27.296875 \n",
       "Q 14.796875 17.390625 18.875 11.75 \n",
       "Q 22.953125 6.109375 30.078125 6.109375 \n",
       "Q 37.203125 6.109375 41.296875 11.75 \n",
       "Q 45.40625 17.390625 45.40625 27.296875 \n",
       "Q 45.40625 37.203125 41.296875 42.84375 \n",
       "Q 37.203125 48.484375 30.078125 48.484375 \n",
       "Q 22.953125 48.484375 18.875 42.84375 \n",
       "Q 14.796875 37.203125 14.796875 27.296875 \n",
       "z\n",
       "\" id=\"DejaVuSans-100\"/>\n",
       "      <path d=\"M 9.421875 75.984375 \n",
       "L 18.40625 75.984375 \n",
       "L 18.40625 0 \n",
       "L 9.421875 0 \n",
       "z\n",
       "\" id=\"DejaVuSans-108\"/>\n",
       "      <path id=\"DejaVuSans-32\"/>\n",
       "     </defs>\n",
       "     <use xlink:href=\"#DejaVuSans-109\"/>\n",
       "     <use x=\"97.412109\" xlink:href=\"#DejaVuSans-111\"/>\n",
       "     <use x=\"158.59375\" xlink:href=\"#DejaVuSans-100\"/>\n",
       "     <use x=\"222.070312\" xlink:href=\"#DejaVuSans-101\"/>\n",
       "     <use x=\"283.59375\" xlink:href=\"#DejaVuSans-108\"/>\n",
       "     <use x=\"311.376953\" xlink:href=\"#DejaVuSans-32\"/>\n",
       "     <use x=\"343.164062\" xlink:href=\"#DejaVuSans-97\"/>\n",
       "     <use x=\"404.443359\" xlink:href=\"#DejaVuSans-99\"/>\n",
       "     <use x=\"459.423828\" xlink:href=\"#DejaVuSans-99\"/>\n",
       "     <use x=\"514.404297\" xlink:href=\"#DejaVuSans-117\"/>\n",
       "     <use x=\"577.783203\" xlink:href=\"#DejaVuSans-114\"/>\n",
       "     <use x=\"618.896484\" xlink:href=\"#DejaVuSans-97\"/>\n",
       "     <use x=\"680.175781\" xlink:href=\"#DejaVuSans-99\"/>\n",
       "     <use x=\"735.15625\" xlink:href=\"#DejaVuSans-121\"/>\n",
       "    </g>\n",
       "   </g>\n",
       "   <g id=\"legend_1\">\n",
       "    <g id=\"patch_7\">\n",
       "     <path d=\"M 296.709375 234.758125 \n",
       "L 377.94375 234.758125 \n",
       "Q 379.94375 234.758125 379.94375 232.758125 \n",
       "L 379.94375 204.401875 \n",
       "Q 379.94375 202.401875 377.94375 202.401875 \n",
       "L 296.709375 202.401875 \n",
       "Q 294.709375 202.401875 294.709375 204.401875 \n",
       "L 294.709375 232.758125 \n",
       "Q 294.709375 234.758125 296.709375 234.758125 \n",
       "z\n",
       "\" style=\"fill:#ffffff;opacity:0.8;stroke:#cccccc;stroke-linejoin:miter;\"/>\n",
       "    </g>\n",
       "    <g id=\"line2d_15\">\n",
       "     <path d=\"M 298.709375 210.500312 \n",
       "L 318.709375 210.500312 \n",
       "\" style=\"fill:none;stroke:#1f77b4;stroke-linecap:square;stroke-width:1.5;\"/>\n",
       "    </g>\n",
       "    <g id=\"line2d_16\"/>\n",
       "    <g id=\"text_16\">\n",
       "     <!-- train -->\n",
       "     <g transform=\"translate(326.709375 214.000312)scale(0.1 -0.1)\">\n",
       "      <defs>\n",
       "       <path d=\"M 18.3125 70.21875 \n",
       "L 18.3125 54.6875 \n",
       "L 36.8125 54.6875 \n",
       "L 36.8125 47.703125 \n",
       "L 18.3125 47.703125 \n",
       "L 18.3125 18.015625 \n",
       "Q 18.3125 11.328125 20.140625 9.421875 \n",
       "Q 21.96875 7.515625 27.59375 7.515625 \n",
       "L 36.8125 7.515625 \n",
       "L 36.8125 0 \n",
       "L 27.59375 0 \n",
       "Q 17.1875 0 13.234375 3.875 \n",
       "Q 9.28125 7.765625 9.28125 18.015625 \n",
       "L 9.28125 47.703125 \n",
       "L 2.6875 47.703125 \n",
       "L 2.6875 54.6875 \n",
       "L 9.28125 54.6875 \n",
       "L 9.28125 70.21875 \n",
       "z\n",
       "\" id=\"DejaVuSans-116\"/>\n",
       "       <path d=\"M 9.421875 54.6875 \n",
       "L 18.40625 54.6875 \n",
       "L 18.40625 0 \n",
       "L 9.421875 0 \n",
       "z\n",
       "M 9.421875 75.984375 \n",
       "L 18.40625 75.984375 \n",
       "L 18.40625 64.59375 \n",
       "L 9.421875 64.59375 \n",
       "z\n",
       "\" id=\"DejaVuSans-105\"/>\n",
       "       <path d=\"M 54.890625 33.015625 \n",
       "L 54.890625 0 \n",
       "L 45.90625 0 \n",
       "L 45.90625 32.71875 \n",
       "Q 45.90625 40.484375 42.875 44.328125 \n",
       "Q 39.84375 48.1875 33.796875 48.1875 \n",
       "Q 26.515625 48.1875 22.3125 43.546875 \n",
       "Q 18.109375 38.921875 18.109375 30.90625 \n",
       "L 18.109375 0 \n",
       "L 9.078125 0 \n",
       "L 9.078125 54.6875 \n",
       "L 18.109375 54.6875 \n",
       "L 18.109375 46.1875 \n",
       "Q 21.34375 51.125 25.703125 53.5625 \n",
       "Q 30.078125 56 35.796875 56 \n",
       "Q 45.21875 56 50.046875 50.171875 \n",
       "Q 54.890625 44.34375 54.890625 33.015625 \n",
       "z\n",
       "\" id=\"DejaVuSans-110\"/>\n",
       "      </defs>\n",
       "      <use xlink:href=\"#DejaVuSans-116\"/>\n",
       "      <use x=\"39.208984\" xlink:href=\"#DejaVuSans-114\"/>\n",
       "      <use x=\"80.322266\" xlink:href=\"#DejaVuSans-97\"/>\n",
       "      <use x=\"141.601562\" xlink:href=\"#DejaVuSans-105\"/>\n",
       "      <use x=\"169.384766\" xlink:href=\"#DejaVuSans-110\"/>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"line2d_17\">\n",
       "     <path d=\"M 298.709375 225.178437 \n",
       "L 318.709375 225.178437 \n",
       "\" style=\"fill:none;stroke:#ff7f0e;stroke-linecap:square;stroke-width:1.5;\"/>\n",
       "    </g>\n",
       "    <g id=\"line2d_18\"/>\n",
       "    <g id=\"text_17\">\n",
       "     <!-- validation -->\n",
       "     <g transform=\"translate(326.709375 228.678437)scale(0.1 -0.1)\">\n",
       "      <defs>\n",
       "       <path d=\"M 2.984375 54.6875 \n",
       "L 12.5 54.6875 \n",
       "L 29.59375 8.796875 \n",
       "L 46.6875 54.6875 \n",
       "L 56.203125 54.6875 \n",
       "L 35.6875 0 \n",
       "L 23.484375 0 \n",
       "z\n",
       "\" id=\"DejaVuSans-118\"/>\n",
       "      </defs>\n",
       "      <use xlink:href=\"#DejaVuSans-118\"/>\n",
       "      <use x=\"59.179688\" xlink:href=\"#DejaVuSans-97\"/>\n",
       "      <use x=\"120.458984\" xlink:href=\"#DejaVuSans-108\"/>\n",
       "      <use x=\"148.242188\" xlink:href=\"#DejaVuSans-105\"/>\n",
       "      <use x=\"176.025391\" xlink:href=\"#DejaVuSans-100\"/>\n",
       "      <use x=\"239.501953\" xlink:href=\"#DejaVuSans-97\"/>\n",
       "      <use x=\"300.78125\" xlink:href=\"#DejaVuSans-116\"/>\n",
       "      <use x=\"339.990234\" xlink:href=\"#DejaVuSans-105\"/>\n",
       "      <use x=\"367.773438\" xlink:href=\"#DejaVuSans-111\"/>\n",
       "      <use x=\"428.955078\" xlink:href=\"#DejaVuSans-110\"/>\n",
       "     </g>\n",
       "    </g>\n",
       "   </g>\n",
       "  </g>\n",
       " </g>\n",
       " <defs>\n",
       "  <clipPath id=\"p849050020c\">\n",
       "   <rect height=\"217.44\" width=\"334.8\" x=\"50.14375\" y=\"22.318125\"/>\n",
       "  </clipPath>\n",
       " </defs>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_hist(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train_Loss: 0.194, Train_Acc: 0.946\n",
      "Test_Loss: 0.193, Test_Acc: 0.948\n"
     ]
    }
   ],
   "source": [
    "# evaluate the model\n",
    "train_loss, train_acc = model.evaluate([X_img_train, X_audio_train], y_train, verbose=0)\n",
    "test_loss, test_acc = model.evaluate([X_img_test, X_audio_test], y_test, verbose=0)\n",
    "print('Train_Loss: %.3f, Train_Acc: %.3f' % (train_loss, train_acc))\n",
    "print('Test_Loss: %.3f, Test_Acc: %.3f' % (test_loss, test_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model.predict([X_img_test, X_audio_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = (model.predict([X_img_test, X_audio_test]) > 0.5)*1    #.astype(\"int32\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score: 0.9475417548812044\n",
      "Precision: 0.0\n",
      "Recall: 0.0\n",
      "F1_score: 0.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, classification_report, confusion_matrix\n",
    "score = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test,y_pred)\n",
    "recall = recall_score(y_test,y_pred)\n",
    "f1 = f1_score(y_test,y_pred)\n",
    "print(\"score:\", score)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"F1_score:\", f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix : \n",
      " [[4028    0]\n",
      " [ 223    0]]\n"
     ]
    }
   ],
   "source": [
    "# confusion matrix\n",
    "matrix = confusion_matrix(y_test, y_pred, labels=[0,1])\n",
    "print('Confusion matrix : \\n',matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report : \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      1.00      0.97      4028\n",
      "           1       0.00      0.00      0.00       223\n",
      "\n",
      "    accuracy                           0.95      4251\n",
      "   macro avg       0.47      0.50      0.49      4251\n",
      "weighted avg       0.90      0.95      0.92      4251\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# classification report for precision, recall f1-score and accuracy\n",
    "matrix = classification_report(y_test, y_pred, labels=[0,1])\n",
    "print('Classification report : \\n',matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Outcome values : \n",
      " 4028 0 223 0\n"
     ]
    }
   ],
   "source": [
    "# outcome values order in sklearn\n",
    "tp, fn, fp, tn = confusion_matrix(y_test, y_pred,labels=[0,1]).reshape(-1)\n",
    "print('Outcome values : \\n', tp, fn, fp, tn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
