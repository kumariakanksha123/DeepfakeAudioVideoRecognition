{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-06 10:17:54.893947: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2022-07-06 10:17:54.898168: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-07-06 10:17:54.898182: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "/home/arman/anaconda3/lib/python3.9/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.0\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "import os\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import (Activation, Dropout, Flatten, Dense, GlobalMaxPooling2D,\n",
    "                          BatchNormalization, Input, Conv2D, GlobalAveragePooling2D,concatenate,Concatenate,multiply, LocallyConnected2D, Lambda)\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras import metrics\n",
    "from keras import backend as K\n",
    "import keras\n",
    "from keras.models import Model\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.applications import EfficientNetB7\n",
    "import skimage.io\n",
    "from skimage.transform import resize\n",
    "\n",
    "from tqdm import tqdm\n",
    "import PIL\n",
    "from PIL import Image, ImageOps\n",
    "import cv2\n",
    "from sklearn.utils import class_weight, shuffle\n",
    "from keras.losses import binary_crossentropy, categorical_crossentropy\n",
    "#from keras.applications.resnet50 import preprocess_input\n",
    "from keras.applications.densenet import DenseNet121,DenseNet169,preprocess_input\n",
    "import keras.backend as K\n",
    "import tensorflow as tf\n",
    "from sklearn.metrics import f1_score, fbeta_score, cohen_kappa_score\n",
    "\n",
    "import keras.callbacks as callbacks\n",
    "from keras.callbacks import Callback\n",
    "get_ipython().run_line_magic('config', 'InlineBackend.figure_format=\"svg\"')\n",
    "get_ipython().run_line_magic('matplotlib', 'inline')\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "SIZE = 224\n",
    "NUM_CLASSES = 2\n",
    "\n",
    "from keras.models import Model, load_model\n",
    "from keras.layers import Embedding, LSTM, Dropout, Dense, Input, Bidirectional, Flatten, Conv2D, MaxPooling2D, concatenate, Conv1D, MaxPooling1D\n",
    "import keras.backend as K\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.optimizers import Adam, RMSprop\n",
    "from keras.callbacks import ModelCheckpoint, CSVLogger, EarlyStopping\n",
    "from keras.layers import Conv2D, MaxPooling2D, Input, Dense, Flatten, concatenate\n",
    "from keras.models import Model\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "\n",
    "\n",
    "def get_num_input():\n",
    "    df = pd.read_csv('Ad.csv')\n",
    "    df = df.drop(['filename'],axis=1)\n",
    "    columns = list(df.columns)\n",
    "    features = columns[:-1]\n",
    "    cls_name = columns[-1]\n",
    "    X = np.zeros((len(df), len(features)))\n",
    "    Y = list()\n",
    "    for i, row in df.iterrows():\n",
    "        X[i] = row[features]                    \n",
    "        Y.append(row[cls_name])\n",
    "\n",
    "    return (X, Y)\n",
    "X_num, Y = get_num_input()\n",
    "encoder = LabelEncoder()\n",
    "Y = encoder.fit_transform(Y)\n",
    "X_audio_train, X_audio_test, y_audio_train, y_audio_test = train_test_split( X_num, Y, test_size=0.2,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Conv2D, MaxPooling2D, Input, Dense, Flatten, concatenate\n",
    "from keras.models import Model\n",
    "import numpy as np\n",
    "from keras import regularizers\n",
    "from keras.layers import Dropout \n",
    "def compile_model():\n",
    "    num_input = Input(shape=(133,))        ## branch 2 with numerical input\n",
    "    x1 = Dense(1024, activation='relu', kernel_regularizer=regularizers.l2(0.01))(num_input)\n",
    "    x1 = Dropout(0.3)(x1)\n",
    "    x1 = Dense(512, activation='relu', kernel_regularizer=regularizers.l2(0.01))(x1)\n",
    "    x1 = Dropout(0.3)(x1)\n",
    "    x1 = Dense(256, activation='relu', kernel_regularizer=regularizers.l2(0.01))(x1)\n",
    "    x1 = Dropout(0.3)(x1)\n",
    "    x1 = Dense(128, activation='relu', kernel_regularizer=regularizers.l2(0.01))(x1)\n",
    "    x1 = Dropout(0.3)(x1)\n",
    "    x1 = Dense(64, activation='relu', kernel_regularizer=regularizers.l2(0.01))(x1)\n",
    "    x1 = Dropout(0.3)(x1)\n",
    "    out_b = Dense(32, activation='relu', kernel_regularizer=regularizers.l2(0.01))(x1)\n",
    "    out_b = Dense(1, activation='sigmoid')(out_b)\n",
    "    model = Model(num_input, out_b)\n",
    "    adam = Adam(lr=0.001, decay=1e-5)\n",
    "    print(model.summary())\n",
    "    model.compile(loss=\"binary_crossentropy\", optimizer=adam, metrics=[\"accuracy\"])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 133)]             0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1024)              137216    \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 1024)              0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 512)               524800    \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 512)               0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 256)               131328    \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 256)               0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 128)               32896     \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 64)                8256      \n",
      "                                                                 \n",
      " dropout_4 (Dropout)         (None, 64)                0         \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 1)                 33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 836,609\n",
      "Trainable params: 836,609\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-06 10:18:07.788803: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/arman/anaconda3/lib/python3.9/site-packages/cv2/../../lib64:\n",
      "2022-07-06 10:18:07.788826: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2022-07-06 10:18:07.788839: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (arman): /proc/driver/nvidia/version does not exist\n",
      "2022-07-06 10:18:07.789097: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "model = compile_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "67/67 [==============================] - 3s 26ms/step - loss: 14.6572 - accuracy: 0.8814 - val_loss: 9.0315 - val_accuracy: 0.9475\n",
      "Epoch 2/1000\n",
      "67/67 [==============================] - 2s 24ms/step - loss: 8.5287 - accuracy: 0.9063 - val_loss: 7.9786 - val_accuracy: 0.9475\n",
      "Epoch 3/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 7.3637 - accuracy: 0.9304 - val_loss: 6.8944 - val_accuracy: 0.9475\n",
      "Epoch 4/1000\n",
      "67/67 [==============================] - 2s 24ms/step - loss: 6.5203 - accuracy: 0.9377 - val_loss: 6.2734 - val_accuracy: 0.9475\n",
      "Epoch 5/1000\n",
      "67/67 [==============================] - 2s 24ms/step - loss: 5.8036 - accuracy: 0.9435 - val_loss: 5.5422 - val_accuracy: 0.9475\n",
      "Epoch 6/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 5.2019 - accuracy: 0.9450 - val_loss: 4.9549 - val_accuracy: 0.9475\n",
      "Epoch 7/1000\n",
      "67/67 [==============================] - 2s 24ms/step - loss: 4.6713 - accuracy: 0.9454 - val_loss: 4.4832 - val_accuracy: 0.9475\n",
      "Epoch 8/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 4.2074 - accuracy: 0.9455 - val_loss: 4.0543 - val_accuracy: 0.9475\n",
      "Epoch 9/1000\n",
      "67/67 [==============================] - 2s 24ms/step - loss: 3.8003 - accuracy: 0.9458 - val_loss: 3.6619 - val_accuracy: 0.9475\n",
      "Epoch 10/1000\n",
      "67/67 [==============================] - 2s 24ms/step - loss: 3.4318 - accuracy: 0.9458 - val_loss: 3.2980 - val_accuracy: 0.9475\n",
      "Epoch 11/1000\n",
      "67/67 [==============================] - 2s 24ms/step - loss: 3.1128 - accuracy: 0.9459 - val_loss: 2.9843 - val_accuracy: 0.9475\n",
      "Epoch 12/1000\n",
      "67/67 [==============================] - 1s 22ms/step - loss: 2.8241 - accuracy: 0.9459 - val_loss: 2.7006 - val_accuracy: 0.9475\n",
      "Epoch 13/1000\n",
      "67/67 [==============================] - 2s 24ms/step - loss: 2.5706 - accuracy: 0.9459 - val_loss: 2.4850 - val_accuracy: 0.9475\n",
      "Epoch 14/1000\n",
      "67/67 [==============================] - 2s 24ms/step - loss: 2.3440 - accuracy: 0.9459 - val_loss: 2.2645 - val_accuracy: 0.9475\n",
      "Epoch 15/1000\n",
      "67/67 [==============================] - 2s 24ms/step - loss: 2.1411 - accuracy: 0.9459 - val_loss: 2.0542 - val_accuracy: 0.9475\n",
      "Epoch 16/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 1.9565 - accuracy: 0.9459 - val_loss: 1.8838 - val_accuracy: 0.9475\n",
      "Epoch 17/1000\n",
      "67/67 [==============================] - 2s 24ms/step - loss: 1.7929 - accuracy: 0.9459 - val_loss: 1.7283 - val_accuracy: 0.9475\n",
      "Epoch 18/1000\n",
      "67/67 [==============================] - 2s 24ms/step - loss: 1.6459 - accuracy: 0.9459 - val_loss: 1.5929 - val_accuracy: 0.9475\n",
      "Epoch 19/1000\n",
      "67/67 [==============================] - 2s 24ms/step - loss: 1.5123 - accuracy: 0.9459 - val_loss: 1.4595 - val_accuracy: 0.9475\n",
      "Epoch 20/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 1.3928 - accuracy: 0.9459 - val_loss: 1.3326 - val_accuracy: 0.9475\n",
      "Epoch 21/1000\n",
      "67/67 [==============================] - 2s 24ms/step - loss: 1.2872 - accuracy: 0.9459 - val_loss: 1.2369 - val_accuracy: 0.9475\n",
      "Epoch 22/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 1.1903 - accuracy: 0.9459 - val_loss: 1.1494 - val_accuracy: 0.9475\n",
      "Epoch 23/1000\n",
      "67/67 [==============================] - 2s 24ms/step - loss: 1.1046 - accuracy: 0.9459 - val_loss: 1.0552 - val_accuracy: 0.9475\n",
      "Epoch 24/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 1.0223 - accuracy: 0.9459 - val_loss: 0.9769 - val_accuracy: 0.9475\n",
      "Epoch 25/1000\n",
      "67/67 [==============================] - 2s 24ms/step - loss: 0.9510 - accuracy: 0.9459 - val_loss: 0.9112 - val_accuracy: 0.9475\n",
      "Epoch 26/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.8855 - accuracy: 0.9459 - val_loss: 0.8529 - val_accuracy: 0.9475\n",
      "Epoch 27/1000\n",
      "67/67 [==============================] - 2s 24ms/step - loss: 0.8270 - accuracy: 0.9459 - val_loss: 0.7946 - val_accuracy: 0.9475\n",
      "Epoch 28/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.7730 - accuracy: 0.9459 - val_loss: 0.7378 - val_accuracy: 0.9475\n",
      "Epoch 29/1000\n",
      "67/67 [==============================] - 2s 24ms/step - loss: 0.7263 - accuracy: 0.9459 - val_loss: 0.6951 - val_accuracy: 0.9475\n",
      "Epoch 30/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.6814 - accuracy: 0.9459 - val_loss: 0.6547 - val_accuracy: 0.9475\n",
      "Epoch 31/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.6400 - accuracy: 0.9459 - val_loss: 0.6137 - val_accuracy: 0.9475\n",
      "Epoch 32/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.6045 - accuracy: 0.9459 - val_loss: 0.5761 - val_accuracy: 0.9475\n",
      "Epoch 33/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.5711 - accuracy: 0.9459 - val_loss: 0.5471 - val_accuracy: 0.9475\n",
      "Epoch 34/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.5412 - accuracy: 0.9459 - val_loss: 0.5190 - val_accuracy: 0.9475\n",
      "Epoch 35/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.5121 - accuracy: 0.9459 - val_loss: 0.4926 - val_accuracy: 0.9475\n",
      "Epoch 36/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.4879 - accuracy: 0.9459 - val_loss: 0.4656 - val_accuracy: 0.9475\n",
      "Epoch 37/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.4665 - accuracy: 0.9459 - val_loss: 0.4466 - val_accuracy: 0.9475\n",
      "Epoch 38/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.4439 - accuracy: 0.9459 - val_loss: 0.4243 - val_accuracy: 0.9475\n",
      "Epoch 39/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.4264 - accuracy: 0.9459 - val_loss: 0.4137 - val_accuracy: 0.9475\n",
      "Epoch 40/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.4096 - accuracy: 0.9459 - val_loss: 0.3897 - val_accuracy: 0.9475\n",
      "Epoch 41/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.3930 - accuracy: 0.9459 - val_loss: 0.3773 - val_accuracy: 0.9475\n",
      "Epoch 42/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.3792 - accuracy: 0.9459 - val_loss: 0.3608 - val_accuracy: 0.9475\n",
      "Epoch 43/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.3655 - accuracy: 0.9459 - val_loss: 0.3598 - val_accuracy: 0.9475\n",
      "Epoch 44/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.3528 - accuracy: 0.9459 - val_loss: 0.3383 - val_accuracy: 0.9475\n",
      "Epoch 45/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.3416 - accuracy: 0.9459 - val_loss: 0.3272 - val_accuracy: 0.9475\n",
      "Epoch 46/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.3301 - accuracy: 0.9459 - val_loss: 0.3189 - val_accuracy: 0.9475\n",
      "Epoch 47/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.3217 - accuracy: 0.9459 - val_loss: 0.3072 - val_accuracy: 0.9475\n",
      "Epoch 48/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.3118 - accuracy: 0.9459 - val_loss: 0.2994 - val_accuracy: 0.9475\n",
      "Epoch 49/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.3044 - accuracy: 0.9459 - val_loss: 0.2940 - val_accuracy: 0.9475\n",
      "Epoch 50/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2969 - accuracy: 0.9459 - val_loss: 0.2831 - val_accuracy: 0.9475\n",
      "Epoch 51/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2912 - accuracy: 0.9459 - val_loss: 0.2777 - val_accuracy: 0.9475\n",
      "Epoch 52/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2838 - accuracy: 0.9459 - val_loss: 0.2709 - val_accuracy: 0.9475\n",
      "Epoch 53/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2780 - accuracy: 0.9459 - val_loss: 0.2657 - val_accuracy: 0.9475\n",
      "Epoch 54/1000\n",
      "67/67 [==============================] - 1s 22ms/step - loss: 0.2758 - accuracy: 0.9459 - val_loss: 0.2646 - val_accuracy: 0.9475\n",
      "Epoch 55/1000\n",
      "67/67 [==============================] - 1s 22ms/step - loss: 0.2689 - accuracy: 0.9459 - val_loss: 0.2598 - val_accuracy: 0.9475\n",
      "Epoch 56/1000\n",
      "67/67 [==============================] - 2s 22ms/step - loss: 0.2664 - accuracy: 0.9459 - val_loss: 0.2527 - val_accuracy: 0.9475\n",
      "Epoch 57/1000\n",
      "67/67 [==============================] - 1s 22ms/step - loss: 0.2609 - accuracy: 0.9459 - val_loss: 0.2510 - val_accuracy: 0.9475\n",
      "Epoch 58/1000\n",
      "67/67 [==============================] - 2s 22ms/step - loss: 0.2567 - accuracy: 0.9459 - val_loss: 0.2446 - val_accuracy: 0.9475\n",
      "Epoch 59/1000\n",
      "67/67 [==============================] - 1s 22ms/step - loss: 0.2515 - accuracy: 0.9459 - val_loss: 0.2433 - val_accuracy: 0.9475\n",
      "Epoch 60/1000\n",
      "67/67 [==============================] - 1s 22ms/step - loss: 0.2478 - accuracy: 0.9459 - val_loss: 0.2389 - val_accuracy: 0.9475\n",
      "Epoch 61/1000\n",
      "67/67 [==============================] - 1s 22ms/step - loss: 0.2469 - accuracy: 0.9459 - val_loss: 0.2394 - val_accuracy: 0.9475\n",
      "Epoch 62/1000\n",
      "67/67 [==============================] - 1s 22ms/step - loss: 0.2442 - accuracy: 0.9459 - val_loss: 0.2327 - val_accuracy: 0.9475\n",
      "Epoch 63/1000\n",
      "67/67 [==============================] - 1s 22ms/step - loss: 0.2424 - accuracy: 0.9459 - val_loss: 0.2311 - val_accuracy: 0.9475\n",
      "Epoch 64/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2395 - accuracy: 0.9459 - val_loss: 0.2287 - val_accuracy: 0.9475\n",
      "Epoch 65/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2368 - accuracy: 0.9459 - val_loss: 0.2271 - val_accuracy: 0.9475\n",
      "Epoch 66/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2343 - accuracy: 0.9459 - val_loss: 0.2284 - val_accuracy: 0.9475\n",
      "Epoch 67/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2327 - accuracy: 0.9459 - val_loss: 0.2231 - val_accuracy: 0.9475\n",
      "Epoch 68/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2301 - accuracy: 0.9459 - val_loss: 0.2217 - val_accuracy: 0.9475\n",
      "Epoch 69/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2294 - accuracy: 0.9459 - val_loss: 0.2209 - val_accuracy: 0.9475\n",
      "Epoch 70/1000\n",
      "67/67 [==============================] - 1s 22ms/step - loss: 0.2269 - accuracy: 0.9459 - val_loss: 0.2378 - val_accuracy: 0.9475\n",
      "Epoch 71/1000\n",
      "67/67 [==============================] - 1s 22ms/step - loss: 0.2285 - accuracy: 0.9459 - val_loss: 0.2316 - val_accuracy: 0.9475\n",
      "Epoch 72/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2281 - accuracy: 0.9459 - val_loss: 0.2175 - val_accuracy: 0.9475\n",
      "Epoch 73/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2237 - accuracy: 0.9459 - val_loss: 0.2162 - val_accuracy: 0.9475\n",
      "Epoch 74/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2231 - accuracy: 0.9459 - val_loss: 0.2146 - val_accuracy: 0.9475\n",
      "Epoch 75/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2216 - accuracy: 0.9459 - val_loss: 0.2142 - val_accuracy: 0.9475\n",
      "Epoch 76/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2213 - accuracy: 0.9459 - val_loss: 0.2219 - val_accuracy: 0.9475\n",
      "Epoch 77/1000\n",
      "67/67 [==============================] - 1s 22ms/step - loss: 0.2243 - accuracy: 0.9459 - val_loss: 0.2119 - val_accuracy: 0.9475\n",
      "Epoch 78/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2198 - accuracy: 0.9459 - val_loss: 0.2110 - val_accuracy: 0.9475\n",
      "Epoch 79/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2205 - accuracy: 0.9459 - val_loss: 0.2139 - val_accuracy: 0.9475\n",
      "Epoch 80/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2189 - accuracy: 0.9459 - val_loss: 0.2106 - val_accuracy: 0.9475\n",
      "Epoch 81/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2177 - accuracy: 0.9459 - val_loss: 0.2091 - val_accuracy: 0.9475\n",
      "Epoch 82/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2167 - accuracy: 0.9459 - val_loss: 0.2117 - val_accuracy: 0.9475\n",
      "Epoch 83/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2168 - accuracy: 0.9459 - val_loss: 0.2145 - val_accuracy: 0.9475\n",
      "Epoch 84/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2147 - accuracy: 0.9459 - val_loss: 0.2066 - val_accuracy: 0.9475\n",
      "Epoch 85/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2152 - accuracy: 0.9459 - val_loss: 0.2071 - val_accuracy: 0.9475\n",
      "Epoch 86/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2159 - accuracy: 0.9459 - val_loss: 0.2085 - val_accuracy: 0.9475\n",
      "Epoch 87/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2133 - accuracy: 0.9459 - val_loss: 0.2056 - val_accuracy: 0.9475\n",
      "Epoch 88/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2135 - accuracy: 0.9459 - val_loss: 0.2054 - val_accuracy: 0.9475\n",
      "Epoch 89/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2150 - accuracy: 0.9459 - val_loss: 0.2060 - val_accuracy: 0.9475\n",
      "Epoch 90/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2134 - accuracy: 0.9459 - val_loss: 0.2170 - val_accuracy: 0.9475\n",
      "Epoch 91/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2148 - accuracy: 0.9459 - val_loss: 0.2046 - val_accuracy: 0.9475\n",
      "Epoch 92/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2128 - accuracy: 0.9459 - val_loss: 0.2038 - val_accuracy: 0.9475\n",
      "Epoch 93/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2113 - accuracy: 0.9459 - val_loss: 0.2035 - val_accuracy: 0.9475\n",
      "Epoch 94/1000\n",
      "67/67 [==============================] - 1s 22ms/step - loss: 0.2122 - accuracy: 0.9459 - val_loss: 0.2066 - val_accuracy: 0.9475\n",
      "Epoch 95/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2109 - accuracy: 0.9459 - val_loss: 0.2068 - val_accuracy: 0.9475\n",
      "Epoch 96/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2129 - accuracy: 0.9459 - val_loss: 0.2029 - val_accuracy: 0.9475\n",
      "Epoch 97/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2108 - accuracy: 0.9459 - val_loss: 0.2033 - val_accuracy: 0.9475\n",
      "Epoch 98/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2117 - accuracy: 0.9459 - val_loss: 0.2034 - val_accuracy: 0.9475\n",
      "Epoch 99/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2106 - accuracy: 0.9459 - val_loss: 0.2028 - val_accuracy: 0.9475\n",
      "Epoch 100/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2096 - accuracy: 0.9459 - val_loss: 0.2023 - val_accuracy: 0.9475\n",
      "Epoch 101/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2121 - accuracy: 0.9459 - val_loss: 0.2031 - val_accuracy: 0.9475\n",
      "Epoch 102/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2122 - accuracy: 0.9459 - val_loss: 0.2053 - val_accuracy: 0.9475\n",
      "Epoch 103/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2105 - accuracy: 0.9459 - val_loss: 0.2030 - val_accuracy: 0.9475\n",
      "Epoch 104/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2115 - accuracy: 0.9459 - val_loss: 0.2057 - val_accuracy: 0.9475\n",
      "Epoch 105/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2100 - accuracy: 0.9459 - val_loss: 0.2040 - val_accuracy: 0.9475\n",
      "Epoch 106/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2099 - accuracy: 0.9459 - val_loss: 0.2032 - val_accuracy: 0.9475\n",
      "Epoch 107/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2107 - accuracy: 0.9459 - val_loss: 0.2025 - val_accuracy: 0.9475\n",
      "Epoch 108/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2092 - accuracy: 0.9459 - val_loss: 0.2027 - val_accuracy: 0.9475\n",
      "Epoch 109/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2097 - accuracy: 0.9459 - val_loss: 0.2023 - val_accuracy: 0.9475\n",
      "Epoch 110/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2111 - accuracy: 0.9459 - val_loss: 0.2026 - val_accuracy: 0.9475\n",
      "Epoch 111/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2084 - accuracy: 0.9459 - val_loss: 0.2012 - val_accuracy: 0.9475\n",
      "Epoch 112/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2083 - accuracy: 0.9459 - val_loss: 0.2016 - val_accuracy: 0.9475\n",
      "Epoch 113/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2086 - accuracy: 0.9459 - val_loss: 0.2024 - val_accuracy: 0.9475\n",
      "Epoch 114/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2084 - accuracy: 0.9459 - val_loss: 0.2032 - val_accuracy: 0.9475\n",
      "Epoch 115/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2088 - accuracy: 0.9459 - val_loss: 0.2073 - val_accuracy: 0.9475\n",
      "Epoch 116/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2083 - accuracy: 0.9459 - val_loss: 0.2036 - val_accuracy: 0.9475\n",
      "Epoch 117/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2084 - accuracy: 0.9459 - val_loss: 0.2020 - val_accuracy: 0.9475\n",
      "Epoch 118/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2077 - accuracy: 0.9459 - val_loss: 0.2011 - val_accuracy: 0.9475\n",
      "Epoch 119/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2085 - accuracy: 0.9459 - val_loss: 0.2052 - val_accuracy: 0.9475\n",
      "Epoch 120/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2090 - accuracy: 0.9459 - val_loss: 0.2048 - val_accuracy: 0.9475\n",
      "Epoch 121/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2098 - accuracy: 0.9459 - val_loss: 0.2012 - val_accuracy: 0.9475\n",
      "Epoch 122/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2070 - accuracy: 0.9459 - val_loss: 0.2012 - val_accuracy: 0.9475\n",
      "Epoch 123/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2078 - accuracy: 0.9459 - val_loss: 0.2028 - val_accuracy: 0.9475\n",
      "Epoch 124/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2076 - accuracy: 0.9459 - val_loss: 0.2016 - val_accuracy: 0.9475\n",
      "Epoch 125/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2079 - accuracy: 0.9459 - val_loss: 0.2022 - val_accuracy: 0.9475\n",
      "Epoch 126/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2096 - accuracy: 0.9459 - val_loss: 0.2010 - val_accuracy: 0.9475\n",
      "Epoch 127/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2081 - accuracy: 0.9459 - val_loss: 0.2022 - val_accuracy: 0.9475\n",
      "Epoch 128/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2081 - accuracy: 0.9459 - val_loss: 0.2010 - val_accuracy: 0.9475\n",
      "Epoch 129/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2074 - accuracy: 0.9459 - val_loss: 0.2027 - val_accuracy: 0.9475\n",
      "Epoch 130/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2087 - accuracy: 0.9459 - val_loss: 0.2033 - val_accuracy: 0.9475\n",
      "Epoch 131/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2093 - accuracy: 0.9459 - val_loss: 0.2014 - val_accuracy: 0.9475\n",
      "Epoch 132/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2088 - accuracy: 0.9459 - val_loss: 0.2005 - val_accuracy: 0.9475\n",
      "Epoch 133/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2074 - accuracy: 0.9459 - val_loss: 0.2010 - val_accuracy: 0.9475\n",
      "Epoch 134/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2075 - accuracy: 0.9459 - val_loss: 0.2009 - val_accuracy: 0.9475\n",
      "Epoch 135/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2082 - accuracy: 0.9459 - val_loss: 0.2008 - val_accuracy: 0.9475\n",
      "Epoch 136/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2081 - accuracy: 0.9459 - val_loss: 0.2006 - val_accuracy: 0.9475\n",
      "Epoch 137/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2084 - accuracy: 0.9459 - val_loss: 0.2007 - val_accuracy: 0.9475\n",
      "Epoch 138/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2071 - accuracy: 0.9459 - val_loss: 0.2004 - val_accuracy: 0.9475\n",
      "Epoch 139/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2072 - accuracy: 0.9459 - val_loss: 0.2007 - val_accuracy: 0.9475\n",
      "Epoch 140/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2079 - accuracy: 0.9459 - val_loss: 0.2210 - val_accuracy: 0.9475\n",
      "Epoch 141/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2104 - accuracy: 0.9459 - val_loss: 0.2010 - val_accuracy: 0.9475\n",
      "Epoch 142/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2072 - accuracy: 0.9459 - val_loss: 0.2004 - val_accuracy: 0.9475\n",
      "Epoch 143/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2070 - accuracy: 0.9459 - val_loss: 0.2021 - val_accuracy: 0.9475\n",
      "Epoch 144/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2097 - accuracy: 0.9459 - val_loss: 0.2027 - val_accuracy: 0.9475\n",
      "Epoch 145/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2095 - accuracy: 0.9459 - val_loss: 0.2013 - val_accuracy: 0.9475\n",
      "Epoch 146/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2078 - accuracy: 0.9459 - val_loss: 0.2021 - val_accuracy: 0.9475\n",
      "Epoch 147/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2089 - accuracy: 0.9459 - val_loss: 0.2070 - val_accuracy: 0.9475\n",
      "Epoch 148/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2093 - accuracy: 0.9459 - val_loss: 0.2006 - val_accuracy: 0.9475\n",
      "Epoch 149/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2082 - accuracy: 0.9459 - val_loss: 0.2011 - val_accuracy: 0.9475\n",
      "Epoch 150/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2073 - accuracy: 0.9459 - val_loss: 0.1998 - val_accuracy: 0.9475\n",
      "Epoch 151/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2075 - accuracy: 0.9459 - val_loss: 0.2019 - val_accuracy: 0.9475\n",
      "Epoch 152/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2062 - accuracy: 0.9459 - val_loss: 0.2006 - val_accuracy: 0.9475\n",
      "Epoch 153/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2063 - accuracy: 0.9459 - val_loss: 0.1998 - val_accuracy: 0.9475\n",
      "Epoch 154/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2094 - accuracy: 0.9459 - val_loss: 0.2001 - val_accuracy: 0.9475\n",
      "Epoch 155/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2067 - accuracy: 0.9459 - val_loss: 0.2012 - val_accuracy: 0.9475\n",
      "Epoch 156/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2073 - accuracy: 0.9459 - val_loss: 0.2035 - val_accuracy: 0.9475\n",
      "Epoch 157/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2068 - accuracy: 0.9459 - val_loss: 0.1997 - val_accuracy: 0.9475\n",
      "Epoch 158/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2069 - accuracy: 0.9459 - val_loss: 0.2015 - val_accuracy: 0.9475\n",
      "Epoch 159/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2069 - accuracy: 0.9459 - val_loss: 0.1998 - val_accuracy: 0.9475\n",
      "Epoch 160/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2065 - accuracy: 0.9459 - val_loss: 0.2001 - val_accuracy: 0.9475\n",
      "Epoch 161/1000\n",
      "67/67 [==============================] - 2s 24ms/step - loss: 0.2060 - accuracy: 0.9459 - val_loss: 0.2002 - val_accuracy: 0.9475\n",
      "Epoch 162/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2073 - accuracy: 0.9459 - val_loss: 0.1999 - val_accuracy: 0.9475\n",
      "Epoch 163/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2066 - accuracy: 0.9459 - val_loss: 0.2019 - val_accuracy: 0.9475\n",
      "Epoch 164/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2067 - accuracy: 0.9459 - val_loss: 0.2006 - val_accuracy: 0.9475\n",
      "Epoch 165/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2065 - accuracy: 0.9459 - val_loss: 0.1997 - val_accuracy: 0.9475\n",
      "Epoch 166/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2058 - accuracy: 0.9459 - val_loss: 0.1997 - val_accuracy: 0.9475\n",
      "Epoch 167/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2066 - accuracy: 0.9459 - val_loss: 0.2027 - val_accuracy: 0.9475\n",
      "Epoch 168/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2070 - accuracy: 0.9459 - val_loss: 0.2072 - val_accuracy: 0.9475\n",
      "Epoch 169/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2064 - accuracy: 0.9459 - val_loss: 0.1993 - val_accuracy: 0.9475\n",
      "Epoch 170/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2054 - accuracy: 0.9459 - val_loss: 0.1990 - val_accuracy: 0.9475\n",
      "Epoch 171/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2066 - accuracy: 0.9459 - val_loss: 0.1997 - val_accuracy: 0.9475\n",
      "Epoch 172/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2057 - accuracy: 0.9459 - val_loss: 0.2024 - val_accuracy: 0.9475\n",
      "Epoch 173/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2079 - accuracy: 0.9459 - val_loss: 0.2015 - val_accuracy: 0.9475\n",
      "Epoch 174/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2066 - accuracy: 0.9459 - val_loss: 0.1993 - val_accuracy: 0.9475\n",
      "Epoch 175/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2082 - accuracy: 0.9459 - val_loss: 0.2010 - val_accuracy: 0.9475\n",
      "Epoch 176/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2074 - accuracy: 0.9459 - val_loss: 0.2021 - val_accuracy: 0.9475\n",
      "Epoch 177/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2076 - accuracy: 0.9459 - val_loss: 0.1993 - val_accuracy: 0.9475\n",
      "Epoch 178/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2058 - accuracy: 0.9459 - val_loss: 0.2017 - val_accuracy: 0.9475\n",
      "Epoch 179/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2067 - accuracy: 0.9459 - val_loss: 0.2003 - val_accuracy: 0.9475\n",
      "Epoch 180/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2071 - accuracy: 0.9459 - val_loss: 0.2004 - val_accuracy: 0.9475\n",
      "Epoch 181/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2058 - accuracy: 0.9459 - val_loss: 0.2003 - val_accuracy: 0.9475\n",
      "Epoch 182/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2076 - accuracy: 0.9459 - val_loss: 0.2004 - val_accuracy: 0.9475\n",
      "Epoch 183/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2045 - accuracy: 0.9459 - val_loss: 0.1996 - val_accuracy: 0.9475\n",
      "Epoch 184/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2055 - accuracy: 0.9459 - val_loss: 0.2002 - val_accuracy: 0.9475\n",
      "Epoch 185/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2078 - accuracy: 0.9459 - val_loss: 0.2003 - val_accuracy: 0.9475\n",
      "Epoch 186/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2072 - accuracy: 0.9459 - val_loss: 0.2027 - val_accuracy: 0.9475\n",
      "Epoch 187/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2072 - accuracy: 0.9459 - val_loss: 0.2033 - val_accuracy: 0.9475\n",
      "Epoch 188/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2062 - accuracy: 0.9459 - val_loss: 0.2035 - val_accuracy: 0.9475\n",
      "Epoch 189/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2064 - accuracy: 0.9459 - val_loss: 0.1994 - val_accuracy: 0.9475\n",
      "Epoch 190/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2064 - accuracy: 0.9459 - val_loss: 0.2058 - val_accuracy: 0.9475\n",
      "Epoch 191/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2071 - accuracy: 0.9459 - val_loss: 0.2009 - val_accuracy: 0.9475\n",
      "Epoch 192/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2084 - accuracy: 0.9459 - val_loss: 0.2021 - val_accuracy: 0.9475\n",
      "Epoch 193/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2063 - accuracy: 0.9459 - val_loss: 0.2026 - val_accuracy: 0.9475\n",
      "Epoch 194/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2066 - accuracy: 0.9459 - val_loss: 0.1992 - val_accuracy: 0.9475\n",
      "Epoch 195/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2050 - accuracy: 0.9459 - val_loss: 0.2002 - val_accuracy: 0.9475\n",
      "Epoch 196/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2058 - accuracy: 0.9459 - val_loss: 0.2143 - val_accuracy: 0.9475\n",
      "Epoch 197/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2080 - accuracy: 0.9459 - val_loss: 0.2010 - val_accuracy: 0.9475\n",
      "Epoch 198/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2069 - accuracy: 0.9459 - val_loss: 0.1993 - val_accuracy: 0.9475\n",
      "Epoch 199/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2047 - accuracy: 0.9459 - val_loss: 0.2026 - val_accuracy: 0.9475\n",
      "Epoch 200/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2056 - accuracy: 0.9459 - val_loss: 0.1990 - val_accuracy: 0.9475\n",
      "Epoch 201/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2064 - accuracy: 0.9459 - val_loss: 0.1996 - val_accuracy: 0.9475\n",
      "Epoch 202/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2065 - accuracy: 0.9459 - val_loss: 0.1995 - val_accuracy: 0.9475\n",
      "Epoch 203/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2078 - accuracy: 0.9459 - val_loss: 0.2043 - val_accuracy: 0.9475\n",
      "Epoch 204/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2074 - accuracy: 0.9459 - val_loss: 0.1990 - val_accuracy: 0.9475\n",
      "Epoch 205/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2057 - accuracy: 0.9459 - val_loss: 0.2092 - val_accuracy: 0.9475\n",
      "Epoch 206/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2079 - accuracy: 0.9459 - val_loss: 0.1990 - val_accuracy: 0.9475\n",
      "Epoch 207/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2051 - accuracy: 0.9459 - val_loss: 0.2012 - val_accuracy: 0.9475\n",
      "Epoch 208/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2069 - accuracy: 0.9459 - val_loss: 0.2054 - val_accuracy: 0.9475\n",
      "Epoch 209/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2053 - accuracy: 0.9459 - val_loss: 0.1986 - val_accuracy: 0.9475\n",
      "Epoch 210/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2043 - accuracy: 0.9459 - val_loss: 0.2021 - val_accuracy: 0.9475\n",
      "Epoch 211/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2068 - accuracy: 0.9459 - val_loss: 0.1992 - val_accuracy: 0.9475\n",
      "Epoch 212/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2062 - accuracy: 0.9459 - val_loss: 0.1996 - val_accuracy: 0.9475\n",
      "Epoch 213/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2054 - accuracy: 0.9459 - val_loss: 0.1982 - val_accuracy: 0.9475\n",
      "Epoch 214/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2052 - accuracy: 0.9459 - val_loss: 0.1987 - val_accuracy: 0.9475\n",
      "Epoch 215/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2058 - accuracy: 0.9459 - val_loss: 0.1987 - val_accuracy: 0.9475\n",
      "Epoch 216/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2066 - accuracy: 0.9459 - val_loss: 0.2000 - val_accuracy: 0.9475\n",
      "Epoch 217/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2067 - accuracy: 0.9459 - val_loss: 0.2012 - val_accuracy: 0.9475\n",
      "Epoch 218/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2059 - accuracy: 0.9459 - val_loss: 0.1985 - val_accuracy: 0.9475\n",
      "Epoch 219/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2044 - accuracy: 0.9459 - val_loss: 0.1984 - val_accuracy: 0.9475\n",
      "Epoch 220/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2038 - accuracy: 0.9459 - val_loss: 0.2001 - val_accuracy: 0.9475\n",
      "Epoch 221/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2056 - accuracy: 0.9459 - val_loss: 0.2014 - val_accuracy: 0.9475\n",
      "Epoch 222/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2090 - accuracy: 0.9459 - val_loss: 0.2024 - val_accuracy: 0.9475\n",
      "Epoch 223/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2063 - accuracy: 0.9459 - val_loss: 0.1987 - val_accuracy: 0.9475\n",
      "Epoch 224/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2056 - accuracy: 0.9459 - val_loss: 0.1996 - val_accuracy: 0.9475\n",
      "Epoch 225/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2057 - accuracy: 0.9459 - val_loss: 0.1999 - val_accuracy: 0.9475\n",
      "Epoch 226/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2059 - accuracy: 0.9459 - val_loss: 0.1985 - val_accuracy: 0.9475\n",
      "Epoch 227/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2051 - accuracy: 0.9459 - val_loss: 0.2087 - val_accuracy: 0.9475\n",
      "Epoch 228/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2069 - accuracy: 0.9459 - val_loss: 0.1984 - val_accuracy: 0.9475\n",
      "Epoch 229/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2052 - accuracy: 0.9459 - val_loss: 0.1995 - val_accuracy: 0.9475\n",
      "Epoch 230/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2055 - accuracy: 0.9459 - val_loss: 0.1991 - val_accuracy: 0.9475\n",
      "Epoch 231/1000\n",
      "67/67 [==============================] - 2s 24ms/step - loss: 0.2073 - accuracy: 0.9459 - val_loss: 0.2007 - val_accuracy: 0.9475\n",
      "Epoch 232/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2052 - accuracy: 0.9459 - val_loss: 0.1983 - val_accuracy: 0.9475\n",
      "Epoch 233/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2039 - accuracy: 0.9459 - val_loss: 0.1981 - val_accuracy: 0.9475\n",
      "Epoch 234/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2044 - accuracy: 0.9459 - val_loss: 0.2033 - val_accuracy: 0.9475\n",
      "Epoch 235/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2038 - accuracy: 0.9459 - val_loss: 0.2032 - val_accuracy: 0.9475\n",
      "Epoch 236/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2053 - accuracy: 0.9459 - val_loss: 0.2018 - val_accuracy: 0.9475\n",
      "Epoch 237/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2069 - accuracy: 0.9459 - val_loss: 0.2047 - val_accuracy: 0.9475\n",
      "Epoch 238/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2050 - accuracy: 0.9459 - val_loss: 0.2005 - val_accuracy: 0.9475\n",
      "Epoch 239/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2053 - accuracy: 0.9459 - val_loss: 0.2021 - val_accuracy: 0.9475\n",
      "Epoch 240/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2054 - accuracy: 0.9459 - val_loss: 0.1984 - val_accuracy: 0.9475\n",
      "Epoch 241/1000\n",
      "67/67 [==============================] - 2s 24ms/step - loss: 0.2063 - accuracy: 0.9459 - val_loss: 0.1985 - val_accuracy: 0.9475\n",
      "Epoch 242/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2048 - accuracy: 0.9459 - val_loss: 0.1993 - val_accuracy: 0.9475\n",
      "Epoch 243/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2045 - accuracy: 0.9459 - val_loss: 0.1979 - val_accuracy: 0.9475\n",
      "Epoch 244/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2038 - accuracy: 0.9459 - val_loss: 0.1979 - val_accuracy: 0.9475\n",
      "Epoch 245/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2043 - accuracy: 0.9459 - val_loss: 0.1983 - val_accuracy: 0.9475\n",
      "Epoch 246/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2031 - accuracy: 0.9459 - val_loss: 0.1980 - val_accuracy: 0.9475\n",
      "Epoch 247/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2037 - accuracy: 0.9459 - val_loss: 0.2020 - val_accuracy: 0.9475\n",
      "Epoch 248/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2054 - accuracy: 0.9459 - val_loss: 0.1976 - val_accuracy: 0.9475\n",
      "Epoch 249/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2060 - accuracy: 0.9459 - val_loss: 0.1997 - val_accuracy: 0.9475\n",
      "Epoch 250/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2044 - accuracy: 0.9459 - val_loss: 0.1979 - val_accuracy: 0.9475\n",
      "Epoch 251/1000\n",
      "67/67 [==============================] - 2s 24ms/step - loss: 0.2042 - accuracy: 0.9459 - val_loss: 0.2019 - val_accuracy: 0.9475\n",
      "Epoch 252/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2068 - accuracy: 0.9459 - val_loss: 0.2096 - val_accuracy: 0.9475\n",
      "Epoch 253/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2055 - accuracy: 0.9459 - val_loss: 0.2081 - val_accuracy: 0.9475\n",
      "Epoch 254/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2067 - accuracy: 0.9459 - val_loss: 0.1996 - val_accuracy: 0.9475\n",
      "Epoch 255/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2046 - accuracy: 0.9459 - val_loss: 0.1983 - val_accuracy: 0.9475\n",
      "Epoch 256/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2040 - accuracy: 0.9459 - val_loss: 0.1978 - val_accuracy: 0.9475\n",
      "Epoch 257/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2043 - accuracy: 0.9459 - val_loss: 0.1981 - val_accuracy: 0.9475\n",
      "Epoch 258/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2044 - accuracy: 0.9459 - val_loss: 0.1983 - val_accuracy: 0.9475\n",
      "Epoch 259/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2033 - accuracy: 0.9459 - val_loss: 0.2050 - val_accuracy: 0.9475\n",
      "Epoch 260/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2051 - accuracy: 0.9459 - val_loss: 0.1997 - val_accuracy: 0.9475\n",
      "Epoch 261/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2045 - accuracy: 0.9459 - val_loss: 0.1982 - val_accuracy: 0.9475\n",
      "Epoch 262/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2034 - accuracy: 0.9459 - val_loss: 0.1983 - val_accuracy: 0.9475\n",
      "Epoch 263/1000\n",
      "67/67 [==============================] - 2s 24ms/step - loss: 0.2051 - accuracy: 0.9459 - val_loss: 0.1982 - val_accuracy: 0.9475\n",
      "Epoch 264/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2040 - accuracy: 0.9459 - val_loss: 0.1982 - val_accuracy: 0.9475\n",
      "Epoch 265/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2051 - accuracy: 0.9459 - val_loss: 0.1987 - val_accuracy: 0.9475\n",
      "Epoch 266/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2044 - accuracy: 0.9459 - val_loss: 0.1989 - val_accuracy: 0.9475\n",
      "Epoch 267/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2038 - accuracy: 0.9459 - val_loss: 0.1979 - val_accuracy: 0.9475\n",
      "Epoch 268/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2053 - accuracy: 0.9459 - val_loss: 0.1978 - val_accuracy: 0.9475\n",
      "Epoch 269/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2057 - accuracy: 0.9459 - val_loss: 0.1993 - val_accuracy: 0.9475\n",
      "Epoch 270/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2029 - accuracy: 0.9459 - val_loss: 0.1995 - val_accuracy: 0.9475\n",
      "Epoch 271/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2068 - accuracy: 0.9459 - val_loss: 0.1980 - val_accuracy: 0.9475\n",
      "Epoch 272/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2069 - accuracy: 0.9459 - val_loss: 0.1989 - val_accuracy: 0.9475\n",
      "Epoch 273/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2056 - accuracy: 0.9459 - val_loss: 0.1984 - val_accuracy: 0.9475\n",
      "Epoch 274/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2032 - accuracy: 0.9459 - val_loss: 0.1979 - val_accuracy: 0.9475\n",
      "Epoch 275/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2043 - accuracy: 0.9459 - val_loss: 0.1975 - val_accuracy: 0.9475\n",
      "Epoch 276/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2037 - accuracy: 0.9459 - val_loss: 0.1987 - val_accuracy: 0.9475\n",
      "Epoch 277/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2055 - accuracy: 0.9459 - val_loss: 0.1976 - val_accuracy: 0.9475\n",
      "Epoch 278/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2038 - accuracy: 0.9459 - val_loss: 0.1978 - val_accuracy: 0.9475\n",
      "Epoch 279/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2034 - accuracy: 0.9459 - val_loss: 0.1972 - val_accuracy: 0.9475\n",
      "Epoch 280/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2045 - accuracy: 0.9459 - val_loss: 0.2022 - val_accuracy: 0.9475\n",
      "Epoch 281/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2049 - accuracy: 0.9459 - val_loss: 0.2004 - val_accuracy: 0.9475\n",
      "Epoch 282/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2059 - accuracy: 0.9459 - val_loss: 0.1973 - val_accuracy: 0.9475\n",
      "Epoch 283/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2039 - accuracy: 0.9459 - val_loss: 0.1972 - val_accuracy: 0.9475\n",
      "Epoch 284/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2037 - accuracy: 0.9459 - val_loss: 0.1971 - val_accuracy: 0.9475\n",
      "Epoch 285/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2032 - accuracy: 0.9459 - val_loss: 0.2002 - val_accuracy: 0.9475\n",
      "Epoch 286/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2032 - accuracy: 0.9459 - val_loss: 0.1995 - val_accuracy: 0.9475\n",
      "Epoch 287/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2068 - accuracy: 0.9459 - val_loss: 0.1991 - val_accuracy: 0.9475\n",
      "Epoch 288/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2042 - accuracy: 0.9459 - val_loss: 0.1976 - val_accuracy: 0.9475\n",
      "Epoch 289/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2044 - accuracy: 0.9459 - val_loss: 0.2032 - val_accuracy: 0.9475\n",
      "Epoch 290/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2045 - accuracy: 0.9459 - val_loss: 0.2030 - val_accuracy: 0.9475\n",
      "Epoch 291/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2036 - accuracy: 0.9459 - val_loss: 0.1987 - val_accuracy: 0.9475\n",
      "Epoch 292/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2036 - accuracy: 0.9459 - val_loss: 0.1970 - val_accuracy: 0.9475\n",
      "Epoch 293/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2044 - accuracy: 0.9459 - val_loss: 0.1975 - val_accuracy: 0.9475\n",
      "Epoch 294/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2043 - accuracy: 0.9459 - val_loss: 0.2004 - val_accuracy: 0.9475\n",
      "Epoch 295/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2057 - accuracy: 0.9459 - val_loss: 0.1977 - val_accuracy: 0.9475\n",
      "Epoch 296/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2031 - accuracy: 0.9459 - val_loss: 0.1975 - val_accuracy: 0.9475\n",
      "Epoch 297/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2027 - accuracy: 0.9459 - val_loss: 0.1998 - val_accuracy: 0.9475\n",
      "Epoch 298/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2036 - accuracy: 0.9459 - val_loss: 0.1970 - val_accuracy: 0.9475\n",
      "Epoch 299/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2028 - accuracy: 0.9459 - val_loss: 0.1981 - val_accuracy: 0.9475\n",
      "Epoch 300/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2040 - accuracy: 0.9459 - val_loss: 0.1988 - val_accuracy: 0.9475\n",
      "Epoch 301/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2045 - accuracy: 0.9459 - val_loss: 0.1975 - val_accuracy: 0.9475\n",
      "Epoch 302/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2050 - accuracy: 0.9459 - val_loss: 0.1977 - val_accuracy: 0.9475\n",
      "Epoch 303/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2047 - accuracy: 0.9459 - val_loss: 0.1993 - val_accuracy: 0.9475\n",
      "Epoch 304/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2042 - accuracy: 0.9459 - val_loss: 0.1994 - val_accuracy: 0.9475\n",
      "Epoch 305/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2065 - accuracy: 0.9459 - val_loss: 0.2004 - val_accuracy: 0.9475\n",
      "Epoch 306/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2043 - accuracy: 0.9459 - val_loss: 0.1988 - val_accuracy: 0.9475\n",
      "Epoch 307/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2032 - accuracy: 0.9459 - val_loss: 0.1981 - val_accuracy: 0.9475\n",
      "Epoch 308/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2042 - accuracy: 0.9459 - val_loss: 0.1971 - val_accuracy: 0.9475\n",
      "Epoch 309/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2050 - accuracy: 0.9459 - val_loss: 0.1975 - val_accuracy: 0.9475\n",
      "Epoch 310/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2058 - accuracy: 0.9459 - val_loss: 0.1985 - val_accuracy: 0.9475\n",
      "Epoch 311/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2063 - accuracy: 0.9459 - val_loss: 0.2014 - val_accuracy: 0.9475\n",
      "Epoch 312/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2038 - accuracy: 0.9459 - val_loss: 0.1975 - val_accuracy: 0.9475\n",
      "Epoch 313/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2034 - accuracy: 0.9459 - val_loss: 0.1997 - val_accuracy: 0.9475\n",
      "Epoch 314/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2061 - accuracy: 0.9459 - val_loss: 0.1989 - val_accuracy: 0.9475\n",
      "Epoch 315/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2033 - accuracy: 0.9459 - val_loss: 0.1972 - val_accuracy: 0.9475\n",
      "Epoch 316/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2058 - accuracy: 0.9459 - val_loss: 0.1994 - val_accuracy: 0.9475\n",
      "Epoch 317/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2043 - accuracy: 0.9459 - val_loss: 0.2035 - val_accuracy: 0.9475\n",
      "Epoch 318/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2035 - accuracy: 0.9459 - val_loss: 0.1971 - val_accuracy: 0.9475\n",
      "Epoch 319/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2043 - accuracy: 0.9459 - val_loss: 0.1979 - val_accuracy: 0.9475\n",
      "Epoch 320/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2033 - accuracy: 0.9459 - val_loss: 0.1967 - val_accuracy: 0.9475\n",
      "Epoch 321/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2031 - accuracy: 0.9459 - val_loss: 0.1966 - val_accuracy: 0.9475\n",
      "Epoch 322/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2044 - accuracy: 0.9459 - val_loss: 0.1990 - val_accuracy: 0.9475\n",
      "Epoch 323/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2059 - accuracy: 0.9459 - val_loss: 0.1973 - val_accuracy: 0.9475\n",
      "Epoch 324/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2043 - accuracy: 0.9459 - val_loss: 0.2013 - val_accuracy: 0.9475\n",
      "Epoch 325/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2032 - accuracy: 0.9459 - val_loss: 0.1968 - val_accuracy: 0.9475\n",
      "Epoch 326/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2043 - accuracy: 0.9459 - val_loss: 0.1974 - val_accuracy: 0.9475\n",
      "Epoch 327/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2021 - accuracy: 0.9459 - val_loss: 0.1983 - val_accuracy: 0.9475\n",
      "Epoch 328/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2025 - accuracy: 0.9459 - val_loss: 0.1970 - val_accuracy: 0.9475\n",
      "Epoch 329/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2039 - accuracy: 0.9459 - val_loss: 0.1976 - val_accuracy: 0.9475\n",
      "Epoch 330/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2018 - accuracy: 0.9459 - val_loss: 0.2012 - val_accuracy: 0.9475\n",
      "Epoch 331/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2043 - accuracy: 0.9459 - val_loss: 0.1997 - val_accuracy: 0.9475\n",
      "Epoch 332/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2044 - accuracy: 0.9459 - val_loss: 0.1979 - val_accuracy: 0.9475\n",
      "Epoch 333/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2031 - accuracy: 0.9459 - val_loss: 0.2017 - val_accuracy: 0.9475\n",
      "Epoch 334/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2048 - accuracy: 0.9459 - val_loss: 0.1971 - val_accuracy: 0.9475\n",
      "Epoch 335/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2040 - accuracy: 0.9459 - val_loss: 0.1999 - val_accuracy: 0.9475\n",
      "Epoch 336/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2037 - accuracy: 0.9459 - val_loss: 0.1987 - val_accuracy: 0.9475\n",
      "Epoch 337/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2044 - accuracy: 0.9459 - val_loss: 0.1970 - val_accuracy: 0.9475\n",
      "Epoch 338/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2050 - accuracy: 0.9459 - val_loss: 0.1969 - val_accuracy: 0.9475\n",
      "Epoch 339/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2026 - accuracy: 0.9459 - val_loss: 0.1992 - val_accuracy: 0.9475\n",
      "Epoch 340/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2034 - accuracy: 0.9459 - val_loss: 0.1969 - val_accuracy: 0.9475\n",
      "Epoch 341/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2036 - accuracy: 0.9459 - val_loss: 0.1971 - val_accuracy: 0.9475\n",
      "Epoch 342/1000\n",
      "67/67 [==============================] - 1s 22ms/step - loss: 0.2036 - accuracy: 0.9459 - val_loss: 0.2000 - val_accuracy: 0.9475\n",
      "Epoch 343/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2036 - accuracy: 0.9459 - val_loss: 0.1974 - val_accuracy: 0.9475\n",
      "Epoch 344/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2034 - accuracy: 0.9459 - val_loss: 0.1965 - val_accuracy: 0.9475\n",
      "Epoch 345/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2051 - accuracy: 0.9459 - val_loss: 0.2003 - val_accuracy: 0.9475\n",
      "Epoch 346/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2050 - accuracy: 0.9459 - val_loss: 0.1962 - val_accuracy: 0.9475\n",
      "Epoch 347/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2040 - accuracy: 0.9459 - val_loss: 0.1967 - val_accuracy: 0.9475\n",
      "Epoch 348/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2024 - accuracy: 0.9459 - val_loss: 0.1975 - val_accuracy: 0.9475\n",
      "Epoch 349/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2041 - accuracy: 0.9459 - val_loss: 0.1985 - val_accuracy: 0.9475\n",
      "Epoch 350/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2035 - accuracy: 0.9459 - val_loss: 0.1972 - val_accuracy: 0.9475\n",
      "Epoch 351/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2041 - accuracy: 0.9459 - val_loss: 0.1975 - val_accuracy: 0.9475\n",
      "Epoch 352/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2034 - accuracy: 0.9459 - val_loss: 0.1975 - val_accuracy: 0.9475\n",
      "Epoch 353/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2040 - accuracy: 0.9459 - val_loss: 0.1985 - val_accuracy: 0.9475\n",
      "Epoch 354/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2025 - accuracy: 0.9459 - val_loss: 0.1972 - val_accuracy: 0.9475\n",
      "Epoch 355/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2025 - accuracy: 0.9459 - val_loss: 0.1983 - val_accuracy: 0.9475\n",
      "Epoch 356/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2042 - accuracy: 0.9459 - val_loss: 0.1993 - val_accuracy: 0.9475\n",
      "Epoch 357/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2041 - accuracy: 0.9459 - val_loss: 0.1981 - val_accuracy: 0.9475\n",
      "Epoch 358/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2046 - accuracy: 0.9459 - val_loss: 0.1971 - val_accuracy: 0.9475\n",
      "Epoch 359/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2043 - accuracy: 0.9459 - val_loss: 0.2029 - val_accuracy: 0.9475\n",
      "Epoch 360/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2034 - accuracy: 0.9459 - val_loss: 0.1974 - val_accuracy: 0.9475\n",
      "Epoch 361/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2029 - accuracy: 0.9459 - val_loss: 0.1973 - val_accuracy: 0.9475\n",
      "Epoch 362/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2038 - accuracy: 0.9459 - val_loss: 0.1964 - val_accuracy: 0.9475\n",
      "Epoch 363/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2046 - accuracy: 0.9459 - val_loss: 0.1966 - val_accuracy: 0.9475\n",
      "Epoch 364/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2023 - accuracy: 0.9459 - val_loss: 0.1968 - val_accuracy: 0.9475\n",
      "Epoch 365/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2035 - accuracy: 0.9459 - val_loss: 0.1969 - val_accuracy: 0.9475\n",
      "Epoch 366/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2023 - accuracy: 0.9459 - val_loss: 0.1968 - val_accuracy: 0.9475\n",
      "Epoch 367/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2025 - accuracy: 0.9459 - val_loss: 0.1979 - val_accuracy: 0.9475\n",
      "Epoch 368/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2043 - accuracy: 0.9459 - val_loss: 0.1974 - val_accuracy: 0.9475\n",
      "Epoch 369/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2035 - accuracy: 0.9459 - val_loss: 0.1972 - val_accuracy: 0.9475\n",
      "Epoch 370/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2029 - accuracy: 0.9459 - val_loss: 0.1972 - val_accuracy: 0.9475\n",
      "Epoch 371/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2025 - accuracy: 0.9459 - val_loss: 0.2003 - val_accuracy: 0.9475\n",
      "Epoch 372/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2030 - accuracy: 0.9459 - val_loss: 0.1972 - val_accuracy: 0.9475\n",
      "Epoch 373/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2036 - accuracy: 0.9459 - val_loss: 0.1985 - val_accuracy: 0.9475\n",
      "Epoch 374/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2026 - accuracy: 0.9459 - val_loss: 0.1967 - val_accuracy: 0.9475\n",
      "Epoch 375/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2028 - accuracy: 0.9459 - val_loss: 0.1964 - val_accuracy: 0.9475\n",
      "Epoch 376/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2030 - accuracy: 0.9459 - val_loss: 0.2017 - val_accuracy: 0.9475\n",
      "Epoch 377/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2040 - accuracy: 0.9459 - val_loss: 0.1966 - val_accuracy: 0.9475\n",
      "Epoch 378/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2061 - accuracy: 0.9459 - val_loss: 0.2019 - val_accuracy: 0.9475\n",
      "Epoch 379/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2035 - accuracy: 0.9459 - val_loss: 0.1963 - val_accuracy: 0.9475\n",
      "Epoch 380/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2041 - accuracy: 0.9459 - val_loss: 0.1980 - val_accuracy: 0.9475\n",
      "Epoch 381/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2041 - accuracy: 0.9459 - val_loss: 0.1965 - val_accuracy: 0.9475\n",
      "Epoch 382/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2037 - accuracy: 0.9459 - val_loss: 0.2031 - val_accuracy: 0.9475\n",
      "Epoch 383/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2048 - accuracy: 0.9459 - val_loss: 0.1976 - val_accuracy: 0.9475\n",
      "Epoch 384/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2031 - accuracy: 0.9459 - val_loss: 0.1971 - val_accuracy: 0.9475\n",
      "Epoch 385/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2029 - accuracy: 0.9459 - val_loss: 0.2023 - val_accuracy: 0.9475\n",
      "Epoch 386/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2033 - accuracy: 0.9459 - val_loss: 0.1964 - val_accuracy: 0.9475\n",
      "Epoch 387/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2036 - accuracy: 0.9459 - val_loss: 0.1980 - val_accuracy: 0.9475\n",
      "Epoch 388/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2021 - accuracy: 0.9459 - val_loss: 0.1964 - val_accuracy: 0.9475\n",
      "Epoch 389/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2036 - accuracy: 0.9459 - val_loss: 0.1995 - val_accuracy: 0.9475\n",
      "Epoch 390/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2022 - accuracy: 0.9459 - val_loss: 0.1969 - val_accuracy: 0.9475\n",
      "Epoch 391/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2023 - accuracy: 0.9459 - val_loss: 0.1957 - val_accuracy: 0.9475\n",
      "Epoch 392/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2021 - accuracy: 0.9459 - val_loss: 0.1997 - val_accuracy: 0.9475\n",
      "Epoch 393/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2040 - accuracy: 0.9459 - val_loss: 0.1999 - val_accuracy: 0.9475\n",
      "Epoch 394/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2029 - accuracy: 0.9459 - val_loss: 0.1973 - val_accuracy: 0.9475\n",
      "Epoch 395/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2026 - accuracy: 0.9459 - val_loss: 0.1967 - val_accuracy: 0.9475\n",
      "Epoch 396/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2026 - accuracy: 0.9459 - val_loss: 0.1964 - val_accuracy: 0.9475\n",
      "Epoch 397/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2025 - accuracy: 0.9459 - val_loss: 0.1992 - val_accuracy: 0.9475\n",
      "Epoch 398/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2033 - accuracy: 0.9459 - val_loss: 0.1969 - val_accuracy: 0.9475\n",
      "Epoch 399/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2029 - accuracy: 0.9459 - val_loss: 0.1987 - val_accuracy: 0.9475\n",
      "Epoch 400/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2019 - accuracy: 0.9459 - val_loss: 0.1962 - val_accuracy: 0.9475\n",
      "Epoch 401/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2040 - accuracy: 0.9459 - val_loss: 0.1975 - val_accuracy: 0.9475\n",
      "Epoch 402/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2032 - accuracy: 0.9459 - val_loss: 0.1979 - val_accuracy: 0.9475\n",
      "Epoch 403/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2046 - accuracy: 0.9459 - val_loss: 0.1966 - val_accuracy: 0.9475\n",
      "Epoch 404/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2041 - accuracy: 0.9459 - val_loss: 0.1966 - val_accuracy: 0.9475\n",
      "Epoch 405/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2033 - accuracy: 0.9459 - val_loss: 0.1967 - val_accuracy: 0.9475\n",
      "Epoch 406/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2030 - accuracy: 0.9459 - val_loss: 0.1975 - val_accuracy: 0.9475\n",
      "Epoch 407/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2032 - accuracy: 0.9459 - val_loss: 0.1959 - val_accuracy: 0.9475\n",
      "Epoch 408/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2012 - accuracy: 0.9459 - val_loss: 0.1971 - val_accuracy: 0.9475\n",
      "Epoch 409/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2033 - accuracy: 0.9459 - val_loss: 0.1966 - val_accuracy: 0.9475\n",
      "Epoch 410/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2036 - accuracy: 0.9459 - val_loss: 0.1979 - val_accuracy: 0.9475\n",
      "Epoch 411/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2023 - accuracy: 0.9459 - val_loss: 0.1955 - val_accuracy: 0.9475\n",
      "Epoch 412/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2033 - accuracy: 0.9459 - val_loss: 0.1987 - val_accuracy: 0.9475\n",
      "Epoch 413/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2030 - accuracy: 0.9459 - val_loss: 0.1962 - val_accuracy: 0.9475\n",
      "Epoch 414/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2060 - accuracy: 0.9459 - val_loss: 0.1980 - val_accuracy: 0.9475\n",
      "Epoch 415/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2014 - accuracy: 0.9459 - val_loss: 0.1953 - val_accuracy: 0.9475\n",
      "Epoch 416/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2028 - accuracy: 0.9459 - val_loss: 0.1959 - val_accuracy: 0.9475\n",
      "Epoch 417/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2028 - accuracy: 0.9459 - val_loss: 0.1970 - val_accuracy: 0.9475\n",
      "Epoch 418/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2030 - accuracy: 0.9459 - val_loss: 0.1996 - val_accuracy: 0.9475\n",
      "Epoch 419/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2024 - accuracy: 0.9459 - val_loss: 0.1965 - val_accuracy: 0.9475\n",
      "Epoch 420/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2023 - accuracy: 0.9459 - val_loss: 0.1976 - val_accuracy: 0.9475\n",
      "Epoch 421/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2024 - accuracy: 0.9459 - val_loss: 0.1986 - val_accuracy: 0.9475\n",
      "Epoch 422/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2027 - accuracy: 0.9459 - val_loss: 0.1969 - val_accuracy: 0.9475\n",
      "Epoch 423/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2034 - accuracy: 0.9459 - val_loss: 0.1961 - val_accuracy: 0.9475\n",
      "Epoch 424/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2020 - accuracy: 0.9459 - val_loss: 0.1987 - val_accuracy: 0.9475\n",
      "Epoch 425/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2029 - accuracy: 0.9459 - val_loss: 0.1955 - val_accuracy: 0.9475\n",
      "Epoch 426/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2032 - accuracy: 0.9459 - val_loss: 0.1966 - val_accuracy: 0.9475\n",
      "Epoch 427/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2018 - accuracy: 0.9459 - val_loss: 0.1978 - val_accuracy: 0.9475\n",
      "Epoch 428/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2023 - accuracy: 0.9459 - val_loss: 0.1976 - val_accuracy: 0.9475\n",
      "Epoch 429/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2038 - accuracy: 0.9459 - val_loss: 0.2083 - val_accuracy: 0.9475\n",
      "Epoch 430/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2034 - accuracy: 0.9459 - val_loss: 0.1959 - val_accuracy: 0.9475\n",
      "Epoch 431/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2023 - accuracy: 0.9459 - val_loss: 0.1961 - val_accuracy: 0.9475\n",
      "Epoch 432/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2017 - accuracy: 0.9459 - val_loss: 0.1964 - val_accuracy: 0.9475\n",
      "Epoch 433/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2022 - accuracy: 0.9459 - val_loss: 0.1962 - val_accuracy: 0.9475\n",
      "Epoch 434/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2019 - accuracy: 0.9459 - val_loss: 0.1976 - val_accuracy: 0.9475\n",
      "Epoch 435/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2041 - accuracy: 0.9459 - val_loss: 0.1967 - val_accuracy: 0.9475\n",
      "Epoch 436/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2033 - accuracy: 0.9459 - val_loss: 0.1967 - val_accuracy: 0.9475\n",
      "Epoch 437/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2040 - accuracy: 0.9459 - val_loss: 0.1976 - val_accuracy: 0.9475\n",
      "Epoch 438/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2033 - accuracy: 0.9459 - val_loss: 0.1962 - val_accuracy: 0.9475\n",
      "Epoch 439/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2034 - accuracy: 0.9459 - val_loss: 0.1973 - val_accuracy: 0.9475\n",
      "Epoch 440/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2035 - accuracy: 0.9459 - val_loss: 0.2014 - val_accuracy: 0.9475\n",
      "Epoch 441/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2030 - accuracy: 0.9459 - val_loss: 0.1978 - val_accuracy: 0.9475\n",
      "Epoch 442/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2030 - accuracy: 0.9459 - val_loss: 0.1956 - val_accuracy: 0.9475\n",
      "Epoch 443/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2048 - accuracy: 0.9459 - val_loss: 0.1965 - val_accuracy: 0.9475\n",
      "Epoch 444/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2019 - accuracy: 0.9459 - val_loss: 0.1997 - val_accuracy: 0.9475\n",
      "Epoch 445/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2036 - accuracy: 0.9459 - val_loss: 0.1962 - val_accuracy: 0.9475\n",
      "Epoch 446/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2024 - accuracy: 0.9459 - val_loss: 0.1956 - val_accuracy: 0.9475\n",
      "Epoch 447/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2015 - accuracy: 0.9459 - val_loss: 0.1958 - val_accuracy: 0.9475\n",
      "Epoch 448/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2041 - accuracy: 0.9459 - val_loss: 0.1966 - val_accuracy: 0.9475\n",
      "Epoch 449/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2014 - accuracy: 0.9459 - val_loss: 0.1956 - val_accuracy: 0.9475\n",
      "Epoch 450/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2019 - accuracy: 0.9459 - val_loss: 0.1966 - val_accuracy: 0.9475\n",
      "Epoch 451/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2032 - accuracy: 0.9459 - val_loss: 0.1988 - val_accuracy: 0.9475\n",
      "Epoch 452/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2033 - accuracy: 0.9459 - val_loss: 0.1957 - val_accuracy: 0.9475\n",
      "Epoch 453/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2022 - accuracy: 0.9459 - val_loss: 0.1982 - val_accuracy: 0.9475\n",
      "Epoch 454/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2046 - accuracy: 0.9459 - val_loss: 0.1959 - val_accuracy: 0.9475\n",
      "Epoch 455/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2015 - accuracy: 0.9459 - val_loss: 0.2002 - val_accuracy: 0.9475\n",
      "Epoch 456/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2029 - accuracy: 0.9459 - val_loss: 0.1992 - val_accuracy: 0.9475\n",
      "Epoch 457/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2029 - accuracy: 0.9459 - val_loss: 0.1982 - val_accuracy: 0.9475\n",
      "Epoch 458/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2022 - accuracy: 0.9459 - val_loss: 0.1960 - val_accuracy: 0.9475\n",
      "Epoch 459/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2023 - accuracy: 0.9459 - val_loss: 0.1966 - val_accuracy: 0.9475\n",
      "Epoch 460/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2021 - accuracy: 0.9459 - val_loss: 0.1964 - val_accuracy: 0.9475\n",
      "Epoch 461/1000\n",
      "67/67 [==============================] - 2s 24ms/step - loss: 0.2016 - accuracy: 0.9459 - val_loss: 0.1963 - val_accuracy: 0.9475\n",
      "Epoch 462/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2035 - accuracy: 0.9459 - val_loss: 0.1972 - val_accuracy: 0.9475\n",
      "Epoch 463/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2029 - accuracy: 0.9459 - val_loss: 0.1981 - val_accuracy: 0.9475\n",
      "Epoch 464/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2019 - accuracy: 0.9459 - val_loss: 0.1956 - val_accuracy: 0.9475\n",
      "Epoch 465/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2032 - accuracy: 0.9459 - val_loss: 0.1960 - val_accuracy: 0.9475\n",
      "Epoch 466/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2025 - accuracy: 0.9459 - val_loss: 0.1961 - val_accuracy: 0.9475\n",
      "Epoch 467/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2025 - accuracy: 0.9459 - val_loss: 0.1963 - val_accuracy: 0.9475\n",
      "Epoch 468/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2033 - accuracy: 0.9459 - val_loss: 0.1980 - val_accuracy: 0.9475\n",
      "Epoch 469/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2022 - accuracy: 0.9459 - val_loss: 0.1966 - val_accuracy: 0.9475\n",
      "Epoch 470/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2031 - accuracy: 0.9459 - val_loss: 0.1954 - val_accuracy: 0.9475\n",
      "Epoch 471/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2036 - accuracy: 0.9459 - val_loss: 0.1979 - val_accuracy: 0.9475\n",
      "Epoch 472/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2056 - accuracy: 0.9459 - val_loss: 0.1958 - val_accuracy: 0.9475\n",
      "Epoch 473/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2033 - accuracy: 0.9459 - val_loss: 0.1996 - val_accuracy: 0.9475\n",
      "Epoch 474/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2027 - accuracy: 0.9459 - val_loss: 0.1956 - val_accuracy: 0.9475\n",
      "Epoch 475/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2043 - accuracy: 0.9459 - val_loss: 0.1968 - val_accuracy: 0.9475\n",
      "Epoch 476/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2037 - accuracy: 0.9459 - val_loss: 0.1963 - val_accuracy: 0.9475\n",
      "Epoch 477/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2023 - accuracy: 0.9459 - val_loss: 0.1961 - val_accuracy: 0.9475\n",
      "Epoch 478/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2025 - accuracy: 0.9459 - val_loss: 0.1994 - val_accuracy: 0.9475\n",
      "Epoch 479/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2019 - accuracy: 0.9459 - val_loss: 0.1960 - val_accuracy: 0.9475\n",
      "Epoch 480/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2021 - accuracy: 0.9459 - val_loss: 0.1958 - val_accuracy: 0.9475\n",
      "Epoch 481/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2010 - accuracy: 0.9459 - val_loss: 0.1968 - val_accuracy: 0.9475\n",
      "Epoch 482/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2018 - accuracy: 0.9459 - val_loss: 0.1954 - val_accuracy: 0.9475\n",
      "Epoch 483/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2021 - accuracy: 0.9459 - val_loss: 0.1954 - val_accuracy: 0.9475\n",
      "Epoch 484/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2025 - accuracy: 0.9459 - val_loss: 0.1953 - val_accuracy: 0.9475\n",
      "Epoch 485/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2032 - accuracy: 0.9459 - val_loss: 0.2017 - val_accuracy: 0.9475\n",
      "Epoch 486/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2048 - accuracy: 0.9459 - val_loss: 0.2021 - val_accuracy: 0.9475\n",
      "Epoch 487/1000\n",
      "67/67 [==============================] - 2s 24ms/step - loss: 0.2020 - accuracy: 0.9459 - val_loss: 0.1954 - val_accuracy: 0.9475\n",
      "Epoch 488/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2025 - accuracy: 0.9459 - val_loss: 0.1989 - val_accuracy: 0.9475\n",
      "Epoch 489/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2026 - accuracy: 0.9459 - val_loss: 0.1982 - val_accuracy: 0.9475\n",
      "Epoch 490/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2033 - accuracy: 0.9459 - val_loss: 0.2034 - val_accuracy: 0.9475\n",
      "Epoch 491/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2035 - accuracy: 0.9459 - val_loss: 0.1948 - val_accuracy: 0.9475\n",
      "Epoch 492/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2033 - accuracy: 0.9459 - val_loss: 0.1960 - val_accuracy: 0.9475\n",
      "Epoch 493/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2016 - accuracy: 0.9459 - val_loss: 0.1949 - val_accuracy: 0.9475\n",
      "Epoch 494/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2005 - accuracy: 0.9459 - val_loss: 0.1950 - val_accuracy: 0.9475\n",
      "Epoch 495/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2023 - accuracy: 0.9459 - val_loss: 0.1969 - val_accuracy: 0.9475\n",
      "Epoch 496/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2042 - accuracy: 0.9459 - val_loss: 0.1954 - val_accuracy: 0.9475\n",
      "Epoch 497/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2035 - accuracy: 0.9459 - val_loss: 0.1986 - val_accuracy: 0.9475\n",
      "Epoch 498/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2039 - accuracy: 0.9459 - val_loss: 0.1960 - val_accuracy: 0.9475\n",
      "Epoch 499/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2007 - accuracy: 0.9459 - val_loss: 0.1962 - val_accuracy: 0.9475\n",
      "Epoch 500/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2024 - accuracy: 0.9459 - val_loss: 0.1973 - val_accuracy: 0.9475\n",
      "Epoch 501/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2024 - accuracy: 0.9459 - val_loss: 0.1960 - val_accuracy: 0.9475\n",
      "Epoch 502/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2019 - accuracy: 0.9459 - val_loss: 0.1961 - val_accuracy: 0.9475\n",
      "Epoch 503/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2021 - accuracy: 0.9459 - val_loss: 0.1954 - val_accuracy: 0.9475\n",
      "Epoch 504/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2013 - accuracy: 0.9459 - val_loss: 0.1968 - val_accuracy: 0.9475\n",
      "Epoch 505/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2013 - accuracy: 0.9459 - val_loss: 0.1965 - val_accuracy: 0.9475\n",
      "Epoch 506/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2006 - accuracy: 0.9459 - val_loss: 0.1986 - val_accuracy: 0.9475\n",
      "Epoch 507/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2019 - accuracy: 0.9459 - val_loss: 0.1991 - val_accuracy: 0.9475\n",
      "Epoch 508/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2021 - accuracy: 0.9459 - val_loss: 0.1969 - val_accuracy: 0.9475\n",
      "Epoch 509/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2020 - accuracy: 0.9459 - val_loss: 0.1952 - val_accuracy: 0.9475\n",
      "Epoch 510/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2011 - accuracy: 0.9459 - val_loss: 0.1995 - val_accuracy: 0.9475\n",
      "Epoch 511/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2026 - accuracy: 0.9459 - val_loss: 0.1955 - val_accuracy: 0.9475\n",
      "Epoch 512/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2030 - accuracy: 0.9459 - val_loss: 0.2013 - val_accuracy: 0.9475\n",
      "Epoch 513/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2023 - accuracy: 0.9459 - val_loss: 0.1968 - val_accuracy: 0.9475\n",
      "Epoch 514/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2021 - accuracy: 0.9459 - val_loss: 0.1958 - val_accuracy: 0.9475\n",
      "Epoch 515/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2047 - accuracy: 0.9459 - val_loss: 0.1980 - val_accuracy: 0.9475\n",
      "Epoch 516/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2022 - accuracy: 0.9459 - val_loss: 0.1961 - val_accuracy: 0.9475\n",
      "Epoch 517/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2017 - accuracy: 0.9459 - val_loss: 0.1953 - val_accuracy: 0.9475\n",
      "Epoch 518/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2012 - accuracy: 0.9459 - val_loss: 0.1951 - val_accuracy: 0.9475\n",
      "Epoch 519/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2018 - accuracy: 0.9459 - val_loss: 0.1953 - val_accuracy: 0.9475\n",
      "Epoch 520/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2019 - accuracy: 0.9459 - val_loss: 0.1975 - val_accuracy: 0.9475\n",
      "Epoch 521/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2024 - accuracy: 0.9459 - val_loss: 0.1959 - val_accuracy: 0.9475\n",
      "Epoch 522/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2020 - accuracy: 0.9459 - val_loss: 0.1952 - val_accuracy: 0.9475\n",
      "Epoch 523/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2031 - accuracy: 0.9459 - val_loss: 0.1951 - val_accuracy: 0.9475\n",
      "Epoch 524/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2009 - accuracy: 0.9459 - val_loss: 0.1981 - val_accuracy: 0.9475\n",
      "Epoch 525/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2038 - accuracy: 0.9459 - val_loss: 0.1959 - val_accuracy: 0.9475\n",
      "Epoch 526/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2027 - accuracy: 0.9459 - val_loss: 0.1956 - val_accuracy: 0.9475\n",
      "Epoch 527/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2019 - accuracy: 0.9459 - val_loss: 0.1953 - val_accuracy: 0.9475\n",
      "Epoch 528/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2019 - accuracy: 0.9459 - val_loss: 0.1964 - val_accuracy: 0.9475\n",
      "Epoch 529/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2035 - accuracy: 0.9459 - val_loss: 0.1967 - val_accuracy: 0.9475\n",
      "Epoch 530/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2014 - accuracy: 0.9459 - val_loss: 0.1951 - val_accuracy: 0.9475\n",
      "Epoch 531/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2018 - accuracy: 0.9459 - val_loss: 0.2025 - val_accuracy: 0.9475\n",
      "Epoch 532/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2029 - accuracy: 0.9459 - val_loss: 0.1958 - val_accuracy: 0.9475\n",
      "Epoch 533/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2021 - accuracy: 0.9459 - val_loss: 0.2023 - val_accuracy: 0.9475\n",
      "Epoch 534/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2025 - accuracy: 0.9459 - val_loss: 0.1981 - val_accuracy: 0.9475\n",
      "Epoch 535/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2007 - accuracy: 0.9459 - val_loss: 0.1971 - val_accuracy: 0.9475\n",
      "Epoch 536/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2009 - accuracy: 0.9459 - val_loss: 0.1950 - val_accuracy: 0.9475\n",
      "Epoch 537/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2009 - accuracy: 0.9459 - val_loss: 0.1959 - val_accuracy: 0.9475\n",
      "Epoch 538/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2015 - accuracy: 0.9459 - val_loss: 0.1950 - val_accuracy: 0.9475\n",
      "Epoch 539/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2011 - accuracy: 0.9459 - val_loss: 0.1992 - val_accuracy: 0.9475\n",
      "Epoch 540/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2015 - accuracy: 0.9459 - val_loss: 0.1967 - val_accuracy: 0.9475\n",
      "Epoch 541/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2005 - accuracy: 0.9459 - val_loss: 0.1949 - val_accuracy: 0.9475\n",
      "Epoch 542/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2016 - accuracy: 0.9459 - val_loss: 0.1951 - val_accuracy: 0.9475\n",
      "Epoch 543/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2020 - accuracy: 0.9459 - val_loss: 0.1962 - val_accuracy: 0.9475\n",
      "Epoch 544/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2023 - accuracy: 0.9459 - val_loss: 0.1983 - val_accuracy: 0.9475\n",
      "Epoch 545/1000\n",
      "67/67 [==============================] - 2s 24ms/step - loss: 0.2021 - accuracy: 0.9459 - val_loss: 0.2019 - val_accuracy: 0.9475\n",
      "Epoch 546/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2033 - accuracy: 0.9459 - val_loss: 0.2046 - val_accuracy: 0.9475\n",
      "Epoch 547/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2027 - accuracy: 0.9459 - val_loss: 0.1958 - val_accuracy: 0.9475\n",
      "Epoch 548/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2013 - accuracy: 0.9459 - val_loss: 0.1949 - val_accuracy: 0.9475\n",
      "Epoch 549/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2027 - accuracy: 0.9459 - val_loss: 0.2087 - val_accuracy: 0.9475\n",
      "Epoch 550/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2029 - accuracy: 0.9459 - val_loss: 0.1957 - val_accuracy: 0.9475\n",
      "Epoch 551/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2041 - accuracy: 0.9459 - val_loss: 0.1987 - val_accuracy: 0.9475\n",
      "Epoch 552/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2015 - accuracy: 0.9459 - val_loss: 0.1950 - val_accuracy: 0.9475\n",
      "Epoch 553/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2018 - accuracy: 0.9459 - val_loss: 0.1954 - val_accuracy: 0.9475\n",
      "Epoch 554/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2019 - accuracy: 0.9459 - val_loss: 0.1961 - val_accuracy: 0.9475\n",
      "Epoch 555/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2019 - accuracy: 0.9459 - val_loss: 0.1967 - val_accuracy: 0.9475\n",
      "Epoch 556/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2058 - accuracy: 0.9459 - val_loss: 0.1975 - val_accuracy: 0.9475\n",
      "Epoch 557/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2054 - accuracy: 0.9459 - val_loss: 0.1975 - val_accuracy: 0.9475\n",
      "Epoch 558/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2036 - accuracy: 0.9459 - val_loss: 0.1968 - val_accuracy: 0.9475\n",
      "Epoch 559/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2023 - accuracy: 0.9459 - val_loss: 0.1969 - val_accuracy: 0.9475\n",
      "Epoch 560/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2025 - accuracy: 0.9459 - val_loss: 0.1978 - val_accuracy: 0.9475\n",
      "Epoch 561/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2029 - accuracy: 0.9459 - val_loss: 0.1957 - val_accuracy: 0.9475\n",
      "Epoch 562/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2035 - accuracy: 0.9459 - val_loss: 0.1977 - val_accuracy: 0.9475\n",
      "Epoch 563/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2021 - accuracy: 0.9459 - val_loss: 0.1966 - val_accuracy: 0.9475\n",
      "Epoch 564/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2030 - accuracy: 0.9459 - val_loss: 0.1966 - val_accuracy: 0.9475\n",
      "Epoch 565/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2013 - accuracy: 0.9459 - val_loss: 0.1951 - val_accuracy: 0.9475\n",
      "Epoch 566/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2038 - accuracy: 0.9459 - val_loss: 0.1970 - val_accuracy: 0.9475\n",
      "Epoch 567/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2040 - accuracy: 0.9459 - val_loss: 0.1975 - val_accuracy: 0.9475\n",
      "Epoch 568/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2023 - accuracy: 0.9459 - val_loss: 0.1968 - val_accuracy: 0.9475\n",
      "Epoch 569/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2015 - accuracy: 0.9459 - val_loss: 0.1949 - val_accuracy: 0.9475\n",
      "Epoch 570/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2010 - accuracy: 0.9459 - val_loss: 0.1947 - val_accuracy: 0.9475\n",
      "Epoch 571/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2012 - accuracy: 0.9459 - val_loss: 0.1951 - val_accuracy: 0.9475\n",
      "Epoch 572/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2021 - accuracy: 0.9459 - val_loss: 0.1949 - val_accuracy: 0.9475\n",
      "Epoch 573/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2012 - accuracy: 0.9459 - val_loss: 0.1975 - val_accuracy: 0.9475\n",
      "Epoch 574/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2007 - accuracy: 0.9459 - val_loss: 0.1954 - val_accuracy: 0.9475\n",
      "Epoch 575/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2024 - accuracy: 0.9459 - val_loss: 0.1959 - val_accuracy: 0.9475\n",
      "Epoch 576/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2005 - accuracy: 0.9459 - val_loss: 0.1950 - val_accuracy: 0.9475\n",
      "Epoch 577/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2021 - accuracy: 0.9459 - val_loss: 0.1950 - val_accuracy: 0.9475\n",
      "Epoch 578/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2019 - accuracy: 0.9459 - val_loss: 0.2035 - val_accuracy: 0.9475\n",
      "Epoch 579/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2005 - accuracy: 0.9459 - val_loss: 0.1946 - val_accuracy: 0.9475\n",
      "Epoch 580/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2009 - accuracy: 0.9459 - val_loss: 0.1959 - val_accuracy: 0.9475\n",
      "Epoch 581/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2021 - accuracy: 0.9459 - val_loss: 0.1953 - val_accuracy: 0.9475\n",
      "Epoch 582/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2005 - accuracy: 0.9459 - val_loss: 0.1977 - val_accuracy: 0.9475\n",
      "Epoch 583/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2029 - accuracy: 0.9459 - val_loss: 0.1968 - val_accuracy: 0.9475\n",
      "Epoch 584/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2027 - accuracy: 0.9459 - val_loss: 0.1978 - val_accuracy: 0.9475\n",
      "Epoch 585/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2014 - accuracy: 0.9459 - val_loss: 0.1955 - val_accuracy: 0.9475\n",
      "Epoch 586/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2013 - accuracy: 0.9459 - val_loss: 0.1956 - val_accuracy: 0.9475\n",
      "Epoch 587/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.1998 - accuracy: 0.9459 - val_loss: 0.1951 - val_accuracy: 0.9475\n",
      "Epoch 588/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2023 - accuracy: 0.9459 - val_loss: 0.1959 - val_accuracy: 0.9475\n",
      "Epoch 589/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2007 - accuracy: 0.9459 - val_loss: 0.1980 - val_accuracy: 0.9475\n",
      "Epoch 590/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2009 - accuracy: 0.9459 - val_loss: 0.1957 - val_accuracy: 0.9475\n",
      "Epoch 591/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2011 - accuracy: 0.9459 - val_loss: 0.1943 - val_accuracy: 0.9475\n",
      "Epoch 592/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2045 - accuracy: 0.9459 - val_loss: 0.1961 - val_accuracy: 0.9475\n",
      "Epoch 593/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2033 - accuracy: 0.9459 - val_loss: 0.1976 - val_accuracy: 0.9475\n",
      "Epoch 594/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2021 - accuracy: 0.9459 - val_loss: 0.1952 - val_accuracy: 0.9475\n",
      "Epoch 595/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2017 - accuracy: 0.9459 - val_loss: 0.1959 - val_accuracy: 0.9475\n",
      "Epoch 596/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2020 - accuracy: 0.9459 - val_loss: 0.1975 - val_accuracy: 0.9475\n",
      "Epoch 597/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2004 - accuracy: 0.9459 - val_loss: 0.1951 - val_accuracy: 0.9475\n",
      "Epoch 598/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2020 - accuracy: 0.9459 - val_loss: 0.1959 - val_accuracy: 0.9475\n",
      "Epoch 599/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2022 - accuracy: 0.9459 - val_loss: 0.1952 - val_accuracy: 0.9475\n",
      "Epoch 600/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2018 - accuracy: 0.9459 - val_loss: 0.2002 - val_accuracy: 0.9475\n",
      "Epoch 601/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2014 - accuracy: 0.9459 - val_loss: 0.1989 - val_accuracy: 0.9475\n",
      "Epoch 602/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2028 - accuracy: 0.9459 - val_loss: 0.1958 - val_accuracy: 0.9475\n",
      "Epoch 603/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2019 - accuracy: 0.9459 - val_loss: 0.1950 - val_accuracy: 0.9475\n",
      "Epoch 604/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2034 - accuracy: 0.9459 - val_loss: 0.1956 - val_accuracy: 0.9475\n",
      "Epoch 605/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2019 - accuracy: 0.9459 - val_loss: 0.1952 - val_accuracy: 0.9475\n",
      "Epoch 606/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2016 - accuracy: 0.9459 - val_loss: 0.1996 - val_accuracy: 0.9475\n",
      "Epoch 607/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2034 - accuracy: 0.9459 - val_loss: 0.1953 - val_accuracy: 0.9475\n",
      "Epoch 608/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2009 - accuracy: 0.9459 - val_loss: 0.1986 - val_accuracy: 0.9475\n",
      "Epoch 609/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2022 - accuracy: 0.9459 - val_loss: 0.1973 - val_accuracy: 0.9475\n",
      "Epoch 610/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2008 - accuracy: 0.9459 - val_loss: 0.1970 - val_accuracy: 0.9475\n",
      "Epoch 611/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2016 - accuracy: 0.9459 - val_loss: 0.1945 - val_accuracy: 0.9475\n",
      "Epoch 612/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2021 - accuracy: 0.9459 - val_loss: 0.1948 - val_accuracy: 0.9475\n",
      "Epoch 613/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2030 - accuracy: 0.9459 - val_loss: 0.1979 - val_accuracy: 0.9475\n",
      "Epoch 614/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2043 - accuracy: 0.9459 - val_loss: 0.1960 - val_accuracy: 0.9475\n",
      "Epoch 615/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2019 - accuracy: 0.9459 - val_loss: 0.1948 - val_accuracy: 0.9475\n",
      "Epoch 616/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2009 - accuracy: 0.9459 - val_loss: 0.1952 - val_accuracy: 0.9475\n",
      "Epoch 617/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2039 - accuracy: 0.9459 - val_loss: 0.1969 - val_accuracy: 0.9475\n",
      "Epoch 618/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2014 - accuracy: 0.9459 - val_loss: 0.2004 - val_accuracy: 0.9475\n",
      "Epoch 619/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2018 - accuracy: 0.9459 - val_loss: 0.1948 - val_accuracy: 0.9475\n",
      "Epoch 620/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2016 - accuracy: 0.9459 - val_loss: 0.1966 - val_accuracy: 0.9475\n",
      "Epoch 621/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2041 - accuracy: 0.9459 - val_loss: 0.1953 - val_accuracy: 0.9475\n",
      "Epoch 622/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2009 - accuracy: 0.9459 - val_loss: 0.1949 - val_accuracy: 0.9475\n",
      "Epoch 623/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2011 - accuracy: 0.9459 - val_loss: 0.1950 - val_accuracy: 0.9475\n",
      "Epoch 624/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.1998 - accuracy: 0.9459 - val_loss: 0.1951 - val_accuracy: 0.9475\n",
      "Epoch 625/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2020 - accuracy: 0.9459 - val_loss: 0.1956 - val_accuracy: 0.9475\n",
      "Epoch 626/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.1998 - accuracy: 0.9459 - val_loss: 0.1949 - val_accuracy: 0.9475\n",
      "Epoch 627/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2013 - accuracy: 0.9459 - val_loss: 0.1972 - val_accuracy: 0.9475\n",
      "Epoch 628/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2014 - accuracy: 0.9459 - val_loss: 0.1953 - val_accuracy: 0.9475\n",
      "Epoch 629/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2006 - accuracy: 0.9459 - val_loss: 0.1946 - val_accuracy: 0.9475\n",
      "Epoch 630/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2006 - accuracy: 0.9459 - val_loss: 0.1944 - val_accuracy: 0.9475\n",
      "Epoch 631/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2029 - accuracy: 0.9459 - val_loss: 0.1957 - val_accuracy: 0.9475\n",
      "Epoch 632/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2015 - accuracy: 0.9459 - val_loss: 0.1948 - val_accuracy: 0.9475\n",
      "Epoch 633/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2007 - accuracy: 0.9459 - val_loss: 0.1988 - val_accuracy: 0.9475\n",
      "Epoch 634/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2012 - accuracy: 0.9459 - val_loss: 0.1946 - val_accuracy: 0.9475\n",
      "Epoch 635/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2019 - accuracy: 0.9459 - val_loss: 0.1958 - val_accuracy: 0.9475\n",
      "Epoch 636/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2023 - accuracy: 0.9459 - val_loss: 0.1944 - val_accuracy: 0.9475\n",
      "Epoch 637/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2012 - accuracy: 0.9459 - val_loss: 0.1948 - val_accuracy: 0.9475\n",
      "Epoch 638/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2020 - accuracy: 0.9459 - val_loss: 0.1946 - val_accuracy: 0.9475\n",
      "Epoch 639/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2023 - accuracy: 0.9459 - val_loss: 0.1952 - val_accuracy: 0.9475\n",
      "Epoch 640/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2016 - accuracy: 0.9459 - val_loss: 0.1946 - val_accuracy: 0.9475\n",
      "Epoch 641/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2017 - accuracy: 0.9459 - val_loss: 0.1959 - val_accuracy: 0.9475\n",
      "Epoch 642/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2005 - accuracy: 0.9459 - val_loss: 0.1966 - val_accuracy: 0.9475\n",
      "Epoch 643/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2004 - accuracy: 0.9459 - val_loss: 0.1944 - val_accuracy: 0.9475\n",
      "Epoch 644/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2010 - accuracy: 0.9459 - val_loss: 0.1943 - val_accuracy: 0.9475\n",
      "Epoch 645/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2025 - accuracy: 0.9459 - val_loss: 0.1945 - val_accuracy: 0.9475\n",
      "Epoch 646/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.1999 - accuracy: 0.9459 - val_loss: 0.1949 - val_accuracy: 0.9475\n",
      "Epoch 647/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2013 - accuracy: 0.9459 - val_loss: 0.1974 - val_accuracy: 0.9475\n",
      "Epoch 648/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2009 - accuracy: 0.9459 - val_loss: 0.1946 - val_accuracy: 0.9475\n",
      "Epoch 649/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2001 - accuracy: 0.9459 - val_loss: 0.1951 - val_accuracy: 0.9475\n",
      "Epoch 650/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2017 - accuracy: 0.9459 - val_loss: 0.1952 - val_accuracy: 0.9475\n",
      "Epoch 651/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2008 - accuracy: 0.9459 - val_loss: 0.1962 - val_accuracy: 0.9475\n",
      "Epoch 652/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2012 - accuracy: 0.9459 - val_loss: 0.1972 - val_accuracy: 0.9475\n",
      "Epoch 653/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2016 - accuracy: 0.9459 - val_loss: 0.1954 - val_accuracy: 0.9475\n",
      "Epoch 654/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2014 - accuracy: 0.9459 - val_loss: 0.1950 - val_accuracy: 0.9475\n",
      "Epoch 655/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2006 - accuracy: 0.9459 - val_loss: 0.1959 - val_accuracy: 0.9475\n",
      "Epoch 656/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2018 - accuracy: 0.9459 - val_loss: 0.1952 - val_accuracy: 0.9475\n",
      "Epoch 657/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2012 - accuracy: 0.9459 - val_loss: 0.1946 - val_accuracy: 0.9475\n",
      "Epoch 658/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2006 - accuracy: 0.9459 - val_loss: 0.1967 - val_accuracy: 0.9475\n",
      "Epoch 659/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2014 - accuracy: 0.9459 - val_loss: 0.1953 - val_accuracy: 0.9475\n",
      "Epoch 660/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2007 - accuracy: 0.9459 - val_loss: 0.1973 - val_accuracy: 0.9475\n",
      "Epoch 661/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2013 - accuracy: 0.9459 - val_loss: 0.1972 - val_accuracy: 0.9475\n",
      "Epoch 662/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2012 - accuracy: 0.9459 - val_loss: 0.1950 - val_accuracy: 0.9475\n",
      "Epoch 663/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2000 - accuracy: 0.9459 - val_loss: 0.1952 - val_accuracy: 0.9475\n",
      "Epoch 664/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2013 - accuracy: 0.9459 - val_loss: 0.1956 - val_accuracy: 0.9475\n",
      "Epoch 665/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2003 - accuracy: 0.9459 - val_loss: 0.1956 - val_accuracy: 0.9475\n",
      "Epoch 666/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2012 - accuracy: 0.9459 - val_loss: 0.1939 - val_accuracy: 0.9475\n",
      "Epoch 667/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2021 - accuracy: 0.9459 - val_loss: 0.1946 - val_accuracy: 0.9475\n",
      "Epoch 668/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2039 - accuracy: 0.9459 - val_loss: 0.1949 - val_accuracy: 0.9475\n",
      "Epoch 669/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2015 - accuracy: 0.9459 - val_loss: 0.1940 - val_accuracy: 0.9475\n",
      "Epoch 670/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2006 - accuracy: 0.9459 - val_loss: 0.1971 - val_accuracy: 0.9475\n",
      "Epoch 671/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2025 - accuracy: 0.9459 - val_loss: 0.1957 - val_accuracy: 0.9475\n",
      "Epoch 672/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2003 - accuracy: 0.9459 - val_loss: 0.1954 - val_accuracy: 0.9475\n",
      "Epoch 673/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.1998 - accuracy: 0.9459 - val_loss: 0.1966 - val_accuracy: 0.9475\n",
      "Epoch 674/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2009 - accuracy: 0.9459 - val_loss: 0.1948 - val_accuracy: 0.9475\n",
      "Epoch 675/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2026 - accuracy: 0.9459 - val_loss: 0.2035 - val_accuracy: 0.9475\n",
      "Epoch 676/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2037 - accuracy: 0.9459 - val_loss: 0.1969 - val_accuracy: 0.9475\n",
      "Epoch 677/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2016 - accuracy: 0.9459 - val_loss: 0.1945 - val_accuracy: 0.9475\n",
      "Epoch 678/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2014 - accuracy: 0.9459 - val_loss: 0.2011 - val_accuracy: 0.9475\n",
      "Epoch 679/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2012 - accuracy: 0.9459 - val_loss: 0.2002 - val_accuracy: 0.9475\n",
      "Epoch 680/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2008 - accuracy: 0.9459 - val_loss: 0.1997 - val_accuracy: 0.9475\n",
      "Epoch 681/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2024 - accuracy: 0.9459 - val_loss: 0.1943 - val_accuracy: 0.9475\n",
      "Epoch 682/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2009 - accuracy: 0.9459 - val_loss: 0.1971 - val_accuracy: 0.9475\n",
      "Epoch 683/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2010 - accuracy: 0.9459 - val_loss: 0.1954 - val_accuracy: 0.9475\n",
      "Epoch 684/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2013 - accuracy: 0.9459 - val_loss: 0.1943 - val_accuracy: 0.9475\n",
      "Epoch 685/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2014 - accuracy: 0.9459 - val_loss: 0.1957 - val_accuracy: 0.9475\n",
      "Epoch 686/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2014 - accuracy: 0.9459 - val_loss: 0.1973 - val_accuracy: 0.9475\n",
      "Epoch 687/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2008 - accuracy: 0.9459 - val_loss: 0.1966 - val_accuracy: 0.9475\n",
      "Epoch 688/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2006 - accuracy: 0.9459 - val_loss: 0.1952 - val_accuracy: 0.9475\n",
      "Epoch 689/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2033 - accuracy: 0.9459 - val_loss: 0.1974 - val_accuracy: 0.9475\n",
      "Epoch 690/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2010 - accuracy: 0.9459 - val_loss: 0.1953 - val_accuracy: 0.9475\n",
      "Epoch 691/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2020 - accuracy: 0.9459 - val_loss: 0.1953 - val_accuracy: 0.9475\n",
      "Epoch 692/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2009 - accuracy: 0.9459 - val_loss: 0.1949 - val_accuracy: 0.9475\n",
      "Epoch 693/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2019 - accuracy: 0.9459 - val_loss: 0.1953 - val_accuracy: 0.9475\n",
      "Epoch 694/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.1998 - accuracy: 0.9459 - val_loss: 0.1940 - val_accuracy: 0.9475\n",
      "Epoch 695/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2017 - accuracy: 0.9459 - val_loss: 0.1963 - val_accuracy: 0.9475\n",
      "Epoch 696/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2002 - accuracy: 0.9459 - val_loss: 0.1939 - val_accuracy: 0.9475\n",
      "Epoch 697/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2009 - accuracy: 0.9459 - val_loss: 0.1956 - val_accuracy: 0.9475\n",
      "Epoch 698/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2013 - accuracy: 0.9459 - val_loss: 0.1948 - val_accuracy: 0.9475\n",
      "Epoch 699/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.1995 - accuracy: 0.9459 - val_loss: 0.1943 - val_accuracy: 0.9475\n",
      "Epoch 700/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2009 - accuracy: 0.9459 - val_loss: 0.1949 - val_accuracy: 0.9475\n",
      "Epoch 701/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2002 - accuracy: 0.9459 - val_loss: 0.1953 - val_accuracy: 0.9475\n",
      "Epoch 702/1000\n",
      "67/67 [==============================] - 2s 22ms/step - loss: 0.1997 - accuracy: 0.9459 - val_loss: 0.1967 - val_accuracy: 0.9475\n",
      "Epoch 703/1000\n",
      "67/67 [==============================] - 1s 22ms/step - loss: 0.2013 - accuracy: 0.9459 - val_loss: 0.1956 - val_accuracy: 0.9475\n",
      "Epoch 704/1000\n",
      "67/67 [==============================] - 1s 22ms/step - loss: 0.2004 - accuracy: 0.9459 - val_loss: 0.1943 - val_accuracy: 0.9475\n",
      "Epoch 705/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2010 - accuracy: 0.9459 - val_loss: 0.1976 - val_accuracy: 0.9475\n",
      "Epoch 706/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2015 - accuracy: 0.9459 - val_loss: 0.1955 - val_accuracy: 0.9475\n",
      "Epoch 707/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2010 - accuracy: 0.9459 - val_loss: 0.1957 - val_accuracy: 0.9475\n",
      "Epoch 708/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2008 - accuracy: 0.9459 - val_loss: 0.1952 - val_accuracy: 0.9475\n",
      "Epoch 709/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.1987 - accuracy: 0.9459 - val_loss: 0.1956 - val_accuracy: 0.9475\n",
      "Epoch 710/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2023 - accuracy: 0.9459 - val_loss: 0.1974 - val_accuracy: 0.9475\n",
      "Epoch 711/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2001 - accuracy: 0.9459 - val_loss: 0.1949 - val_accuracy: 0.9475\n",
      "Epoch 712/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2000 - accuracy: 0.9459 - val_loss: 0.1944 - val_accuracy: 0.9475\n",
      "Epoch 713/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2011 - accuracy: 0.9459 - val_loss: 0.1957 - val_accuracy: 0.9475\n",
      "Epoch 714/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2031 - accuracy: 0.9459 - val_loss: 0.1946 - val_accuracy: 0.9475\n",
      "Epoch 715/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2027 - accuracy: 0.9459 - val_loss: 0.1952 - val_accuracy: 0.9475\n",
      "Epoch 716/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2009 - accuracy: 0.9459 - val_loss: 0.1940 - val_accuracy: 0.9475\n",
      "Epoch 717/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2000 - accuracy: 0.9459 - val_loss: 0.1943 - val_accuracy: 0.9475\n",
      "Epoch 718/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2007 - accuracy: 0.9459 - val_loss: 0.1942 - val_accuracy: 0.9475\n",
      "Epoch 719/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2009 - accuracy: 0.9459 - val_loss: 0.1950 - val_accuracy: 0.9475\n",
      "Epoch 720/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2013 - accuracy: 0.9459 - val_loss: 0.1968 - val_accuracy: 0.9475\n",
      "Epoch 721/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2019 - accuracy: 0.9459 - val_loss: 0.1942 - val_accuracy: 0.9475\n",
      "Epoch 722/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2019 - accuracy: 0.9459 - val_loss: 0.1965 - val_accuracy: 0.9475\n",
      "Epoch 723/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.1998 - accuracy: 0.9459 - val_loss: 0.1964 - val_accuracy: 0.9475\n",
      "Epoch 724/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2004 - accuracy: 0.9459 - val_loss: 0.1942 - val_accuracy: 0.9475\n",
      "Epoch 725/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.1994 - accuracy: 0.9459 - val_loss: 0.1961 - val_accuracy: 0.9475\n",
      "Epoch 726/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.1999 - accuracy: 0.9459 - val_loss: 0.1947 - val_accuracy: 0.9475\n",
      "Epoch 727/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2015 - accuracy: 0.9459 - val_loss: 0.1950 - val_accuracy: 0.9475\n",
      "Epoch 728/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2011 - accuracy: 0.9459 - val_loss: 0.2018 - val_accuracy: 0.9475\n",
      "Epoch 729/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2018 - accuracy: 0.9459 - val_loss: 0.1961 - val_accuracy: 0.9475\n",
      "Epoch 730/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2011 - accuracy: 0.9459 - val_loss: 0.1941 - val_accuracy: 0.9475\n",
      "Epoch 731/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2009 - accuracy: 0.9459 - val_loss: 0.1946 - val_accuracy: 0.9475\n",
      "Epoch 732/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2016 - accuracy: 0.9459 - val_loss: 0.1967 - val_accuracy: 0.9475\n",
      "Epoch 733/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2025 - accuracy: 0.9459 - val_loss: 0.1952 - val_accuracy: 0.9475\n",
      "Epoch 734/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2006 - accuracy: 0.9459 - val_loss: 0.1953 - val_accuracy: 0.9475\n",
      "Epoch 735/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2012 - accuracy: 0.9459 - val_loss: 0.1951 - val_accuracy: 0.9475\n",
      "Epoch 736/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2025 - accuracy: 0.9459 - val_loss: 0.1964 - val_accuracy: 0.9475\n",
      "Epoch 737/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2032 - accuracy: 0.9459 - val_loss: 0.1946 - val_accuracy: 0.9475\n",
      "Epoch 738/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2004 - accuracy: 0.9459 - val_loss: 0.2020 - val_accuracy: 0.9475\n",
      "Epoch 739/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2022 - accuracy: 0.9459 - val_loss: 0.1939 - val_accuracy: 0.9475\n",
      "Epoch 740/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2007 - accuracy: 0.9459 - val_loss: 0.1952 - val_accuracy: 0.9475\n",
      "Epoch 741/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2011 - accuracy: 0.9459 - val_loss: 0.1956 - val_accuracy: 0.9475\n",
      "Epoch 742/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2005 - accuracy: 0.9459 - val_loss: 0.1941 - val_accuracy: 0.9475\n",
      "Epoch 743/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2005 - accuracy: 0.9459 - val_loss: 0.1949 - val_accuracy: 0.9475\n",
      "Epoch 744/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2032 - accuracy: 0.9459 - val_loss: 0.1942 - val_accuracy: 0.9475\n",
      "Epoch 745/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2010 - accuracy: 0.9459 - val_loss: 0.1941 - val_accuracy: 0.9475\n",
      "Epoch 746/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2004 - accuracy: 0.9459 - val_loss: 0.1952 - val_accuracy: 0.9475\n",
      "Epoch 747/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2002 - accuracy: 0.9459 - val_loss: 0.1971 - val_accuracy: 0.9475\n",
      "Epoch 748/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2018 - accuracy: 0.9459 - val_loss: 0.1985 - val_accuracy: 0.9475\n",
      "Epoch 749/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2019 - accuracy: 0.9459 - val_loss: 0.1940 - val_accuracy: 0.9475\n",
      "Epoch 750/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.1999 - accuracy: 0.9459 - val_loss: 0.2004 - val_accuracy: 0.9475\n",
      "Epoch 751/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2023 - accuracy: 0.9459 - val_loss: 0.1967 - val_accuracy: 0.9475\n",
      "Epoch 752/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2021 - accuracy: 0.9459 - val_loss: 0.1967 - val_accuracy: 0.9475\n",
      "Epoch 753/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2010 - accuracy: 0.9459 - val_loss: 0.1940 - val_accuracy: 0.9475\n",
      "Epoch 754/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2023 - accuracy: 0.9459 - val_loss: 0.2000 - val_accuracy: 0.9475\n",
      "Epoch 755/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2013 - accuracy: 0.9459 - val_loss: 0.1960 - val_accuracy: 0.9475\n",
      "Epoch 756/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2003 - accuracy: 0.9459 - val_loss: 0.1964 - val_accuracy: 0.9475\n",
      "Epoch 757/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2005 - accuracy: 0.9459 - val_loss: 0.1950 - val_accuracy: 0.9475\n",
      "Epoch 758/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2020 - accuracy: 0.9459 - val_loss: 0.1939 - val_accuracy: 0.9475\n",
      "Epoch 759/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2015 - accuracy: 0.9459 - val_loss: 0.1993 - val_accuracy: 0.9475\n",
      "Epoch 760/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2004 - accuracy: 0.9459 - val_loss: 0.1994 - val_accuracy: 0.9475\n",
      "Epoch 761/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2024 - accuracy: 0.9459 - val_loss: 0.1937 - val_accuracy: 0.9475\n",
      "Epoch 762/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2004 - accuracy: 0.9459 - val_loss: 0.1941 - val_accuracy: 0.9475\n",
      "Epoch 763/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2005 - accuracy: 0.9459 - val_loss: 0.1941 - val_accuracy: 0.9475\n",
      "Epoch 764/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.1995 - accuracy: 0.9459 - val_loss: 0.1951 - val_accuracy: 0.9475\n",
      "Epoch 765/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2009 - accuracy: 0.9459 - val_loss: 0.1949 - val_accuracy: 0.9475\n",
      "Epoch 766/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2007 - accuracy: 0.9459 - val_loss: 0.1942 - val_accuracy: 0.9475\n",
      "Epoch 767/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2009 - accuracy: 0.9459 - val_loss: 0.1947 - val_accuracy: 0.9475\n",
      "Epoch 768/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.1997 - accuracy: 0.9459 - val_loss: 0.1974 - val_accuracy: 0.9475\n",
      "Epoch 769/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2001 - accuracy: 0.9459 - val_loss: 0.1949 - val_accuracy: 0.9475\n",
      "Epoch 770/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2003 - accuracy: 0.9459 - val_loss: 0.1943 - val_accuracy: 0.9475\n",
      "Epoch 771/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2012 - accuracy: 0.9459 - val_loss: 0.1992 - val_accuracy: 0.9475\n",
      "Epoch 772/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2019 - accuracy: 0.9459 - val_loss: 0.1979 - val_accuracy: 0.9475\n",
      "Epoch 773/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2018 - accuracy: 0.9459 - val_loss: 0.1942 - val_accuracy: 0.9475\n",
      "Epoch 774/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2004 - accuracy: 0.9459 - val_loss: 0.1981 - val_accuracy: 0.9475\n",
      "Epoch 775/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2012 - accuracy: 0.9459 - val_loss: 0.1970 - val_accuracy: 0.9475\n",
      "Epoch 776/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2004 - accuracy: 0.9459 - val_loss: 0.1942 - val_accuracy: 0.9475\n",
      "Epoch 777/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2001 - accuracy: 0.9459 - val_loss: 0.1939 - val_accuracy: 0.9475\n",
      "Epoch 778/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2009 - accuracy: 0.9459 - val_loss: 0.1961 - val_accuracy: 0.9475\n",
      "Epoch 779/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.1994 - accuracy: 0.9459 - val_loss: 0.2007 - val_accuracy: 0.9475\n",
      "Epoch 780/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2010 - accuracy: 0.9459 - val_loss: 0.1943 - val_accuracy: 0.9475\n",
      "Epoch 781/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.1995 - accuracy: 0.9459 - val_loss: 0.1951 - val_accuracy: 0.9475\n",
      "Epoch 782/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2008 - accuracy: 0.9459 - val_loss: 0.1945 - val_accuracy: 0.9475\n",
      "Epoch 783/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.1993 - accuracy: 0.9459 - val_loss: 0.1943 - val_accuracy: 0.9475\n",
      "Epoch 784/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2026 - accuracy: 0.9459 - val_loss: 0.2017 - val_accuracy: 0.9475\n",
      "Epoch 785/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2009 - accuracy: 0.9459 - val_loss: 0.1949 - val_accuracy: 0.9475\n",
      "Epoch 786/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2002 - accuracy: 0.9459 - val_loss: 0.1945 - val_accuracy: 0.9475\n",
      "Epoch 787/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2015 - accuracy: 0.9459 - val_loss: 0.1960 - val_accuracy: 0.9475\n",
      "Epoch 788/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.1998 - accuracy: 0.9459 - val_loss: 0.1947 - val_accuracy: 0.9475\n",
      "Epoch 789/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2014 - accuracy: 0.9459 - val_loss: 0.1947 - val_accuracy: 0.9475\n",
      "Epoch 790/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2003 - accuracy: 0.9459 - val_loss: 0.1983 - val_accuracy: 0.9475\n",
      "Epoch 791/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2008 - accuracy: 0.9459 - val_loss: 0.1964 - val_accuracy: 0.9475\n",
      "Epoch 792/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2009 - accuracy: 0.9459 - val_loss: 0.1941 - val_accuracy: 0.9475\n",
      "Epoch 793/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.1995 - accuracy: 0.9459 - val_loss: 0.1947 - val_accuracy: 0.9475\n",
      "Epoch 794/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2009 - accuracy: 0.9459 - val_loss: 0.1940 - val_accuracy: 0.9475\n",
      "Epoch 795/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2020 - accuracy: 0.9459 - val_loss: 0.1954 - val_accuracy: 0.9475\n",
      "Epoch 796/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.1993 - accuracy: 0.9459 - val_loss: 0.1940 - val_accuracy: 0.9475\n",
      "Epoch 797/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2012 - accuracy: 0.9459 - val_loss: 0.1937 - val_accuracy: 0.9475\n",
      "Epoch 798/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2008 - accuracy: 0.9459 - val_loss: 0.1962 - val_accuracy: 0.9475\n",
      "Epoch 799/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2006 - accuracy: 0.9459 - val_loss: 0.1940 - val_accuracy: 0.9475\n",
      "Epoch 800/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2001 - accuracy: 0.9459 - val_loss: 0.1940 - val_accuracy: 0.9475\n",
      "Epoch 801/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2007 - accuracy: 0.9459 - val_loss: 0.1944 - val_accuracy: 0.9475\n",
      "Epoch 802/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2002 - accuracy: 0.9459 - val_loss: 0.1946 - val_accuracy: 0.9475\n",
      "Epoch 803/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2000 - accuracy: 0.9459 - val_loss: 0.1962 - val_accuracy: 0.9475\n",
      "Epoch 804/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2012 - accuracy: 0.9459 - val_loss: 0.1942 - val_accuracy: 0.9475\n",
      "Epoch 805/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2013 - accuracy: 0.9459 - val_loss: 0.1962 - val_accuracy: 0.9475\n",
      "Epoch 806/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2013 - accuracy: 0.9459 - val_loss: 0.1941 - val_accuracy: 0.9475\n",
      "Epoch 807/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.1999 - accuracy: 0.9459 - val_loss: 0.1936 - val_accuracy: 0.9475\n",
      "Epoch 808/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2002 - accuracy: 0.9459 - val_loss: 0.1940 - val_accuracy: 0.9475\n",
      "Epoch 809/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.1996 - accuracy: 0.9459 - val_loss: 0.1937 - val_accuracy: 0.9475\n",
      "Epoch 810/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2006 - accuracy: 0.9459 - val_loss: 0.1984 - val_accuracy: 0.9475\n",
      "Epoch 811/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2001 - accuracy: 0.9459 - val_loss: 0.1937 - val_accuracy: 0.9475\n",
      "Epoch 812/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2010 - accuracy: 0.9459 - val_loss: 0.1962 - val_accuracy: 0.9475\n",
      "Epoch 813/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.1991 - accuracy: 0.9459 - val_loss: 0.1951 - val_accuracy: 0.9475\n",
      "Epoch 814/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.1999 - accuracy: 0.9459 - val_loss: 0.2002 - val_accuracy: 0.9475\n",
      "Epoch 815/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2009 - accuracy: 0.9459 - val_loss: 0.1952 - val_accuracy: 0.9475\n",
      "Epoch 816/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.1998 - accuracy: 0.9459 - val_loss: 0.1951 - val_accuracy: 0.9475\n",
      "Epoch 817/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2004 - accuracy: 0.9459 - val_loss: 0.1945 - val_accuracy: 0.9475\n",
      "Epoch 818/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2013 - accuracy: 0.9459 - val_loss: 0.1959 - val_accuracy: 0.9475\n",
      "Epoch 819/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2011 - accuracy: 0.9459 - val_loss: 0.1957 - val_accuracy: 0.9475\n",
      "Epoch 820/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2000 - accuracy: 0.9459 - val_loss: 0.1967 - val_accuracy: 0.9475\n",
      "Epoch 821/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2015 - accuracy: 0.9459 - val_loss: 0.1962 - val_accuracy: 0.9475\n",
      "Epoch 822/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.1998 - accuracy: 0.9459 - val_loss: 0.1944 - val_accuracy: 0.9475\n",
      "Epoch 823/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2002 - accuracy: 0.9459 - val_loss: 0.1953 - val_accuracy: 0.9475\n",
      "Epoch 824/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2008 - accuracy: 0.9459 - val_loss: 0.1965 - val_accuracy: 0.9475\n",
      "Epoch 825/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2001 - accuracy: 0.9459 - val_loss: 0.1950 - val_accuracy: 0.9475\n",
      "Epoch 826/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2014 - accuracy: 0.9459 - val_loss: 0.1965 - val_accuracy: 0.9475\n",
      "Epoch 827/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2006 - accuracy: 0.9459 - val_loss: 0.1941 - val_accuracy: 0.9475\n",
      "Epoch 828/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.1991 - accuracy: 0.9459 - val_loss: 0.1940 - val_accuracy: 0.9475\n",
      "Epoch 829/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2015 - accuracy: 0.9459 - val_loss: 0.1958 - val_accuracy: 0.9475\n",
      "Epoch 830/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2001 - accuracy: 0.9459 - val_loss: 0.1937 - val_accuracy: 0.9475\n",
      "Epoch 831/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.1993 - accuracy: 0.9459 - val_loss: 0.1939 - val_accuracy: 0.9475\n",
      "Epoch 832/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.1997 - accuracy: 0.9459 - val_loss: 0.1946 - val_accuracy: 0.9475\n",
      "Epoch 833/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2009 - accuracy: 0.9459 - val_loss: 0.1968 - val_accuracy: 0.9475\n",
      "Epoch 834/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2024 - accuracy: 0.9459 - val_loss: 0.1965 - val_accuracy: 0.9475\n",
      "Epoch 835/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2000 - accuracy: 0.9459 - val_loss: 0.1944 - val_accuracy: 0.9475\n",
      "Epoch 836/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2007 - accuracy: 0.9459 - val_loss: 0.1947 - val_accuracy: 0.9475\n",
      "Epoch 837/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2004 - accuracy: 0.9459 - val_loss: 0.1949 - val_accuracy: 0.9475\n",
      "Epoch 838/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.1996 - accuracy: 0.9459 - val_loss: 0.1937 - val_accuracy: 0.9475\n",
      "Epoch 839/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.1991 - accuracy: 0.9459 - val_loss: 0.1933 - val_accuracy: 0.9475\n",
      "Epoch 840/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.1997 - accuracy: 0.9459 - val_loss: 0.1938 - val_accuracy: 0.9475\n",
      "Epoch 841/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.1993 - accuracy: 0.9459 - val_loss: 0.1933 - val_accuracy: 0.9475\n",
      "Epoch 842/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2015 - accuracy: 0.9459 - val_loss: 0.1976 - val_accuracy: 0.9475\n",
      "Epoch 843/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2011 - accuracy: 0.9459 - val_loss: 0.1986 - val_accuracy: 0.9475\n",
      "Epoch 844/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2010 - accuracy: 0.9459 - val_loss: 0.1946 - val_accuracy: 0.9475\n",
      "Epoch 845/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2006 - accuracy: 0.9459 - val_loss: 0.1939 - val_accuracy: 0.9475\n",
      "Epoch 846/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2010 - accuracy: 0.9459 - val_loss: 0.1993 - val_accuracy: 0.9475\n",
      "Epoch 847/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2025 - accuracy: 0.9459 - val_loss: 0.1943 - val_accuracy: 0.9475\n",
      "Epoch 848/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2000 - accuracy: 0.9459 - val_loss: 0.1940 - val_accuracy: 0.9475\n",
      "Epoch 849/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.1998 - accuracy: 0.9459 - val_loss: 0.1938 - val_accuracy: 0.9475\n",
      "Epoch 850/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2005 - accuracy: 0.9459 - val_loss: 0.1941 - val_accuracy: 0.9475\n",
      "Epoch 851/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2003 - accuracy: 0.9459 - val_loss: 0.1947 - val_accuracy: 0.9475\n",
      "Epoch 852/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.1993 - accuracy: 0.9459 - val_loss: 0.1938 - val_accuracy: 0.9475\n",
      "Epoch 853/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2007 - accuracy: 0.9459 - val_loss: 0.1955 - val_accuracy: 0.9475\n",
      "Epoch 854/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.1995 - accuracy: 0.9459 - val_loss: 0.1934 - val_accuracy: 0.9475\n",
      "Epoch 855/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.1999 - accuracy: 0.9459 - val_loss: 0.1936 - val_accuracy: 0.9475\n",
      "Epoch 856/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2010 - accuracy: 0.9459 - val_loss: 0.1959 - val_accuracy: 0.9475\n",
      "Epoch 857/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2018 - accuracy: 0.9459 - val_loss: 0.1988 - val_accuracy: 0.9475\n",
      "Epoch 858/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2003 - accuracy: 0.9459 - val_loss: 0.1939 - val_accuracy: 0.9475\n",
      "Epoch 859/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2006 - accuracy: 0.9459 - val_loss: 0.1933 - val_accuracy: 0.9475\n",
      "Epoch 860/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2021 - accuracy: 0.9459 - val_loss: 0.1941 - val_accuracy: 0.9475\n",
      "Epoch 861/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2018 - accuracy: 0.9459 - val_loss: 0.1960 - val_accuracy: 0.9475\n",
      "Epoch 862/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2004 - accuracy: 0.9459 - val_loss: 0.1960 - val_accuracy: 0.9475\n",
      "Epoch 863/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2005 - accuracy: 0.9459 - val_loss: 0.1970 - val_accuracy: 0.9475\n",
      "Epoch 864/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2007 - accuracy: 0.9459 - val_loss: 0.1941 - val_accuracy: 0.9475\n",
      "Epoch 865/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.1988 - accuracy: 0.9459 - val_loss: 0.1944 - val_accuracy: 0.9475\n",
      "Epoch 866/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.1996 - accuracy: 0.9459 - val_loss: 0.1952 - val_accuracy: 0.9475\n",
      "Epoch 867/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2000 - accuracy: 0.9459 - val_loss: 0.1953 - val_accuracy: 0.9475\n",
      "Epoch 868/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.1998 - accuracy: 0.9459 - val_loss: 0.2001 - val_accuracy: 0.9475\n",
      "Epoch 869/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2017 - accuracy: 0.9459 - val_loss: 0.1941 - val_accuracy: 0.9475\n",
      "Epoch 870/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2002 - accuracy: 0.9459 - val_loss: 0.1936 - val_accuracy: 0.9475\n",
      "Epoch 871/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.1996 - accuracy: 0.9459 - val_loss: 0.1938 - val_accuracy: 0.9475\n",
      "Epoch 872/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2004 - accuracy: 0.9459 - val_loss: 0.1940 - val_accuracy: 0.9475\n",
      "Epoch 873/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.1999 - accuracy: 0.9459 - val_loss: 0.1992 - val_accuracy: 0.9475\n",
      "Epoch 874/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2010 - accuracy: 0.9459 - val_loss: 0.1954 - val_accuracy: 0.9475\n",
      "Epoch 875/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2029 - accuracy: 0.9459 - val_loss: 0.2005 - val_accuracy: 0.9475\n",
      "Epoch 876/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2004 - accuracy: 0.9459 - val_loss: 0.1943 - val_accuracy: 0.9475\n",
      "Epoch 877/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2016 - accuracy: 0.9459 - val_loss: 0.1960 - val_accuracy: 0.9475\n",
      "Epoch 878/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2002 - accuracy: 0.9459 - val_loss: 0.1939 - val_accuracy: 0.9475\n",
      "Epoch 879/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2003 - accuracy: 0.9459 - val_loss: 0.1951 - val_accuracy: 0.9475\n",
      "Epoch 880/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2011 - accuracy: 0.9459 - val_loss: 0.1935 - val_accuracy: 0.9475\n",
      "Epoch 881/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2016 - accuracy: 0.9459 - val_loss: 0.1965 - val_accuracy: 0.9475\n",
      "Epoch 882/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.1990 - accuracy: 0.9459 - val_loss: 0.1975 - val_accuracy: 0.9475\n",
      "Epoch 883/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2014 - accuracy: 0.9459 - val_loss: 0.1944 - val_accuracy: 0.9475\n",
      "Epoch 884/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2012 - accuracy: 0.9459 - val_loss: 0.1933 - val_accuracy: 0.9475\n",
      "Epoch 885/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.1997 - accuracy: 0.9459 - val_loss: 0.1994 - val_accuracy: 0.9475\n",
      "Epoch 886/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.1996 - accuracy: 0.9459 - val_loss: 0.1950 - val_accuracy: 0.9475\n",
      "Epoch 887/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2012 - accuracy: 0.9459 - val_loss: 0.1945 - val_accuracy: 0.9475\n",
      "Epoch 888/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2005 - accuracy: 0.9459 - val_loss: 0.1942 - val_accuracy: 0.9475\n",
      "Epoch 889/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2000 - accuracy: 0.9459 - val_loss: 0.1938 - val_accuracy: 0.9475\n",
      "Epoch 890/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.1998 - accuracy: 0.9459 - val_loss: 0.1945 - val_accuracy: 0.9475\n",
      "Epoch 891/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.1992 - accuracy: 0.9459 - val_loss: 0.1939 - val_accuracy: 0.9475\n",
      "Epoch 892/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.1995 - accuracy: 0.9459 - val_loss: 0.1982 - val_accuracy: 0.9475\n",
      "Epoch 893/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2007 - accuracy: 0.9459 - val_loss: 0.1950 - val_accuracy: 0.9475\n",
      "Epoch 894/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.1990 - accuracy: 0.9459 - val_loss: 0.1949 - val_accuracy: 0.9475\n",
      "Epoch 895/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2001 - accuracy: 0.9459 - val_loss: 0.1965 - val_accuracy: 0.9475\n",
      "Epoch 896/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2013 - accuracy: 0.9459 - val_loss: 0.1946 - val_accuracy: 0.9475\n",
      "Epoch 897/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2013 - accuracy: 0.9459 - val_loss: 0.1956 - val_accuracy: 0.9475\n",
      "Epoch 898/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2011 - accuracy: 0.9459 - val_loss: 0.2005 - val_accuracy: 0.9475\n",
      "Epoch 899/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2001 - accuracy: 0.9459 - val_loss: 0.1936 - val_accuracy: 0.9475\n",
      "Epoch 900/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.1996 - accuracy: 0.9459 - val_loss: 0.1949 - val_accuracy: 0.9475\n",
      "Epoch 901/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.1995 - accuracy: 0.9459 - val_loss: 0.1940 - val_accuracy: 0.9475\n",
      "Epoch 902/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.1992 - accuracy: 0.9459 - val_loss: 0.1937 - val_accuracy: 0.9475\n",
      "Epoch 903/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.1995 - accuracy: 0.9459 - val_loss: 0.1938 - val_accuracy: 0.9475\n",
      "Epoch 904/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2005 - accuracy: 0.9459 - val_loss: 0.1935 - val_accuracy: 0.9475\n",
      "Epoch 905/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.1989 - accuracy: 0.9459 - val_loss: 0.1972 - val_accuracy: 0.9475\n",
      "Epoch 906/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.1996 - accuracy: 0.9459 - val_loss: 0.1984 - val_accuracy: 0.9475\n",
      "Epoch 907/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.1999 - accuracy: 0.9459 - val_loss: 0.1955 - val_accuracy: 0.9475\n",
      "Epoch 908/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2002 - accuracy: 0.9459 - val_loss: 0.1936 - val_accuracy: 0.9475\n",
      "Epoch 909/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.1991 - accuracy: 0.9459 - val_loss: 0.1937 - val_accuracy: 0.9475\n",
      "Epoch 910/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2006 - accuracy: 0.9459 - val_loss: 0.1940 - val_accuracy: 0.9475\n",
      "Epoch 911/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2005 - accuracy: 0.9459 - val_loss: 0.1949 - val_accuracy: 0.9475\n",
      "Epoch 912/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.1993 - accuracy: 0.9459 - val_loss: 0.1938 - val_accuracy: 0.9475\n",
      "Epoch 913/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2007 - accuracy: 0.9459 - val_loss: 0.1943 - val_accuracy: 0.9475\n",
      "Epoch 914/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.1987 - accuracy: 0.9459 - val_loss: 0.1936 - val_accuracy: 0.9475\n",
      "Epoch 915/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.1988 - accuracy: 0.9459 - val_loss: 0.1965 - val_accuracy: 0.9475\n",
      "Epoch 916/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2000 - accuracy: 0.9459 - val_loss: 0.1944 - val_accuracy: 0.9475\n",
      "Epoch 917/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.1997 - accuracy: 0.9459 - val_loss: 0.1954 - val_accuracy: 0.9475\n",
      "Epoch 918/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.1998 - accuracy: 0.9459 - val_loss: 0.1937 - val_accuracy: 0.9475\n",
      "Epoch 919/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2003 - accuracy: 0.9459 - val_loss: 0.1956 - val_accuracy: 0.9475\n",
      "Epoch 920/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.1999 - accuracy: 0.9459 - val_loss: 0.1971 - val_accuracy: 0.9475\n",
      "Epoch 921/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2009 - accuracy: 0.9459 - val_loss: 0.1939 - val_accuracy: 0.9475\n",
      "Epoch 922/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.1996 - accuracy: 0.9459 - val_loss: 0.1953 - val_accuracy: 0.9475\n",
      "Epoch 923/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.1985 - accuracy: 0.9459 - val_loss: 0.1949 - val_accuracy: 0.9475\n",
      "Epoch 924/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2000 - accuracy: 0.9459 - val_loss: 0.1936 - val_accuracy: 0.9475\n",
      "Epoch 925/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.1993 - accuracy: 0.9459 - val_loss: 0.1940 - val_accuracy: 0.9475\n",
      "Epoch 926/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2008 - accuracy: 0.9459 - val_loss: 0.1947 - val_accuracy: 0.9475\n",
      "Epoch 927/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.1995 - accuracy: 0.9459 - val_loss: 0.1956 - val_accuracy: 0.9475\n",
      "Epoch 928/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2004 - accuracy: 0.9459 - val_loss: 0.1971 - val_accuracy: 0.9475\n",
      "Epoch 929/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2002 - accuracy: 0.9459 - val_loss: 0.1933 - val_accuracy: 0.9475\n",
      "Epoch 930/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.1989 - accuracy: 0.9459 - val_loss: 0.1939 - val_accuracy: 0.9475\n",
      "Epoch 931/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.1985 - accuracy: 0.9459 - val_loss: 0.1947 - val_accuracy: 0.9475\n",
      "Epoch 932/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.1999 - accuracy: 0.9459 - val_loss: 0.1944 - val_accuracy: 0.9475\n",
      "Epoch 933/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.1985 - accuracy: 0.9459 - val_loss: 0.1932 - val_accuracy: 0.9475\n",
      "Epoch 934/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2010 - accuracy: 0.9459 - val_loss: 0.1937 - val_accuracy: 0.9475\n",
      "Epoch 935/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2001 - accuracy: 0.9459 - val_loss: 0.1960 - val_accuracy: 0.9475\n",
      "Epoch 936/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2002 - accuracy: 0.9459 - val_loss: 0.1938 - val_accuracy: 0.9475\n",
      "Epoch 937/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2009 - accuracy: 0.9459 - val_loss: 0.1949 - val_accuracy: 0.9475\n",
      "Epoch 938/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2000 - accuracy: 0.9459 - val_loss: 0.1946 - val_accuracy: 0.9475\n",
      "Epoch 939/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2021 - accuracy: 0.9459 - val_loss: 0.1948 - val_accuracy: 0.9475\n",
      "Epoch 940/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.1999 - accuracy: 0.9459 - val_loss: 0.1951 - val_accuracy: 0.9475\n",
      "Epoch 941/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2003 - accuracy: 0.9459 - val_loss: 0.1949 - val_accuracy: 0.9475\n",
      "Epoch 942/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.1986 - accuracy: 0.9459 - val_loss: 0.1938 - val_accuracy: 0.9475\n",
      "Epoch 943/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.1995 - accuracy: 0.9459 - val_loss: 0.1933 - val_accuracy: 0.9475\n",
      "Epoch 944/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.1989 - accuracy: 0.9459 - val_loss: 0.1936 - val_accuracy: 0.9475\n",
      "Epoch 945/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.1988 - accuracy: 0.9459 - val_loss: 0.1969 - val_accuracy: 0.9475\n",
      "Epoch 946/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2030 - accuracy: 0.9459 - val_loss: 0.1974 - val_accuracy: 0.9475\n",
      "Epoch 947/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2010 - accuracy: 0.9459 - val_loss: 0.1949 - val_accuracy: 0.9475\n",
      "Epoch 948/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.1997 - accuracy: 0.9459 - val_loss: 0.1959 - val_accuracy: 0.9475\n",
      "Epoch 949/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.1989 - accuracy: 0.9459 - val_loss: 0.1943 - val_accuracy: 0.9475\n",
      "Epoch 950/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.1986 - accuracy: 0.9459 - val_loss: 0.1946 - val_accuracy: 0.9475\n",
      "Epoch 951/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2026 - accuracy: 0.9459 - val_loss: 0.1943 - val_accuracy: 0.9475\n",
      "Epoch 952/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2007 - accuracy: 0.9459 - val_loss: 0.1937 - val_accuracy: 0.9475\n",
      "Epoch 953/1000\n",
      "67/67 [==============================] - 2s 24ms/step - loss: 0.1994 - accuracy: 0.9459 - val_loss: 0.1987 - val_accuracy: 0.9475\n",
      "Epoch 954/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.1993 - accuracy: 0.9459 - val_loss: 0.1937 - val_accuracy: 0.9475\n",
      "Epoch 955/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.1994 - accuracy: 0.9459 - val_loss: 0.1937 - val_accuracy: 0.9475\n",
      "Epoch 956/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.1998 - accuracy: 0.9459 - val_loss: 0.1968 - val_accuracy: 0.9475\n",
      "Epoch 957/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2008 - accuracy: 0.9459 - val_loss: 0.1985 - val_accuracy: 0.9475\n",
      "Epoch 958/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2000 - accuracy: 0.9459 - val_loss: 0.1940 - val_accuracy: 0.9475\n",
      "Epoch 959/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.1992 - accuracy: 0.9459 - val_loss: 0.1940 - val_accuracy: 0.9475\n",
      "Epoch 960/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2000 - accuracy: 0.9459 - val_loss: 0.1954 - val_accuracy: 0.9475\n",
      "Epoch 961/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2004 - accuracy: 0.9459 - val_loss: 0.1933 - val_accuracy: 0.9475\n",
      "Epoch 962/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2004 - accuracy: 0.9459 - val_loss: 0.1947 - val_accuracy: 0.9475\n",
      "Epoch 963/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2003 - accuracy: 0.9459 - val_loss: 0.1943 - val_accuracy: 0.9475\n",
      "Epoch 964/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2004 - accuracy: 0.9459 - val_loss: 0.1939 - val_accuracy: 0.9475\n",
      "Epoch 965/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2009 - accuracy: 0.9459 - val_loss: 0.1941 - val_accuracy: 0.9475\n",
      "Epoch 966/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.1981 - accuracy: 0.9459 - val_loss: 0.1955 - val_accuracy: 0.9475\n",
      "Epoch 967/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.1999 - accuracy: 0.9459 - val_loss: 0.1956 - val_accuracy: 0.9475\n",
      "Epoch 968/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.1996 - accuracy: 0.9459 - val_loss: 0.1963 - val_accuracy: 0.9475\n",
      "Epoch 969/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2009 - accuracy: 0.9459 - val_loss: 0.1933 - val_accuracy: 0.9475\n",
      "Epoch 970/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2022 - accuracy: 0.9459 - val_loss: 0.1943 - val_accuracy: 0.9475\n",
      "Epoch 971/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.1998 - accuracy: 0.9459 - val_loss: 0.1951 - val_accuracy: 0.9475\n",
      "Epoch 972/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2007 - accuracy: 0.9459 - val_loss: 0.1984 - val_accuracy: 0.9475\n",
      "Epoch 973/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2003 - accuracy: 0.9459 - val_loss: 0.1939 - val_accuracy: 0.9475\n",
      "Epoch 974/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.1990 - accuracy: 0.9459 - val_loss: 0.1942 - val_accuracy: 0.9475\n",
      "Epoch 975/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.1995 - accuracy: 0.9459 - val_loss: 0.1938 - val_accuracy: 0.9475\n",
      "Epoch 976/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2001 - accuracy: 0.9459 - val_loss: 0.1946 - val_accuracy: 0.9475\n",
      "Epoch 977/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2011 - accuracy: 0.9459 - val_loss: 0.1940 - val_accuracy: 0.9475\n",
      "Epoch 978/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.1996 - accuracy: 0.9459 - val_loss: 0.1937 - val_accuracy: 0.9475\n",
      "Epoch 979/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2012 - accuracy: 0.9459 - val_loss: 0.1951 - val_accuracy: 0.9475\n",
      "Epoch 980/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.1996 - accuracy: 0.9459 - val_loss: 0.1934 - val_accuracy: 0.9475\n",
      "Epoch 981/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.1985 - accuracy: 0.9459 - val_loss: 0.1947 - val_accuracy: 0.9475\n",
      "Epoch 982/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.1988 - accuracy: 0.9459 - val_loss: 0.1934 - val_accuracy: 0.9475\n",
      "Epoch 983/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2014 - accuracy: 0.9459 - val_loss: 0.1948 - val_accuracy: 0.9475\n",
      "Epoch 984/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2014 - accuracy: 0.9459 - val_loss: 0.1970 - val_accuracy: 0.9475\n",
      "Epoch 985/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2006 - accuracy: 0.9459 - val_loss: 0.1940 - val_accuracy: 0.9475\n",
      "Epoch 986/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.1983 - accuracy: 0.9459 - val_loss: 0.1950 - val_accuracy: 0.9475\n",
      "Epoch 987/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2008 - accuracy: 0.9459 - val_loss: 0.1931 - val_accuracy: 0.9475\n",
      "Epoch 988/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.1993 - accuracy: 0.9459 - val_loss: 0.1994 - val_accuracy: 0.9475\n",
      "Epoch 989/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.1993 - accuracy: 0.9459 - val_loss: 0.1939 - val_accuracy: 0.9475\n",
      "Epoch 990/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2002 - accuracy: 0.9459 - val_loss: 0.1964 - val_accuracy: 0.9475\n",
      "Epoch 991/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2010 - accuracy: 0.9459 - val_loss: 0.1935 - val_accuracy: 0.9475\n",
      "Epoch 992/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.1988 - accuracy: 0.9459 - val_loss: 0.1939 - val_accuracy: 0.9475\n",
      "Epoch 993/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.1989 - accuracy: 0.9459 - val_loss: 0.1949 - val_accuracy: 0.9475\n",
      "Epoch 994/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.1990 - accuracy: 0.9459 - val_loss: 0.1935 - val_accuracy: 0.9475\n",
      "Epoch 995/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2011 - accuracy: 0.9459 - val_loss: 0.1941 - val_accuracy: 0.9475\n",
      "Epoch 996/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.1996 - accuracy: 0.9459 - val_loss: 0.1949 - val_accuracy: 0.9475\n",
      "Epoch 997/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.1984 - accuracy: 0.9459 - val_loss: 0.1939 - val_accuracy: 0.9475\n",
      "Epoch 998/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.1995 - accuracy: 0.9459 - val_loss: 0.1947 - val_accuracy: 0.9475\n",
      "Epoch 999/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.1983 - accuracy: 0.9459 - val_loss: 0.1939 - val_accuracy: 0.9475\n",
      "Epoch 1000/1000\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2011 - accuracy: 0.9459 - val_loss: 0.1937 - val_accuracy: 0.9475\n"
     ]
    }
   ],
   "source": [
    "from keras.callbacks import EarlyStopping\n",
    "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=100)\n",
    "history1=model.fit(X_audio_train, y_audio_train, batch_size=256, epochs=1000,\n",
    "                            validation_data=(X_audio_test, y_audio_test), callbacks=[es])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_hist(hist):\n",
    "    plt.plot(hist.history[\"accuracy\"])\n",
    "    plt.plot(hist.history[\"val_accuracy\"])\n",
    "    plt.title(\"model accuracy\")\n",
    "    plt.ylabel(\"accuracy\")\n",
    "    plt.xlabel(\"epoch\")\n",
    "    plt.legend([\"train\", \"validation\"], loc=\"lower right\")\n",
    "    plt.savefig('fakeav_audio_acc.eps', format='eps')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_loss(hist):\n",
    "    plt.plot(hist.history['loss'])\n",
    "    plt.plot(hist.history['val_loss'])\n",
    "    plt.title('model loss')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(['train', 'validation'], loc='upper right')\n",
    "    plt.savefig('fakeav_audio_loss.eps', format='eps')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.DataFrame(history1.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('fakeavceleb_aud_net.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The PostScript backend does not support transparency; partially transparent artists will be rendered opaque.\n"
     ]
    },
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"utf-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       "  \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<svg xmlns:xlink=\"http://www.w3.org/1999/xlink\" width=\"382.603125pt\" height=\"277.314375pt\" viewBox=\"0 0 382.603125 277.314375\" xmlns=\"http://www.w3.org/2000/svg\" version=\"1.1\">\n",
       " <metadata>\n",
       "  <rdf:RDF xmlns:dc=\"http://purl.org/dc/elements/1.1/\" xmlns:cc=\"http://creativecommons.org/ns#\" xmlns:rdf=\"http://www.w3.org/1999/02/22-rdf-syntax-ns#\">\n",
       "   <cc:Work>\n",
       "    <dc:type rdf:resource=\"http://purl.org/dc/dcmitype/StillImage\"/>\n",
       "    <dc:date>2022-07-06T18:00:22.416737</dc:date>\n",
       "    <dc:format>image/svg+xml</dc:format>\n",
       "    <dc:creator>\n",
       "     <cc:Agent>\n",
       "      <dc:title>Matplotlib v3.5.1, https://matplotlib.org/</dc:title>\n",
       "     </cc:Agent>\n",
       "    </dc:creator>\n",
       "   </cc:Work>\n",
       "  </rdf:RDF>\n",
       " </metadata>\n",
       " <defs>\n",
       "  <style type=\"text/css\">*{stroke-linejoin: round; stroke-linecap: butt}</style>\n",
       " </defs>\n",
       " <g id=\"figure_1\">\n",
       "  <g id=\"patch_1\">\n",
       "   <path d=\"M 0 277.314375 \n",
       "L 382.603125 277.314375 \n",
       "L 382.603125 0 \n",
       "L 0 0 \n",
       "L 0 277.314375 \n",
       "z\n",
       "\" style=\"fill: none\"/>\n",
       "  </g>\n",
       "  <g id=\"axes_1\">\n",
       "   <g id=\"patch_2\">\n",
       "    <path d=\"M 40.603125 239.758125 \n",
       "L 375.403125 239.758125 \n",
       "L 375.403125 22.318125 \n",
       "L 40.603125 22.318125 \n",
       "z\n",
       "\" style=\"fill: #ffffff\"/>\n",
       "   </g>\n",
       "   <g id=\"matplotlib.axis_1\">\n",
       "    <g id=\"xtick_1\">\n",
       "     <g id=\"line2d_1\">\n",
       "      <defs>\n",
       "       <path id=\"m20f2c87a9f\" d=\"M 0 0 \n",
       "L 0 3.5 \n",
       "\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </defs>\n",
       "      <g>\n",
       "       <use xlink:href=\"#m20f2c87a9f\" x=\"55.821307\" y=\"239.758125\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_1\">\n",
       "      <!-- 0 -->\n",
       "      <g transform=\"translate(52.640057 254.356562)scale(0.1 -0.1)\">\n",
       "       <defs>\n",
       "        <path id=\"DejaVuSans-30\" d=\"M 2034 4250 \n",
       "Q 1547 4250 1301 3770 \n",
       "Q 1056 3291 1056 2328 \n",
       "Q 1056 1369 1301 889 \n",
       "Q 1547 409 2034 409 \n",
       "Q 2525 409 2770 889 \n",
       "Q 3016 1369 3016 2328 \n",
       "Q 3016 3291 2770 3770 \n",
       "Q 2525 4250 2034 4250 \n",
       "z\n",
       "M 2034 4750 \n",
       "Q 2819 4750 3233 4129 \n",
       "Q 3647 3509 3647 2328 \n",
       "Q 3647 1150 3233 529 \n",
       "Q 2819 -91 2034 -91 \n",
       "Q 1250 -91 836 529 \n",
       "Q 422 1150 422 2328 \n",
       "Q 422 3509 836 4129 \n",
       "Q 1250 4750 2034 4750 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#DejaVuSans-30\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_2\">\n",
       "     <g id=\"line2d_2\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#m20f2c87a9f\" x=\"116.754968\" y=\"239.758125\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_2\">\n",
       "      <!-- 200 -->\n",
       "      <g transform=\"translate(107.211218 254.356562)scale(0.1 -0.1)\">\n",
       "       <defs>\n",
       "        <path id=\"DejaVuSans-32\" d=\"M 1228 531 \n",
       "L 3431 531 \n",
       "L 3431 0 \n",
       "L 469 0 \n",
       "L 469 531 \n",
       "Q 828 903 1448 1529 \n",
       "Q 2069 2156 2228 2338 \n",
       "Q 2531 2678 2651 2914 \n",
       "Q 2772 3150 2772 3378 \n",
       "Q 2772 3750 2511 3984 \n",
       "Q 2250 4219 1831 4219 \n",
       "Q 1534 4219 1204 4116 \n",
       "Q 875 4013 500 3803 \n",
       "L 500 4441 \n",
       "Q 881 4594 1212 4672 \n",
       "Q 1544 4750 1819 4750 \n",
       "Q 2544 4750 2975 4387 \n",
       "Q 3406 4025 3406 3419 \n",
       "Q 3406 3131 3298 2873 \n",
       "Q 3191 2616 2906 2266 \n",
       "Q 2828 2175 2409 1742 \n",
       "Q 1991 1309 1228 531 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#DejaVuSans-32\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-30\" x=\"63.623047\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-30\" x=\"127.246094\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_3\">\n",
       "     <g id=\"line2d_3\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#m20f2c87a9f\" x=\"177.688629\" y=\"239.758125\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_3\">\n",
       "      <!-- 400 -->\n",
       "      <g transform=\"translate(168.144879 254.356562)scale(0.1 -0.1)\">\n",
       "       <defs>\n",
       "        <path id=\"DejaVuSans-34\" d=\"M 2419 4116 \n",
       "L 825 1625 \n",
       "L 2419 1625 \n",
       "L 2419 4116 \n",
       "z\n",
       "M 2253 4666 \n",
       "L 3047 4666 \n",
       "L 3047 1625 \n",
       "L 3713 1625 \n",
       "L 3713 1100 \n",
       "L 3047 1100 \n",
       "L 3047 0 \n",
       "L 2419 0 \n",
       "L 2419 1100 \n",
       "L 313 1100 \n",
       "L 313 1709 \n",
       "L 2253 4666 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#DejaVuSans-34\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-30\" x=\"63.623047\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-30\" x=\"127.246094\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_4\">\n",
       "     <g id=\"line2d_4\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#m20f2c87a9f\" x=\"238.62229\" y=\"239.758125\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_4\">\n",
       "      <!-- 600 -->\n",
       "      <g transform=\"translate(229.07854 254.356562)scale(0.1 -0.1)\">\n",
       "       <defs>\n",
       "        <path id=\"DejaVuSans-36\" d=\"M 2113 2584 \n",
       "Q 1688 2584 1439 2293 \n",
       "Q 1191 2003 1191 1497 \n",
       "Q 1191 994 1439 701 \n",
       "Q 1688 409 2113 409 \n",
       "Q 2538 409 2786 701 \n",
       "Q 3034 994 3034 1497 \n",
       "Q 3034 2003 2786 2293 \n",
       "Q 2538 2584 2113 2584 \n",
       "z\n",
       "M 3366 4563 \n",
       "L 3366 3988 \n",
       "Q 3128 4100 2886 4159 \n",
       "Q 2644 4219 2406 4219 \n",
       "Q 1781 4219 1451 3797 \n",
       "Q 1122 3375 1075 2522 \n",
       "Q 1259 2794 1537 2939 \n",
       "Q 1816 3084 2150 3084 \n",
       "Q 2853 3084 3261 2657 \n",
       "Q 3669 2231 3669 1497 \n",
       "Q 3669 778 3244 343 \n",
       "Q 2819 -91 2113 -91 \n",
       "Q 1303 -91 875 529 \n",
       "Q 447 1150 447 2328 \n",
       "Q 447 3434 972 4092 \n",
       "Q 1497 4750 2381 4750 \n",
       "Q 2619 4750 2861 4703 \n",
       "Q 3103 4656 3366 4563 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#DejaVuSans-36\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-30\" x=\"63.623047\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-30\" x=\"127.246094\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_5\">\n",
       "     <g id=\"line2d_5\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#m20f2c87a9f\" x=\"299.555951\" y=\"239.758125\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_5\">\n",
       "      <!-- 800 -->\n",
       "      <g transform=\"translate(290.012201 254.356562)scale(0.1 -0.1)\">\n",
       "       <defs>\n",
       "        <path id=\"DejaVuSans-38\" d=\"M 2034 2216 \n",
       "Q 1584 2216 1326 1975 \n",
       "Q 1069 1734 1069 1313 \n",
       "Q 1069 891 1326 650 \n",
       "Q 1584 409 2034 409 \n",
       "Q 2484 409 2743 651 \n",
       "Q 3003 894 3003 1313 \n",
       "Q 3003 1734 2745 1975 \n",
       "Q 2488 2216 2034 2216 \n",
       "z\n",
       "M 1403 2484 \n",
       "Q 997 2584 770 2862 \n",
       "Q 544 3141 544 3541 \n",
       "Q 544 4100 942 4425 \n",
       "Q 1341 4750 2034 4750 \n",
       "Q 2731 4750 3128 4425 \n",
       "Q 3525 4100 3525 3541 \n",
       "Q 3525 3141 3298 2862 \n",
       "Q 3072 2584 2669 2484 \n",
       "Q 3125 2378 3379 2068 \n",
       "Q 3634 1759 3634 1313 \n",
       "Q 3634 634 3220 271 \n",
       "Q 2806 -91 2034 -91 \n",
       "Q 1263 -91 848 271 \n",
       "Q 434 634 434 1313 \n",
       "Q 434 1759 690 2068 \n",
       "Q 947 2378 1403 2484 \n",
       "z\n",
       "M 1172 3481 \n",
       "Q 1172 3119 1398 2916 \n",
       "Q 1625 2713 2034 2713 \n",
       "Q 2441 2713 2670 2916 \n",
       "Q 2900 3119 2900 3481 \n",
       "Q 2900 3844 2670 4047 \n",
       "Q 2441 4250 2034 4250 \n",
       "Q 1625 4250 1398 4047 \n",
       "Q 1172 3844 1172 3481 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#DejaVuSans-38\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-30\" x=\"63.623047\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-30\" x=\"127.246094\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_6\">\n",
       "     <g id=\"line2d_6\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#m20f2c87a9f\" x=\"360.489611\" y=\"239.758125\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_6\">\n",
       "      <!-- 1000 -->\n",
       "      <g transform=\"translate(347.764611 254.356562)scale(0.1 -0.1)\">\n",
       "       <defs>\n",
       "        <path id=\"DejaVuSans-31\" d=\"M 794 531 \n",
       "L 1825 531 \n",
       "L 1825 4091 \n",
       "L 703 3866 \n",
       "L 703 4441 \n",
       "L 1819 4666 \n",
       "L 2450 4666 \n",
       "L 2450 531 \n",
       "L 3481 531 \n",
       "L 3481 0 \n",
       "L 794 0 \n",
       "L 794 531 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#DejaVuSans-31\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-30\" x=\"63.623047\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-30\" x=\"127.246094\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-30\" x=\"190.869141\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"text_7\">\n",
       "     <!-- Epoch -->\n",
       "     <g transform=\"translate(192.692187 268.034687)scale(0.1 -0.1)\">\n",
       "      <defs>\n",
       "       <path id=\"DejaVuSans-45\" d=\"M 628 4666 \n",
       "L 3578 4666 \n",
       "L 3578 4134 \n",
       "L 1259 4134 \n",
       "L 1259 2753 \n",
       "L 3481 2753 \n",
       "L 3481 2222 \n",
       "L 1259 2222 \n",
       "L 1259 531 \n",
       "L 3634 531 \n",
       "L 3634 0 \n",
       "L 628 0 \n",
       "L 628 4666 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       <path id=\"DejaVuSans-70\" d=\"M 1159 525 \n",
       "L 1159 -1331 \n",
       "L 581 -1331 \n",
       "L 581 3500 \n",
       "L 1159 3500 \n",
       "L 1159 2969 \n",
       "Q 1341 3281 1617 3432 \n",
       "Q 1894 3584 2278 3584 \n",
       "Q 2916 3584 3314 3078 \n",
       "Q 3713 2572 3713 1747 \n",
       "Q 3713 922 3314 415 \n",
       "Q 2916 -91 2278 -91 \n",
       "Q 1894 -91 1617 61 \n",
       "Q 1341 213 1159 525 \n",
       "z\n",
       "M 3116 1747 \n",
       "Q 3116 2381 2855 2742 \n",
       "Q 2594 3103 2138 3103 \n",
       "Q 1681 3103 1420 2742 \n",
       "Q 1159 2381 1159 1747 \n",
       "Q 1159 1113 1420 752 \n",
       "Q 1681 391 2138 391 \n",
       "Q 2594 391 2855 752 \n",
       "Q 3116 1113 3116 1747 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       <path id=\"DejaVuSans-6f\" d=\"M 1959 3097 \n",
       "Q 1497 3097 1228 2736 \n",
       "Q 959 2375 959 1747 \n",
       "Q 959 1119 1226 758 \n",
       "Q 1494 397 1959 397 \n",
       "Q 2419 397 2687 759 \n",
       "Q 2956 1122 2956 1747 \n",
       "Q 2956 2369 2687 2733 \n",
       "Q 2419 3097 1959 3097 \n",
       "z\n",
       "M 1959 3584 \n",
       "Q 2709 3584 3137 3096 \n",
       "Q 3566 2609 3566 1747 \n",
       "Q 3566 888 3137 398 \n",
       "Q 2709 -91 1959 -91 \n",
       "Q 1206 -91 779 398 \n",
       "Q 353 888 353 1747 \n",
       "Q 353 2609 779 3096 \n",
       "Q 1206 3584 1959 3584 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       <path id=\"DejaVuSans-63\" d=\"M 3122 3366 \n",
       "L 3122 2828 \n",
       "Q 2878 2963 2633 3030 \n",
       "Q 2388 3097 2138 3097 \n",
       "Q 1578 3097 1268 2742 \n",
       "Q 959 2388 959 1747 \n",
       "Q 959 1106 1268 751 \n",
       "Q 1578 397 2138 397 \n",
       "Q 2388 397 2633 464 \n",
       "Q 2878 531 3122 666 \n",
       "L 3122 134 \n",
       "Q 2881 22 2623 -34 \n",
       "Q 2366 -91 2075 -91 \n",
       "Q 1284 -91 818 406 \n",
       "Q 353 903 353 1747 \n",
       "Q 353 2603 823 3093 \n",
       "Q 1294 3584 2113 3584 \n",
       "Q 2378 3584 2631 3529 \n",
       "Q 2884 3475 3122 3366 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       <path id=\"DejaVuSans-68\" d=\"M 3513 2113 \n",
       "L 3513 0 \n",
       "L 2938 0 \n",
       "L 2938 2094 \n",
       "Q 2938 2591 2744 2837 \n",
       "Q 2550 3084 2163 3084 \n",
       "Q 1697 3084 1428 2787 \n",
       "Q 1159 2491 1159 1978 \n",
       "L 1159 0 \n",
       "L 581 0 \n",
       "L 581 4863 \n",
       "L 1159 4863 \n",
       "L 1159 2956 \n",
       "Q 1366 3272 1645 3428 \n",
       "Q 1925 3584 2291 3584 \n",
       "Q 2894 3584 3203 3211 \n",
       "Q 3513 2838 3513 2113 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "      </defs>\n",
       "      <use xlink:href=\"#DejaVuSans-45\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-70\" x=\"63.183594\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-6f\" x=\"126.660156\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-63\" x=\"187.841797\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-68\" x=\"242.822266\"/>\n",
       "     </g>\n",
       "    </g>\n",
       "   </g>\n",
       "   <g id=\"matplotlib.axis_2\">\n",
       "    <g id=\"ytick_1\">\n",
       "     <g id=\"line2d_7\">\n",
       "      <defs>\n",
       "       <path id=\"m74fe3a449f\" d=\"M 0 0 \n",
       "L -3.5 0 \n",
       "\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </defs>\n",
       "      <g>\n",
       "       <use xlink:href=\"#m74fe3a449f\" x=\"40.603125\" y=\"232.513763\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_8\">\n",
       "      <!-- 0 -->\n",
       "      <g transform=\"translate(27.240625 236.312981)scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-30\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_2\">\n",
       "     <g id=\"line2d_8\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#m74fe3a449f\" x=\"40.603125\" y=\"205.180792\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_9\">\n",
       "      <!-- 2 -->\n",
       "      <g transform=\"translate(27.240625 208.980011)scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-32\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_3\">\n",
       "     <g id=\"line2d_9\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#m74fe3a449f\" x=\"40.603125\" y=\"177.847822\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_10\">\n",
       "      <!-- 4 -->\n",
       "      <g transform=\"translate(27.240625 181.64704)scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-34\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_4\">\n",
       "     <g id=\"line2d_10\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#m74fe3a449f\" x=\"40.603125\" y=\"150.514851\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_11\">\n",
       "      <!-- 6 -->\n",
       "      <g transform=\"translate(27.240625 154.31407)scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-36\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_5\">\n",
       "     <g id=\"line2d_11\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#m74fe3a449f\" x=\"40.603125\" y=\"123.181881\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_12\">\n",
       "      <!-- 8 -->\n",
       "      <g transform=\"translate(27.240625 126.9811)scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-38\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_6\">\n",
       "     <g id=\"line2d_12\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#m74fe3a449f\" x=\"40.603125\" y=\"95.84891\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_13\">\n",
       "      <!-- 10 -->\n",
       "      <g transform=\"translate(20.878125 99.648129)scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-31\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-30\" x=\"63.623047\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_7\">\n",
       "     <g id=\"line2d_13\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#m74fe3a449f\" x=\"40.603125\" y=\"68.51594\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_14\">\n",
       "      <!-- 12 -->\n",
       "      <g transform=\"translate(20.878125 72.315159)scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-31\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-32\" x=\"63.623047\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_8\">\n",
       "     <g id=\"line2d_14\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#m74fe3a449f\" x=\"40.603125\" y=\"41.182969\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_15\">\n",
       "      <!-- 14 -->\n",
       "      <g transform=\"translate(20.878125 44.982188)scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-31\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-34\" x=\"63.623047\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"text_16\">\n",
       "     <!-- Loss -->\n",
       "     <g transform=\"translate(14.798438 142.005312)rotate(-90)scale(0.1 -0.1)\">\n",
       "      <defs>\n",
       "       <path id=\"DejaVuSans-4c\" d=\"M 628 4666 \n",
       "L 1259 4666 \n",
       "L 1259 531 \n",
       "L 3531 531 \n",
       "L 3531 0 \n",
       "L 628 0 \n",
       "L 628 4666 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       <path id=\"DejaVuSans-73\" d=\"M 2834 3397 \n",
       "L 2834 2853 \n",
       "Q 2591 2978 2328 3040 \n",
       "Q 2066 3103 1784 3103 \n",
       "Q 1356 3103 1142 2972 \n",
       "Q 928 2841 928 2578 \n",
       "Q 928 2378 1081 2264 \n",
       "Q 1234 2150 1697 2047 \n",
       "L 1894 2003 \n",
       "Q 2506 1872 2764 1633 \n",
       "Q 3022 1394 3022 966 \n",
       "Q 3022 478 2636 193 \n",
       "Q 2250 -91 1575 -91 \n",
       "Q 1294 -91 989 -36 \n",
       "Q 684 19 347 128 \n",
       "L 347 722 \n",
       "Q 666 556 975 473 \n",
       "Q 1284 391 1588 391 \n",
       "Q 1994 391 2212 530 \n",
       "Q 2431 669 2431 922 \n",
       "Q 2431 1156 2273 1281 \n",
       "Q 2116 1406 1581 1522 \n",
       "L 1381 1569 \n",
       "Q 847 1681 609 1914 \n",
       "Q 372 2147 372 2553 \n",
       "Q 372 3047 722 3315 \n",
       "Q 1072 3584 1716 3584 \n",
       "Q 2034 3584 2315 3537 \n",
       "Q 2597 3491 2834 3397 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "      </defs>\n",
       "      <use xlink:href=\"#DejaVuSans-4c\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-6f\" x=\"53.962891\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-73\" x=\"115.144531\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-73\" x=\"167.244141\"/>\n",
       "     </g>\n",
       "    </g>\n",
       "   </g>\n",
       "   <g id=\"line2d_15\">\n",
       "    <path d=\"M 55.821307 32.201761 \n",
       "L 56.125975 115.956438 \n",
       "L 56.735312 143.404304 \n",
       "L 57.344648 161.422145 \n",
       "L 58.258653 180.576727 \n",
       "L 59.172658 193.918307 \n",
       "L 60.086663 203.251934 \n",
       "L 61.000668 210.019459 \n",
       "L 61.914673 214.922569 \n",
       "L 62.828678 218.542199 \n",
       "L 63.742683 221.211948 \n",
       "L 64.656688 223.20112 \n",
       "L 65.570693 224.708218 \n",
       "L 66.484697 225.845357 \n",
       "L 67.703371 226.915459 \n",
       "L 68.922044 227.692477 \n",
       "L 70.445385 228.353797 \n",
       "L 71.664059 228.714808 \n",
       "L 72.578064 228.87358 \n",
       "L 74.101405 229.139572 \n",
       "L 77.148088 229.391651 \n",
       "L 80.804108 229.550575 \n",
       "L 82.327449 229.595688 \n",
       "L 83.546123 229.605434 \n",
       "L 85.374132 229.62111 \n",
       "L 87.811479 229.645159 \n",
       "L 90.248825 229.665103 \n",
       "L 95.732855 229.660296 \n",
       "L 97.865533 229.68261 \n",
       "L 100.912216 229.668575 \n",
       "L 103.958899 229.68667 \n",
       "L 110.661602 229.701301 \n",
       "L 112.184943 229.682538 \n",
       "L 130.160373 229.722295 \n",
       "L 131.988383 229.723695 \n",
       "L 132.902388 229.689459 \n",
       "L 134.425729 229.735917 \n",
       "L 135.644403 229.710624 \n",
       "L 137.777081 229.740669 \n",
       "L 138.386417 229.686618 \n",
       "L 140.823764 229.71893 \n",
       "L 145.393788 229.702657 \n",
       "L 146.612462 229.742367 \n",
       "L 148.74514 229.721311 \n",
       "L 150.877818 229.733455 \n",
       "L 151.791823 229.700789 \n",
       "L 153.619833 229.719711 \n",
       "L 154.838506 229.721044 \n",
       "L 156.057179 229.755908 \n",
       "L 157.275852 229.714535 \n",
       "L 160.322535 229.733492 \n",
       "L 161.845877 229.723942 \n",
       "L 165.806565 229.728085 \n",
       "L 168.853248 229.738796 \n",
       "L 173.423272 229.731015 \n",
       "L 174.946614 229.751277 \n",
       "L 176.165287 229.745566 \n",
       "L 309.305336 229.768616 \n",
       "L 310.52401 229.775108 \n",
       "L 313.266024 229.76744 \n",
       "L 314.484697 229.774311 \n",
       "L 327.280766 229.787399 \n",
       "L 329.413444 229.779732 \n",
       "L 335.202142 229.783319 \n",
       "L 339.467498 229.782025 \n",
       "L 340.99084 229.768414 \n",
       "L 343.428186 229.79726 \n",
       "L 344.037523 229.767356 \n",
       "L 346.170201 229.790034 \n",
       "L 360.184943 229.766073 \n",
       "L 360.184943 229.766073 \n",
       "\" clip-path=\"url(#p732a8da0eb)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n",
       "   </g>\n",
       "   <g id=\"line2d_16\">\n",
       "    <path d=\"M 55.821307 109.085151 \n",
       "L 56.430643 138.291715 \n",
       "L 57.649317 171.244299 \n",
       "L 58.563322 187.442312 \n",
       "L 59.172658 195.606034 \n",
       "L 60.391331 206.769427 \n",
       "L 61.305336 212.56713 \n",
       "L 61.914673 215.609824 \n",
       "L 63.133346 220.060378 \n",
       "L 64.352019 223.013798 \n",
       "L 65.570693 225.036653 \n",
       "L 66.789366 226.409763 \n",
       "L 67.094034 226.714853 \n",
       "L 67.398702 226.859827 \n",
       "L 68.008039 227.357592 \n",
       "L 68.312707 227.583044 \n",
       "L 68.617376 227.596853 \n",
       "L 69.226712 228.042138 \n",
       "L 71.664059 228.882005 \n",
       "L 72.273395 228.962678 \n",
       "L 73.1874 229.170646 \n",
       "L 74.710742 229.355929 \n",
       "L 76.538752 229.495424 \n",
       "L 76.84342 229.264367 \n",
       "L 78.366761 229.586194 \n",
       "L 78.67143 229.481119 \n",
       "L 78.976098 229.617529 \n",
       "L 80.499439 229.620648 \n",
       "L 80.804108 229.582051 \n",
       "L 81.413444 229.683092 \n",
       "L 82.936786 229.547534 \n",
       "L 83.241454 229.718037 \n",
       "L 86.288137 229.738246 \n",
       "L 87.506811 229.726323 \n",
       "L 90.248825 229.737359 \n",
       "L 90.858162 229.730649 \n",
       "L 92.686172 229.763606 \n",
       "L 94.209513 229.750067 \n",
       "L 96.342191 229.768453 \n",
       "L 97.865533 229.770639 \n",
       "L 98.170201 229.493171 \n",
       "L 98.474869 229.766727 \n",
       "L 99.998211 229.751657 \n",
       "L 100.302879 229.685353 \n",
       "L 100.912216 229.765747 \n",
       "L 102.740226 229.764414 \n",
       "L 103.654231 229.760053 \n",
       "L 104.872904 229.782025 \n",
       "L 105.786909 229.785065 \n",
       "L 114.926958 229.777203 \n",
       "L 115.231626 229.584986 \n",
       "L 115.536295 229.766839 \n",
       "L 117.059636 229.787558 \n",
       "L 117.364304 229.721876 \n",
       "L 117.668973 229.794583 \n",
       "L 117.973641 229.654929 \n",
       "L 118.278309 229.793817 \n",
       "L 119.496982 229.752329 \n",
       "L 120.715656 229.798127 \n",
       "L 124.371675 229.801564 \n",
       "L 124.676344 229.662186 \n",
       "L 124.981012 229.802788 \n",
       "L 127.723027 229.715881 \n",
       "L 128.637032 229.802157 \n",
       "L 131.988383 229.75389 \n",
       "L 132.293051 229.649171 \n",
       "L 135.949071 229.804545 \n",
       "L 141.128432 229.774372 \n",
       "L 142.042437 229.819915 \n",
       "L 142.956442 229.793374 \n",
       "L 143.565779 229.73667 \n",
       "L 156.666516 229.809788 \n",
       "L 156.971184 229.757765 \n",
       "L 157.580521 229.782338 \n",
       "L 159.40853 229.820441 \n",
       "L 160.017867 229.816187 \n",
       "L 162.759882 229.814776 \n",
       "L 165.197228 229.816094 \n",
       "L 171.595263 229.828199 \n",
       "L 171.899931 229.7387 \n",
       "L 172.509268 229.819853 \n",
       "L 172.813936 229.749106 \n",
       "L 173.423272 229.807194 \n",
       "L 174.641946 229.83879 \n",
       "L 175.251282 229.782218 \n",
       "L 176.165287 229.830268 \n",
       "L 177.079292 229.797709 \n",
       "L 178.297965 229.82625 \n",
       "L 185.914673 229.813769 \n",
       "L 186.219341 229.667079 \n",
       "L 186.52401 229.836065 \n",
       "L 198.406073 229.827493 \n",
       "L 200.538752 229.830892 \n",
       "L 204.499439 229.804674 \n",
       "L 204.804108 229.734353 \n",
       "L 205.108776 229.851449 \n",
       "L 207.850791 229.817131 \n",
       "L 209.374132 229.827716 \n",
       "L 210.288137 229.8224 \n",
       "L 211.202142 229.841545 \n",
       "L 211.506811 229.762623 \n",
       "L 212.116147 229.838444 \n",
       "L 213.030152 229.844025 \n",
       "L 216.99084 229.847392 \n",
       "L 217.295508 229.74565 \n",
       "L 217.600177 229.837294 \n",
       "L 217.904845 229.74951 \n",
       "L 218.81885 229.848864 \n",
       "L 221.865533 229.717386 \n",
       "L 222.474869 229.849802 \n",
       "L 222.779538 229.662146 \n",
       "L 223.084206 229.838798 \n",
       "L 223.693543 229.848321 \n",
       "L 230.091577 229.814518 \n",
       "L 231.31025 229.848564 \n",
       "L 231.614919 229.732995 \n",
       "L 231.919587 229.854615 \n",
       "L 233.747597 229.842382 \n",
       "L 250.199685 229.846318 \n",
       "L 253.551037 229.845445 \n",
       "L 255.988383 229.825473 \n",
       "L 257.816393 229.83997 \n",
       "L 260.863076 229.852077 \n",
       "L 261.167744 229.732489 \n",
       "L 261.777081 229.855285 \n",
       "L 262.386417 229.778351 \n",
       "L 270.003125 229.858672 \n",
       "L 270.612462 229.841946 \n",
       "L 280.361847 229.75368 \n",
       "L 280.666516 229.864022 \n",
       "L 283.40853 229.801076 \n",
       "L 283.713199 229.862149 \n",
       "L 284.017867 229.774591 \n",
       "L 284.931872 229.862816 \n",
       "L 285.23654 229.779811 \n",
       "L 286.150545 229.849187 \n",
       "L 288.283223 229.847581 \n",
       "L 292.54858 229.833717 \n",
       "L 292.853248 229.771003 \n",
       "L 293.462584 229.847046 \n",
       "L 294.071921 229.858183 \n",
       "L 294.376589 229.757223 \n",
       "L 294.985926 229.855272 \n",
       "L 296.509268 229.829862 \n",
       "L 297.727941 229.84276 \n",
       "L 299.555951 229.857263 \n",
       "L 309.610005 229.828325 \n",
       "L 311.133346 229.872431 \n",
       "L 315.703371 229.871185 \n",
       "L 324.538752 229.856758 \n",
       "L 326.67143 229.856305 \n",
       "L 328.804108 229.840151 \n",
       "L 329.108776 229.773743 \n",
       "L 329.718113 229.849969 \n",
       "L 331.241454 229.818141 \n",
       "L 332.155459 229.868324 \n",
       "L 360.184943 229.866928 \n",
       "L 360.184943 229.866928 \n",
       "\" clip-path=\"url(#p732a8da0eb)\" style=\"fill: none; stroke: #ff7f0e; stroke-width: 1.5; stroke-linecap: square\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_3\">\n",
       "    <path d=\"M 40.603125 239.758125 \n",
       "L 40.603125 22.318125 \n",
       "\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_4\">\n",
       "    <path d=\"M 375.403125 239.758125 \n",
       "L 375.403125 22.318125 \n",
       "\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_5\">\n",
       "    <path d=\"M 40.603125 239.758125 \n",
       "L 375.403125 239.758125 \n",
       "\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_6\">\n",
       "    <path d=\"M 40.603125 22.318125 \n",
       "L 375.403125 22.318125 \n",
       "\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n",
       "   </g>\n",
       "   <g id=\"text_17\">\n",
       "    <!-- model loss -->\n",
       "    <g transform=\"translate(175.823437 16.318125)scale(0.12 -0.12)\">\n",
       "     <defs>\n",
       "      <path id=\"DejaVuSans-6d\" d=\"M 3328 2828 \n",
       "Q 3544 3216 3844 3400 \n",
       "Q 4144 3584 4550 3584 \n",
       "Q 5097 3584 5394 3201 \n",
       "Q 5691 2819 5691 2113 \n",
       "L 5691 0 \n",
       "L 5113 0 \n",
       "L 5113 2094 \n",
       "Q 5113 2597 4934 2840 \n",
       "Q 4756 3084 4391 3084 \n",
       "Q 3944 3084 3684 2787 \n",
       "Q 3425 2491 3425 1978 \n",
       "L 3425 0 \n",
       "L 2847 0 \n",
       "L 2847 2094 \n",
       "Q 2847 2600 2669 2842 \n",
       "Q 2491 3084 2119 3084 \n",
       "Q 1678 3084 1418 2786 \n",
       "Q 1159 2488 1159 1978 \n",
       "L 1159 0 \n",
       "L 581 0 \n",
       "L 581 3500 \n",
       "L 1159 3500 \n",
       "L 1159 2956 \n",
       "Q 1356 3278 1631 3431 \n",
       "Q 1906 3584 2284 3584 \n",
       "Q 2666 3584 2933 3390 \n",
       "Q 3200 3197 3328 2828 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "      <path id=\"DejaVuSans-64\" d=\"M 2906 2969 \n",
       "L 2906 4863 \n",
       "L 3481 4863 \n",
       "L 3481 0 \n",
       "L 2906 0 \n",
       "L 2906 525 \n",
       "Q 2725 213 2448 61 \n",
       "Q 2172 -91 1784 -91 \n",
       "Q 1150 -91 751 415 \n",
       "Q 353 922 353 1747 \n",
       "Q 353 2572 751 3078 \n",
       "Q 1150 3584 1784 3584 \n",
       "Q 2172 3584 2448 3432 \n",
       "Q 2725 3281 2906 2969 \n",
       "z\n",
       "M 947 1747 \n",
       "Q 947 1113 1208 752 \n",
       "Q 1469 391 1925 391 \n",
       "Q 2381 391 2643 752 \n",
       "Q 2906 1113 2906 1747 \n",
       "Q 2906 2381 2643 2742 \n",
       "Q 2381 3103 1925 3103 \n",
       "Q 1469 3103 1208 2742 \n",
       "Q 947 2381 947 1747 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "      <path id=\"DejaVuSans-65\" d=\"M 3597 1894 \n",
       "L 3597 1613 \n",
       "L 953 1613 \n",
       "Q 991 1019 1311 708 \n",
       "Q 1631 397 2203 397 \n",
       "Q 2534 397 2845 478 \n",
       "Q 3156 559 3463 722 \n",
       "L 3463 178 \n",
       "Q 3153 47 2828 -22 \n",
       "Q 2503 -91 2169 -91 \n",
       "Q 1331 -91 842 396 \n",
       "Q 353 884 353 1716 \n",
       "Q 353 2575 817 3079 \n",
       "Q 1281 3584 2069 3584 \n",
       "Q 2775 3584 3186 3129 \n",
       "Q 3597 2675 3597 1894 \n",
       "z\n",
       "M 3022 2063 \n",
       "Q 3016 2534 2758 2815 \n",
       "Q 2500 3097 2075 3097 \n",
       "Q 1594 3097 1305 2825 \n",
       "Q 1016 2553 972 2059 \n",
       "L 3022 2063 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "      <path id=\"DejaVuSans-6c\" d=\"M 603 4863 \n",
       "L 1178 4863 \n",
       "L 1178 0 \n",
       "L 603 0 \n",
       "L 603 4863 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "      <path id=\"DejaVuSans-20\" transform=\"scale(0.015625)\"/>\n",
       "     </defs>\n",
       "     <use xlink:href=\"#DejaVuSans-6d\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-6f\" x=\"97.412109\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-64\" x=\"158.59375\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-65\" x=\"222.070312\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-6c\" x=\"283.59375\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-20\" x=\"311.376953\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-6c\" x=\"343.164062\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-6f\" x=\"370.947266\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-73\" x=\"432.128906\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-73\" x=\"484.228516\"/>\n",
       "    </g>\n",
       "   </g>\n",
       "   <g id=\"legend_1\">\n",
       "    <g id=\"patch_7\">\n",
       "     <path d=\"M 287.16875 59.674375 \n",
       "L 368.403125 59.674375 \n",
       "Q 370.403125 59.674375 370.403125 57.674375 \n",
       "L 370.403125 29.318125 \n",
       "Q 370.403125 27.318125 368.403125 27.318125 \n",
       "L 287.16875 27.318125 \n",
       "Q 285.16875 27.318125 285.16875 29.318125 \n",
       "L 285.16875 57.674375 \n",
       "Q 285.16875 59.674375 287.16875 59.674375 \n",
       "z\n",
       "\" style=\"fill: #ffffff; opacity: 0.8; stroke: #cccccc; stroke-linejoin: miter\"/>\n",
       "    </g>\n",
       "    <g id=\"line2d_17\">\n",
       "     <path d=\"M 289.16875 35.416562 \n",
       "L 299.16875 35.416562 \n",
       "L 309.16875 35.416562 \n",
       "\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n",
       "    </g>\n",
       "    <g id=\"text_18\">\n",
       "     <!-- train -->\n",
       "     <g transform=\"translate(317.16875 38.916562)scale(0.1 -0.1)\">\n",
       "      <defs>\n",
       "       <path id=\"DejaVuSans-74\" d=\"M 1172 4494 \n",
       "L 1172 3500 \n",
       "L 2356 3500 \n",
       "L 2356 3053 \n",
       "L 1172 3053 \n",
       "L 1172 1153 \n",
       "Q 1172 725 1289 603 \n",
       "Q 1406 481 1766 481 \n",
       "L 2356 481 \n",
       "L 2356 0 \n",
       "L 1766 0 \n",
       "Q 1100 0 847 248 \n",
       "Q 594 497 594 1153 \n",
       "L 594 3053 \n",
       "L 172 3053 \n",
       "L 172 3500 \n",
       "L 594 3500 \n",
       "L 594 4494 \n",
       "L 1172 4494 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       <path id=\"DejaVuSans-72\" d=\"M 2631 2963 \n",
       "Q 2534 3019 2420 3045 \n",
       "Q 2306 3072 2169 3072 \n",
       "Q 1681 3072 1420 2755 \n",
       "Q 1159 2438 1159 1844 \n",
       "L 1159 0 \n",
       "L 581 0 \n",
       "L 581 3500 \n",
       "L 1159 3500 \n",
       "L 1159 2956 \n",
       "Q 1341 3275 1631 3429 \n",
       "Q 1922 3584 2338 3584 \n",
       "Q 2397 3584 2469 3576 \n",
       "Q 2541 3569 2628 3553 \n",
       "L 2631 2963 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       <path id=\"DejaVuSans-61\" d=\"M 2194 1759 \n",
       "Q 1497 1759 1228 1600 \n",
       "Q 959 1441 959 1056 \n",
       "Q 959 750 1161 570 \n",
       "Q 1363 391 1709 391 \n",
       "Q 2188 391 2477 730 \n",
       "Q 2766 1069 2766 1631 \n",
       "L 2766 1759 \n",
       "L 2194 1759 \n",
       "z\n",
       "M 3341 1997 \n",
       "L 3341 0 \n",
       "L 2766 0 \n",
       "L 2766 531 \n",
       "Q 2569 213 2275 61 \n",
       "Q 1981 -91 1556 -91 \n",
       "Q 1019 -91 701 211 \n",
       "Q 384 513 384 1019 \n",
       "Q 384 1609 779 1909 \n",
       "Q 1175 2209 1959 2209 \n",
       "L 2766 2209 \n",
       "L 2766 2266 \n",
       "Q 2766 2663 2505 2880 \n",
       "Q 2244 3097 1772 3097 \n",
       "Q 1472 3097 1187 3025 \n",
       "Q 903 2953 641 2809 \n",
       "L 641 3341 \n",
       "Q 956 3463 1253 3523 \n",
       "Q 1550 3584 1831 3584 \n",
       "Q 2591 3584 2966 3190 \n",
       "Q 3341 2797 3341 1997 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       <path id=\"DejaVuSans-69\" d=\"M 603 3500 \n",
       "L 1178 3500 \n",
       "L 1178 0 \n",
       "L 603 0 \n",
       "L 603 3500 \n",
       "z\n",
       "M 603 4863 \n",
       "L 1178 4863 \n",
       "L 1178 4134 \n",
       "L 603 4134 \n",
       "L 603 4863 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       <path id=\"DejaVuSans-6e\" d=\"M 3513 2113 \n",
       "L 3513 0 \n",
       "L 2938 0 \n",
       "L 2938 2094 \n",
       "Q 2938 2591 2744 2837 \n",
       "Q 2550 3084 2163 3084 \n",
       "Q 1697 3084 1428 2787 \n",
       "Q 1159 2491 1159 1978 \n",
       "L 1159 0 \n",
       "L 581 0 \n",
       "L 581 3500 \n",
       "L 1159 3500 \n",
       "L 1159 2956 \n",
       "Q 1366 3272 1645 3428 \n",
       "Q 1925 3584 2291 3584 \n",
       "Q 2894 3584 3203 3211 \n",
       "Q 3513 2838 3513 2113 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "      </defs>\n",
       "      <use xlink:href=\"#DejaVuSans-74\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-72\" x=\"39.208984\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-61\" x=\"80.322266\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-69\" x=\"141.601562\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-6e\" x=\"169.384766\"/>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"line2d_18\">\n",
       "     <path d=\"M 289.16875 50.094687 \n",
       "L 299.16875 50.094687 \n",
       "L 309.16875 50.094687 \n",
       "\" style=\"fill: none; stroke: #ff7f0e; stroke-width: 1.5; stroke-linecap: square\"/>\n",
       "    </g>\n",
       "    <g id=\"text_19\">\n",
       "     <!-- validation -->\n",
       "     <g transform=\"translate(317.16875 53.594687)scale(0.1 -0.1)\">\n",
       "      <defs>\n",
       "       <path id=\"DejaVuSans-76\" d=\"M 191 3500 \n",
       "L 800 3500 \n",
       "L 1894 563 \n",
       "L 2988 3500 \n",
       "L 3597 3500 \n",
       "L 2284 0 \n",
       "L 1503 0 \n",
       "L 191 3500 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "      </defs>\n",
       "      <use xlink:href=\"#DejaVuSans-76\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-61\" x=\"59.179688\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-6c\" x=\"120.458984\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-69\" x=\"148.242188\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-64\" x=\"176.025391\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-61\" x=\"239.501953\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-74\" x=\"300.78125\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-69\" x=\"339.990234\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-6f\" x=\"367.773438\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-6e\" x=\"428.955078\"/>\n",
       "     </g>\n",
       "    </g>\n",
       "   </g>\n",
       "  </g>\n",
       " </g>\n",
       " <defs>\n",
       "  <clipPath id=\"p732a8da0eb\">\n",
       "   <rect x=\"40.603125\" y=\"22.318125\" width=\"334.8\" height=\"217.44\"/>\n",
       "  </clipPath>\n",
       " </defs>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_loss(history1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The PostScript backend does not support transparency; partially transparent artists will be rendered opaque.\n"
     ]
    },
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"utf-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       "  \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<svg xmlns:xlink=\"http://www.w3.org/1999/xlink\" width=\"392.14375pt\" height=\"277.314375pt\" viewBox=\"0 0 392.14375 277.314375\" xmlns=\"http://www.w3.org/2000/svg\" version=\"1.1\">\n",
       " <metadata>\n",
       "  <rdf:RDF xmlns:dc=\"http://purl.org/dc/elements/1.1/\" xmlns:cc=\"http://creativecommons.org/ns#\" xmlns:rdf=\"http://www.w3.org/1999/02/22-rdf-syntax-ns#\">\n",
       "   <cc:Work>\n",
       "    <dc:type rdf:resource=\"http://purl.org/dc/dcmitype/StillImage\"/>\n",
       "    <dc:date>2022-07-06T18:00:33.879508</dc:date>\n",
       "    <dc:format>image/svg+xml</dc:format>\n",
       "    <dc:creator>\n",
       "     <cc:Agent>\n",
       "      <dc:title>Matplotlib v3.5.1, https://matplotlib.org/</dc:title>\n",
       "     </cc:Agent>\n",
       "    </dc:creator>\n",
       "   </cc:Work>\n",
       "  </rdf:RDF>\n",
       " </metadata>\n",
       " <defs>\n",
       "  <style type=\"text/css\">*{stroke-linejoin: round; stroke-linecap: butt}</style>\n",
       " </defs>\n",
       " <g id=\"figure_1\">\n",
       "  <g id=\"patch_1\">\n",
       "   <path d=\"M 0 277.314375 \n",
       "L 392.14375 277.314375 \n",
       "L 392.14375 0 \n",
       "L 0 0 \n",
       "L 0 277.314375 \n",
       "z\n",
       "\" style=\"fill: none\"/>\n",
       "  </g>\n",
       "  <g id=\"axes_1\">\n",
       "   <g id=\"patch_2\">\n",
       "    <path d=\"M 50.14375 239.758125 \n",
       "L 384.94375 239.758125 \n",
       "L 384.94375 22.318125 \n",
       "L 50.14375 22.318125 \n",
       "z\n",
       "\" style=\"fill: #ffffff\"/>\n",
       "   </g>\n",
       "   <g id=\"matplotlib.axis_1\">\n",
       "    <g id=\"xtick_1\">\n",
       "     <g id=\"line2d_1\">\n",
       "      <defs>\n",
       "       <path id=\"mcb902d4128\" d=\"M 0 0 \n",
       "L 0 3.5 \n",
       "\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </defs>\n",
       "      <g>\n",
       "       <use xlink:href=\"#mcb902d4128\" x=\"65.361932\" y=\"239.758125\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_1\">\n",
       "      <!-- 0 -->\n",
       "      <g transform=\"translate(62.180682 254.356562)scale(0.1 -0.1)\">\n",
       "       <defs>\n",
       "        <path id=\"DejaVuSans-30\" d=\"M 2034 4250 \n",
       "Q 1547 4250 1301 3770 \n",
       "Q 1056 3291 1056 2328 \n",
       "Q 1056 1369 1301 889 \n",
       "Q 1547 409 2034 409 \n",
       "Q 2525 409 2770 889 \n",
       "Q 3016 1369 3016 2328 \n",
       "Q 3016 3291 2770 3770 \n",
       "Q 2525 4250 2034 4250 \n",
       "z\n",
       "M 2034 4750 \n",
       "Q 2819 4750 3233 4129 \n",
       "Q 3647 3509 3647 2328 \n",
       "Q 3647 1150 3233 529 \n",
       "Q 2819 -91 2034 -91 \n",
       "Q 1250 -91 836 529 \n",
       "Q 422 1150 422 2328 \n",
       "Q 422 3509 836 4129 \n",
       "Q 1250 4750 2034 4750 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#DejaVuSans-30\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_2\">\n",
       "     <g id=\"line2d_2\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#mcb902d4128\" x=\"126.295593\" y=\"239.758125\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_2\">\n",
       "      <!-- 200 -->\n",
       "      <g transform=\"translate(116.751843 254.356562)scale(0.1 -0.1)\">\n",
       "       <defs>\n",
       "        <path id=\"DejaVuSans-32\" d=\"M 1228 531 \n",
       "L 3431 531 \n",
       "L 3431 0 \n",
       "L 469 0 \n",
       "L 469 531 \n",
       "Q 828 903 1448 1529 \n",
       "Q 2069 2156 2228 2338 \n",
       "Q 2531 2678 2651 2914 \n",
       "Q 2772 3150 2772 3378 \n",
       "Q 2772 3750 2511 3984 \n",
       "Q 2250 4219 1831 4219 \n",
       "Q 1534 4219 1204 4116 \n",
       "Q 875 4013 500 3803 \n",
       "L 500 4441 \n",
       "Q 881 4594 1212 4672 \n",
       "Q 1544 4750 1819 4750 \n",
       "Q 2544 4750 2975 4387 \n",
       "Q 3406 4025 3406 3419 \n",
       "Q 3406 3131 3298 2873 \n",
       "Q 3191 2616 2906 2266 \n",
       "Q 2828 2175 2409 1742 \n",
       "Q 1991 1309 1228 531 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#DejaVuSans-32\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-30\" x=\"63.623047\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-30\" x=\"127.246094\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_3\">\n",
       "     <g id=\"line2d_3\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#mcb902d4128\" x=\"187.229254\" y=\"239.758125\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_3\">\n",
       "      <!-- 400 -->\n",
       "      <g transform=\"translate(177.685504 254.356562)scale(0.1 -0.1)\">\n",
       "       <defs>\n",
       "        <path id=\"DejaVuSans-34\" d=\"M 2419 4116 \n",
       "L 825 1625 \n",
       "L 2419 1625 \n",
       "L 2419 4116 \n",
       "z\n",
       "M 2253 4666 \n",
       "L 3047 4666 \n",
       "L 3047 1625 \n",
       "L 3713 1625 \n",
       "L 3713 1100 \n",
       "L 3047 1100 \n",
       "L 3047 0 \n",
       "L 2419 0 \n",
       "L 2419 1100 \n",
       "L 313 1100 \n",
       "L 313 1709 \n",
       "L 2253 4666 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#DejaVuSans-34\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-30\" x=\"63.623047\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-30\" x=\"127.246094\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_4\">\n",
       "     <g id=\"line2d_4\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#mcb902d4128\" x=\"248.162915\" y=\"239.758125\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_4\">\n",
       "      <!-- 600 -->\n",
       "      <g transform=\"translate(238.619165 254.356562)scale(0.1 -0.1)\">\n",
       "       <defs>\n",
       "        <path id=\"DejaVuSans-36\" d=\"M 2113 2584 \n",
       "Q 1688 2584 1439 2293 \n",
       "Q 1191 2003 1191 1497 \n",
       "Q 1191 994 1439 701 \n",
       "Q 1688 409 2113 409 \n",
       "Q 2538 409 2786 701 \n",
       "Q 3034 994 3034 1497 \n",
       "Q 3034 2003 2786 2293 \n",
       "Q 2538 2584 2113 2584 \n",
       "z\n",
       "M 3366 4563 \n",
       "L 3366 3988 \n",
       "Q 3128 4100 2886 4159 \n",
       "Q 2644 4219 2406 4219 \n",
       "Q 1781 4219 1451 3797 \n",
       "Q 1122 3375 1075 2522 \n",
       "Q 1259 2794 1537 2939 \n",
       "Q 1816 3084 2150 3084 \n",
       "Q 2853 3084 3261 2657 \n",
       "Q 3669 2231 3669 1497 \n",
       "Q 3669 778 3244 343 \n",
       "Q 2819 -91 2113 -91 \n",
       "Q 1303 -91 875 529 \n",
       "Q 447 1150 447 2328 \n",
       "Q 447 3434 972 4092 \n",
       "Q 1497 4750 2381 4750 \n",
       "Q 2619 4750 2861 4703 \n",
       "Q 3103 4656 3366 4563 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#DejaVuSans-36\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-30\" x=\"63.623047\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-30\" x=\"127.246094\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_5\">\n",
       "     <g id=\"line2d_5\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#mcb902d4128\" x=\"309.096576\" y=\"239.758125\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_5\">\n",
       "      <!-- 800 -->\n",
       "      <g transform=\"translate(299.552826 254.356562)scale(0.1 -0.1)\">\n",
       "       <defs>\n",
       "        <path id=\"DejaVuSans-38\" d=\"M 2034 2216 \n",
       "Q 1584 2216 1326 1975 \n",
       "Q 1069 1734 1069 1313 \n",
       "Q 1069 891 1326 650 \n",
       "Q 1584 409 2034 409 \n",
       "Q 2484 409 2743 651 \n",
       "Q 3003 894 3003 1313 \n",
       "Q 3003 1734 2745 1975 \n",
       "Q 2488 2216 2034 2216 \n",
       "z\n",
       "M 1403 2484 \n",
       "Q 997 2584 770 2862 \n",
       "Q 544 3141 544 3541 \n",
       "Q 544 4100 942 4425 \n",
       "Q 1341 4750 2034 4750 \n",
       "Q 2731 4750 3128 4425 \n",
       "Q 3525 4100 3525 3541 \n",
       "Q 3525 3141 3298 2862 \n",
       "Q 3072 2584 2669 2484 \n",
       "Q 3125 2378 3379 2068 \n",
       "Q 3634 1759 3634 1313 \n",
       "Q 3634 634 3220 271 \n",
       "Q 2806 -91 2034 -91 \n",
       "Q 1263 -91 848 271 \n",
       "Q 434 634 434 1313 \n",
       "Q 434 1759 690 2068 \n",
       "Q 947 2378 1403 2484 \n",
       "z\n",
       "M 1172 3481 \n",
       "Q 1172 3119 1398 2916 \n",
       "Q 1625 2713 2034 2713 \n",
       "Q 2441 2713 2670 2916 \n",
       "Q 2900 3119 2900 3481 \n",
       "Q 2900 3844 2670 4047 \n",
       "Q 2441 4250 2034 4250 \n",
       "Q 1625 4250 1398 4047 \n",
       "Q 1172 3844 1172 3481 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#DejaVuSans-38\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-30\" x=\"63.623047\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-30\" x=\"127.246094\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_6\">\n",
       "     <g id=\"line2d_6\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#mcb902d4128\" x=\"370.030236\" y=\"239.758125\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_6\">\n",
       "      <!-- 1000 -->\n",
       "      <g transform=\"translate(357.305236 254.356562)scale(0.1 -0.1)\">\n",
       "       <defs>\n",
       "        <path id=\"DejaVuSans-31\" d=\"M 794 531 \n",
       "L 1825 531 \n",
       "L 1825 4091 \n",
       "L 703 3866 \n",
       "L 703 4441 \n",
       "L 1819 4666 \n",
       "L 2450 4666 \n",
       "L 2450 531 \n",
       "L 3481 531 \n",
       "L 3481 0 \n",
       "L 794 0 \n",
       "L 794 531 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#DejaVuSans-31\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-30\" x=\"63.623047\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-30\" x=\"127.246094\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-30\" x=\"190.869141\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"text_7\">\n",
       "     <!-- epoch -->\n",
       "     <g transform=\"translate(202.315625 268.034687)scale(0.1 -0.1)\">\n",
       "      <defs>\n",
       "       <path id=\"DejaVuSans-65\" d=\"M 3597 1894 \n",
       "L 3597 1613 \n",
       "L 953 1613 \n",
       "Q 991 1019 1311 708 \n",
       "Q 1631 397 2203 397 \n",
       "Q 2534 397 2845 478 \n",
       "Q 3156 559 3463 722 \n",
       "L 3463 178 \n",
       "Q 3153 47 2828 -22 \n",
       "Q 2503 -91 2169 -91 \n",
       "Q 1331 -91 842 396 \n",
       "Q 353 884 353 1716 \n",
       "Q 353 2575 817 3079 \n",
       "Q 1281 3584 2069 3584 \n",
       "Q 2775 3584 3186 3129 \n",
       "Q 3597 2675 3597 1894 \n",
       "z\n",
       "M 3022 2063 \n",
       "Q 3016 2534 2758 2815 \n",
       "Q 2500 3097 2075 3097 \n",
       "Q 1594 3097 1305 2825 \n",
       "Q 1016 2553 972 2059 \n",
       "L 3022 2063 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       <path id=\"DejaVuSans-70\" d=\"M 1159 525 \n",
       "L 1159 -1331 \n",
       "L 581 -1331 \n",
       "L 581 3500 \n",
       "L 1159 3500 \n",
       "L 1159 2969 \n",
       "Q 1341 3281 1617 3432 \n",
       "Q 1894 3584 2278 3584 \n",
       "Q 2916 3584 3314 3078 \n",
       "Q 3713 2572 3713 1747 \n",
       "Q 3713 922 3314 415 \n",
       "Q 2916 -91 2278 -91 \n",
       "Q 1894 -91 1617 61 \n",
       "Q 1341 213 1159 525 \n",
       "z\n",
       "M 3116 1747 \n",
       "Q 3116 2381 2855 2742 \n",
       "Q 2594 3103 2138 3103 \n",
       "Q 1681 3103 1420 2742 \n",
       "Q 1159 2381 1159 1747 \n",
       "Q 1159 1113 1420 752 \n",
       "Q 1681 391 2138 391 \n",
       "Q 2594 391 2855 752 \n",
       "Q 3116 1113 3116 1747 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       <path id=\"DejaVuSans-6f\" d=\"M 1959 3097 \n",
       "Q 1497 3097 1228 2736 \n",
       "Q 959 2375 959 1747 \n",
       "Q 959 1119 1226 758 \n",
       "Q 1494 397 1959 397 \n",
       "Q 2419 397 2687 759 \n",
       "Q 2956 1122 2956 1747 \n",
       "Q 2956 2369 2687 2733 \n",
       "Q 2419 3097 1959 3097 \n",
       "z\n",
       "M 1959 3584 \n",
       "Q 2709 3584 3137 3096 \n",
       "Q 3566 2609 3566 1747 \n",
       "Q 3566 888 3137 398 \n",
       "Q 2709 -91 1959 -91 \n",
       "Q 1206 -91 779 398 \n",
       "Q 353 888 353 1747 \n",
       "Q 353 2609 779 3096 \n",
       "Q 1206 3584 1959 3584 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       <path id=\"DejaVuSans-63\" d=\"M 3122 3366 \n",
       "L 3122 2828 \n",
       "Q 2878 2963 2633 3030 \n",
       "Q 2388 3097 2138 3097 \n",
       "Q 1578 3097 1268 2742 \n",
       "Q 959 2388 959 1747 \n",
       "Q 959 1106 1268 751 \n",
       "Q 1578 397 2138 397 \n",
       "Q 2388 397 2633 464 \n",
       "Q 2878 531 3122 666 \n",
       "L 3122 134 \n",
       "Q 2881 22 2623 -34 \n",
       "Q 2366 -91 2075 -91 \n",
       "Q 1284 -91 818 406 \n",
       "Q 353 903 353 1747 \n",
       "Q 353 2603 823 3093 \n",
       "Q 1294 3584 2113 3584 \n",
       "Q 2378 3584 2631 3529 \n",
       "Q 2884 3475 3122 3366 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       <path id=\"DejaVuSans-68\" d=\"M 3513 2113 \n",
       "L 3513 0 \n",
       "L 2938 0 \n",
       "L 2938 2094 \n",
       "Q 2938 2591 2744 2837 \n",
       "Q 2550 3084 2163 3084 \n",
       "Q 1697 3084 1428 2787 \n",
       "Q 1159 2491 1159 1978 \n",
       "L 1159 0 \n",
       "L 581 0 \n",
       "L 581 4863 \n",
       "L 1159 4863 \n",
       "L 1159 2956 \n",
       "Q 1366 3272 1645 3428 \n",
       "Q 1925 3584 2291 3584 \n",
       "Q 2894 3584 3203 3211 \n",
       "Q 3513 2838 3513 2113 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "      </defs>\n",
       "      <use xlink:href=\"#DejaVuSans-65\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-70\" x=\"61.523438\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-6f\" x=\"125\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-63\" x=\"186.181641\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-68\" x=\"241.162109\"/>\n",
       "     </g>\n",
       "    </g>\n",
       "   </g>\n",
       "   <g id=\"matplotlib.axis_2\">\n",
       "    <g id=\"ytick_1\">\n",
       "     <g id=\"line2d_7\">\n",
       "      <defs>\n",
       "       <path id=\"mbe9e75c0c8\" d=\"M 0 0 \n",
       "L -3.5 0 \n",
       "\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </defs>\n",
       "      <g>\n",
       "       <use xlink:href=\"#mbe9e75c0c8\" x=\"50.14375\" y=\"233.936359\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_8\">\n",
       "      <!-- 0.88 -->\n",
       "      <g transform=\"translate(20.878125 237.735577)scale(0.1 -0.1)\">\n",
       "       <defs>\n",
       "        <path id=\"DejaVuSans-2e\" d=\"M 684 794 \n",
       "L 1344 794 \n",
       "L 1344 0 \n",
       "L 684 0 \n",
       "L 684 794 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#DejaVuSans-30\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-38\" x=\"95.410156\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-38\" x=\"159.033203\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_2\">\n",
       "     <g id=\"line2d_8\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#mbe9e75c0c8\" x=\"50.14375\" y=\"204.068236\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_9\">\n",
       "      <!-- 0.89 -->\n",
       "      <g transform=\"translate(20.878125 207.867455)scale(0.1 -0.1)\">\n",
       "       <defs>\n",
       "        <path id=\"DejaVuSans-39\" d=\"M 703 97 \n",
       "L 703 672 \n",
       "Q 941 559 1184 500 \n",
       "Q 1428 441 1663 441 \n",
       "Q 2288 441 2617 861 \n",
       "Q 2947 1281 2994 2138 \n",
       "Q 2813 1869 2534 1725 \n",
       "Q 2256 1581 1919 1581 \n",
       "Q 1219 1581 811 2004 \n",
       "Q 403 2428 403 3163 \n",
       "Q 403 3881 828 4315 \n",
       "Q 1253 4750 1959 4750 \n",
       "Q 2769 4750 3195 4129 \n",
       "Q 3622 3509 3622 2328 \n",
       "Q 3622 1225 3098 567 \n",
       "Q 2575 -91 1691 -91 \n",
       "Q 1453 -91 1209 -44 \n",
       "Q 966 3 703 97 \n",
       "z\n",
       "M 1959 2075 \n",
       "Q 2384 2075 2632 2365 \n",
       "Q 2881 2656 2881 3163 \n",
       "Q 2881 3666 2632 3958 \n",
       "Q 2384 4250 1959 4250 \n",
       "Q 1534 4250 1286 3958 \n",
       "Q 1038 3666 1038 3163 \n",
       "Q 1038 2656 1286 2365 \n",
       "Q 1534 2075 1959 2075 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#DejaVuSans-30\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-38\" x=\"95.410156\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-39\" x=\"159.033203\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_3\">\n",
       "     <g id=\"line2d_9\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#mbe9e75c0c8\" x=\"50.14375\" y=\"174.200113\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_10\">\n",
       "      <!-- 0.90 -->\n",
       "      <g transform=\"translate(20.878125 177.999332)scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-30\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-39\" x=\"95.410156\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-30\" x=\"159.033203\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_4\">\n",
       "     <g id=\"line2d_10\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#mbe9e75c0c8\" x=\"50.14375\" y=\"144.331991\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_11\">\n",
       "      <!-- 0.91 -->\n",
       "      <g transform=\"translate(20.878125 148.131209)scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-30\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-39\" x=\"95.410156\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-31\" x=\"159.033203\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_5\">\n",
       "     <g id=\"line2d_11\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#mbe9e75c0c8\" x=\"50.14375\" y=\"114.463868\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_12\">\n",
       "      <!-- 0.92 -->\n",
       "      <g transform=\"translate(20.878125 118.263087)scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-30\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-39\" x=\"95.410156\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-32\" x=\"159.033203\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_6\">\n",
       "     <g id=\"line2d_12\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#mbe9e75c0c8\" x=\"50.14375\" y=\"84.595745\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_13\">\n",
       "      <!-- 0.93 -->\n",
       "      <g transform=\"translate(20.878125 88.394964)scale(0.1 -0.1)\">\n",
       "       <defs>\n",
       "        <path id=\"DejaVuSans-33\" d=\"M 2597 2516 \n",
       "Q 3050 2419 3304 2112 \n",
       "Q 3559 1806 3559 1356 \n",
       "Q 3559 666 3084 287 \n",
       "Q 2609 -91 1734 -91 \n",
       "Q 1441 -91 1130 -33 \n",
       "Q 819 25 488 141 \n",
       "L 488 750 \n",
       "Q 750 597 1062 519 \n",
       "Q 1375 441 1716 441 \n",
       "Q 2309 441 2620 675 \n",
       "Q 2931 909 2931 1356 \n",
       "Q 2931 1769 2642 2001 \n",
       "Q 2353 2234 1838 2234 \n",
       "L 1294 2234 \n",
       "L 1294 2753 \n",
       "L 1863 2753 \n",
       "Q 2328 2753 2575 2939 \n",
       "Q 2822 3125 2822 3475 \n",
       "Q 2822 3834 2567 4026 \n",
       "Q 2313 4219 1838 4219 \n",
       "Q 1578 4219 1281 4162 \n",
       "Q 984 4106 628 3988 \n",
       "L 628 4550 \n",
       "Q 988 4650 1302 4700 \n",
       "Q 1616 4750 1894 4750 \n",
       "Q 2613 4750 3031 4423 \n",
       "Q 3450 4097 3450 3541 \n",
       "Q 3450 3153 3228 2886 \n",
       "Q 3006 2619 2597 2516 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#DejaVuSans-30\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-39\" x=\"95.410156\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-33\" x=\"159.033203\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_7\">\n",
       "     <g id=\"line2d_13\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#mbe9e75c0c8\" x=\"50.14375\" y=\"54.727622\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_14\">\n",
       "      <!-- 0.94 -->\n",
       "      <g transform=\"translate(20.878125 58.526841)scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-30\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-39\" x=\"95.410156\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-34\" x=\"159.033203\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_8\">\n",
       "     <g id=\"line2d_14\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#mbe9e75c0c8\" x=\"50.14375\" y=\"24.8595\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_15\">\n",
       "      <!-- 0.95 -->\n",
       "      <g transform=\"translate(20.878125 28.658719)scale(0.1 -0.1)\">\n",
       "       <defs>\n",
       "        <path id=\"DejaVuSans-35\" d=\"M 691 4666 \n",
       "L 3169 4666 \n",
       "L 3169 4134 \n",
       "L 1269 4134 \n",
       "L 1269 2991 \n",
       "Q 1406 3038 1543 3061 \n",
       "Q 1681 3084 1819 3084 \n",
       "Q 2600 3084 3056 2656 \n",
       "Q 3513 2228 3513 1497 \n",
       "Q 3513 744 3044 326 \n",
       "Q 2575 -91 1722 -91 \n",
       "Q 1428 -91 1123 -41 \n",
       "Q 819 9 494 109 \n",
       "L 494 744 \n",
       "Q 775 591 1075 516 \n",
       "Q 1375 441 1709 441 \n",
       "Q 2250 441 2565 725 \n",
       "Q 2881 1009 2881 1497 \n",
       "Q 2881 1984 2565 2268 \n",
       "Q 2250 2553 1709 2553 \n",
       "Q 1456 2553 1204 2497 \n",
       "Q 953 2441 691 2322 \n",
       "L 691 4666 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#DejaVuSans-30\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-39\" x=\"95.410156\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-35\" x=\"159.033203\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"text_16\">\n",
       "     <!-- accuracy -->\n",
       "     <g transform=\"translate(14.798438 153.5975)rotate(-90)scale(0.1 -0.1)\">\n",
       "      <defs>\n",
       "       <path id=\"DejaVuSans-61\" d=\"M 2194 1759 \n",
       "Q 1497 1759 1228 1600 \n",
       "Q 959 1441 959 1056 \n",
       "Q 959 750 1161 570 \n",
       "Q 1363 391 1709 391 \n",
       "Q 2188 391 2477 730 \n",
       "Q 2766 1069 2766 1631 \n",
       "L 2766 1759 \n",
       "L 2194 1759 \n",
       "z\n",
       "M 3341 1997 \n",
       "L 3341 0 \n",
       "L 2766 0 \n",
       "L 2766 531 \n",
       "Q 2569 213 2275 61 \n",
       "Q 1981 -91 1556 -91 \n",
       "Q 1019 -91 701 211 \n",
       "Q 384 513 384 1019 \n",
       "Q 384 1609 779 1909 \n",
       "Q 1175 2209 1959 2209 \n",
       "L 2766 2209 \n",
       "L 2766 2266 \n",
       "Q 2766 2663 2505 2880 \n",
       "Q 2244 3097 1772 3097 \n",
       "Q 1472 3097 1187 3025 \n",
       "Q 903 2953 641 2809 \n",
       "L 641 3341 \n",
       "Q 956 3463 1253 3523 \n",
       "Q 1550 3584 1831 3584 \n",
       "Q 2591 3584 2966 3190 \n",
       "Q 3341 2797 3341 1997 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       <path id=\"DejaVuSans-75\" d=\"M 544 1381 \n",
       "L 544 3500 \n",
       "L 1119 3500 \n",
       "L 1119 1403 \n",
       "Q 1119 906 1312 657 \n",
       "Q 1506 409 1894 409 \n",
       "Q 2359 409 2629 706 \n",
       "Q 2900 1003 2900 1516 \n",
       "L 2900 3500 \n",
       "L 3475 3500 \n",
       "L 3475 0 \n",
       "L 2900 0 \n",
       "L 2900 538 \n",
       "Q 2691 219 2414 64 \n",
       "Q 2138 -91 1772 -91 \n",
       "Q 1169 -91 856 284 \n",
       "Q 544 659 544 1381 \n",
       "z\n",
       "M 1991 3584 \n",
       "L 1991 3584 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       <path id=\"DejaVuSans-72\" d=\"M 2631 2963 \n",
       "Q 2534 3019 2420 3045 \n",
       "Q 2306 3072 2169 3072 \n",
       "Q 1681 3072 1420 2755 \n",
       "Q 1159 2438 1159 1844 \n",
       "L 1159 0 \n",
       "L 581 0 \n",
       "L 581 3500 \n",
       "L 1159 3500 \n",
       "L 1159 2956 \n",
       "Q 1341 3275 1631 3429 \n",
       "Q 1922 3584 2338 3584 \n",
       "Q 2397 3584 2469 3576 \n",
       "Q 2541 3569 2628 3553 \n",
       "L 2631 2963 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       <path id=\"DejaVuSans-79\" d=\"M 2059 -325 \n",
       "Q 1816 -950 1584 -1140 \n",
       "Q 1353 -1331 966 -1331 \n",
       "L 506 -1331 \n",
       "L 506 -850 \n",
       "L 844 -850 \n",
       "Q 1081 -850 1212 -737 \n",
       "Q 1344 -625 1503 -206 \n",
       "L 1606 56 \n",
       "L 191 3500 \n",
       "L 800 3500 \n",
       "L 1894 763 \n",
       "L 2988 3500 \n",
       "L 3597 3500 \n",
       "L 2059 -325 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "      </defs>\n",
       "      <use xlink:href=\"#DejaVuSans-61\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-63\" x=\"61.279297\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-63\" x=\"116.259766\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-75\" x=\"171.240234\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-72\" x=\"234.619141\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-61\" x=\"275.732422\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-63\" x=\"337.011719\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-79\" x=\"391.992188\"/>\n",
       "     </g>\n",
       "    </g>\n",
       "   </g>\n",
       "   <g id=\"line2d_15\">\n",
       "    <path d=\"M 65.361932 229.874489 \n",
       "L 65.971268 83.353623 \n",
       "L 66.580605 44.176095 \n",
       "L 66.885273 39.783969 \n",
       "L 67.189942 38.554152 \n",
       "L 67.49461 38.378439 \n",
       "L 67.799278 37.324336 \n",
       "L 68.103947 37.500049 \n",
       "L 68.408615 37.148622 \n",
       "L 369.725568 37.148622 \n",
       "L 369.725568 37.148622 \n",
       "\" clip-path=\"url(#p5b16f8e657)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n",
       "   </g>\n",
       "   <g id=\"line2d_16\">\n",
       "    <path d=\"M 65.361932 32.201761 \n",
       "L 369.725568 32.201761 \n",
       "L 369.725568 32.201761 \n",
       "\" clip-path=\"url(#p5b16f8e657)\" style=\"fill: none; stroke: #ff7f0e; stroke-width: 1.5; stroke-linecap: square\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_3\">\n",
       "    <path d=\"M 50.14375 239.758125 \n",
       "L 50.14375 22.318125 \n",
       "\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_4\">\n",
       "    <path d=\"M 384.94375 239.758125 \n",
       "L 384.94375 22.318125 \n",
       "\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_5\">\n",
       "    <path d=\"M 50.14375 239.758125 \n",
       "L 384.94375 239.758125 \n",
       "\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_6\">\n",
       "    <path d=\"M 50.14375 22.318125 \n",
       "L 384.94375 22.318125 \n",
       "\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n",
       "   </g>\n",
       "   <g id=\"text_17\">\n",
       "    <!-- model accuracy -->\n",
       "    <g transform=\"translate(169.882188 16.318125)scale(0.12 -0.12)\">\n",
       "     <defs>\n",
       "      <path id=\"DejaVuSans-6d\" d=\"M 3328 2828 \n",
       "Q 3544 3216 3844 3400 \n",
       "Q 4144 3584 4550 3584 \n",
       "Q 5097 3584 5394 3201 \n",
       "Q 5691 2819 5691 2113 \n",
       "L 5691 0 \n",
       "L 5113 0 \n",
       "L 5113 2094 \n",
       "Q 5113 2597 4934 2840 \n",
       "Q 4756 3084 4391 3084 \n",
       "Q 3944 3084 3684 2787 \n",
       "Q 3425 2491 3425 1978 \n",
       "L 3425 0 \n",
       "L 2847 0 \n",
       "L 2847 2094 \n",
       "Q 2847 2600 2669 2842 \n",
       "Q 2491 3084 2119 3084 \n",
       "Q 1678 3084 1418 2786 \n",
       "Q 1159 2488 1159 1978 \n",
       "L 1159 0 \n",
       "L 581 0 \n",
       "L 581 3500 \n",
       "L 1159 3500 \n",
       "L 1159 2956 \n",
       "Q 1356 3278 1631 3431 \n",
       "Q 1906 3584 2284 3584 \n",
       "Q 2666 3584 2933 3390 \n",
       "Q 3200 3197 3328 2828 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "      <path id=\"DejaVuSans-64\" d=\"M 2906 2969 \n",
       "L 2906 4863 \n",
       "L 3481 4863 \n",
       "L 3481 0 \n",
       "L 2906 0 \n",
       "L 2906 525 \n",
       "Q 2725 213 2448 61 \n",
       "Q 2172 -91 1784 -91 \n",
       "Q 1150 -91 751 415 \n",
       "Q 353 922 353 1747 \n",
       "Q 353 2572 751 3078 \n",
       "Q 1150 3584 1784 3584 \n",
       "Q 2172 3584 2448 3432 \n",
       "Q 2725 3281 2906 2969 \n",
       "z\n",
       "M 947 1747 \n",
       "Q 947 1113 1208 752 \n",
       "Q 1469 391 1925 391 \n",
       "Q 2381 391 2643 752 \n",
       "Q 2906 1113 2906 1747 \n",
       "Q 2906 2381 2643 2742 \n",
       "Q 2381 3103 1925 3103 \n",
       "Q 1469 3103 1208 2742 \n",
       "Q 947 2381 947 1747 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "      <path id=\"DejaVuSans-6c\" d=\"M 603 4863 \n",
       "L 1178 4863 \n",
       "L 1178 0 \n",
       "L 603 0 \n",
       "L 603 4863 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "      <path id=\"DejaVuSans-20\" transform=\"scale(0.015625)\"/>\n",
       "     </defs>\n",
       "     <use xlink:href=\"#DejaVuSans-6d\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-6f\" x=\"97.412109\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-64\" x=\"158.59375\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-65\" x=\"222.070312\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-6c\" x=\"283.59375\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-20\" x=\"311.376953\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-61\" x=\"343.164062\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-63\" x=\"404.443359\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-63\" x=\"459.423828\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-75\" x=\"514.404297\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-72\" x=\"577.783203\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-61\" x=\"618.896484\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-63\" x=\"680.175781\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-79\" x=\"735.15625\"/>\n",
       "    </g>\n",
       "   </g>\n",
       "   <g id=\"legend_1\">\n",
       "    <g id=\"patch_7\">\n",
       "     <path d=\"M 296.709375 234.758125 \n",
       "L 377.94375 234.758125 \n",
       "Q 379.94375 234.758125 379.94375 232.758125 \n",
       "L 379.94375 204.401875 \n",
       "Q 379.94375 202.401875 377.94375 202.401875 \n",
       "L 296.709375 202.401875 \n",
       "Q 294.709375 202.401875 294.709375 204.401875 \n",
       "L 294.709375 232.758125 \n",
       "Q 294.709375 234.758125 296.709375 234.758125 \n",
       "z\n",
       "\" style=\"fill: #ffffff; opacity: 0.8; stroke: #cccccc; stroke-linejoin: miter\"/>\n",
       "    </g>\n",
       "    <g id=\"line2d_17\">\n",
       "     <path d=\"M 298.709375 210.500312 \n",
       "L 308.709375 210.500312 \n",
       "L 318.709375 210.500312 \n",
       "\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n",
       "    </g>\n",
       "    <g id=\"text_18\">\n",
       "     <!-- train -->\n",
       "     <g transform=\"translate(326.709375 214.000312)scale(0.1 -0.1)\">\n",
       "      <defs>\n",
       "       <path id=\"DejaVuSans-74\" d=\"M 1172 4494 \n",
       "L 1172 3500 \n",
       "L 2356 3500 \n",
       "L 2356 3053 \n",
       "L 1172 3053 \n",
       "L 1172 1153 \n",
       "Q 1172 725 1289 603 \n",
       "Q 1406 481 1766 481 \n",
       "L 2356 481 \n",
       "L 2356 0 \n",
       "L 1766 0 \n",
       "Q 1100 0 847 248 \n",
       "Q 594 497 594 1153 \n",
       "L 594 3053 \n",
       "L 172 3053 \n",
       "L 172 3500 \n",
       "L 594 3500 \n",
       "L 594 4494 \n",
       "L 1172 4494 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       <path id=\"DejaVuSans-69\" d=\"M 603 3500 \n",
       "L 1178 3500 \n",
       "L 1178 0 \n",
       "L 603 0 \n",
       "L 603 3500 \n",
       "z\n",
       "M 603 4863 \n",
       "L 1178 4863 \n",
       "L 1178 4134 \n",
       "L 603 4134 \n",
       "L 603 4863 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       <path id=\"DejaVuSans-6e\" d=\"M 3513 2113 \n",
       "L 3513 0 \n",
       "L 2938 0 \n",
       "L 2938 2094 \n",
       "Q 2938 2591 2744 2837 \n",
       "Q 2550 3084 2163 3084 \n",
       "Q 1697 3084 1428 2787 \n",
       "Q 1159 2491 1159 1978 \n",
       "L 1159 0 \n",
       "L 581 0 \n",
       "L 581 3500 \n",
       "L 1159 3500 \n",
       "L 1159 2956 \n",
       "Q 1366 3272 1645 3428 \n",
       "Q 1925 3584 2291 3584 \n",
       "Q 2894 3584 3203 3211 \n",
       "Q 3513 2838 3513 2113 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "      </defs>\n",
       "      <use xlink:href=\"#DejaVuSans-74\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-72\" x=\"39.208984\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-61\" x=\"80.322266\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-69\" x=\"141.601562\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-6e\" x=\"169.384766\"/>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"line2d_18\">\n",
       "     <path d=\"M 298.709375 225.178437 \n",
       "L 308.709375 225.178437 \n",
       "L 318.709375 225.178437 \n",
       "\" style=\"fill: none; stroke: #ff7f0e; stroke-width: 1.5; stroke-linecap: square\"/>\n",
       "    </g>\n",
       "    <g id=\"text_19\">\n",
       "     <!-- validation -->\n",
       "     <g transform=\"translate(326.709375 228.678437)scale(0.1 -0.1)\">\n",
       "      <defs>\n",
       "       <path id=\"DejaVuSans-76\" d=\"M 191 3500 \n",
       "L 800 3500 \n",
       "L 1894 563 \n",
       "L 2988 3500 \n",
       "L 3597 3500 \n",
       "L 2284 0 \n",
       "L 1503 0 \n",
       "L 191 3500 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "      </defs>\n",
       "      <use xlink:href=\"#DejaVuSans-76\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-61\" x=\"59.179688\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-6c\" x=\"120.458984\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-69\" x=\"148.242188\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-64\" x=\"176.025391\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-61\" x=\"239.501953\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-74\" x=\"300.78125\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-69\" x=\"339.990234\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-6f\" x=\"367.773438\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-6e\" x=\"428.955078\"/>\n",
       "     </g>\n",
       "    </g>\n",
       "   </g>\n",
       "  </g>\n",
       " </g>\n",
       " <defs>\n",
       "  <clipPath id=\"p5b16f8e657\">\n",
       "   <rect x=\"50.14375\" y=\"22.318125\" width=\"334.8\" height=\"217.44\"/>\n",
       "  </clipPath>\n",
       " </defs>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_hist(history1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train_Loss: 0.195, Train_Acc: 0.946\n",
      "Test_Loss: 0.194, Test_Acc: 0.948\n"
     ]
    }
   ],
   "source": [
    "# evaluate the model\n",
    "train_loss, train_acc = model.evaluate(X_audio_train, y_audio_train, verbose=0)\n",
    "test_loss, test_acc = model.evaluate(X_audio_test, y_audio_test, verbose=0)\n",
    "print('Train_Loss: %.3f, Train_Acc: %.3f' % (train_loss, train_acc))\n",
    "print('Test_Loss: %.3f, Test_Acc: %.3f' % (test_loss, test_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "133/133 [==============================] - 1s 4ms/step\n"
     ]
    }
   ],
   "source": [
    "pred = model.predict(X_audio_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "133/133 [==============================] - 1s 4ms/step\n"
     ]
    }
   ],
   "source": [
    "y_pred = (model.predict(X_audio_test) > 0.5)*1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score: 0.9475417548812044\n",
      "Precision: 0.0\n",
      "Recall: 0.0\n",
      "F1_score: 0.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, classification_report, confusion_matrix\n",
    "score = accuracy_score(y_audio_test, y_pred)\n",
    "precision = precision_score(y_audio_test,y_pred)\n",
    "recall = recall_score(y_audio_test,y_pred)\n",
    "f1 = f1_score(y_audio_test,y_pred)\n",
    "print(\"score:\", score)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"F1_score:\", f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix : \n",
      " [[4028    0]\n",
      " [ 223    0]]\n"
     ]
    }
   ],
   "source": [
    "# confusion matrix\n",
    "matrix = confusion_matrix(y_audio_test, y_pred, labels=[0,1])\n",
    "print('Confusion matrix : \\n',matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report : \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      1.00      0.97      4028\n",
      "           1       0.00      0.00      0.00       223\n",
      "\n",
      "    accuracy                           0.95      4251\n",
      "   macro avg       0.47      0.50      0.49      4251\n",
      "weighted avg       0.90      0.95      0.92      4251\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# classification report for precision, recall f1-score and accuracy\n",
    "matrix = classification_report(y_audio_test, y_pred, labels=[0,1])\n",
    "print('Classification report : \\n',matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Outcome values : \n",
      " 4028 0 223 0\n"
     ]
    }
   ],
   "source": [
    "# outcome values order in sklearn\n",
    "tp, fn, fp, tn = confusion_matrix(y_audio_test, y_pred,labels=[0,1]).reshape(-1)\n",
    "print('Outcome values : \\n', tp, fn, fp, tn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "\n",
    "def get_img_input():\n",
    "    df = pd.read_csv('Vd.csv')\n",
    "    columns = list(df.columns)\n",
    "    features = columns[:-1]\n",
    "    cls_name = columns[-1]\n",
    "    X = np.zeros((len(df), len(features)))\n",
    "    Y = list()\n",
    "    for i, row in df.iterrows():\n",
    "        X[i] = row[features]                    \n",
    "        Y.append(row[cls_name])\n",
    "\n",
    "    return (X, Y)\n",
    "X_img, Y_img = get_img_input()\n",
    "encoder = LabelEncoder()\n",
    "Y_img = encoder.fit_transform(Y_img)\n",
    "X_img_train, X_img_test, y_img_train, y_img_test = train_test_split( X_img, Y_img, test_size=0.3,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Conv2D, MaxPooling2D, Input, Dense, Flatten, concatenate\n",
    "from keras.models import Model\n",
    "import numpy as np\n",
    "from keras import regularizers\n",
    "from keras.layers import Dropout \n",
    "def compile_model():\n",
    "    img_input = Input(shape=(50176,)) \n",
    "    ## branch 1 with image input\n",
    "    x = Dense(1024, activation='relu', kernel_regularizer=regularizers.l2(0.01))(img_input)\n",
    "    x = Dropout(0.3)(x)\n",
    "    x = Dense(512, activation='relu', kernel_regularizer=regularizers.l2(0.01))(x)\n",
    "    x = Dropout(0.3)(x)\n",
    "    x = Dense(256, activation='relu', kernel_regularizer=regularizers.l2(0.01))(x)\n",
    "    x = Dropout(0.3)(x)\n",
    "    x = Dense(128, activation='relu', kernel_regularizer=regularizers.l2(0.01))(x)\n",
    "    x = Dropout(0.3)(x)\n",
    "    x = Dense(64, activation='relu', kernel_regularizer=regularizers.l2(0.01))(x)\n",
    "    x = Dropout(0.3)(x)\n",
    "    out_a = Dense(32, activation='relu', kernel_regularizer=regularizers.l2(0.01))(x)\n",
    "    out_a = Dense(1, activation='sigmoid')(out_a)\n",
    "    model = Model(img_input, out_a)\n",
    "    adam = Adam(lr=0.001, decay=1e-5)\n",
    "    print(model.summary())\n",
    "    model.compile(loss=\"binary_crossentropy\", optimizer=adam, metrics=[\"accuracy\"])\n",
    "    return model\n",
    "    #x = MaxPooling2D((2, 2))(x)\n",
    "    #x = Flatten()(x)\n",
    "    #out_a = Dense(64)(x)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_2 (InputLayer)        [(None, 50176)]           0         \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 1024)              51381248  \n",
      "                                                                 \n",
      " dropout_5 (Dropout)         (None, 1024)              0         \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 512)               524800    \n",
      "                                                                 \n",
      " dropout_6 (Dropout)         (None, 512)               0         \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 256)               131328    \n",
      "                                                                 \n",
      " dropout_7 (Dropout)         (None, 256)               0         \n",
      "                                                                 \n",
      " dense_10 (Dense)            (None, 128)               32896     \n",
      "                                                                 \n",
      " dropout_8 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_11 (Dense)            (None, 64)                8256      \n",
      "                                                                 \n",
      " dropout_9 (Dropout)         (None, 64)                0         \n",
      "                                                                 \n",
      " dense_12 (Dense)            (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_13 (Dense)            (None, 1)                 33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 52,080,641\n",
      "Trainable params: 52,080,641\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model = compile_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "59/59 [==============================] - 14s 219ms/step - loss: 155.3273 - accuracy: 0.9190 - val_loss: 38.6815 - val_accuracy: 0.9694\n",
      "Epoch 2/1000\n",
      "59/59 [==============================] - 12s 203ms/step - loss: 49.8872 - accuracy: 0.9287 - val_loss: 31.2612 - val_accuracy: 0.9694\n",
      "Epoch 3/1000\n",
      "59/59 [==============================] - 12s 203ms/step - loss: 34.4430 - accuracy: 0.9351 - val_loss: 25.5541 - val_accuracy: 0.9694\n",
      "Epoch 4/1000\n",
      "59/59 [==============================] - 12s 203ms/step - loss: 26.8122 - accuracy: 0.9330 - val_loss: 21.9566 - val_accuracy: 0.9694\n",
      "Epoch 5/1000\n",
      "59/59 [==============================] - 12s 201ms/step - loss: 22.7347 - accuracy: 0.9312 - val_loss: 19.0775 - val_accuracy: 0.7048\n",
      "Epoch 6/1000\n",
      "59/59 [==============================] - 12s 202ms/step - loss: 19.3736 - accuracy: 0.9376 - val_loss: 16.5245 - val_accuracy: 0.9611\n",
      "Epoch 7/1000\n",
      "59/59 [==============================] - 12s 203ms/step - loss: 16.8165 - accuracy: 0.9344 - val_loss: 14.8097 - val_accuracy: 0.9627\n",
      "Epoch 8/1000\n",
      "59/59 [==============================] - 12s 202ms/step - loss: 14.5294 - accuracy: 0.9376 - val_loss: 13.2214 - val_accuracy: 0.9694\n",
      "Epoch 9/1000\n",
      "59/59 [==============================] - 12s 201ms/step - loss: 13.2944 - accuracy: 0.9361 - val_loss: 12.0975 - val_accuracy: 0.9694\n",
      "Epoch 10/1000\n",
      "59/59 [==============================] - 12s 202ms/step - loss: 11.9678 - accuracy: 0.9408 - val_loss: 11.3543 - val_accuracy: 0.9694\n",
      "Epoch 11/1000\n",
      "59/59 [==============================] - 12s 201ms/step - loss: 10.9484 - accuracy: 0.9461 - val_loss: 10.2769 - val_accuracy: 0.9694\n",
      "Epoch 12/1000\n",
      "59/59 [==============================] - 12s 202ms/step - loss: 10.1617 - accuracy: 0.9488 - val_loss: 9.6860 - val_accuracy: 0.9694\n",
      "Epoch 13/1000\n",
      "59/59 [==============================] - 12s 203ms/step - loss: 9.6246 - accuracy: 0.9535 - val_loss: 9.1766 - val_accuracy: 0.9694\n",
      "Epoch 14/1000\n",
      "59/59 [==============================] - 12s 202ms/step - loss: 9.0925 - accuracy: 0.9538 - val_loss: 8.7093 - val_accuracy: 0.9694\n",
      "Epoch 15/1000\n",
      "59/59 [==============================] - 12s 202ms/step - loss: 8.7169 - accuracy: 0.9526 - val_loss: 8.4059 - val_accuracy: 0.9694\n",
      "Epoch 16/1000\n",
      "59/59 [==============================] - 12s 201ms/step - loss: 8.2991 - accuracy: 0.9572 - val_loss: 8.1217 - val_accuracy: 0.9694\n",
      "Epoch 17/1000\n",
      "59/59 [==============================] - 12s 203ms/step - loss: 8.0374 - accuracy: 0.9529 - val_loss: 7.7125 - val_accuracy: 0.9694\n",
      "Epoch 18/1000\n",
      "59/59 [==============================] - 12s 201ms/step - loss: 7.6913 - accuracy: 0.9574 - val_loss: 7.6405 - val_accuracy: 0.9694\n",
      "Epoch 19/1000\n",
      "59/59 [==============================] - 12s 201ms/step - loss: 7.4901 - accuracy: 0.9558 - val_loss: 7.3923 - val_accuracy: 0.9694\n",
      "Epoch 20/1000\n",
      "59/59 [==============================] - 12s 201ms/step - loss: 7.2156 - accuracy: 0.9618 - val_loss: 7.0550 - val_accuracy: 0.9694\n",
      "Epoch 21/1000\n",
      "59/59 [==============================] - 12s 202ms/step - loss: 7.0033 - accuracy: 0.9624 - val_loss: 6.8216 - val_accuracy: 0.9694\n",
      "Epoch 22/1000\n",
      "59/59 [==============================] - 12s 203ms/step - loss: 7.1624 - accuracy: 0.9548 - val_loss: 6.7792 - val_accuracy: 0.9694\n",
      "Epoch 23/1000\n",
      "59/59 [==============================] - 12s 201ms/step - loss: 6.7604 - accuracy: 0.9599 - val_loss: 6.5427 - val_accuracy: 0.9694\n",
      "Epoch 24/1000\n",
      "59/59 [==============================] - 12s 202ms/step - loss: 6.4756 - accuracy: 0.9660 - val_loss: 6.3563 - val_accuracy: 0.9694\n",
      "Epoch 25/1000\n",
      "59/59 [==============================] - 12s 202ms/step - loss: 6.3611 - accuracy: 0.9663 - val_loss: 6.2553 - val_accuracy: 0.9694\n",
      "Epoch 26/1000\n",
      "59/59 [==============================] - 12s 202ms/step - loss: 6.2599 - accuracy: 0.9648 - val_loss: 6.1396 - val_accuracy: 0.9694\n",
      "Epoch 27/1000\n",
      "59/59 [==============================] - 12s 202ms/step - loss: 6.1001 - accuracy: 0.9659 - val_loss: 6.0179 - val_accuracy: 0.9694\n",
      "Epoch 28/1000\n",
      "59/59 [==============================] - 12s 203ms/step - loss: 5.9851 - accuracy: 0.9670 - val_loss: 5.9043 - val_accuracy: 0.9694\n",
      "Epoch 29/1000\n",
      "59/59 [==============================] - 12s 202ms/step - loss: 5.8439 - accuracy: 0.9674 - val_loss: 5.7702 - val_accuracy: 0.9694\n",
      "Epoch 30/1000\n",
      "59/59 [==============================] - 12s 202ms/step - loss: 5.7795 - accuracy: 0.9657 - val_loss: 5.7000 - val_accuracy: 0.9694\n",
      "Epoch 31/1000\n",
      "59/59 [==============================] - 12s 202ms/step - loss: 5.6678 - accuracy: 0.9667 - val_loss: 5.5893 - val_accuracy: 0.9694\n",
      "Epoch 32/1000\n",
      "59/59 [==============================] - 12s 200ms/step - loss: 5.5386 - accuracy: 0.9677 - val_loss: 5.4565 - val_accuracy: 0.9694\n",
      "Epoch 33/1000\n",
      "59/59 [==============================] - 12s 202ms/step - loss: 5.4371 - accuracy: 0.9681 - val_loss: 5.3787 - val_accuracy: 0.9694\n",
      "Epoch 34/1000\n",
      "59/59 [==============================] - 12s 202ms/step - loss: 5.3192 - accuracy: 0.9682 - val_loss: 5.2693 - val_accuracy: 0.9694\n",
      "Epoch 35/1000\n",
      "59/59 [==============================] - 12s 202ms/step - loss: 5.2512 - accuracy: 0.9681 - val_loss: 5.2000 - val_accuracy: 0.9694\n",
      "Epoch 36/1000\n",
      "59/59 [==============================] - 12s 203ms/step - loss: 5.1449 - accuracy: 0.9685 - val_loss: 5.0872 - val_accuracy: 0.9694\n",
      "Epoch 37/1000\n",
      "59/59 [==============================] - 12s 202ms/step - loss: 5.0472 - accuracy: 0.9686 - val_loss: 5.0071 - val_accuracy: 0.9694\n",
      "Epoch 38/1000\n",
      "59/59 [==============================] - 12s 202ms/step - loss: 5.0034 - accuracy: 0.9677 - val_loss: 4.9195 - val_accuracy: 0.9694\n",
      "Epoch 39/1000\n",
      "59/59 [==============================] - 12s 201ms/step - loss: 4.8987 - accuracy: 0.9685 - val_loss: 4.8561 - val_accuracy: 0.9694\n",
      "Epoch 40/1000\n",
      "59/59 [==============================] - 12s 202ms/step - loss: 4.8062 - accuracy: 0.9688 - val_loss: 4.7391 - val_accuracy: 0.9694\n",
      "Epoch 41/1000\n",
      "59/59 [==============================] - 12s 203ms/step - loss: 4.7704 - accuracy: 0.9679 - val_loss: 4.7055 - val_accuracy: 0.9694\n",
      "Epoch 42/1000\n",
      "59/59 [==============================] - 12s 203ms/step - loss: 4.6959 - accuracy: 0.9678 - val_loss: 4.6339 - val_accuracy: 0.9694\n",
      "Epoch 43/1000\n",
      "59/59 [==============================] - 12s 202ms/step - loss: 4.6402 - accuracy: 0.9669 - val_loss: 4.5587 - val_accuracy: 0.9694\n",
      "Epoch 44/1000\n",
      "59/59 [==============================] - 12s 203ms/step - loss: 4.5440 - accuracy: 0.9671 - val_loss: 4.5027 - val_accuracy: 0.9694\n",
      "Epoch 45/1000\n",
      "59/59 [==============================] - 12s 202ms/step - loss: 4.4690 - accuracy: 0.9678 - val_loss: 4.3813 - val_accuracy: 0.9694\n",
      "Epoch 46/1000\n",
      "59/59 [==============================] - 12s 201ms/step - loss: 4.3808 - accuracy: 0.9680 - val_loss: 4.3433 - val_accuracy: 0.9694\n",
      "Epoch 47/1000\n",
      "59/59 [==============================] - 12s 204ms/step - loss: 4.2755 - accuracy: 0.9686 - val_loss: 4.2105 - val_accuracy: 0.9694\n",
      "Epoch 48/1000\n",
      "59/59 [==============================] - 12s 202ms/step - loss: 4.1834 - accuracy: 0.9688 - val_loss: 4.1363 - val_accuracy: 0.9694\n",
      "Epoch 49/1000\n",
      "59/59 [==============================] - 12s 203ms/step - loss: 4.2081 - accuracy: 0.9653 - val_loss: 4.1001 - val_accuracy: 0.9694\n",
      "Epoch 50/1000\n",
      "59/59 [==============================] - 12s 203ms/step - loss: 4.0683 - accuracy: 0.9685 - val_loss: 4.0065 - val_accuracy: 0.9694\n",
      "Epoch 51/1000\n",
      "59/59 [==============================] - 12s 203ms/step - loss: 3.9755 - accuracy: 0.9687 - val_loss: 3.9183 - val_accuracy: 0.9694\n",
      "Epoch 52/1000\n",
      "59/59 [==============================] - 12s 202ms/step - loss: 3.8961 - accuracy: 0.9689 - val_loss: 3.8668 - val_accuracy: 0.9694\n",
      "Epoch 53/1000\n",
      "59/59 [==============================] - 12s 202ms/step - loss: 3.8892 - accuracy: 0.9673 - val_loss: 3.8313 - val_accuracy: 0.9694\n",
      "Epoch 54/1000\n",
      "59/59 [==============================] - 12s 204ms/step - loss: 3.7775 - accuracy: 0.9685 - val_loss: 3.7405 - val_accuracy: 0.9694\n",
      "Epoch 55/1000\n",
      "59/59 [==============================] - 12s 204ms/step - loss: 3.7592 - accuracy: 0.9661 - val_loss: 3.6792 - val_accuracy: 0.9694\n",
      "Epoch 56/1000\n",
      "59/59 [==============================] - 12s 202ms/step - loss: 3.6413 - accuracy: 0.9689 - val_loss: 3.5997 - val_accuracy: 0.9694\n",
      "Epoch 57/1000\n",
      "59/59 [==============================] - 12s 199ms/step - loss: 3.5574 - accuracy: 0.9687 - val_loss: 3.5080 - val_accuracy: 0.9694\n",
      "Epoch 58/1000\n",
      "59/59 [==============================] - 12s 200ms/step - loss: 3.4893 - accuracy: 0.9687 - val_loss: 3.4364 - val_accuracy: 0.9694\n",
      "Epoch 59/1000\n",
      "59/59 [==============================] - 12s 203ms/step - loss: 3.4353 - accuracy: 0.9687 - val_loss: 3.3876 - val_accuracy: 0.9694\n",
      "Epoch 60/1000\n",
      "59/59 [==============================] - 12s 202ms/step - loss: 3.3912 - accuracy: 0.9683 - val_loss: 3.3249 - val_accuracy: 0.9694\n",
      "Epoch 61/1000\n",
      "59/59 [==============================] - 12s 202ms/step - loss: 3.3005 - accuracy: 0.9689 - val_loss: 3.2515 - val_accuracy: 0.9694\n",
      "Epoch 62/1000\n",
      "59/59 [==============================] - 12s 200ms/step - loss: 3.2450 - accuracy: 0.9683 - val_loss: 3.1958 - val_accuracy: 0.9694\n",
      "Epoch 63/1000\n",
      "59/59 [==============================] - 12s 201ms/step - loss: 3.1952 - accuracy: 0.9687 - val_loss: 3.1434 - val_accuracy: 0.9694\n",
      "Epoch 64/1000\n",
      "59/59 [==============================] - 12s 200ms/step - loss: 3.1424 - accuracy: 0.9684 - val_loss: 3.0716 - val_accuracy: 0.9694\n",
      "Epoch 65/1000\n",
      "59/59 [==============================] - 12s 201ms/step - loss: 3.0423 - accuracy: 0.9687 - val_loss: 3.0064 - val_accuracy: 0.9694\n",
      "Epoch 66/1000\n",
      "59/59 [==============================] - 12s 201ms/step - loss: 2.9749 - accuracy: 0.9685 - val_loss: 2.9491 - val_accuracy: 0.9694\n",
      "Epoch 67/1000\n",
      "59/59 [==============================] - 12s 200ms/step - loss: 2.9247 - accuracy: 0.9685 - val_loss: 2.8870 - val_accuracy: 0.9694\n",
      "Epoch 68/1000\n",
      "59/59 [==============================] - 12s 201ms/step - loss: 2.8526 - accuracy: 0.9688 - val_loss: 2.8191 - val_accuracy: 0.9694\n",
      "Epoch 69/1000\n",
      "59/59 [==============================] - 12s 201ms/step - loss: 2.7849 - accuracy: 0.9688 - val_loss: 2.7424 - val_accuracy: 0.9694\n",
      "Epoch 70/1000\n",
      "59/59 [==============================] - 12s 202ms/step - loss: 2.7456 - accuracy: 0.9688 - val_loss: 2.6926 - val_accuracy: 0.9694\n",
      "Epoch 71/1000\n",
      "59/59 [==============================] - 12s 201ms/step - loss: 2.6718 - accuracy: 0.9688 - val_loss: 2.6441 - val_accuracy: 0.9694\n",
      "Epoch 72/1000\n",
      "59/59 [==============================] - 12s 200ms/step - loss: 2.6428 - accuracy: 0.9681 - val_loss: 2.5964 - val_accuracy: 0.9694\n",
      "Epoch 73/1000\n",
      "59/59 [==============================] - 12s 201ms/step - loss: 2.5560 - accuracy: 0.9689 - val_loss: 2.5111 - val_accuracy: 0.9694\n",
      "Epoch 74/1000\n",
      "59/59 [==============================] - 12s 203ms/step - loss: 2.4906 - accuracy: 0.9689 - val_loss: 2.4606 - val_accuracy: 0.9694\n",
      "Epoch 75/1000\n",
      "59/59 [==============================] - 12s 199ms/step - loss: 2.4333 - accuracy: 0.9689 - val_loss: 2.3910 - val_accuracy: 0.9694\n",
      "Epoch 76/1000\n",
      "59/59 [==============================] - 12s 203ms/step - loss: 2.3853 - accuracy: 0.9687 - val_loss: 2.3499 - val_accuracy: 0.9694\n",
      "Epoch 77/1000\n",
      "59/59 [==============================] - 12s 200ms/step - loss: 2.3268 - accuracy: 0.9688 - val_loss: 2.2857 - val_accuracy: 0.9694\n",
      "Epoch 78/1000\n",
      "59/59 [==============================] - 12s 201ms/step - loss: 2.2666 - accuracy: 0.9689 - val_loss: 2.2415 - val_accuracy: 0.9694\n",
      "Epoch 79/1000\n",
      "59/59 [==============================] - 12s 202ms/step - loss: 2.2240 - accuracy: 0.9689 - val_loss: 2.2028 - val_accuracy: 0.9694\n",
      "Epoch 80/1000\n",
      "59/59 [==============================] - 12s 201ms/step - loss: 2.2094 - accuracy: 0.9681 - val_loss: 2.1483 - val_accuracy: 0.9694\n",
      "Epoch 81/1000\n",
      "59/59 [==============================] - 12s 201ms/step - loss: 2.1168 - accuracy: 0.9689 - val_loss: 2.0920 - val_accuracy: 0.9694\n",
      "Epoch 82/1000\n",
      "59/59 [==============================] - 12s 201ms/step - loss: 2.0618 - accuracy: 0.9689 - val_loss: 2.0271 - val_accuracy: 0.9694\n",
      "Epoch 83/1000\n",
      "59/59 [==============================] - 12s 200ms/step - loss: 2.0155 - accuracy: 0.9686 - val_loss: 1.9995 - val_accuracy: 0.9694\n",
      "Epoch 84/1000\n",
      "59/59 [==============================] - 12s 202ms/step - loss: 1.9655 - accuracy: 0.9687 - val_loss: 1.9381 - val_accuracy: 0.9694\n",
      "Epoch 85/1000\n",
      "59/59 [==============================] - 12s 201ms/step - loss: 1.9159 - accuracy: 0.9687 - val_loss: 1.8981 - val_accuracy: 0.9694\n",
      "Epoch 86/1000\n",
      "59/59 [==============================] - 12s 201ms/step - loss: 1.9279 - accuracy: 0.9689 - val_loss: 1.8417 - val_accuracy: 0.9694\n",
      "Epoch 87/1000\n",
      "59/59 [==============================] - 12s 202ms/step - loss: 1.8282 - accuracy: 0.9689 - val_loss: 1.8038 - val_accuracy: 0.9694\n",
      "Epoch 88/1000\n",
      "59/59 [==============================] - 12s 200ms/step - loss: 1.7841 - accuracy: 0.9689 - val_loss: 1.7465 - val_accuracy: 0.9694\n",
      "Epoch 89/1000\n",
      "59/59 [==============================] - 12s 200ms/step - loss: 1.7218 - accuracy: 0.9689 - val_loss: 1.6928 - val_accuracy: 0.9694\n",
      "Epoch 90/1000\n",
      "59/59 [==============================] - 12s 202ms/step - loss: 1.6735 - accuracy: 0.9689 - val_loss: 1.6475 - val_accuracy: 0.9694\n",
      "Epoch 91/1000\n",
      "59/59 [==============================] - 12s 202ms/step - loss: 1.6241 - accuracy: 0.9688 - val_loss: 1.5983 - val_accuracy: 0.9694\n",
      "Epoch 92/1000\n",
      "59/59 [==============================] - 12s 200ms/step - loss: 1.5975 - accuracy: 0.9687 - val_loss: 1.5667 - val_accuracy: 0.9694\n",
      "Epoch 93/1000\n",
      "59/59 [==============================] - 12s 201ms/step - loss: 1.5473 - accuracy: 0.9689 - val_loss: 1.5223 - val_accuracy: 0.9694\n",
      "Epoch 94/1000\n",
      "59/59 [==============================] - 12s 202ms/step - loss: 1.5135 - accuracy: 0.9689 - val_loss: 1.4833 - val_accuracy: 0.9694\n",
      "Epoch 95/1000\n",
      "59/59 [==============================] - 12s 202ms/step - loss: 1.4669 - accuracy: 0.9688 - val_loss: 1.4448 - val_accuracy: 0.9694\n",
      "Epoch 96/1000\n",
      "59/59 [==============================] - 12s 200ms/step - loss: 1.4276 - accuracy: 0.9688 - val_loss: 1.4046 - val_accuracy: 0.9694\n",
      "Epoch 97/1000\n",
      "59/59 [==============================] - 12s 201ms/step - loss: 1.3888 - accuracy: 0.9689 - val_loss: 1.3570 - val_accuracy: 0.9694\n",
      "Epoch 98/1000\n",
      "59/59 [==============================] - 12s 200ms/step - loss: 1.3373 - accuracy: 0.9689 - val_loss: 1.3113 - val_accuracy: 0.9694\n",
      "Epoch 99/1000\n",
      "59/59 [==============================] - 12s 202ms/step - loss: 1.3050 - accuracy: 0.9689 - val_loss: 1.2848 - val_accuracy: 0.9694\n",
      "Epoch 100/1000\n",
      "59/59 [==============================] - 12s 201ms/step - loss: 1.2613 - accuracy: 0.9689 - val_loss: 1.2344 - val_accuracy: 0.9694\n",
      "Epoch 101/1000\n",
      "59/59 [==============================] - 12s 201ms/step - loss: 1.2242 - accuracy: 0.9689 - val_loss: 1.2075 - val_accuracy: 0.9694\n",
      "Epoch 102/1000\n",
      "59/59 [==============================] - 12s 202ms/step - loss: 1.1891 - accuracy: 0.9689 - val_loss: 1.1726 - val_accuracy: 0.9694\n",
      "Epoch 103/1000\n",
      "59/59 [==============================] - 12s 202ms/step - loss: 1.1583 - accuracy: 0.9689 - val_loss: 1.1374 - val_accuracy: 0.9694\n",
      "Epoch 104/1000\n",
      "59/59 [==============================] - 12s 202ms/step - loss: 1.1224 - accuracy: 0.9689 - val_loss: 1.1006 - val_accuracy: 0.9694\n",
      "Epoch 105/1000\n",
      "59/59 [==============================] - 12s 202ms/step - loss: 1.0899 - accuracy: 0.9689 - val_loss: 1.0682 - val_accuracy: 0.9694\n",
      "Epoch 106/1000\n",
      "59/59 [==============================] - 12s 201ms/step - loss: 1.0596 - accuracy: 0.9687 - val_loss: 1.0348 - val_accuracy: 0.9694\n",
      "Epoch 107/1000\n",
      "59/59 [==============================] - 12s 201ms/step - loss: 1.0243 - accuracy: 0.9688 - val_loss: 0.9989 - val_accuracy: 0.9694\n",
      "Epoch 108/1000\n",
      "59/59 [==============================] - 12s 201ms/step - loss: 0.9829 - accuracy: 0.9689 - val_loss: 0.9640 - val_accuracy: 0.9694\n",
      "Epoch 109/1000\n",
      "59/59 [==============================] - 12s 203ms/step - loss: 0.9546 - accuracy: 0.9689 - val_loss: 0.9340 - val_accuracy: 0.9694\n",
      "Epoch 110/1000\n",
      "59/59 [==============================] - 12s 202ms/step - loss: 0.9211 - accuracy: 0.9689 - val_loss: 0.9029 - val_accuracy: 0.9694\n",
      "Epoch 111/1000\n",
      "59/59 [==============================] - 12s 202ms/step - loss: 0.8918 - accuracy: 0.9689 - val_loss: 0.8750 - val_accuracy: 0.9694\n",
      "Epoch 112/1000\n",
      "59/59 [==============================] - 12s 201ms/step - loss: 0.8642 - accuracy: 0.9689 - val_loss: 0.8450 - val_accuracy: 0.9694\n",
      "Epoch 113/1000\n",
      "59/59 [==============================] - 12s 202ms/step - loss: 0.8394 - accuracy: 0.9689 - val_loss: 0.8278 - val_accuracy: 0.9694\n",
      "Epoch 114/1000\n",
      "59/59 [==============================] - 12s 200ms/step - loss: 0.8225 - accuracy: 0.9689 - val_loss: 0.7999 - val_accuracy: 0.9694\n",
      "Epoch 115/1000\n",
      "59/59 [==============================] - 12s 202ms/step - loss: 0.7884 - accuracy: 0.9689 - val_loss: 0.7684 - val_accuracy: 0.9694\n",
      "Epoch 116/1000\n",
      "59/59 [==============================] - 12s 202ms/step - loss: 0.7550 - accuracy: 0.9689 - val_loss: 0.7414 - val_accuracy: 0.9694\n",
      "Epoch 117/1000\n",
      "59/59 [==============================] - 12s 201ms/step - loss: 0.7292 - accuracy: 0.9689 - val_loss: 0.7143 - val_accuracy: 0.9694\n",
      "Epoch 118/1000\n",
      "59/59 [==============================] - 12s 201ms/step - loss: 0.7022 - accuracy: 0.9689 - val_loss: 0.6872 - val_accuracy: 0.9694\n",
      "Epoch 119/1000\n",
      "59/59 [==============================] - 12s 200ms/step - loss: 0.6820 - accuracy: 0.9689 - val_loss: 0.6707 - val_accuracy: 0.9694\n",
      "Epoch 120/1000\n",
      "59/59 [==============================] - 12s 200ms/step - loss: 0.6645 - accuracy: 0.9689 - val_loss: 0.6520 - val_accuracy: 0.9694\n",
      "Epoch 121/1000\n",
      "59/59 [==============================] - 12s 202ms/step - loss: 0.6396 - accuracy: 0.9689 - val_loss: 0.6272 - val_accuracy: 0.9694\n",
      "Epoch 122/1000\n",
      "59/59 [==============================] - 12s 202ms/step - loss: 0.6198 - accuracy: 0.9689 - val_loss: 0.6097 - val_accuracy: 0.9694\n",
      "Epoch 123/1000\n",
      "59/59 [==============================] - 12s 201ms/step - loss: 0.6039 - accuracy: 0.9689 - val_loss: 0.5870 - val_accuracy: 0.9694\n",
      "Epoch 124/1000\n",
      "59/59 [==============================] - 12s 200ms/step - loss: 0.5771 - accuracy: 0.9689 - val_loss: 0.5653 - val_accuracy: 0.9694\n",
      "Epoch 125/1000\n",
      "59/59 [==============================] - 12s 200ms/step - loss: 0.5590 - accuracy: 0.9689 - val_loss: 0.5450 - val_accuracy: 0.9694\n",
      "Epoch 126/1000\n",
      "59/59 [==============================] - 12s 202ms/step - loss: 0.5397 - accuracy: 0.9689 - val_loss: 0.5255 - val_accuracy: 0.9694\n",
      "Epoch 127/1000\n",
      "59/59 [==============================] - 12s 201ms/step - loss: 0.5191 - accuracy: 0.9689 - val_loss: 0.5061 - val_accuracy: 0.9694\n",
      "Epoch 128/1000\n",
      "59/59 [==============================] - 12s 201ms/step - loss: 0.5005 - accuracy: 0.9689 - val_loss: 0.4879 - val_accuracy: 0.9694\n",
      "Epoch 129/1000\n",
      "59/59 [==============================] - 12s 200ms/step - loss: 0.4815 - accuracy: 0.9689 - val_loss: 0.4771 - val_accuracy: 0.9694\n",
      "Epoch 130/1000\n",
      "59/59 [==============================] - 12s 203ms/step - loss: 0.4696 - accuracy: 0.9689 - val_loss: 0.4567 - val_accuracy: 0.9694\n",
      "Epoch 131/1000\n",
      "59/59 [==============================] - 12s 200ms/step - loss: 0.4564 - accuracy: 0.9689 - val_loss: 0.4436 - val_accuracy: 0.9694\n",
      "Epoch 132/1000\n",
      "59/59 [==============================] - 12s 201ms/step - loss: 0.4362 - accuracy: 0.9689 - val_loss: 0.4240 - val_accuracy: 0.9694\n",
      "Epoch 133/1000\n",
      "59/59 [==============================] - 12s 200ms/step - loss: 0.4201 - accuracy: 0.9689 - val_loss: 0.4095 - val_accuracy: 0.9694\n",
      "Epoch 134/1000\n",
      "59/59 [==============================] - 12s 202ms/step - loss: 0.4051 - accuracy: 0.9689 - val_loss: 0.3953 - val_accuracy: 0.9694\n",
      "Epoch 135/1000\n",
      "59/59 [==============================] - 12s 201ms/step - loss: 0.3916 - accuracy: 0.9689 - val_loss: 0.3817 - val_accuracy: 0.9694\n",
      "Epoch 136/1000\n",
      "59/59 [==============================] - 12s 202ms/step - loss: 0.3766 - accuracy: 0.9689 - val_loss: 0.3678 - val_accuracy: 0.9694\n",
      "Epoch 137/1000\n",
      "59/59 [==============================] - 12s 200ms/step - loss: 0.3642 - accuracy: 0.9689 - val_loss: 0.3551 - val_accuracy: 0.9694\n",
      "Epoch 138/1000\n",
      "59/59 [==============================] - 12s 201ms/step - loss: 0.3513 - accuracy: 0.9689 - val_loss: 0.3432 - val_accuracy: 0.9694\n",
      "Epoch 139/1000\n",
      "59/59 [==============================] - 12s 202ms/step - loss: 0.3396 - accuracy: 0.9689 - val_loss: 0.3321 - val_accuracy: 0.9694\n",
      "Epoch 140/1000\n",
      "59/59 [==============================] - 12s 202ms/step - loss: 0.3287 - accuracy: 0.9689 - val_loss: 0.3212 - val_accuracy: 0.9694\n",
      "Epoch 141/1000\n",
      "59/59 [==============================] - 12s 201ms/step - loss: 0.3182 - accuracy: 0.9689 - val_loss: 0.3111 - val_accuracy: 0.9694\n",
      "Epoch 142/1000\n",
      "59/59 [==============================] - 12s 201ms/step - loss: 0.3082 - accuracy: 0.9689 - val_loss: 0.3013 - val_accuracy: 0.9694\n",
      "Epoch 143/1000\n",
      "59/59 [==============================] - 12s 202ms/step - loss: 0.2987 - accuracy: 0.9689 - val_loss: 0.2920 - val_accuracy: 0.9694\n",
      "Epoch 144/1000\n",
      "59/59 [==============================] - 12s 201ms/step - loss: 0.2897 - accuracy: 0.9689 - val_loss: 0.2832 - val_accuracy: 0.9694\n",
      "Epoch 145/1000\n",
      "59/59 [==============================] - 12s 201ms/step - loss: 0.2810 - accuracy: 0.9689 - val_loss: 0.2747 - val_accuracy: 0.9694\n",
      "Epoch 146/1000\n",
      "59/59 [==============================] - 12s 201ms/step - loss: 0.2727 - accuracy: 0.9689 - val_loss: 0.2667 - val_accuracy: 0.9694\n",
      "Epoch 147/1000\n",
      "59/59 [==============================] - 12s 201ms/step - loss: 0.2648 - accuracy: 0.9689 - val_loss: 0.2590 - val_accuracy: 0.9694\n",
      "Epoch 148/1000\n",
      "59/59 [==============================] - 12s 202ms/step - loss: 0.2574 - accuracy: 0.9689 - val_loss: 0.2517 - val_accuracy: 0.9694\n",
      "Epoch 149/1000\n",
      "59/59 [==============================] - 12s 201ms/step - loss: 0.2503 - accuracy: 0.9689 - val_loss: 0.2448 - val_accuracy: 0.9694\n",
      "Epoch 150/1000\n",
      "59/59 [==============================] - 12s 202ms/step - loss: 0.2435 - accuracy: 0.9689 - val_loss: 0.2383 - val_accuracy: 0.9694\n",
      "Epoch 151/1000\n",
      "59/59 [==============================] - 12s 200ms/step - loss: 0.2371 - accuracy: 0.9689 - val_loss: 0.2320 - val_accuracy: 0.9694\n",
      "Epoch 152/1000\n",
      "59/59 [==============================] - 12s 202ms/step - loss: 0.2311 - accuracy: 0.9689 - val_loss: 0.2261 - val_accuracy: 0.9694\n",
      "Epoch 153/1000\n",
      "59/59 [==============================] - 12s 202ms/step - loss: 0.2252 - accuracy: 0.9689 - val_loss: 0.2205 - val_accuracy: 0.9694\n",
      "Epoch 154/1000\n",
      "59/59 [==============================] - 12s 201ms/step - loss: 0.2198 - accuracy: 0.9689 - val_loss: 0.2152 - val_accuracy: 0.9694\n",
      "Epoch 155/1000\n",
      "59/59 [==============================] - 12s 201ms/step - loss: 0.2146 - accuracy: 0.9689 - val_loss: 0.2102 - val_accuracy: 0.9694\n",
      "Epoch 156/1000\n",
      "59/59 [==============================] - 12s 201ms/step - loss: 0.2097 - accuracy: 0.9689 - val_loss: 0.2054 - val_accuracy: 0.9694\n",
      "Epoch 157/1000\n",
      "59/59 [==============================] - 12s 202ms/step - loss: 0.2051 - accuracy: 0.9689 - val_loss: 0.2009 - val_accuracy: 0.9694\n",
      "Epoch 158/1000\n",
      "59/59 [==============================] - 12s 202ms/step - loss: 0.2007 - accuracy: 0.9689 - val_loss: 0.1967 - val_accuracy: 0.9694\n",
      "Epoch 159/1000\n",
      "59/59 [==============================] - 12s 201ms/step - loss: 0.1966 - accuracy: 0.9689 - val_loss: 0.1927 - val_accuracy: 0.9694\n",
      "Epoch 160/1000\n",
      "59/59 [==============================] - 12s 202ms/step - loss: 0.1927 - accuracy: 0.9689 - val_loss: 0.1889 - val_accuracy: 0.9694\n",
      "Epoch 161/1000\n",
      "59/59 [==============================] - 12s 202ms/step - loss: 0.1891 - accuracy: 0.9689 - val_loss: 0.1854 - val_accuracy: 0.9694\n",
      "Epoch 162/1000\n",
      "59/59 [==============================] - 12s 200ms/step - loss: 0.1857 - accuracy: 0.9689 - val_loss: 0.1820 - val_accuracy: 0.9694\n",
      "Epoch 163/1000\n",
      "59/59 [==============================] - 12s 201ms/step - loss: 0.1824 - accuracy: 0.9689 - val_loss: 0.1789 - val_accuracy: 0.9694\n",
      "Epoch 164/1000\n",
      "59/59 [==============================] - 12s 201ms/step - loss: 0.1793 - accuracy: 0.9689 - val_loss: 0.1760 - val_accuracy: 0.9694\n",
      "Epoch 165/1000\n",
      "59/59 [==============================] - 12s 203ms/step - loss: 0.1765 - accuracy: 0.9689 - val_loss: 0.1732 - val_accuracy: 0.9694\n",
      "Epoch 166/1000\n",
      "59/59 [==============================] - 12s 200ms/step - loss: 0.1738 - accuracy: 0.9689 - val_loss: 0.1706 - val_accuracy: 0.9694\n",
      "Epoch 167/1000\n",
      "59/59 [==============================] - 12s 202ms/step - loss: 0.1713 - accuracy: 0.9689 - val_loss: 0.1682 - val_accuracy: 0.9694\n",
      "Epoch 168/1000\n",
      "59/59 [==============================] - 12s 203ms/step - loss: 0.1690 - accuracy: 0.9689 - val_loss: 0.1659 - val_accuracy: 0.9694\n",
      "Epoch 169/1000\n",
      "59/59 [==============================] - 12s 201ms/step - loss: 0.1667 - accuracy: 0.9689 - val_loss: 0.1638 - val_accuracy: 0.9694\n",
      "Epoch 170/1000\n",
      "59/59 [==============================] - 12s 201ms/step - loss: 0.1647 - accuracy: 0.9689 - val_loss: 0.1618 - val_accuracy: 0.9694\n",
      "Epoch 171/1000\n",
      "59/59 [==============================] - 12s 201ms/step - loss: 0.1627 - accuracy: 0.9689 - val_loss: 0.1599 - val_accuracy: 0.9694\n",
      "Epoch 172/1000\n",
      "59/59 [==============================] - 12s 202ms/step - loss: 0.1609 - accuracy: 0.9689 - val_loss: 0.1582 - val_accuracy: 0.9694\n",
      "Epoch 173/1000\n",
      "59/59 [==============================] - 12s 201ms/step - loss: 0.1593 - accuracy: 0.9689 - val_loss: 0.1565 - val_accuracy: 0.9694\n",
      "Epoch 174/1000\n",
      "59/59 [==============================] - 12s 200ms/step - loss: 0.1577 - accuracy: 0.9689 - val_loss: 0.1551 - val_accuracy: 0.9694\n",
      "Epoch 175/1000\n",
      "59/59 [==============================] - 12s 201ms/step - loss: 0.1563 - accuracy: 0.9689 - val_loss: 0.1536 - val_accuracy: 0.9694\n",
      "Epoch 176/1000\n",
      "59/59 [==============================] - 12s 202ms/step - loss: 0.1549 - accuracy: 0.9689 - val_loss: 0.1523 - val_accuracy: 0.9694\n",
      "Epoch 177/1000\n",
      "59/59 [==============================] - 12s 201ms/step - loss: 0.1536 - accuracy: 0.9689 - val_loss: 0.1511 - val_accuracy: 0.9694\n",
      "Epoch 178/1000\n",
      "59/59 [==============================] - 12s 200ms/step - loss: 0.1525 - accuracy: 0.9689 - val_loss: 0.1500 - val_accuracy: 0.9694\n",
      "Epoch 179/1000\n",
      "59/59 [==============================] - 12s 201ms/step - loss: 0.1514 - accuracy: 0.9689 - val_loss: 0.1489 - val_accuracy: 0.9694\n",
      "Epoch 180/1000\n",
      "59/59 [==============================] - 12s 201ms/step - loss: 0.1504 - accuracy: 0.9689 - val_loss: 0.1480 - val_accuracy: 0.9694\n",
      "Epoch 181/1000\n",
      "59/59 [==============================] - 12s 201ms/step - loss: 0.1494 - accuracy: 0.9689 - val_loss: 0.1471 - val_accuracy: 0.9694\n",
      "Epoch 182/1000\n",
      "59/59 [==============================] - 12s 202ms/step - loss: 0.1486 - accuracy: 0.9689 - val_loss: 0.1462 - val_accuracy: 0.9694\n",
      "Epoch 183/1000\n",
      "59/59 [==============================] - 12s 203ms/step - loss: 0.1477 - accuracy: 0.9689 - val_loss: 0.1455 - val_accuracy: 0.9694\n",
      "Epoch 184/1000\n",
      "59/59 [==============================] - 12s 201ms/step - loss: 0.1470 - accuracy: 0.9689 - val_loss: 0.1447 - val_accuracy: 0.9694\n",
      "Epoch 185/1000\n",
      "59/59 [==============================] - 12s 200ms/step - loss: 0.1463 - accuracy: 0.9689 - val_loss: 0.1441 - val_accuracy: 0.9694\n",
      "Epoch 186/1000\n",
      "59/59 [==============================] - 12s 200ms/step - loss: 0.1457 - accuracy: 0.9689 - val_loss: 0.1435 - val_accuracy: 0.9694\n",
      "Epoch 187/1000\n",
      "59/59 [==============================] - 12s 201ms/step - loss: 0.1451 - accuracy: 0.9689 - val_loss: 0.1429 - val_accuracy: 0.9694\n",
      "Epoch 188/1000\n",
      "59/59 [==============================] - 12s 201ms/step - loss: 0.1446 - accuracy: 0.9689 - val_loss: 0.1424 - val_accuracy: 0.9694\n",
      "Epoch 189/1000\n",
      "59/59 [==============================] - 12s 200ms/step - loss: 0.1440 - accuracy: 0.9689 - val_loss: 0.1419 - val_accuracy: 0.9694\n",
      "Epoch 190/1000\n",
      "59/59 [==============================] - 12s 203ms/step - loss: 0.1436 - accuracy: 0.9689 - val_loss: 0.1415 - val_accuracy: 0.9694\n",
      "Epoch 191/1000\n",
      "59/59 [==============================] - 12s 201ms/step - loss: 0.1432 - accuracy: 0.9689 - val_loss: 0.1411 - val_accuracy: 0.9694\n",
      "Epoch 192/1000\n",
      "59/59 [==============================] - 12s 200ms/step - loss: 0.1428 - accuracy: 0.9689 - val_loss: 0.1407 - val_accuracy: 0.9694\n",
      "Epoch 193/1000\n",
      "59/59 [==============================] - 12s 201ms/step - loss: 0.1425 - accuracy: 0.9689 - val_loss: 0.1404 - val_accuracy: 0.9694\n",
      "Epoch 194/1000\n",
      "59/59 [==============================] - 12s 200ms/step - loss: 0.1421 - accuracy: 0.9689 - val_loss: 0.1401 - val_accuracy: 0.9694\n",
      "Epoch 195/1000\n",
      "59/59 [==============================] - 12s 202ms/step - loss: 0.1418 - accuracy: 0.9689 - val_loss: 0.1398 - val_accuracy: 0.9694\n",
      "Epoch 196/1000\n",
      "59/59 [==============================] - 12s 200ms/step - loss: 0.1415 - accuracy: 0.9689 - val_loss: 0.1395 - val_accuracy: 0.9694\n",
      "Epoch 197/1000\n",
      "59/59 [==============================] - 12s 201ms/step - loss: 0.1413 - accuracy: 0.9689 - val_loss: 0.1393 - val_accuracy: 0.9694\n",
      "Epoch 198/1000\n",
      "59/59 [==============================] - 12s 200ms/step - loss: 0.1410 - accuracy: 0.9689 - val_loss: 0.1390 - val_accuracy: 0.9694\n",
      "Epoch 199/1000\n",
      "59/59 [==============================] - 12s 202ms/step - loss: 0.1408 - accuracy: 0.9689 - val_loss: 0.1388 - val_accuracy: 0.9694\n",
      "Epoch 200/1000\n",
      "59/59 [==============================] - 12s 200ms/step - loss: 0.1406 - accuracy: 0.9689 - val_loss: 0.1386 - val_accuracy: 0.9694\n",
      "Epoch 201/1000\n",
      "59/59 [==============================] - 12s 200ms/step - loss: 0.1405 - accuracy: 0.9689 - val_loss: 0.1385 - val_accuracy: 0.9694\n",
      "Epoch 202/1000\n",
      "59/59 [==============================] - 12s 201ms/step - loss: 0.1403 - accuracy: 0.9689 - val_loss: 0.1383 - val_accuracy: 0.9694\n",
      "Epoch 203/1000\n",
      "59/59 [==============================] - 12s 201ms/step - loss: 0.1402 - accuracy: 0.9689 - val_loss: 0.1382 - val_accuracy: 0.9694\n",
      "Epoch 204/1000\n",
      "59/59 [==============================] - 12s 201ms/step - loss: 0.1400 - accuracy: 0.9689 - val_loss: 0.1380 - val_accuracy: 0.9694\n",
      "Epoch 205/1000\n",
      "59/59 [==============================] - 12s 200ms/step - loss: 0.1399 - accuracy: 0.9689 - val_loss: 0.1379 - val_accuracy: 0.9694\n",
      "Epoch 206/1000\n",
      "59/59 [==============================] - 12s 202ms/step - loss: 0.1398 - accuracy: 0.9689 - val_loss: 0.1378 - val_accuracy: 0.9694\n",
      "Epoch 207/1000\n",
      "59/59 [==============================] - 12s 200ms/step - loss: 0.1397 - accuracy: 0.9689 - val_loss: 0.1377 - val_accuracy: 0.9694\n",
      "Epoch 208/1000\n",
      "59/59 [==============================] - 12s 203ms/step - loss: 0.1396 - accuracy: 0.9689 - val_loss: 0.1376 - val_accuracy: 0.9694\n",
      "Epoch 209/1000\n",
      "59/59 [==============================] - 12s 201ms/step - loss: 0.1395 - accuracy: 0.9689 - val_loss: 0.1375 - val_accuracy: 0.9694\n",
      "Epoch 210/1000\n",
      "59/59 [==============================] - 12s 202ms/step - loss: 0.1394 - accuracy: 0.9689 - val_loss: 0.1375 - val_accuracy: 0.9694\n",
      "Epoch 211/1000\n",
      "59/59 [==============================] - 12s 202ms/step - loss: 0.1393 - accuracy: 0.9689 - val_loss: 0.1374 - val_accuracy: 0.9694\n",
      "Epoch 212/1000\n",
      "59/59 [==============================] - 12s 201ms/step - loss: 0.1392 - accuracy: 0.9689 - val_loss: 0.1373 - val_accuracy: 0.9694\n",
      "Epoch 213/1000\n",
      "59/59 [==============================] - 12s 201ms/step - loss: 0.1392 - accuracy: 0.9689 - val_loss: 0.1373 - val_accuracy: 0.9694\n",
      "Epoch 214/1000\n",
      "59/59 [==============================] - 12s 201ms/step - loss: 0.1392 - accuracy: 0.9689 - val_loss: 0.1372 - val_accuracy: 0.9694\n",
      "Epoch 215/1000\n",
      "59/59 [==============================] - 12s 202ms/step - loss: 0.1391 - accuracy: 0.9689 - val_loss: 0.1372 - val_accuracy: 0.9694\n",
      "Epoch 216/1000\n",
      "59/59 [==============================] - 12s 201ms/step - loss: 0.1391 - accuracy: 0.9689 - val_loss: 0.1371 - val_accuracy: 0.9694\n",
      "Epoch 217/1000\n",
      "59/59 [==============================] - 12s 202ms/step - loss: 0.1390 - accuracy: 0.9689 - val_loss: 0.1371 - val_accuracy: 0.9694\n",
      "Epoch 218/1000\n",
      "59/59 [==============================] - 12s 201ms/step - loss: 0.1390 - accuracy: 0.9689 - val_loss: 0.1371 - val_accuracy: 0.9694\n",
      "Epoch 219/1000\n",
      "59/59 [==============================] - 12s 202ms/step - loss: 0.1389 - accuracy: 0.9689 - val_loss: 0.1370 - val_accuracy: 0.9694\n",
      "Epoch 220/1000\n",
      "59/59 [==============================] - 12s 202ms/step - loss: 0.1390 - accuracy: 0.9689 - val_loss: 0.1371 - val_accuracy: 0.9694\n",
      "Epoch 221/1000\n",
      "59/59 [==============================] - 12s 201ms/step - loss: 0.1389 - accuracy: 0.9689 - val_loss: 0.1370 - val_accuracy: 0.9694\n",
      "Epoch 222/1000\n",
      "59/59 [==============================] - 12s 203ms/step - loss: 0.1389 - accuracy: 0.9689 - val_loss: 0.1370 - val_accuracy: 0.9694\n",
      "Epoch 223/1000\n",
      "59/59 [==============================] - 12s 201ms/step - loss: 0.1388 - accuracy: 0.9689 - val_loss: 0.1369 - val_accuracy: 0.9694\n",
      "Epoch 224/1000\n",
      "59/59 [==============================] - 12s 201ms/step - loss: 0.1388 - accuracy: 0.9689 - val_loss: 0.1369 - val_accuracy: 0.9694\n",
      "Epoch 225/1000\n",
      "59/59 [==============================] - 12s 201ms/step - loss: 0.1388 - accuracy: 0.9689 - val_loss: 0.1369 - val_accuracy: 0.9694\n",
      "Epoch 226/1000\n",
      "59/59 [==============================] - 12s 201ms/step - loss: 0.1388 - accuracy: 0.9689 - val_loss: 0.1369 - val_accuracy: 0.9694\n",
      "Epoch 227/1000\n",
      "59/59 [==============================] - 12s 201ms/step - loss: 0.1388 - accuracy: 0.9689 - val_loss: 0.1369 - val_accuracy: 0.9694\n",
      "Epoch 228/1000\n",
      "59/59 [==============================] - 12s 202ms/step - loss: 0.1387 - accuracy: 0.9689 - val_loss: 0.1369 - val_accuracy: 0.9694\n",
      "Epoch 229/1000\n",
      "59/59 [==============================] - 12s 202ms/step - loss: 0.1387 - accuracy: 0.9689 - val_loss: 0.1368 - val_accuracy: 0.9694\n",
      "Epoch 230/1000\n",
      "59/59 [==============================] - 12s 201ms/step - loss: 0.1387 - accuracy: 0.9689 - val_loss: 0.1368 - val_accuracy: 0.9694\n",
      "Epoch 231/1000\n",
      "59/59 [==============================] - 12s 202ms/step - loss: 0.1387 - accuracy: 0.9689 - val_loss: 0.1368 - val_accuracy: 0.9694\n",
      "Epoch 232/1000\n",
      "59/59 [==============================] - 12s 201ms/step - loss: 0.1388 - accuracy: 0.9689 - val_loss: 0.1368 - val_accuracy: 0.9694\n",
      "Epoch 233/1000\n",
      "59/59 [==============================] - 12s 201ms/step - loss: 0.1387 - accuracy: 0.9689 - val_loss: 0.1368 - val_accuracy: 0.9694\n",
      "Epoch 234/1000\n",
      "59/59 [==============================] - 12s 200ms/step - loss: 0.1387 - accuracy: 0.9689 - val_loss: 0.1368 - val_accuracy: 0.9694\n",
      "Epoch 235/1000\n",
      "59/59 [==============================] - 12s 201ms/step - loss: 0.1388 - accuracy: 0.9689 - val_loss: 0.1368 - val_accuracy: 0.9694\n",
      "Epoch 236/1000\n",
      "59/59 [==============================] - 12s 202ms/step - loss: 0.1387 - accuracy: 0.9689 - val_loss: 0.1368 - val_accuracy: 0.9694\n",
      "Epoch 237/1000\n",
      "59/59 [==============================] - 12s 201ms/step - loss: 0.1387 - accuracy: 0.9689 - val_loss: 0.1368 - val_accuracy: 0.9694\n",
      "Epoch 238/1000\n",
      "59/59 [==============================] - 12s 202ms/step - loss: 0.1387 - accuracy: 0.9689 - val_loss: 0.1368 - val_accuracy: 0.9694\n",
      "Epoch 239/1000\n",
      "59/59 [==============================] - 12s 200ms/step - loss: 0.1387 - accuracy: 0.9689 - val_loss: 0.1368 - val_accuracy: 0.9694\n",
      "Epoch 240/1000\n",
      "59/59 [==============================] - 12s 201ms/step - loss: 0.1387 - accuracy: 0.9689 - val_loss: 0.1368 - val_accuracy: 0.9694\n",
      "Epoch 241/1000\n",
      "59/59 [==============================] - 12s 205ms/step - loss: 0.1387 - accuracy: 0.9689 - val_loss: 0.1368 - val_accuracy: 0.9694\n",
      "Epoch 242/1000\n",
      "59/59 [==============================] - 12s 201ms/step - loss: 0.1387 - accuracy: 0.9689 - val_loss: 0.1368 - val_accuracy: 0.9694\n",
      "Epoch 243/1000\n",
      "59/59 [==============================] - 12s 201ms/step - loss: 0.1387 - accuracy: 0.9689 - val_loss: 0.1368 - val_accuracy: 0.9694\n",
      "Epoch 244/1000\n",
      "59/59 [==============================] - 12s 202ms/step - loss: 0.1387 - accuracy: 0.9689 - val_loss: 0.1368 - val_accuracy: 0.9694\n",
      "Epoch 245/1000\n",
      "59/59 [==============================] - 12s 202ms/step - loss: 0.1387 - accuracy: 0.9689 - val_loss: 0.1368 - val_accuracy: 0.9694\n",
      "Epoch 246/1000\n",
      "59/59 [==============================] - 12s 201ms/step - loss: 0.1387 - accuracy: 0.9689 - val_loss: 0.1368 - val_accuracy: 0.9694\n",
      "Epoch 247/1000\n",
      "59/59 [==============================] - 12s 202ms/step - loss: 0.1387 - accuracy: 0.9689 - val_loss: 0.1368 - val_accuracy: 0.9694\n",
      "Epoch 248/1000\n",
      "59/59 [==============================] - 12s 202ms/step - loss: 0.1387 - accuracy: 0.9689 - val_loss: 0.1368 - val_accuracy: 0.9694\n",
      "Epoch 249/1000\n",
      "59/59 [==============================] - 12s 201ms/step - loss: 0.1387 - accuracy: 0.9689 - val_loss: 0.1368 - val_accuracy: 0.9694\n",
      "Epoch 250/1000\n",
      "59/59 [==============================] - 12s 201ms/step - loss: 0.1387 - accuracy: 0.9689 - val_loss: 0.1368 - val_accuracy: 0.9694\n",
      "Epoch 251/1000\n",
      "59/59 [==============================] - 12s 200ms/step - loss: 0.1387 - accuracy: 0.9689 - val_loss: 0.1368 - val_accuracy: 0.9694\n",
      "Epoch 252/1000\n",
      "59/59 [==============================] - 12s 200ms/step - loss: 0.1387 - accuracy: 0.9689 - val_loss: 0.1368 - val_accuracy: 0.9694\n",
      "Epoch 253/1000\n",
      "59/59 [==============================] - 12s 202ms/step - loss: 0.1388 - accuracy: 0.9689 - val_loss: 0.1368 - val_accuracy: 0.9694\n",
      "Epoch 254/1000\n",
      "59/59 [==============================] - 12s 202ms/step - loss: 0.1388 - accuracy: 0.9689 - val_loss: 0.1368 - val_accuracy: 0.9694\n",
      "Epoch 255/1000\n",
      "59/59 [==============================] - 12s 202ms/step - loss: 0.1387 - accuracy: 0.9689 - val_loss: 0.1368 - val_accuracy: 0.9694\n",
      "Epoch 256/1000\n",
      "59/59 [==============================] - 12s 201ms/step - loss: 0.1387 - accuracy: 0.9689 - val_loss: 0.1368 - val_accuracy: 0.9694\n",
      "Epoch 257/1000\n",
      "59/59 [==============================] - 12s 201ms/step - loss: 0.1387 - accuracy: 0.9689 - val_loss: 0.1368 - val_accuracy: 0.9694\n",
      "Epoch 258/1000\n",
      "59/59 [==============================] - 12s 201ms/step - loss: 0.1387 - accuracy: 0.9689 - val_loss: 0.1368 - val_accuracy: 0.9694\n",
      "Epoch 259/1000\n",
      "59/59 [==============================] - 12s 201ms/step - loss: 0.1387 - accuracy: 0.9689 - val_loss: 0.1368 - val_accuracy: 0.9694\n",
      "Epoch 260/1000\n",
      "59/59 [==============================] - 12s 201ms/step - loss: 0.1387 - accuracy: 0.9689 - val_loss: 0.1368 - val_accuracy: 0.9694\n",
      "Epoch 261/1000\n",
      "59/59 [==============================] - 12s 201ms/step - loss: 0.1387 - accuracy: 0.9689 - val_loss: 0.1368 - val_accuracy: 0.9694\n",
      "Epoch 262/1000\n",
      "59/59 [==============================] - 12s 202ms/step - loss: 0.1387 - accuracy: 0.9689 - val_loss: 0.1368 - val_accuracy: 0.9694\n",
      "Epoch 263/1000\n",
      "59/59 [==============================] - 12s 201ms/step - loss: 0.1387 - accuracy: 0.9689 - val_loss: 0.1368 - val_accuracy: 0.9694\n",
      "Epoch 264/1000\n",
      "59/59 [==============================] - 12s 203ms/step - loss: 0.1387 - accuracy: 0.9689 - val_loss: 0.1368 - val_accuracy: 0.9694\n",
      "Epoch 265/1000\n",
      "59/59 [==============================] - 12s 201ms/step - loss: 0.1387 - accuracy: 0.9689 - val_loss: 0.1368 - val_accuracy: 0.9694\n",
      "Epoch 266/1000\n",
      "59/59 [==============================] - 12s 202ms/step - loss: 0.1387 - accuracy: 0.9689 - val_loss: 0.1368 - val_accuracy: 0.9694\n",
      "Epoch 267/1000\n",
      "59/59 [==============================] - 12s 202ms/step - loss: 0.1387 - accuracy: 0.9689 - val_loss: 0.1368 - val_accuracy: 0.9694\n",
      "Epoch 268/1000\n",
      "59/59 [==============================] - 12s 204ms/step - loss: 0.1387 - accuracy: 0.9689 - val_loss: 0.1368 - val_accuracy: 0.9694\n",
      "Epoch 269/1000\n",
      "59/59 [==============================] - 13s 212ms/step - loss: 0.1387 - accuracy: 0.9689 - val_loss: 0.1368 - val_accuracy: 0.9694\n",
      "Epoch 270/1000\n",
      "59/59 [==============================] - 12s 208ms/step - loss: 0.1387 - accuracy: 0.9689 - val_loss: 0.1368 - val_accuracy: 0.9694\n",
      "Epoch 271/1000\n",
      "59/59 [==============================] - 12s 201ms/step - loss: 0.1387 - accuracy: 0.9689 - val_loss: 0.1368 - val_accuracy: 0.9694\n",
      "Epoch 272/1000\n",
      "59/59 [==============================] - 12s 201ms/step - loss: 0.1387 - accuracy: 0.9689 - val_loss: 0.1368 - val_accuracy: 0.9694\n",
      "Epoch 273/1000\n",
      "59/59 [==============================] - 12s 203ms/step - loss: 0.1387 - accuracy: 0.9689 - val_loss: 0.1368 - val_accuracy: 0.9694\n",
      "Epoch 274/1000\n",
      "59/59 [==============================] - 12s 202ms/step - loss: 0.1387 - accuracy: 0.9689 - val_loss: 0.1368 - val_accuracy: 0.9694\n",
      "Epoch 275/1000\n",
      "59/59 [==============================] - 12s 201ms/step - loss: 0.1387 - accuracy: 0.9689 - val_loss: 0.1368 - val_accuracy: 0.9694\n",
      "Epoch 276/1000\n",
      "59/59 [==============================] - 12s 201ms/step - loss: 0.1387 - accuracy: 0.9689 - val_loss: 0.1368 - val_accuracy: 0.9694\n",
      "Epoch 277/1000\n",
      "59/59 [==============================] - 12s 200ms/step - loss: 0.1387 - accuracy: 0.9689 - val_loss: 0.1368 - val_accuracy: 0.9694\n",
      "Epoch 278/1000\n",
      "59/59 [==============================] - 12s 200ms/step - loss: 0.1387 - accuracy: 0.9689 - val_loss: 0.1368 - val_accuracy: 0.9694\n",
      "Epoch 279/1000\n",
      "59/59 [==============================] - 12s 202ms/step - loss: 0.1387 - accuracy: 0.9689 - val_loss: 0.1368 - val_accuracy: 0.9694\n",
      "Epoch 280/1000\n",
      "59/59 [==============================] - 12s 201ms/step - loss: 0.1387 - accuracy: 0.9689 - val_loss: 0.1368 - val_accuracy: 0.9694\n",
      "Epoch 281/1000\n",
      "59/59 [==============================] - 12s 202ms/step - loss: 0.1387 - accuracy: 0.9689 - val_loss: 0.1368 - val_accuracy: 0.9694\n",
      "Epoch 282/1000\n",
      "59/59 [==============================] - 12s 200ms/step - loss: 0.1388 - accuracy: 0.9689 - val_loss: 0.1368 - val_accuracy: 0.9694\n",
      "Epoch 283/1000\n",
      "59/59 [==============================] - 12s 201ms/step - loss: 0.1387 - accuracy: 0.9689 - val_loss: 0.1368 - val_accuracy: 0.9694\n",
      "Epoch 284/1000\n",
      "59/59 [==============================] - 12s 200ms/step - loss: 0.1387 - accuracy: 0.9689 - val_loss: 0.1368 - val_accuracy: 0.9694\n",
      "Epoch 285/1000\n",
      "59/59 [==============================] - 12s 201ms/step - loss: 0.1387 - accuracy: 0.9689 - val_loss: 0.1368 - val_accuracy: 0.9694\n",
      "Epoch 286/1000\n",
      "59/59 [==============================] - 12s 201ms/step - loss: 0.1388 - accuracy: 0.9689 - val_loss: 0.1368 - val_accuracy: 0.9694\n",
      "Epoch 287/1000\n",
      "59/59 [==============================] - 12s 201ms/step - loss: 0.1387 - accuracy: 0.9689 - val_loss: 0.1368 - val_accuracy: 0.9694\n",
      "Epoch 288/1000\n",
      "59/59 [==============================] - 12s 200ms/step - loss: 0.1387 - accuracy: 0.9689 - val_loss: 0.1368 - val_accuracy: 0.9694\n",
      "Epoch 289/1000\n",
      "59/59 [==============================] - 12s 201ms/step - loss: 0.1387 - accuracy: 0.9689 - val_loss: 0.1368 - val_accuracy: 0.9694\n",
      "Epoch 290/1000\n",
      "59/59 [==============================] - 12s 201ms/step - loss: 0.1387 - accuracy: 0.9689 - val_loss: 0.1368 - val_accuracy: 0.9694\n",
      "Epoch 291/1000\n",
      "59/59 [==============================] - 12s 201ms/step - loss: 0.1387 - accuracy: 0.9689 - val_loss: 0.1368 - val_accuracy: 0.9694\n",
      "Epoch 292/1000\n",
      "59/59 [==============================] - 12s 203ms/step - loss: 0.1387 - accuracy: 0.9689 - val_loss: 0.1369 - val_accuracy: 0.9694\n",
      "Epoch 293/1000\n",
      "59/59 [==============================] - 12s 201ms/step - loss: 0.1387 - accuracy: 0.9689 - val_loss: 0.1368 - val_accuracy: 0.9694\n",
      "Epoch 294/1000\n",
      "59/59 [==============================] - 12s 200ms/step - loss: 0.1387 - accuracy: 0.9689 - val_loss: 0.1368 - val_accuracy: 0.9694\n",
      "Epoch 295/1000\n",
      "59/59 [==============================] - 12s 201ms/step - loss: 0.1387 - accuracy: 0.9689 - val_loss: 0.1368 - val_accuracy: 0.9694\n",
      "Epoch 296/1000\n",
      "59/59 [==============================] - 12s 200ms/step - loss: 0.1387 - accuracy: 0.9689 - val_loss: 0.1368 - val_accuracy: 0.9694\n",
      "Epoch 297/1000\n",
      "59/59 [==============================] - 12s 200ms/step - loss: 0.1388 - accuracy: 0.9689 - val_loss: 0.1368 - val_accuracy: 0.9694\n",
      "Epoch 298/1000\n",
      "59/59 [==============================] - 12s 201ms/step - loss: 0.1387 - accuracy: 0.9689 - val_loss: 0.1368 - val_accuracy: 0.9694\n",
      "Epoch 299/1000\n",
      "59/59 [==============================] - 12s 202ms/step - loss: 0.1387 - accuracy: 0.9689 - val_loss: 0.1368 - val_accuracy: 0.9694\n",
      "Epoch 300/1000\n",
      "59/59 [==============================] - 12s 202ms/step - loss: 0.1387 - accuracy: 0.9689 - val_loss: 0.1368 - val_accuracy: 0.9694\n",
      "Epoch 301/1000\n",
      "59/59 [==============================] - 12s 201ms/step - loss: 0.1387 - accuracy: 0.9689 - val_loss: 0.1368 - val_accuracy: 0.9694\n",
      "Epoch 302/1000\n",
      "59/59 [==============================] - 12s 203ms/step - loss: 0.1388 - accuracy: 0.9689 - val_loss: 0.1368 - val_accuracy: 0.9694\n",
      "Epoch 303/1000\n",
      "59/59 [==============================] - 12s 201ms/step - loss: 0.1387 - accuracy: 0.9689 - val_loss: 0.1369 - val_accuracy: 0.9694\n",
      "Epoch 304/1000\n",
      "59/59 [==============================] - 12s 203ms/step - loss: 0.1387 - accuracy: 0.9689 - val_loss: 0.1368 - val_accuracy: 0.9694\n",
      "Epoch 305/1000\n",
      "59/59 [==============================] - 12s 201ms/step - loss: 0.1387 - accuracy: 0.9689 - val_loss: 0.1368 - val_accuracy: 0.9694\n",
      "Epoch 306/1000\n",
      "59/59 [==============================] - 12s 200ms/step - loss: 0.1388 - accuracy: 0.9689 - val_loss: 0.1369 - val_accuracy: 0.9694\n",
      "Epoch 307/1000\n",
      "59/59 [==============================] - 12s 202ms/step - loss: 0.1387 - accuracy: 0.9689 - val_loss: 0.1368 - val_accuracy: 0.9694\n",
      "Epoch 308/1000\n",
      "59/59 [==============================] - 12s 201ms/step - loss: 0.1387 - accuracy: 0.9689 - val_loss: 0.1370 - val_accuracy: 0.9694\n",
      "Epoch 309/1000\n",
      "59/59 [==============================] - 12s 201ms/step - loss: 0.1388 - accuracy: 0.9689 - val_loss: 0.1368 - val_accuracy: 0.9694\n",
      "Epoch 310/1000\n",
      "59/59 [==============================] - 12s 200ms/step - loss: 0.1387 - accuracy: 0.9689 - val_loss: 0.1368 - val_accuracy: 0.9694\n",
      "Epoch 311/1000\n",
      "59/59 [==============================] - 12s 201ms/step - loss: 0.1387 - accuracy: 0.9689 - val_loss: 0.1368 - val_accuracy: 0.9694\n",
      "Epoch 312/1000\n",
      "59/59 [==============================] - 12s 201ms/step - loss: 0.1387 - accuracy: 0.9689 - val_loss: 0.1369 - val_accuracy: 0.9694\n",
      "Epoch 313/1000\n",
      "59/59 [==============================] - 12s 201ms/step - loss: 0.1387 - accuracy: 0.9689 - val_loss: 0.1368 - val_accuracy: 0.9694\n",
      "Epoch 314/1000\n",
      "59/59 [==============================] - 12s 201ms/step - loss: 0.1387 - accuracy: 0.9689 - val_loss: 0.1368 - val_accuracy: 0.9694\n",
      "Epoch 315/1000\n",
      "59/59 [==============================] - 12s 201ms/step - loss: 0.1387 - accuracy: 0.9689 - val_loss: 0.1368 - val_accuracy: 0.9694\n",
      "Epoch 316/1000\n",
      "59/59 [==============================] - 12s 202ms/step - loss: 0.1387 - accuracy: 0.9689 - val_loss: 0.1368 - val_accuracy: 0.9694\n",
      "Epoch 317/1000\n",
      "59/59 [==============================] - 12s 200ms/step - loss: 0.1388 - accuracy: 0.9689 - val_loss: 0.1369 - val_accuracy: 0.9694\n",
      "Epoch 318/1000\n",
      "59/59 [==============================] - 12s 202ms/step - loss: 0.1388 - accuracy: 0.9689 - val_loss: 0.1369 - val_accuracy: 0.9694\n",
      "Epoch 319/1000\n",
      "59/59 [==============================] - 12s 202ms/step - loss: 0.1387 - accuracy: 0.9689 - val_loss: 0.1368 - val_accuracy: 0.9694\n",
      "Epoch 320/1000\n",
      "59/59 [==============================] - 12s 201ms/step - loss: 0.1388 - accuracy: 0.9689 - val_loss: 0.1368 - val_accuracy: 0.9694\n",
      "Epoch 321/1000\n",
      "59/59 [==============================] - 12s 202ms/step - loss: 0.1388 - accuracy: 0.9689 - val_loss: 0.1374 - val_accuracy: 0.9694\n",
      "Epoch 322/1000\n",
      "59/59 [==============================] - 12s 203ms/step - loss: 0.1388 - accuracy: 0.9689 - val_loss: 0.1368 - val_accuracy: 0.9694\n",
      "Epoch 323/1000\n",
      "59/59 [==============================] - 12s 201ms/step - loss: 0.1388 - accuracy: 0.9689 - val_loss: 0.1368 - val_accuracy: 0.9694\n",
      "Epoch 324/1000\n",
      "59/59 [==============================] - 12s 203ms/step - loss: 0.1388 - accuracy: 0.9689 - val_loss: 0.1378 - val_accuracy: 0.9694\n",
      "Epoch 325/1000\n",
      "59/59 [==============================] - 12s 201ms/step - loss: 0.1409 - accuracy: 0.9689 - val_loss: 0.1389 - val_accuracy: 0.9694\n",
      "Epoch 326/1000\n",
      "59/59 [==============================] - 12s 201ms/step - loss: 0.1395 - accuracy: 0.9689 - val_loss: 0.1371 - val_accuracy: 0.9694\n",
      "Epoch 327/1000\n",
      "59/59 [==============================] - 12s 202ms/step - loss: 0.1389 - accuracy: 0.9689 - val_loss: 0.1369 - val_accuracy: 0.9694\n",
      "Epoch 328/1000\n",
      "59/59 [==============================] - 12s 202ms/step - loss: 0.1388 - accuracy: 0.9689 - val_loss: 0.1369 - val_accuracy: 0.9694\n",
      "Epoch 329/1000\n",
      "59/59 [==============================] - 12s 203ms/step - loss: 0.1387 - accuracy: 0.9689 - val_loss: 0.1368 - val_accuracy: 0.9694\n",
      "Epoch 330/1000\n",
      "59/59 [==============================] - 12s 202ms/step - loss: 0.1387 - accuracy: 0.9689 - val_loss: 0.1370 - val_accuracy: 0.9694\n",
      "Epoch 331/1000\n",
      "59/59 [==============================] - 12s 202ms/step - loss: 0.1396 - accuracy: 0.9689 - val_loss: 0.1374 - val_accuracy: 0.9694\n",
      "Epoch 332/1000\n",
      "59/59 [==============================] - 12s 202ms/step - loss: 0.1392 - accuracy: 0.9689 - val_loss: 0.1370 - val_accuracy: 0.9694\n",
      "Epoch 333/1000\n",
      "59/59 [==============================] - 12s 202ms/step - loss: 0.1389 - accuracy: 0.9689 - val_loss: 0.1368 - val_accuracy: 0.9694\n",
      "Epoch 334/1000\n",
      "59/59 [==============================] - 12s 202ms/step - loss: 0.1387 - accuracy: 0.9689 - val_loss: 0.1368 - val_accuracy: 0.9694\n",
      "Epoch 335/1000\n",
      "59/59 [==============================] - 12s 202ms/step - loss: 0.1387 - accuracy: 0.9689 - val_loss: 0.1372 - val_accuracy: 0.9694\n",
      "Epoch 336/1000\n",
      "59/59 [==============================] - 12s 201ms/step - loss: 0.1388 - accuracy: 0.9689 - val_loss: 0.1368 - val_accuracy: 0.9694\n",
      "Epoch 337/1000\n",
      "59/59 [==============================] - 12s 203ms/step - loss: 0.1387 - accuracy: 0.9689 - val_loss: 0.1369 - val_accuracy: 0.9694\n",
      "Epoch 338/1000\n",
      "59/59 [==============================] - 12s 201ms/step - loss: 0.1390 - accuracy: 0.9689 - val_loss: 0.1370 - val_accuracy: 0.9694\n",
      "Epoch 339/1000\n",
      "59/59 [==============================] - 12s 202ms/step - loss: 0.1387 - accuracy: 0.9689 - val_loss: 0.1368 - val_accuracy: 0.9694\n",
      "Epoch 340/1000\n",
      "59/59 [==============================] - 12s 200ms/step - loss: 0.1388 - accuracy: 0.9689 - val_loss: 0.1370 - val_accuracy: 0.9694\n",
      "Epoch 341/1000\n",
      "59/59 [==============================] - 12s 200ms/step - loss: 0.1390 - accuracy: 0.9689 - val_loss: 0.1370 - val_accuracy: 0.9694\n",
      "Epoch 342/1000\n",
      "59/59 [==============================] - 12s 202ms/step - loss: 0.1387 - accuracy: 0.9689 - val_loss: 0.1368 - val_accuracy: 0.9694\n",
      "Epoch 343/1000\n",
      "59/59 [==============================] - 12s 202ms/step - loss: 0.1387 - accuracy: 0.9689 - val_loss: 0.1368 - val_accuracy: 0.9694\n",
      "Epoch 344/1000\n",
      "59/59 [==============================] - 12s 200ms/step - loss: 0.1387 - accuracy: 0.9689 - val_loss: 0.1368 - val_accuracy: 0.9694\n",
      "Epoch 345/1000\n",
      "59/59 [==============================] - 12s 202ms/step - loss: 0.1389 - accuracy: 0.9689 - val_loss: 0.1370 - val_accuracy: 0.9694\n",
      "Epoch 346/1000\n",
      "59/59 [==============================] - 12s 203ms/step - loss: 0.1389 - accuracy: 0.9689 - val_loss: 0.1372 - val_accuracy: 0.9694\n",
      "Epoch 347/1000\n",
      "59/59 [==============================] - 12s 202ms/step - loss: 0.1388 - accuracy: 0.9689 - val_loss: 0.1369 - val_accuracy: 0.9694\n",
      "Epoch 348/1000\n",
      "59/59 [==============================] - 12s 200ms/step - loss: 0.1387 - accuracy: 0.9689 - val_loss: 0.1368 - val_accuracy: 0.9694\n",
      "Epoch 349/1000\n",
      "59/59 [==============================] - 12s 200ms/step - loss: 0.1387 - accuracy: 0.9689 - val_loss: 0.1368 - val_accuracy: 0.9694\n",
      "Epoch 350/1000\n",
      "59/59 [==============================] - 12s 201ms/step - loss: 0.1387 - accuracy: 0.9689 - val_loss: 0.1370 - val_accuracy: 0.9694\n",
      "Epoch 351/1000\n",
      "59/59 [==============================] - 12s 201ms/step - loss: 0.1388 - accuracy: 0.9689 - val_loss: 0.1368 - val_accuracy: 0.9694\n",
      "Epoch 352/1000\n",
      "59/59 [==============================] - 12s 200ms/step - loss: 0.1388 - accuracy: 0.9689 - val_loss: 0.1371 - val_accuracy: 0.9694\n",
      "Epoch 353/1000\n",
      "59/59 [==============================] - 12s 201ms/step - loss: 0.1388 - accuracy: 0.9689 - val_loss: 0.1368 - val_accuracy: 0.9694\n",
      "Epoch 354/1000\n",
      "59/59 [==============================] - 12s 201ms/step - loss: 0.1388 - accuracy: 0.9689 - val_loss: 0.1369 - val_accuracy: 0.9694\n",
      "Epoch 355/1000\n",
      "59/59 [==============================] - 12s 201ms/step - loss: 0.1387 - accuracy: 0.9689 - val_loss: 0.1368 - val_accuracy: 0.9694\n",
      "Epoch 356/1000\n",
      "59/59 [==============================] - 12s 200ms/step - loss: 0.1387 - accuracy: 0.9689 - val_loss: 0.1369 - val_accuracy: 0.9694\n",
      "Epoch 357/1000\n",
      "59/59 [==============================] - 12s 201ms/step - loss: 0.1389 - accuracy: 0.9689 - val_loss: 0.1368 - val_accuracy: 0.9694\n",
      "Epoch 358/1000\n",
      "59/59 [==============================] - 12s 201ms/step - loss: 0.1388 - accuracy: 0.9689 - val_loss: 0.1369 - val_accuracy: 0.9694\n",
      "Epoch 359/1000\n",
      "59/59 [==============================] - 12s 201ms/step - loss: 0.1387 - accuracy: 0.9689 - val_loss: 0.1375 - val_accuracy: 0.9694\n",
      "Epoch 360/1000\n",
      "59/59 [==============================] - 12s 202ms/step - loss: 0.1388 - accuracy: 0.9689 - val_loss: 0.1368 - val_accuracy: 0.9694\n",
      "Epoch 361/1000\n",
      "59/59 [==============================] - 12s 202ms/step - loss: 0.1387 - accuracy: 0.9689 - val_loss: 0.1369 - val_accuracy: 0.9694\n",
      "Epoch 362/1000\n",
      "59/59 [==============================] - 12s 201ms/step - loss: 0.1387 - accuracy: 0.9689 - val_loss: 0.1368 - val_accuracy: 0.9694\n",
      "Epoch 362: early stopping\n"
     ]
    }
   ],
   "source": [
    "from keras.callbacks import EarlyStopping\n",
    "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=100)\n",
    "history2=model.fit(X_img_train, y_img_train, batch_size=256, epochs=1000,\n",
    "                            validation_data=(X_img_test, y_img_test), callbacks=[es])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_hist(hist):\n",
    "    plt.plot(hist.history[\"accuracy\"])\n",
    "    plt.plot(hist.history[\"val_accuracy\"])\n",
    "    plt.title(\"model accuracy\")\n",
    "    plt.ylabel(\"accuracy\")\n",
    "    plt.xlabel(\"epoch\")\n",
    "    plt.legend([\"train\", \"validation\"], loc=\"lower right\")\n",
    "    plt.savefig('fakeav_video_acc.eps', format='eps')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_loss(hist):\n",
    "    plt.plot(hist.history['loss'])\n",
    "    plt.plot(hist.history['val_loss'])\n",
    "    plt.title('model loss')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(['train', 'validation'], loc='upper right')\n",
    "    plt.savefig('fakeav_video_loss.eps', format='eps')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.DataFrame(history2.history)\n",
    "df.to_csv('fakeavceleb_vis_net.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The PostScript backend does not support transparency; partially transparent artists will be rendered opaque.\n"
     ]
    },
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"utf-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       "  \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<svg xmlns:xlink=\"http://www.w3.org/1999/xlink\" width=\"388.965625pt\" height=\"277.314375pt\" viewBox=\"0 0 388.965625 277.314375\" xmlns=\"http://www.w3.org/2000/svg\" version=\"1.1\">\n",
       " <metadata>\n",
       "  <rdf:RDF xmlns:dc=\"http://purl.org/dc/elements/1.1/\" xmlns:cc=\"http://creativecommons.org/ns#\" xmlns:rdf=\"http://www.w3.org/1999/02/22-rdf-syntax-ns#\">\n",
       "   <cc:Work>\n",
       "    <dc:type rdf:resource=\"http://purl.org/dc/dcmitype/StillImage\"/>\n",
       "    <dc:date>2022-07-06T19:30:41.914472</dc:date>\n",
       "    <dc:format>image/svg+xml</dc:format>\n",
       "    <dc:creator>\n",
       "     <cc:Agent>\n",
       "      <dc:title>Matplotlib v3.5.1, https://matplotlib.org/</dc:title>\n",
       "     </cc:Agent>\n",
       "    </dc:creator>\n",
       "   </cc:Work>\n",
       "  </rdf:RDF>\n",
       " </metadata>\n",
       " <defs>\n",
       "  <style type=\"text/css\">*{stroke-linejoin: round; stroke-linecap: butt}</style>\n",
       " </defs>\n",
       " <g id=\"figure_1\">\n",
       "  <g id=\"patch_1\">\n",
       "   <path d=\"M -0 277.314375 \n",
       "L 388.965625 277.314375 \n",
       "L 388.965625 0 \n",
       "L -0 0 \n",
       "L -0 277.314375 \n",
       "z\n",
       "\" style=\"fill: none\"/>\n",
       "  </g>\n",
       "  <g id=\"axes_1\">\n",
       "   <g id=\"patch_2\">\n",
       "    <path d=\"M 46.965625 239.758125 \n",
       "L 381.765625 239.758125 \n",
       "L 381.765625 22.318125 \n",
       "L 46.965625 22.318125 \n",
       "z\n",
       "\" style=\"fill: #ffffff\"/>\n",
       "   </g>\n",
       "   <g id=\"matplotlib.axis_1\">\n",
       "    <g id=\"xtick_1\">\n",
       "     <g id=\"line2d_1\">\n",
       "      <defs>\n",
       "       <path id=\"mbf3dc5259f\" d=\"M 0 0 \n",
       "L 0 3.5 \n",
       "\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </defs>\n",
       "      <g>\n",
       "       <use xlink:href=\"#mbf3dc5259f\" x=\"62.183807\" y=\"239.758125\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_1\">\n",
       "      <!-- 0 -->\n",
       "      <g transform=\"translate(59.002557 254.356562)scale(0.1 -0.1)\">\n",
       "       <defs>\n",
       "        <path id=\"DejaVuSans-30\" d=\"M 2034 4250 \n",
       "Q 1547 4250 1301 3770 \n",
       "Q 1056 3291 1056 2328 \n",
       "Q 1056 1369 1301 889 \n",
       "Q 1547 409 2034 409 \n",
       "Q 2525 409 2770 889 \n",
       "Q 3016 1369 3016 2328 \n",
       "Q 3016 3291 2770 3770 \n",
       "Q 2525 4250 2034 4250 \n",
       "z\n",
       "M 2034 4750 \n",
       "Q 2819 4750 3233 4129 \n",
       "Q 3647 3509 3647 2328 \n",
       "Q 3647 1150 3233 529 \n",
       "Q 2819 -91 2034 -91 \n",
       "Q 1250 -91 836 529 \n",
       "Q 422 1150 422 2328 \n",
       "Q 422 3509 836 4129 \n",
       "Q 1250 4750 2034 4750 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#DejaVuSans-30\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_2\">\n",
       "     <g id=\"line2d_2\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#mbf3dc5259f\" x=\"104.339435\" y=\"239.758125\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_2\">\n",
       "      <!-- 50 -->\n",
       "      <g transform=\"translate(97.976935 254.356562)scale(0.1 -0.1)\">\n",
       "       <defs>\n",
       "        <path id=\"DejaVuSans-35\" d=\"M 691 4666 \n",
       "L 3169 4666 \n",
       "L 3169 4134 \n",
       "L 1269 4134 \n",
       "L 1269 2991 \n",
       "Q 1406 3038 1543 3061 \n",
       "Q 1681 3084 1819 3084 \n",
       "Q 2600 3084 3056 2656 \n",
       "Q 3513 2228 3513 1497 \n",
       "Q 3513 744 3044 326 \n",
       "Q 2575 -91 1722 -91 \n",
       "Q 1428 -91 1123 -41 \n",
       "Q 819 9 494 109 \n",
       "L 494 744 \n",
       "Q 775 591 1075 516 \n",
       "Q 1375 441 1709 441 \n",
       "Q 2250 441 2565 725 \n",
       "Q 2881 1009 2881 1497 \n",
       "Q 2881 1984 2565 2268 \n",
       "Q 2250 2553 1709 2553 \n",
       "Q 1456 2553 1204 2497 \n",
       "Q 953 2441 691 2322 \n",
       "L 691 4666 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#DejaVuSans-35\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-30\" x=\"63.623047\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_3\">\n",
       "     <g id=\"line2d_3\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#mbf3dc5259f\" x=\"146.495063\" y=\"239.758125\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_3\">\n",
       "      <!-- 100 -->\n",
       "      <g transform=\"translate(136.951313 254.356562)scale(0.1 -0.1)\">\n",
       "       <defs>\n",
       "        <path id=\"DejaVuSans-31\" d=\"M 794 531 \n",
       "L 1825 531 \n",
       "L 1825 4091 \n",
       "L 703 3866 \n",
       "L 703 4441 \n",
       "L 1819 4666 \n",
       "L 2450 4666 \n",
       "L 2450 531 \n",
       "L 3481 531 \n",
       "L 3481 0 \n",
       "L 794 0 \n",
       "L 794 531 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#DejaVuSans-31\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-30\" x=\"63.623047\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-30\" x=\"127.246094\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_4\">\n",
       "     <g id=\"line2d_4\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#mbf3dc5259f\" x=\"188.650692\" y=\"239.758125\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_4\">\n",
       "      <!-- 150 -->\n",
       "      <g transform=\"translate(179.106942 254.356562)scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-31\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-35\" x=\"63.623047\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-30\" x=\"127.246094\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_5\">\n",
       "     <g id=\"line2d_5\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#mbf3dc5259f\" x=\"230.80632\" y=\"239.758125\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_5\">\n",
       "      <!-- 200 -->\n",
       "      <g transform=\"translate(221.26257 254.356562)scale(0.1 -0.1)\">\n",
       "       <defs>\n",
       "        <path id=\"DejaVuSans-32\" d=\"M 1228 531 \n",
       "L 3431 531 \n",
       "L 3431 0 \n",
       "L 469 0 \n",
       "L 469 531 \n",
       "Q 828 903 1448 1529 \n",
       "Q 2069 2156 2228 2338 \n",
       "Q 2531 2678 2651 2914 \n",
       "Q 2772 3150 2772 3378 \n",
       "Q 2772 3750 2511 3984 \n",
       "Q 2250 4219 1831 4219 \n",
       "Q 1534 4219 1204 4116 \n",
       "Q 875 4013 500 3803 \n",
       "L 500 4441 \n",
       "Q 881 4594 1212 4672 \n",
       "Q 1544 4750 1819 4750 \n",
       "Q 2544 4750 2975 4387 \n",
       "Q 3406 4025 3406 3419 \n",
       "Q 3406 3131 3298 2873 \n",
       "Q 3191 2616 2906 2266 \n",
       "Q 2828 2175 2409 1742 \n",
       "Q 1991 1309 1228 531 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#DejaVuSans-32\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-30\" x=\"63.623047\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-30\" x=\"127.246094\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_6\">\n",
       "     <g id=\"line2d_6\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#mbf3dc5259f\" x=\"272.961948\" y=\"239.758125\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_6\">\n",
       "      <!-- 250 -->\n",
       "      <g transform=\"translate(263.418198 254.356562)scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-32\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-35\" x=\"63.623047\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-30\" x=\"127.246094\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_7\">\n",
       "     <g id=\"line2d_7\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#mbf3dc5259f\" x=\"315.117577\" y=\"239.758125\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_7\">\n",
       "      <!-- 300 -->\n",
       "      <g transform=\"translate(305.573827 254.356562)scale(0.1 -0.1)\">\n",
       "       <defs>\n",
       "        <path id=\"DejaVuSans-33\" d=\"M 2597 2516 \n",
       "Q 3050 2419 3304 2112 \n",
       "Q 3559 1806 3559 1356 \n",
       "Q 3559 666 3084 287 \n",
       "Q 2609 -91 1734 -91 \n",
       "Q 1441 -91 1130 -33 \n",
       "Q 819 25 488 141 \n",
       "L 488 750 \n",
       "Q 750 597 1062 519 \n",
       "Q 1375 441 1716 441 \n",
       "Q 2309 441 2620 675 \n",
       "Q 2931 909 2931 1356 \n",
       "Q 2931 1769 2642 2001 \n",
       "Q 2353 2234 1838 2234 \n",
       "L 1294 2234 \n",
       "L 1294 2753 \n",
       "L 1863 2753 \n",
       "Q 2328 2753 2575 2939 \n",
       "Q 2822 3125 2822 3475 \n",
       "Q 2822 3834 2567 4026 \n",
       "Q 2313 4219 1838 4219 \n",
       "Q 1578 4219 1281 4162 \n",
       "Q 984 4106 628 3988 \n",
       "L 628 4550 \n",
       "Q 988 4650 1302 4700 \n",
       "Q 1616 4750 1894 4750 \n",
       "Q 2613 4750 3031 4423 \n",
       "Q 3450 4097 3450 3541 \n",
       "Q 3450 3153 3228 2886 \n",
       "Q 3006 2619 2597 2516 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#DejaVuSans-33\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-30\" x=\"63.623047\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-30\" x=\"127.246094\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_8\">\n",
       "     <g id=\"line2d_8\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#mbf3dc5259f\" x=\"357.273205\" y=\"239.758125\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_8\">\n",
       "      <!-- 350 -->\n",
       "      <g transform=\"translate(347.729455 254.356562)scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-33\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-35\" x=\"63.623047\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-30\" x=\"127.246094\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"text_9\">\n",
       "     <!-- Epoch -->\n",
       "     <g transform=\"translate(199.054688 268.034687)scale(0.1 -0.1)\">\n",
       "      <defs>\n",
       "       <path id=\"DejaVuSans-45\" d=\"M 628 4666 \n",
       "L 3578 4666 \n",
       "L 3578 4134 \n",
       "L 1259 4134 \n",
       "L 1259 2753 \n",
       "L 3481 2753 \n",
       "L 3481 2222 \n",
       "L 1259 2222 \n",
       "L 1259 531 \n",
       "L 3634 531 \n",
       "L 3634 0 \n",
       "L 628 0 \n",
       "L 628 4666 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       <path id=\"DejaVuSans-70\" d=\"M 1159 525 \n",
       "L 1159 -1331 \n",
       "L 581 -1331 \n",
       "L 581 3500 \n",
       "L 1159 3500 \n",
       "L 1159 2969 \n",
       "Q 1341 3281 1617 3432 \n",
       "Q 1894 3584 2278 3584 \n",
       "Q 2916 3584 3314 3078 \n",
       "Q 3713 2572 3713 1747 \n",
       "Q 3713 922 3314 415 \n",
       "Q 2916 -91 2278 -91 \n",
       "Q 1894 -91 1617 61 \n",
       "Q 1341 213 1159 525 \n",
       "z\n",
       "M 3116 1747 \n",
       "Q 3116 2381 2855 2742 \n",
       "Q 2594 3103 2138 3103 \n",
       "Q 1681 3103 1420 2742 \n",
       "Q 1159 2381 1159 1747 \n",
       "Q 1159 1113 1420 752 \n",
       "Q 1681 391 2138 391 \n",
       "Q 2594 391 2855 752 \n",
       "Q 3116 1113 3116 1747 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       <path id=\"DejaVuSans-6f\" d=\"M 1959 3097 \n",
       "Q 1497 3097 1228 2736 \n",
       "Q 959 2375 959 1747 \n",
       "Q 959 1119 1226 758 \n",
       "Q 1494 397 1959 397 \n",
       "Q 2419 397 2687 759 \n",
       "Q 2956 1122 2956 1747 \n",
       "Q 2956 2369 2687 2733 \n",
       "Q 2419 3097 1959 3097 \n",
       "z\n",
       "M 1959 3584 \n",
       "Q 2709 3584 3137 3096 \n",
       "Q 3566 2609 3566 1747 \n",
       "Q 3566 888 3137 398 \n",
       "Q 2709 -91 1959 -91 \n",
       "Q 1206 -91 779 398 \n",
       "Q 353 888 353 1747 \n",
       "Q 353 2609 779 3096 \n",
       "Q 1206 3584 1959 3584 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       <path id=\"DejaVuSans-63\" d=\"M 3122 3366 \n",
       "L 3122 2828 \n",
       "Q 2878 2963 2633 3030 \n",
       "Q 2388 3097 2138 3097 \n",
       "Q 1578 3097 1268 2742 \n",
       "Q 959 2388 959 1747 \n",
       "Q 959 1106 1268 751 \n",
       "Q 1578 397 2138 397 \n",
       "Q 2388 397 2633 464 \n",
       "Q 2878 531 3122 666 \n",
       "L 3122 134 \n",
       "Q 2881 22 2623 -34 \n",
       "Q 2366 -91 2075 -91 \n",
       "Q 1284 -91 818 406 \n",
       "Q 353 903 353 1747 \n",
       "Q 353 2603 823 3093 \n",
       "Q 1294 3584 2113 3584 \n",
       "Q 2378 3584 2631 3529 \n",
       "Q 2884 3475 3122 3366 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       <path id=\"DejaVuSans-68\" d=\"M 3513 2113 \n",
       "L 3513 0 \n",
       "L 2938 0 \n",
       "L 2938 2094 \n",
       "Q 2938 2591 2744 2837 \n",
       "Q 2550 3084 2163 3084 \n",
       "Q 1697 3084 1428 2787 \n",
       "Q 1159 2491 1159 1978 \n",
       "L 1159 0 \n",
       "L 581 0 \n",
       "L 581 4863 \n",
       "L 1159 4863 \n",
       "L 1159 2956 \n",
       "Q 1366 3272 1645 3428 \n",
       "Q 1925 3584 2291 3584 \n",
       "Q 2894 3584 3203 3211 \n",
       "Q 3513 2838 3513 2113 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "      </defs>\n",
       "      <use xlink:href=\"#DejaVuSans-45\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-70\" x=\"63.183594\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-6f\" x=\"126.660156\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-63\" x=\"187.841797\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-68\" x=\"242.822266\"/>\n",
       "     </g>\n",
       "    </g>\n",
       "   </g>\n",
       "   <g id=\"matplotlib.axis_2\">\n",
       "    <g id=\"ytick_1\">\n",
       "     <g id=\"line2d_9\">\n",
       "      <defs>\n",
       "       <path id=\"m4bd37306d1\" d=\"M 0 0 \n",
       "L -3.5 0 \n",
       "\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </defs>\n",
       "      <g>\n",
       "       <use xlink:href=\"#m4bd37306d1\" x=\"46.965625\" y=\"230.048702\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_10\">\n",
       "      <!-- 0 -->\n",
       "      <g transform=\"translate(33.603125 233.847921)scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-30\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_2\">\n",
       "     <g id=\"line2d_10\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#m4bd37306d1\" x=\"46.965625\" y=\"204.573858\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_11\">\n",
       "      <!-- 20 -->\n",
       "      <g transform=\"translate(27.240625 208.373077)scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-32\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-30\" x=\"63.623047\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_3\">\n",
       "     <g id=\"line2d_11\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#m4bd37306d1\" x=\"46.965625\" y=\"179.099013\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_12\">\n",
       "      <!-- 40 -->\n",
       "      <g transform=\"translate(27.240625 182.898232)scale(0.1 -0.1)\">\n",
       "       <defs>\n",
       "        <path id=\"DejaVuSans-34\" d=\"M 2419 4116 \n",
       "L 825 1625 \n",
       "L 2419 1625 \n",
       "L 2419 4116 \n",
       "z\n",
       "M 2253 4666 \n",
       "L 3047 4666 \n",
       "L 3047 1625 \n",
       "L 3713 1625 \n",
       "L 3713 1100 \n",
       "L 3047 1100 \n",
       "L 3047 0 \n",
       "L 2419 0 \n",
       "L 2419 1100 \n",
       "L 313 1100 \n",
       "L 313 1709 \n",
       "L 2253 4666 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#DejaVuSans-34\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-30\" x=\"63.623047\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_4\">\n",
       "     <g id=\"line2d_12\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#m4bd37306d1\" x=\"46.965625\" y=\"153.624169\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_13\">\n",
       "      <!-- 60 -->\n",
       "      <g transform=\"translate(27.240625 157.423388)scale(0.1 -0.1)\">\n",
       "       <defs>\n",
       "        <path id=\"DejaVuSans-36\" d=\"M 2113 2584 \n",
       "Q 1688 2584 1439 2293 \n",
       "Q 1191 2003 1191 1497 \n",
       "Q 1191 994 1439 701 \n",
       "Q 1688 409 2113 409 \n",
       "Q 2538 409 2786 701 \n",
       "Q 3034 994 3034 1497 \n",
       "Q 3034 2003 2786 2293 \n",
       "Q 2538 2584 2113 2584 \n",
       "z\n",
       "M 3366 4563 \n",
       "L 3366 3988 \n",
       "Q 3128 4100 2886 4159 \n",
       "Q 2644 4219 2406 4219 \n",
       "Q 1781 4219 1451 3797 \n",
       "Q 1122 3375 1075 2522 \n",
       "Q 1259 2794 1537 2939 \n",
       "Q 1816 3084 2150 3084 \n",
       "Q 2853 3084 3261 2657 \n",
       "Q 3669 2231 3669 1497 \n",
       "Q 3669 778 3244 343 \n",
       "Q 2819 -91 2113 -91 \n",
       "Q 1303 -91 875 529 \n",
       "Q 447 1150 447 2328 \n",
       "Q 447 3434 972 4092 \n",
       "Q 1497 4750 2381 4750 \n",
       "Q 2619 4750 2861 4703 \n",
       "Q 3103 4656 3366 4563 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#DejaVuSans-36\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-30\" x=\"63.623047\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_5\">\n",
       "     <g id=\"line2d_13\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#m4bd37306d1\" x=\"46.965625\" y=\"128.149325\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_14\">\n",
       "      <!-- 80 -->\n",
       "      <g transform=\"translate(27.240625 131.948544)scale(0.1 -0.1)\">\n",
       "       <defs>\n",
       "        <path id=\"DejaVuSans-38\" d=\"M 2034 2216 \n",
       "Q 1584 2216 1326 1975 \n",
       "Q 1069 1734 1069 1313 \n",
       "Q 1069 891 1326 650 \n",
       "Q 1584 409 2034 409 \n",
       "Q 2484 409 2743 651 \n",
       "Q 3003 894 3003 1313 \n",
       "Q 3003 1734 2745 1975 \n",
       "Q 2488 2216 2034 2216 \n",
       "z\n",
       "M 1403 2484 \n",
       "Q 997 2584 770 2862 \n",
       "Q 544 3141 544 3541 \n",
       "Q 544 4100 942 4425 \n",
       "Q 1341 4750 2034 4750 \n",
       "Q 2731 4750 3128 4425 \n",
       "Q 3525 4100 3525 3541 \n",
       "Q 3525 3141 3298 2862 \n",
       "Q 3072 2584 2669 2484 \n",
       "Q 3125 2378 3379 2068 \n",
       "Q 3634 1759 3634 1313 \n",
       "Q 3634 634 3220 271 \n",
       "Q 2806 -91 2034 -91 \n",
       "Q 1263 -91 848 271 \n",
       "Q 434 634 434 1313 \n",
       "Q 434 1759 690 2068 \n",
       "Q 947 2378 1403 2484 \n",
       "z\n",
       "M 1172 3481 \n",
       "Q 1172 3119 1398 2916 \n",
       "Q 1625 2713 2034 2713 \n",
       "Q 2441 2713 2670 2916 \n",
       "Q 2900 3119 2900 3481 \n",
       "Q 2900 3844 2670 4047 \n",
       "Q 2441 4250 2034 4250 \n",
       "Q 1625 4250 1398 4047 \n",
       "Q 1172 3844 1172 3481 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#DejaVuSans-38\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-30\" x=\"63.623047\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_6\">\n",
       "     <g id=\"line2d_14\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#m4bd37306d1\" x=\"46.965625\" y=\"102.67448\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_15\">\n",
       "      <!-- 100 -->\n",
       "      <g transform=\"translate(20.878125 106.473699)scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-31\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-30\" x=\"63.623047\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-30\" x=\"127.246094\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_7\">\n",
       "     <g id=\"line2d_15\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#m4bd37306d1\" x=\"46.965625\" y=\"77.199636\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_16\">\n",
       "      <!-- 120 -->\n",
       "      <g transform=\"translate(20.878125 80.998855)scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-31\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-32\" x=\"63.623047\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-30\" x=\"127.246094\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_8\">\n",
       "     <g id=\"line2d_16\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#m4bd37306d1\" x=\"46.965625\" y=\"51.724792\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_17\">\n",
       "      <!-- 140 -->\n",
       "      <g transform=\"translate(20.878125 55.524011)scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-31\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-34\" x=\"63.623047\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-30\" x=\"127.246094\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_9\">\n",
       "     <g id=\"line2d_17\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#m4bd37306d1\" x=\"46.965625\" y=\"26.249947\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_18\">\n",
       "      <!-- 160 -->\n",
       "      <g transform=\"translate(20.878125 30.049166)scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-31\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-36\" x=\"63.623047\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-30\" x=\"127.246094\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"text_19\">\n",
       "     <!-- Loss -->\n",
       "     <g transform=\"translate(14.798438 142.005312)rotate(-90)scale(0.1 -0.1)\">\n",
       "      <defs>\n",
       "       <path id=\"DejaVuSans-4c\" d=\"M 628 4666 \n",
       "L 1259 4666 \n",
       "L 1259 531 \n",
       "L 3531 531 \n",
       "L 3531 0 \n",
       "L 628 0 \n",
       "L 628 4666 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       <path id=\"DejaVuSans-73\" d=\"M 2834 3397 \n",
       "L 2834 2853 \n",
       "Q 2591 2978 2328 3040 \n",
       "Q 2066 3103 1784 3103 \n",
       "Q 1356 3103 1142 2972 \n",
       "Q 928 2841 928 2578 \n",
       "Q 928 2378 1081 2264 \n",
       "Q 1234 2150 1697 2047 \n",
       "L 1894 2003 \n",
       "Q 2506 1872 2764 1633 \n",
       "Q 3022 1394 3022 966 \n",
       "Q 3022 478 2636 193 \n",
       "Q 2250 -91 1575 -91 \n",
       "Q 1294 -91 989 -36 \n",
       "Q 684 19 347 128 \n",
       "L 347 722 \n",
       "Q 666 556 975 473 \n",
       "Q 1284 391 1588 391 \n",
       "Q 1994 391 2212 530 \n",
       "Q 2431 669 2431 922 \n",
       "Q 2431 1156 2273 1281 \n",
       "Q 2116 1406 1581 1522 \n",
       "L 1381 1569 \n",
       "Q 847 1681 609 1914 \n",
       "Q 372 2147 372 2553 \n",
       "Q 372 3047 722 3315 \n",
       "Q 1072 3584 1716 3584 \n",
       "Q 2034 3584 2315 3537 \n",
       "Q 2597 3491 2834 3397 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "      </defs>\n",
       "      <use xlink:href=\"#DejaVuSans-4c\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-6f\" x=\"53.962891\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-73\" x=\"115.144531\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-73\" x=\"167.244141\"/>\n",
       "     </g>\n",
       "    </g>\n",
       "   </g>\n",
       "   <g id=\"line2d_18\">\n",
       "    <path d=\"M 62.183807 32.201761 \n",
       "L 63.026919 166.505246 \n",
       "L 63.870032 186.177256 \n",
       "L 64.713145 195.896861 \n",
       "L 65.556257 201.090493 \n",
       "L 66.39937 205.371708 \n",
       "L 68.085595 211.542006 \n",
       "L 70.614932 216.1032 \n",
       "L 71.458045 217.105352 \n",
       "L 73.14427 218.467233 \n",
       "L 75.673608 219.811113 \n",
       "L 76.51672 220.251982 \n",
       "L 79.046058 221.128349 \n",
       "L 79.889171 220.925693 \n",
       "L 80.732283 221.437707 \n",
       "L 81.575396 221.800502 \n",
       "L 92.535859 223.61993 \n",
       "L 94.222084 223.808974 \n",
       "L 96.751422 224.06731 \n",
       "L 99.28076 224.35633 \n",
       "L 101.810097 224.720083 \n",
       "L 102.65321 224.688631 \n",
       "L 104.339435 224.98495 \n",
       "L 106.868773 225.23709 \n",
       "L 107.711885 225.260486 \n",
       "L 110.241223 225.604176 \n",
       "L 117.829236 226.323422 \n",
       "L 124.574137 226.949287 \n",
       "L 149.024401 228.619012 \n",
       "L 164.200427 229.259234 \n",
       "L 188.650692 229.746708 \n",
       "L 212.257844 229.85592 \n",
       "L 299.098438 229.871968 \n",
       "L 366.547443 229.872023 \n",
       "L 366.547443 229.872023 \n",
       "\" clip-path=\"url(#pa03d1c7204)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n",
       "   </g>\n",
       "   <g id=\"line2d_19\">\n",
       "    <path d=\"M 62.183807 180.778414 \n",
       "L 63.026919 190.22998 \n",
       "L 63.870032 197.49942 \n",
       "L 64.713145 202.081598 \n",
       "L 66.39937 209.000698 \n",
       "L 68.085595 213.207992 \n",
       "L 68.928707 214.639588 \n",
       "L 69.77182 215.586231 \n",
       "L 70.614932 216.958602 \n",
       "L 72.301158 218.360093 \n",
       "L 73.14427 218.955289 \n",
       "L 75.673608 220.224919 \n",
       "L 76.51672 220.316721 \n",
       "L 79.046058 221.359712 \n",
       "L 79.889171 221.413803 \n",
       "L 81.575396 221.952397 \n",
       "L 87.477184 222.929415 \n",
       "L 90.006521 223.336952 \n",
       "L 94.222084 223.863317 \n",
       "L 95.908309 224.055067 \n",
       "L 120.358574 226.618996 \n",
       "L 149.867514 228.688146 \n",
       "L 162.514202 229.218247 \n",
       "L 173.474666 229.52705 \n",
       "L 188.650692 229.75319 \n",
       "L 212.257844 229.858991 \n",
       "L 298.255325 229.874487 \n",
       "L 366.547443 229.874419 \n",
       "L 366.547443 229.874419 \n",
       "\" clip-path=\"url(#pa03d1c7204)\" style=\"fill: none; stroke: #ff7f0e; stroke-width: 1.5; stroke-linecap: square\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_3\">\n",
       "    <path d=\"M 46.965625 239.758125 \n",
       "L 46.965625 22.318125 \n",
       "\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_4\">\n",
       "    <path d=\"M 381.765625 239.758125 \n",
       "L 381.765625 22.318125 \n",
       "\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_5\">\n",
       "    <path d=\"M 46.965625 239.758125 \n",
       "L 381.765625 239.758125 \n",
       "\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_6\">\n",
       "    <path d=\"M 46.965625 22.318125 \n",
       "L 381.765625 22.318125 \n",
       "\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n",
       "   </g>\n",
       "   <g id=\"text_20\">\n",
       "    <!-- model loss -->\n",
       "    <g transform=\"translate(182.185938 16.318125)scale(0.12 -0.12)\">\n",
       "     <defs>\n",
       "      <path id=\"DejaVuSans-6d\" d=\"M 3328 2828 \n",
       "Q 3544 3216 3844 3400 \n",
       "Q 4144 3584 4550 3584 \n",
       "Q 5097 3584 5394 3201 \n",
       "Q 5691 2819 5691 2113 \n",
       "L 5691 0 \n",
       "L 5113 0 \n",
       "L 5113 2094 \n",
       "Q 5113 2597 4934 2840 \n",
       "Q 4756 3084 4391 3084 \n",
       "Q 3944 3084 3684 2787 \n",
       "Q 3425 2491 3425 1978 \n",
       "L 3425 0 \n",
       "L 2847 0 \n",
       "L 2847 2094 \n",
       "Q 2847 2600 2669 2842 \n",
       "Q 2491 3084 2119 3084 \n",
       "Q 1678 3084 1418 2786 \n",
       "Q 1159 2488 1159 1978 \n",
       "L 1159 0 \n",
       "L 581 0 \n",
       "L 581 3500 \n",
       "L 1159 3500 \n",
       "L 1159 2956 \n",
       "Q 1356 3278 1631 3431 \n",
       "Q 1906 3584 2284 3584 \n",
       "Q 2666 3584 2933 3390 \n",
       "Q 3200 3197 3328 2828 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "      <path id=\"DejaVuSans-64\" d=\"M 2906 2969 \n",
       "L 2906 4863 \n",
       "L 3481 4863 \n",
       "L 3481 0 \n",
       "L 2906 0 \n",
       "L 2906 525 \n",
       "Q 2725 213 2448 61 \n",
       "Q 2172 -91 1784 -91 \n",
       "Q 1150 -91 751 415 \n",
       "Q 353 922 353 1747 \n",
       "Q 353 2572 751 3078 \n",
       "Q 1150 3584 1784 3584 \n",
       "Q 2172 3584 2448 3432 \n",
       "Q 2725 3281 2906 2969 \n",
       "z\n",
       "M 947 1747 \n",
       "Q 947 1113 1208 752 \n",
       "Q 1469 391 1925 391 \n",
       "Q 2381 391 2643 752 \n",
       "Q 2906 1113 2906 1747 \n",
       "Q 2906 2381 2643 2742 \n",
       "Q 2381 3103 1925 3103 \n",
       "Q 1469 3103 1208 2742 \n",
       "Q 947 2381 947 1747 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "      <path id=\"DejaVuSans-65\" d=\"M 3597 1894 \n",
       "L 3597 1613 \n",
       "L 953 1613 \n",
       "Q 991 1019 1311 708 \n",
       "Q 1631 397 2203 397 \n",
       "Q 2534 397 2845 478 \n",
       "Q 3156 559 3463 722 \n",
       "L 3463 178 \n",
       "Q 3153 47 2828 -22 \n",
       "Q 2503 -91 2169 -91 \n",
       "Q 1331 -91 842 396 \n",
       "Q 353 884 353 1716 \n",
       "Q 353 2575 817 3079 \n",
       "Q 1281 3584 2069 3584 \n",
       "Q 2775 3584 3186 3129 \n",
       "Q 3597 2675 3597 1894 \n",
       "z\n",
       "M 3022 2063 \n",
       "Q 3016 2534 2758 2815 \n",
       "Q 2500 3097 2075 3097 \n",
       "Q 1594 3097 1305 2825 \n",
       "Q 1016 2553 972 2059 \n",
       "L 3022 2063 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "      <path id=\"DejaVuSans-6c\" d=\"M 603 4863 \n",
       "L 1178 4863 \n",
       "L 1178 0 \n",
       "L 603 0 \n",
       "L 603 4863 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "      <path id=\"DejaVuSans-20\" transform=\"scale(0.015625)\"/>\n",
       "     </defs>\n",
       "     <use xlink:href=\"#DejaVuSans-6d\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-6f\" x=\"97.412109\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-64\" x=\"158.59375\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-65\" x=\"222.070312\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-6c\" x=\"283.59375\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-20\" x=\"311.376953\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-6c\" x=\"343.164062\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-6f\" x=\"370.947266\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-73\" x=\"432.128906\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-73\" x=\"484.228516\"/>\n",
       "    </g>\n",
       "   </g>\n",
       "   <g id=\"legend_1\">\n",
       "    <g id=\"patch_7\">\n",
       "     <path d=\"M 293.53125 59.674375 \n",
       "L 374.765625 59.674375 \n",
       "Q 376.765625 59.674375 376.765625 57.674375 \n",
       "L 376.765625 29.318125 \n",
       "Q 376.765625 27.318125 374.765625 27.318125 \n",
       "L 293.53125 27.318125 \n",
       "Q 291.53125 27.318125 291.53125 29.318125 \n",
       "L 291.53125 57.674375 \n",
       "Q 291.53125 59.674375 293.53125 59.674375 \n",
       "z\n",
       "\" style=\"fill: #ffffff; opacity: 0.8; stroke: #cccccc; stroke-linejoin: miter\"/>\n",
       "    </g>\n",
       "    <g id=\"line2d_20\">\n",
       "     <path d=\"M 295.53125 35.416562 \n",
       "L 305.53125 35.416562 \n",
       "L 315.53125 35.416562 \n",
       "\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n",
       "    </g>\n",
       "    <g id=\"text_21\">\n",
       "     <!-- train -->\n",
       "     <g transform=\"translate(323.53125 38.916562)scale(0.1 -0.1)\">\n",
       "      <defs>\n",
       "       <path id=\"DejaVuSans-74\" d=\"M 1172 4494 \n",
       "L 1172 3500 \n",
       "L 2356 3500 \n",
       "L 2356 3053 \n",
       "L 1172 3053 \n",
       "L 1172 1153 \n",
       "Q 1172 725 1289 603 \n",
       "Q 1406 481 1766 481 \n",
       "L 2356 481 \n",
       "L 2356 0 \n",
       "L 1766 0 \n",
       "Q 1100 0 847 248 \n",
       "Q 594 497 594 1153 \n",
       "L 594 3053 \n",
       "L 172 3053 \n",
       "L 172 3500 \n",
       "L 594 3500 \n",
       "L 594 4494 \n",
       "L 1172 4494 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       <path id=\"DejaVuSans-72\" d=\"M 2631 2963 \n",
       "Q 2534 3019 2420 3045 \n",
       "Q 2306 3072 2169 3072 \n",
       "Q 1681 3072 1420 2755 \n",
       "Q 1159 2438 1159 1844 \n",
       "L 1159 0 \n",
       "L 581 0 \n",
       "L 581 3500 \n",
       "L 1159 3500 \n",
       "L 1159 2956 \n",
       "Q 1341 3275 1631 3429 \n",
       "Q 1922 3584 2338 3584 \n",
       "Q 2397 3584 2469 3576 \n",
       "Q 2541 3569 2628 3553 \n",
       "L 2631 2963 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       <path id=\"DejaVuSans-61\" d=\"M 2194 1759 \n",
       "Q 1497 1759 1228 1600 \n",
       "Q 959 1441 959 1056 \n",
       "Q 959 750 1161 570 \n",
       "Q 1363 391 1709 391 \n",
       "Q 2188 391 2477 730 \n",
       "Q 2766 1069 2766 1631 \n",
       "L 2766 1759 \n",
       "L 2194 1759 \n",
       "z\n",
       "M 3341 1997 \n",
       "L 3341 0 \n",
       "L 2766 0 \n",
       "L 2766 531 \n",
       "Q 2569 213 2275 61 \n",
       "Q 1981 -91 1556 -91 \n",
       "Q 1019 -91 701 211 \n",
       "Q 384 513 384 1019 \n",
       "Q 384 1609 779 1909 \n",
       "Q 1175 2209 1959 2209 \n",
       "L 2766 2209 \n",
       "L 2766 2266 \n",
       "Q 2766 2663 2505 2880 \n",
       "Q 2244 3097 1772 3097 \n",
       "Q 1472 3097 1187 3025 \n",
       "Q 903 2953 641 2809 \n",
       "L 641 3341 \n",
       "Q 956 3463 1253 3523 \n",
       "Q 1550 3584 1831 3584 \n",
       "Q 2591 3584 2966 3190 \n",
       "Q 3341 2797 3341 1997 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       <path id=\"DejaVuSans-69\" d=\"M 603 3500 \n",
       "L 1178 3500 \n",
       "L 1178 0 \n",
       "L 603 0 \n",
       "L 603 3500 \n",
       "z\n",
       "M 603 4863 \n",
       "L 1178 4863 \n",
       "L 1178 4134 \n",
       "L 603 4134 \n",
       "L 603 4863 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       <path id=\"DejaVuSans-6e\" d=\"M 3513 2113 \n",
       "L 3513 0 \n",
       "L 2938 0 \n",
       "L 2938 2094 \n",
       "Q 2938 2591 2744 2837 \n",
       "Q 2550 3084 2163 3084 \n",
       "Q 1697 3084 1428 2787 \n",
       "Q 1159 2491 1159 1978 \n",
       "L 1159 0 \n",
       "L 581 0 \n",
       "L 581 3500 \n",
       "L 1159 3500 \n",
       "L 1159 2956 \n",
       "Q 1366 3272 1645 3428 \n",
       "Q 1925 3584 2291 3584 \n",
       "Q 2894 3584 3203 3211 \n",
       "Q 3513 2838 3513 2113 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "      </defs>\n",
       "      <use xlink:href=\"#DejaVuSans-74\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-72\" x=\"39.208984\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-61\" x=\"80.322266\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-69\" x=\"141.601562\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-6e\" x=\"169.384766\"/>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"line2d_21\">\n",
       "     <path d=\"M 295.53125 50.094687 \n",
       "L 305.53125 50.094687 \n",
       "L 315.53125 50.094687 \n",
       "\" style=\"fill: none; stroke: #ff7f0e; stroke-width: 1.5; stroke-linecap: square\"/>\n",
       "    </g>\n",
       "    <g id=\"text_22\">\n",
       "     <!-- validation -->\n",
       "     <g transform=\"translate(323.53125 53.594687)scale(0.1 -0.1)\">\n",
       "      <defs>\n",
       "       <path id=\"DejaVuSans-76\" d=\"M 191 3500 \n",
       "L 800 3500 \n",
       "L 1894 563 \n",
       "L 2988 3500 \n",
       "L 3597 3500 \n",
       "L 2284 0 \n",
       "L 1503 0 \n",
       "L 191 3500 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "      </defs>\n",
       "      <use xlink:href=\"#DejaVuSans-76\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-61\" x=\"59.179688\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-6c\" x=\"120.458984\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-69\" x=\"148.242188\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-64\" x=\"176.025391\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-61\" x=\"239.501953\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-74\" x=\"300.78125\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-69\" x=\"339.990234\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-6f\" x=\"367.773438\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-6e\" x=\"428.955078\"/>\n",
       "     </g>\n",
       "    </g>\n",
       "   </g>\n",
       "  </g>\n",
       " </g>\n",
       " <defs>\n",
       "  <clipPath id=\"pa03d1c7204\">\n",
       "   <rect x=\"46.965625\" y=\"22.318125\" width=\"334.8\" height=\"217.44\"/>\n",
       "  </clipPath>\n",
       " </defs>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_loss(history2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The PostScript backend does not support transparency; partially transparent artists will be rendered opaque.\n"
     ]
    },
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"utf-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       "  \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<svg xmlns:xlink=\"http://www.w3.org/1999/xlink\" width=\"392.14375pt\" height=\"277.314375pt\" viewBox=\"0 0 392.14375 277.314375\" xmlns=\"http://www.w3.org/2000/svg\" version=\"1.1\">\n",
       " <metadata>\n",
       "  <rdf:RDF xmlns:dc=\"http://purl.org/dc/elements/1.1/\" xmlns:cc=\"http://creativecommons.org/ns#\" xmlns:rdf=\"http://www.w3.org/1999/02/22-rdf-syntax-ns#\">\n",
       "   <cc:Work>\n",
       "    <dc:type rdf:resource=\"http://purl.org/dc/dcmitype/StillImage\"/>\n",
       "    <dc:date>2022-07-06T19:30:42.086313</dc:date>\n",
       "    <dc:format>image/svg+xml</dc:format>\n",
       "    <dc:creator>\n",
       "     <cc:Agent>\n",
       "      <dc:title>Matplotlib v3.5.1, https://matplotlib.org/</dc:title>\n",
       "     </cc:Agent>\n",
       "    </dc:creator>\n",
       "   </cc:Work>\n",
       "  </rdf:RDF>\n",
       " </metadata>\n",
       " <defs>\n",
       "  <style type=\"text/css\">*{stroke-linejoin: round; stroke-linecap: butt}</style>\n",
       " </defs>\n",
       " <g id=\"figure_1\">\n",
       "  <g id=\"patch_1\">\n",
       "   <path d=\"M 0 277.314375 \n",
       "L 392.14375 277.314375 \n",
       "L 392.14375 0 \n",
       "L 0 0 \n",
       "L 0 277.314375 \n",
       "z\n",
       "\" style=\"fill: none\"/>\n",
       "  </g>\n",
       "  <g id=\"axes_1\">\n",
       "   <g id=\"patch_2\">\n",
       "    <path d=\"M 50.14375 239.758125 \n",
       "L 384.94375 239.758125 \n",
       "L 384.94375 22.318125 \n",
       "L 50.14375 22.318125 \n",
       "z\n",
       "\" style=\"fill: #ffffff\"/>\n",
       "   </g>\n",
       "   <g id=\"matplotlib.axis_1\">\n",
       "    <g id=\"xtick_1\">\n",
       "     <g id=\"line2d_1\">\n",
       "      <defs>\n",
       "       <path id=\"md2e8c04733\" d=\"M 0 0 \n",
       "L 0 3.5 \n",
       "\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </defs>\n",
       "      <g>\n",
       "       <use xlink:href=\"#md2e8c04733\" x=\"65.361932\" y=\"239.758125\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_1\">\n",
       "      <!-- 0 -->\n",
       "      <g transform=\"translate(62.180682 254.356562)scale(0.1 -0.1)\">\n",
       "       <defs>\n",
       "        <path id=\"DejaVuSans-30\" d=\"M 2034 4250 \n",
       "Q 1547 4250 1301 3770 \n",
       "Q 1056 3291 1056 2328 \n",
       "Q 1056 1369 1301 889 \n",
       "Q 1547 409 2034 409 \n",
       "Q 2525 409 2770 889 \n",
       "Q 3016 1369 3016 2328 \n",
       "Q 3016 3291 2770 3770 \n",
       "Q 2525 4250 2034 4250 \n",
       "z\n",
       "M 2034 4750 \n",
       "Q 2819 4750 3233 4129 \n",
       "Q 3647 3509 3647 2328 \n",
       "Q 3647 1150 3233 529 \n",
       "Q 2819 -91 2034 -91 \n",
       "Q 1250 -91 836 529 \n",
       "Q 422 1150 422 2328 \n",
       "Q 422 3509 836 4129 \n",
       "Q 1250 4750 2034 4750 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#DejaVuSans-30\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_2\">\n",
       "     <g id=\"line2d_2\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#md2e8c04733\" x=\"107.51756\" y=\"239.758125\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_2\">\n",
       "      <!-- 50 -->\n",
       "      <g transform=\"translate(101.15506 254.356562)scale(0.1 -0.1)\">\n",
       "       <defs>\n",
       "        <path id=\"DejaVuSans-35\" d=\"M 691 4666 \n",
       "L 3169 4666 \n",
       "L 3169 4134 \n",
       "L 1269 4134 \n",
       "L 1269 2991 \n",
       "Q 1406 3038 1543 3061 \n",
       "Q 1681 3084 1819 3084 \n",
       "Q 2600 3084 3056 2656 \n",
       "Q 3513 2228 3513 1497 \n",
       "Q 3513 744 3044 326 \n",
       "Q 2575 -91 1722 -91 \n",
       "Q 1428 -91 1123 -41 \n",
       "Q 819 9 494 109 \n",
       "L 494 744 \n",
       "Q 775 591 1075 516 \n",
       "Q 1375 441 1709 441 \n",
       "Q 2250 441 2565 725 \n",
       "Q 2881 1009 2881 1497 \n",
       "Q 2881 1984 2565 2268 \n",
       "Q 2250 2553 1709 2553 \n",
       "Q 1456 2553 1204 2497 \n",
       "Q 953 2441 691 2322 \n",
       "L 691 4666 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#DejaVuSans-35\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-30\" x=\"63.623047\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_3\">\n",
       "     <g id=\"line2d_3\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#md2e8c04733\" x=\"149.673188\" y=\"239.758125\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_3\">\n",
       "      <!-- 100 -->\n",
       "      <g transform=\"translate(140.129438 254.356562)scale(0.1 -0.1)\">\n",
       "       <defs>\n",
       "        <path id=\"DejaVuSans-31\" d=\"M 794 531 \n",
       "L 1825 531 \n",
       "L 1825 4091 \n",
       "L 703 3866 \n",
       "L 703 4441 \n",
       "L 1819 4666 \n",
       "L 2450 4666 \n",
       "L 2450 531 \n",
       "L 3481 531 \n",
       "L 3481 0 \n",
       "L 794 0 \n",
       "L 794 531 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#DejaVuSans-31\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-30\" x=\"63.623047\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-30\" x=\"127.246094\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_4\">\n",
       "     <g id=\"line2d_4\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#md2e8c04733\" x=\"191.828817\" y=\"239.758125\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_4\">\n",
       "      <!-- 150 -->\n",
       "      <g transform=\"translate(182.285067 254.356562)scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-31\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-35\" x=\"63.623047\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-30\" x=\"127.246094\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_5\">\n",
       "     <g id=\"line2d_5\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#md2e8c04733\" x=\"233.984445\" y=\"239.758125\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_5\">\n",
       "      <!-- 200 -->\n",
       "      <g transform=\"translate(224.440695 254.356562)scale(0.1 -0.1)\">\n",
       "       <defs>\n",
       "        <path id=\"DejaVuSans-32\" d=\"M 1228 531 \n",
       "L 3431 531 \n",
       "L 3431 0 \n",
       "L 469 0 \n",
       "L 469 531 \n",
       "Q 828 903 1448 1529 \n",
       "Q 2069 2156 2228 2338 \n",
       "Q 2531 2678 2651 2914 \n",
       "Q 2772 3150 2772 3378 \n",
       "Q 2772 3750 2511 3984 \n",
       "Q 2250 4219 1831 4219 \n",
       "Q 1534 4219 1204 4116 \n",
       "Q 875 4013 500 3803 \n",
       "L 500 4441 \n",
       "Q 881 4594 1212 4672 \n",
       "Q 1544 4750 1819 4750 \n",
       "Q 2544 4750 2975 4387 \n",
       "Q 3406 4025 3406 3419 \n",
       "Q 3406 3131 3298 2873 \n",
       "Q 3191 2616 2906 2266 \n",
       "Q 2828 2175 2409 1742 \n",
       "Q 1991 1309 1228 531 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#DejaVuSans-32\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-30\" x=\"63.623047\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-30\" x=\"127.246094\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_6\">\n",
       "     <g id=\"line2d_6\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#md2e8c04733\" x=\"276.140073\" y=\"239.758125\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_6\">\n",
       "      <!-- 250 -->\n",
       "      <g transform=\"translate(266.596323 254.356562)scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-32\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-35\" x=\"63.623047\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-30\" x=\"127.246094\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_7\">\n",
       "     <g id=\"line2d_7\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#md2e8c04733\" x=\"318.295702\" y=\"239.758125\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_7\">\n",
       "      <!-- 300 -->\n",
       "      <g transform=\"translate(308.751952 254.356562)scale(0.1 -0.1)\">\n",
       "       <defs>\n",
       "        <path id=\"DejaVuSans-33\" d=\"M 2597 2516 \n",
       "Q 3050 2419 3304 2112 \n",
       "Q 3559 1806 3559 1356 \n",
       "Q 3559 666 3084 287 \n",
       "Q 2609 -91 1734 -91 \n",
       "Q 1441 -91 1130 -33 \n",
       "Q 819 25 488 141 \n",
       "L 488 750 \n",
       "Q 750 597 1062 519 \n",
       "Q 1375 441 1716 441 \n",
       "Q 2309 441 2620 675 \n",
       "Q 2931 909 2931 1356 \n",
       "Q 2931 1769 2642 2001 \n",
       "Q 2353 2234 1838 2234 \n",
       "L 1294 2234 \n",
       "L 1294 2753 \n",
       "L 1863 2753 \n",
       "Q 2328 2753 2575 2939 \n",
       "Q 2822 3125 2822 3475 \n",
       "Q 2822 3834 2567 4026 \n",
       "Q 2313 4219 1838 4219 \n",
       "Q 1578 4219 1281 4162 \n",
       "Q 984 4106 628 3988 \n",
       "L 628 4550 \n",
       "Q 988 4650 1302 4700 \n",
       "Q 1616 4750 1894 4750 \n",
       "Q 2613 4750 3031 4423 \n",
       "Q 3450 4097 3450 3541 \n",
       "Q 3450 3153 3228 2886 \n",
       "Q 3006 2619 2597 2516 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#DejaVuSans-33\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-30\" x=\"63.623047\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-30\" x=\"127.246094\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_8\">\n",
       "     <g id=\"line2d_8\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#md2e8c04733\" x=\"360.45133\" y=\"239.758125\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_8\">\n",
       "      <!-- 350 -->\n",
       "      <g transform=\"translate(350.90758 254.356562)scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-33\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-35\" x=\"63.623047\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-30\" x=\"127.246094\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"text_9\">\n",
       "     <!-- epoch -->\n",
       "     <g transform=\"translate(202.315625 268.034687)scale(0.1 -0.1)\">\n",
       "      <defs>\n",
       "       <path id=\"DejaVuSans-65\" d=\"M 3597 1894 \n",
       "L 3597 1613 \n",
       "L 953 1613 \n",
       "Q 991 1019 1311 708 \n",
       "Q 1631 397 2203 397 \n",
       "Q 2534 397 2845 478 \n",
       "Q 3156 559 3463 722 \n",
       "L 3463 178 \n",
       "Q 3153 47 2828 -22 \n",
       "Q 2503 -91 2169 -91 \n",
       "Q 1331 -91 842 396 \n",
       "Q 353 884 353 1716 \n",
       "Q 353 2575 817 3079 \n",
       "Q 1281 3584 2069 3584 \n",
       "Q 2775 3584 3186 3129 \n",
       "Q 3597 2675 3597 1894 \n",
       "z\n",
       "M 3022 2063 \n",
       "Q 3016 2534 2758 2815 \n",
       "Q 2500 3097 2075 3097 \n",
       "Q 1594 3097 1305 2825 \n",
       "Q 1016 2553 972 2059 \n",
       "L 3022 2063 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       <path id=\"DejaVuSans-70\" d=\"M 1159 525 \n",
       "L 1159 -1331 \n",
       "L 581 -1331 \n",
       "L 581 3500 \n",
       "L 1159 3500 \n",
       "L 1159 2969 \n",
       "Q 1341 3281 1617 3432 \n",
       "Q 1894 3584 2278 3584 \n",
       "Q 2916 3584 3314 3078 \n",
       "Q 3713 2572 3713 1747 \n",
       "Q 3713 922 3314 415 \n",
       "Q 2916 -91 2278 -91 \n",
       "Q 1894 -91 1617 61 \n",
       "Q 1341 213 1159 525 \n",
       "z\n",
       "M 3116 1747 \n",
       "Q 3116 2381 2855 2742 \n",
       "Q 2594 3103 2138 3103 \n",
       "Q 1681 3103 1420 2742 \n",
       "Q 1159 2381 1159 1747 \n",
       "Q 1159 1113 1420 752 \n",
       "Q 1681 391 2138 391 \n",
       "Q 2594 391 2855 752 \n",
       "Q 3116 1113 3116 1747 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       <path id=\"DejaVuSans-6f\" d=\"M 1959 3097 \n",
       "Q 1497 3097 1228 2736 \n",
       "Q 959 2375 959 1747 \n",
       "Q 959 1119 1226 758 \n",
       "Q 1494 397 1959 397 \n",
       "Q 2419 397 2687 759 \n",
       "Q 2956 1122 2956 1747 \n",
       "Q 2956 2369 2687 2733 \n",
       "Q 2419 3097 1959 3097 \n",
       "z\n",
       "M 1959 3584 \n",
       "Q 2709 3584 3137 3096 \n",
       "Q 3566 2609 3566 1747 \n",
       "Q 3566 888 3137 398 \n",
       "Q 2709 -91 1959 -91 \n",
       "Q 1206 -91 779 398 \n",
       "Q 353 888 353 1747 \n",
       "Q 353 2609 779 3096 \n",
       "Q 1206 3584 1959 3584 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       <path id=\"DejaVuSans-63\" d=\"M 3122 3366 \n",
       "L 3122 2828 \n",
       "Q 2878 2963 2633 3030 \n",
       "Q 2388 3097 2138 3097 \n",
       "Q 1578 3097 1268 2742 \n",
       "Q 959 2388 959 1747 \n",
       "Q 959 1106 1268 751 \n",
       "Q 1578 397 2138 397 \n",
       "Q 2388 397 2633 464 \n",
       "Q 2878 531 3122 666 \n",
       "L 3122 134 \n",
       "Q 2881 22 2623 -34 \n",
       "Q 2366 -91 2075 -91 \n",
       "Q 1284 -91 818 406 \n",
       "Q 353 903 353 1747 \n",
       "Q 353 2603 823 3093 \n",
       "Q 1294 3584 2113 3584 \n",
       "Q 2378 3584 2631 3529 \n",
       "Q 2884 3475 3122 3366 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       <path id=\"DejaVuSans-68\" d=\"M 3513 2113 \n",
       "L 3513 0 \n",
       "L 2938 0 \n",
       "L 2938 2094 \n",
       "Q 2938 2591 2744 2837 \n",
       "Q 2550 3084 2163 3084 \n",
       "Q 1697 3084 1428 2787 \n",
       "Q 1159 2491 1159 1978 \n",
       "L 1159 0 \n",
       "L 581 0 \n",
       "L 581 4863 \n",
       "L 1159 4863 \n",
       "L 1159 2956 \n",
       "Q 1366 3272 1645 3428 \n",
       "Q 1925 3584 2291 3584 \n",
       "Q 2894 3584 3203 3211 \n",
       "Q 3513 2838 3513 2113 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "      </defs>\n",
       "      <use xlink:href=\"#DejaVuSans-65\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-70\" x=\"61.523438\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-6f\" x=\"125\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-63\" x=\"186.181641\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-68\" x=\"241.162109\"/>\n",
       "     </g>\n",
       "    </g>\n",
       "   </g>\n",
       "   <g id=\"matplotlib.axis_2\">\n",
       "    <g id=\"ytick_1\">\n",
       "     <g id=\"line2d_9\">\n",
       "      <defs>\n",
       "       <path id=\"m81f83d1fd2\" d=\"M 0 0 \n",
       "L -3.5 0 \n",
       "\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </defs>\n",
       "      <g>\n",
       "       <use xlink:href=\"#m81f83d1fd2\" x=\"50.14375\" y=\"233.48343\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_10\">\n",
       "      <!-- 0.70 -->\n",
       "      <g transform=\"translate(20.878125 237.282649)scale(0.1 -0.1)\">\n",
       "       <defs>\n",
       "        <path id=\"DejaVuSans-2e\" d=\"M 684 794 \n",
       "L 1344 794 \n",
       "L 1344 0 \n",
       "L 684 0 \n",
       "L 684 794 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "        <path id=\"DejaVuSans-37\" d=\"M 525 4666 \n",
       "L 3525 4666 \n",
       "L 3525 4397 \n",
       "L 1831 0 \n",
       "L 1172 0 \n",
       "L 2766 4134 \n",
       "L 525 4134 \n",
       "L 525 4666 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#DejaVuSans-30\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-37\" x=\"95.410156\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-30\" x=\"159.033203\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_2\">\n",
       "     <g id=\"line2d_10\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#m81f83d1fd2\" x=\"50.14375\" y=\"196.128327\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_11\">\n",
       "      <!-- 0.75 -->\n",
       "      <g transform=\"translate(20.878125 199.927545)scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-30\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-37\" x=\"95.410156\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-35\" x=\"159.033203\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_3\">\n",
       "     <g id=\"line2d_11\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#m81f83d1fd2\" x=\"50.14375\" y=\"158.773223\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_12\">\n",
       "      <!-- 0.80 -->\n",
       "      <g transform=\"translate(20.878125 162.572442)scale(0.1 -0.1)\">\n",
       "       <defs>\n",
       "        <path id=\"DejaVuSans-38\" d=\"M 2034 2216 \n",
       "Q 1584 2216 1326 1975 \n",
       "Q 1069 1734 1069 1313 \n",
       "Q 1069 891 1326 650 \n",
       "Q 1584 409 2034 409 \n",
       "Q 2484 409 2743 651 \n",
       "Q 3003 894 3003 1313 \n",
       "Q 3003 1734 2745 1975 \n",
       "Q 2488 2216 2034 2216 \n",
       "z\n",
       "M 1403 2484 \n",
       "Q 997 2584 770 2862 \n",
       "Q 544 3141 544 3541 \n",
       "Q 544 4100 942 4425 \n",
       "Q 1341 4750 2034 4750 \n",
       "Q 2731 4750 3128 4425 \n",
       "Q 3525 4100 3525 3541 \n",
       "Q 3525 3141 3298 2862 \n",
       "Q 3072 2584 2669 2484 \n",
       "Q 3125 2378 3379 2068 \n",
       "Q 3634 1759 3634 1313 \n",
       "Q 3634 634 3220 271 \n",
       "Q 2806 -91 2034 -91 \n",
       "Q 1263 -91 848 271 \n",
       "Q 434 634 434 1313 \n",
       "Q 434 1759 690 2068 \n",
       "Q 947 2378 1403 2484 \n",
       "z\n",
       "M 1172 3481 \n",
       "Q 1172 3119 1398 2916 \n",
       "Q 1625 2713 2034 2713 \n",
       "Q 2441 2713 2670 2916 \n",
       "Q 2900 3119 2900 3481 \n",
       "Q 2900 3844 2670 4047 \n",
       "Q 2441 4250 2034 4250 \n",
       "Q 1625 4250 1398 4047 \n",
       "Q 1172 3844 1172 3481 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#DejaVuSans-30\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-38\" x=\"95.410156\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-30\" x=\"159.033203\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_4\">\n",
       "     <g id=\"line2d_12\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#m81f83d1fd2\" x=\"50.14375\" y=\"121.41812\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_13\">\n",
       "      <!-- 0.85 -->\n",
       "      <g transform=\"translate(20.878125 125.217338)scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-30\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-38\" x=\"95.410156\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-35\" x=\"159.033203\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_5\">\n",
       "     <g id=\"line2d_13\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#m81f83d1fd2\" x=\"50.14375\" y=\"84.063016\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_14\">\n",
       "      <!-- 0.90 -->\n",
       "      <g transform=\"translate(20.878125 87.862235)scale(0.1 -0.1)\">\n",
       "       <defs>\n",
       "        <path id=\"DejaVuSans-39\" d=\"M 703 97 \n",
       "L 703 672 \n",
       "Q 941 559 1184 500 \n",
       "Q 1428 441 1663 441 \n",
       "Q 2288 441 2617 861 \n",
       "Q 2947 1281 2994 2138 \n",
       "Q 2813 1869 2534 1725 \n",
       "Q 2256 1581 1919 1581 \n",
       "Q 1219 1581 811 2004 \n",
       "Q 403 2428 403 3163 \n",
       "Q 403 3881 828 4315 \n",
       "Q 1253 4750 1959 4750 \n",
       "Q 2769 4750 3195 4129 \n",
       "Q 3622 3509 3622 2328 \n",
       "Q 3622 1225 3098 567 \n",
       "Q 2575 -91 1691 -91 \n",
       "Q 1453 -91 1209 -44 \n",
       "Q 966 3 703 97 \n",
       "z\n",
       "M 1959 2075 \n",
       "Q 2384 2075 2632 2365 \n",
       "Q 2881 2656 2881 3163 \n",
       "Q 2881 3666 2632 3958 \n",
       "Q 2384 4250 1959 4250 \n",
       "Q 1534 4250 1286 3958 \n",
       "Q 1038 3666 1038 3163 \n",
       "Q 1038 2656 1286 2365 \n",
       "Q 1534 2075 1959 2075 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#DejaVuSans-30\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-39\" x=\"95.410156\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-30\" x=\"159.033203\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_6\">\n",
       "     <g id=\"line2d_14\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#m81f83d1fd2\" x=\"50.14375\" y=\"46.707913\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_15\">\n",
       "      <!-- 0.95 -->\n",
       "      <g transform=\"translate(20.878125 50.507131)scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-30\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-39\" x=\"95.410156\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-35\" x=\"159.033203\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"text_16\">\n",
       "     <!-- accuracy -->\n",
       "     <g transform=\"translate(14.798438 153.5975)rotate(-90)scale(0.1 -0.1)\">\n",
       "      <defs>\n",
       "       <path id=\"DejaVuSans-61\" d=\"M 2194 1759 \n",
       "Q 1497 1759 1228 1600 \n",
       "Q 959 1441 959 1056 \n",
       "Q 959 750 1161 570 \n",
       "Q 1363 391 1709 391 \n",
       "Q 2188 391 2477 730 \n",
       "Q 2766 1069 2766 1631 \n",
       "L 2766 1759 \n",
       "L 2194 1759 \n",
       "z\n",
       "M 3341 1997 \n",
       "L 3341 0 \n",
       "L 2766 0 \n",
       "L 2766 531 \n",
       "Q 2569 213 2275 61 \n",
       "Q 1981 -91 1556 -91 \n",
       "Q 1019 -91 701 211 \n",
       "Q 384 513 384 1019 \n",
       "Q 384 1609 779 1909 \n",
       "Q 1175 2209 1959 2209 \n",
       "L 2766 2209 \n",
       "L 2766 2266 \n",
       "Q 2766 2663 2505 2880 \n",
       "Q 2244 3097 1772 3097 \n",
       "Q 1472 3097 1187 3025 \n",
       "Q 903 2953 641 2809 \n",
       "L 641 3341 \n",
       "Q 956 3463 1253 3523 \n",
       "Q 1550 3584 1831 3584 \n",
       "Q 2591 3584 2966 3190 \n",
       "Q 3341 2797 3341 1997 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       <path id=\"DejaVuSans-75\" d=\"M 544 1381 \n",
       "L 544 3500 \n",
       "L 1119 3500 \n",
       "L 1119 1403 \n",
       "Q 1119 906 1312 657 \n",
       "Q 1506 409 1894 409 \n",
       "Q 2359 409 2629 706 \n",
       "Q 2900 1003 2900 1516 \n",
       "L 2900 3500 \n",
       "L 3475 3500 \n",
       "L 3475 0 \n",
       "L 2900 0 \n",
       "L 2900 538 \n",
       "Q 2691 219 2414 64 \n",
       "Q 2138 -91 1772 -91 \n",
       "Q 1169 -91 856 284 \n",
       "Q 544 659 544 1381 \n",
       "z\n",
       "M 1991 3584 \n",
       "L 1991 3584 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       <path id=\"DejaVuSans-72\" d=\"M 2631 2963 \n",
       "Q 2534 3019 2420 3045 \n",
       "Q 2306 3072 2169 3072 \n",
       "Q 1681 3072 1420 2755 \n",
       "Q 1159 2438 1159 1844 \n",
       "L 1159 0 \n",
       "L 581 0 \n",
       "L 581 3500 \n",
       "L 1159 3500 \n",
       "L 1159 2956 \n",
       "Q 1341 3275 1631 3429 \n",
       "Q 1922 3584 2338 3584 \n",
       "Q 2397 3584 2469 3576 \n",
       "Q 2541 3569 2628 3553 \n",
       "L 2631 2963 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       <path id=\"DejaVuSans-79\" d=\"M 2059 -325 \n",
       "Q 1816 -950 1584 -1140 \n",
       "Q 1353 -1331 966 -1331 \n",
       "L 506 -1331 \n",
       "L 506 -850 \n",
       "L 844 -850 \n",
       "Q 1081 -850 1212 -737 \n",
       "Q 1344 -625 1503 -206 \n",
       "L 1606 56 \n",
       "L 191 3500 \n",
       "L 800 3500 \n",
       "L 1894 763 \n",
       "L 2988 3500 \n",
       "L 3597 3500 \n",
       "L 2059 -325 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "      </defs>\n",
       "      <use xlink:href=\"#DejaVuSans-61\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-63\" x=\"61.279297\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-63\" x=\"116.259766\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-75\" x=\"171.240234\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-72\" x=\"234.619141\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-61\" x=\"275.732422\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-63\" x=\"337.011719\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-79\" x=\"391.992188\"/>\n",
       "     </g>\n",
       "    </g>\n",
       "   </g>\n",
       "   <g id=\"line2d_15\">\n",
       "    <path d=\"M 65.361932 69.870281 \n",
       "L 66.205044 62.588123 \n",
       "L 67.048157 57.817009 \n",
       "L 67.89127 59.424123 \n",
       "L 68.734382 60.729899 \n",
       "L 69.577495 56.009015 \n",
       "L 70.420607 58.369457 \n",
       "L 71.26372 56.009015 \n",
       "L 72.106832 57.063682 \n",
       "L 72.949945 53.598388 \n",
       "L 73.793057 49.630831 \n",
       "L 74.63617 47.571729 \n",
       "L 75.479283 44.106435 \n",
       "L 76.322395 43.855326 \n",
       "L 77.165508 44.7593 \n",
       "L 78.00862 41.294006 \n",
       "L 78.851733 44.558422 \n",
       "L 79.694845 41.193545 \n",
       "L 80.537958 42.398859 \n",
       "L 81.381071 37.929129 \n",
       "L 82.224183 37.426911 \n",
       "L 83.067296 43.101955 \n",
       "L 83.910408 39.335321 \n",
       "L 84.753521 34.76513 \n",
       "L 85.596633 34.514021 \n",
       "L 86.439746 35.618918 \n",
       "L 88.125971 34.011803 \n",
       "L 88.969084 33.710463 \n",
       "L 89.812196 34.966008 \n",
       "L 91.498421 33.459354 \n",
       "L 92.341534 33.158015 \n",
       "L 93.184646 33.107784 \n",
       "L 94.027759 33.208245 \n",
       "L 94.870872 32.906906 \n",
       "L 95.713984 32.806489 \n",
       "L 96.557097 33.509585 \n",
       "L 97.400209 32.906906 \n",
       "L 98.243322 32.655797 \n",
       "L 99.086434 33.358893 \n",
       "L 99.929547 33.409124 \n",
       "L 100.77266 34.062034 \n",
       "L 101.615772 33.911342 \n",
       "L 102.458885 33.409124 \n",
       "L 103.301997 33.258476 \n",
       "L 104.14511 32.806489 \n",
       "L 104.988222 32.655797 \n",
       "L 105.831335 35.267347 \n",
       "L 106.674448 32.906906 \n",
       "L 108.360673 32.605566 \n",
       "L 109.203785 33.810925 \n",
       "L 110.046898 32.856675 \n",
       "L 110.89001 34.664668 \n",
       "L 111.733123 32.605566 \n",
       "L 112.576236 32.756258 \n",
       "L 114.262461 32.756258 \n",
       "L 115.105573 33.007367 \n",
       "L 115.948686 32.605566 \n",
       "L 116.791798 33.007367 \n",
       "L 117.634911 32.706028 \n",
       "L 118.478023 32.957137 \n",
       "L 119.321136 32.756258 \n",
       "L 121.007361 32.906906 \n",
       "L 121.850474 32.655797 \n",
       "L 124.379811 32.655797 \n",
       "L 125.222924 33.208245 \n",
       "L 126.066037 32.605566 \n",
       "L 127.752262 32.605566 \n",
       "L 128.595374 32.756258 \n",
       "L 130.281599 32.605566 \n",
       "L 131.124712 32.605566 \n",
       "L 131.967825 33.158015 \n",
       "L 132.810937 32.605566 \n",
       "L 133.65405 32.605566 \n",
       "L 134.497162 32.806489 \n",
       "L 137.0265 32.605566 \n",
       "L 141.242063 32.655797 \n",
       "L 142.085175 32.756258 \n",
       "L 142.928288 32.605566 \n",
       "L 369.725568 32.605566 \n",
       "L 369.725568 32.605566 \n",
       "\" clip-path=\"url(#pa868c1d5ce)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n",
       "   </g>\n",
       "   <g id=\"line2d_16\">\n",
       "    <path d=\"M 65.361932 32.201761 \n",
       "L 67.89127 32.201761 \n",
       "L 68.734382 229.874489 \n",
       "L 69.577495 38.411976 \n",
       "L 70.420607 37.240238 \n",
       "L 71.26372 32.201761 \n",
       "L 369.725568 32.201761 \n",
       "L 369.725568 32.201761 \n",
       "\" clip-path=\"url(#pa868c1d5ce)\" style=\"fill: none; stroke: #ff7f0e; stroke-width: 1.5; stroke-linecap: square\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_3\">\n",
       "    <path d=\"M 50.14375 239.758125 \n",
       "L 50.14375 22.318125 \n",
       "\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_4\">\n",
       "    <path d=\"M 384.94375 239.758125 \n",
       "L 384.94375 22.318125 \n",
       "\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_5\">\n",
       "    <path d=\"M 50.14375 239.758125 \n",
       "L 384.94375 239.758125 \n",
       "\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_6\">\n",
       "    <path d=\"M 50.14375 22.318125 \n",
       "L 384.94375 22.318125 \n",
       "\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n",
       "   </g>\n",
       "   <g id=\"text_17\">\n",
       "    <!-- model accuracy -->\n",
       "    <g transform=\"translate(169.882188 16.318125)scale(0.12 -0.12)\">\n",
       "     <defs>\n",
       "      <path id=\"DejaVuSans-6d\" d=\"M 3328 2828 \n",
       "Q 3544 3216 3844 3400 \n",
       "Q 4144 3584 4550 3584 \n",
       "Q 5097 3584 5394 3201 \n",
       "Q 5691 2819 5691 2113 \n",
       "L 5691 0 \n",
       "L 5113 0 \n",
       "L 5113 2094 \n",
       "Q 5113 2597 4934 2840 \n",
       "Q 4756 3084 4391 3084 \n",
       "Q 3944 3084 3684 2787 \n",
       "Q 3425 2491 3425 1978 \n",
       "L 3425 0 \n",
       "L 2847 0 \n",
       "L 2847 2094 \n",
       "Q 2847 2600 2669 2842 \n",
       "Q 2491 3084 2119 3084 \n",
       "Q 1678 3084 1418 2786 \n",
       "Q 1159 2488 1159 1978 \n",
       "L 1159 0 \n",
       "L 581 0 \n",
       "L 581 3500 \n",
       "L 1159 3500 \n",
       "L 1159 2956 \n",
       "Q 1356 3278 1631 3431 \n",
       "Q 1906 3584 2284 3584 \n",
       "Q 2666 3584 2933 3390 \n",
       "Q 3200 3197 3328 2828 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "      <path id=\"DejaVuSans-64\" d=\"M 2906 2969 \n",
       "L 2906 4863 \n",
       "L 3481 4863 \n",
       "L 3481 0 \n",
       "L 2906 0 \n",
       "L 2906 525 \n",
       "Q 2725 213 2448 61 \n",
       "Q 2172 -91 1784 -91 \n",
       "Q 1150 -91 751 415 \n",
       "Q 353 922 353 1747 \n",
       "Q 353 2572 751 3078 \n",
       "Q 1150 3584 1784 3584 \n",
       "Q 2172 3584 2448 3432 \n",
       "Q 2725 3281 2906 2969 \n",
       "z\n",
       "M 947 1747 \n",
       "Q 947 1113 1208 752 \n",
       "Q 1469 391 1925 391 \n",
       "Q 2381 391 2643 752 \n",
       "Q 2906 1113 2906 1747 \n",
       "Q 2906 2381 2643 2742 \n",
       "Q 2381 3103 1925 3103 \n",
       "Q 1469 3103 1208 2742 \n",
       "Q 947 2381 947 1747 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "      <path id=\"DejaVuSans-6c\" d=\"M 603 4863 \n",
       "L 1178 4863 \n",
       "L 1178 0 \n",
       "L 603 0 \n",
       "L 603 4863 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "      <path id=\"DejaVuSans-20\" transform=\"scale(0.015625)\"/>\n",
       "     </defs>\n",
       "     <use xlink:href=\"#DejaVuSans-6d\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-6f\" x=\"97.412109\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-64\" x=\"158.59375\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-65\" x=\"222.070312\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-6c\" x=\"283.59375\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-20\" x=\"311.376953\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-61\" x=\"343.164062\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-63\" x=\"404.443359\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-63\" x=\"459.423828\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-75\" x=\"514.404297\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-72\" x=\"577.783203\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-61\" x=\"618.896484\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-63\" x=\"680.175781\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-79\" x=\"735.15625\"/>\n",
       "    </g>\n",
       "   </g>\n",
       "   <g id=\"legend_1\">\n",
       "    <g id=\"patch_7\">\n",
       "     <path d=\"M 296.709375 234.758125 \n",
       "L 377.94375 234.758125 \n",
       "Q 379.94375 234.758125 379.94375 232.758125 \n",
       "L 379.94375 204.401875 \n",
       "Q 379.94375 202.401875 377.94375 202.401875 \n",
       "L 296.709375 202.401875 \n",
       "Q 294.709375 202.401875 294.709375 204.401875 \n",
       "L 294.709375 232.758125 \n",
       "Q 294.709375 234.758125 296.709375 234.758125 \n",
       "z\n",
       "\" style=\"fill: #ffffff; opacity: 0.8; stroke: #cccccc; stroke-linejoin: miter\"/>\n",
       "    </g>\n",
       "    <g id=\"line2d_17\">\n",
       "     <path d=\"M 298.709375 210.500312 \n",
       "L 308.709375 210.500312 \n",
       "L 318.709375 210.500312 \n",
       "\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n",
       "    </g>\n",
       "    <g id=\"text_18\">\n",
       "     <!-- train -->\n",
       "     <g transform=\"translate(326.709375 214.000312)scale(0.1 -0.1)\">\n",
       "      <defs>\n",
       "       <path id=\"DejaVuSans-74\" d=\"M 1172 4494 \n",
       "L 1172 3500 \n",
       "L 2356 3500 \n",
       "L 2356 3053 \n",
       "L 1172 3053 \n",
       "L 1172 1153 \n",
       "Q 1172 725 1289 603 \n",
       "Q 1406 481 1766 481 \n",
       "L 2356 481 \n",
       "L 2356 0 \n",
       "L 1766 0 \n",
       "Q 1100 0 847 248 \n",
       "Q 594 497 594 1153 \n",
       "L 594 3053 \n",
       "L 172 3053 \n",
       "L 172 3500 \n",
       "L 594 3500 \n",
       "L 594 4494 \n",
       "L 1172 4494 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       <path id=\"DejaVuSans-69\" d=\"M 603 3500 \n",
       "L 1178 3500 \n",
       "L 1178 0 \n",
       "L 603 0 \n",
       "L 603 3500 \n",
       "z\n",
       "M 603 4863 \n",
       "L 1178 4863 \n",
       "L 1178 4134 \n",
       "L 603 4134 \n",
       "L 603 4863 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       <path id=\"DejaVuSans-6e\" d=\"M 3513 2113 \n",
       "L 3513 0 \n",
       "L 2938 0 \n",
       "L 2938 2094 \n",
       "Q 2938 2591 2744 2837 \n",
       "Q 2550 3084 2163 3084 \n",
       "Q 1697 3084 1428 2787 \n",
       "Q 1159 2491 1159 1978 \n",
       "L 1159 0 \n",
       "L 581 0 \n",
       "L 581 3500 \n",
       "L 1159 3500 \n",
       "L 1159 2956 \n",
       "Q 1366 3272 1645 3428 \n",
       "Q 1925 3584 2291 3584 \n",
       "Q 2894 3584 3203 3211 \n",
       "Q 3513 2838 3513 2113 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "      </defs>\n",
       "      <use xlink:href=\"#DejaVuSans-74\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-72\" x=\"39.208984\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-61\" x=\"80.322266\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-69\" x=\"141.601562\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-6e\" x=\"169.384766\"/>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"line2d_18\">\n",
       "     <path d=\"M 298.709375 225.178437 \n",
       "L 308.709375 225.178437 \n",
       "L 318.709375 225.178437 \n",
       "\" style=\"fill: none; stroke: #ff7f0e; stroke-width: 1.5; stroke-linecap: square\"/>\n",
       "    </g>\n",
       "    <g id=\"text_19\">\n",
       "     <!-- validation -->\n",
       "     <g transform=\"translate(326.709375 228.678437)scale(0.1 -0.1)\">\n",
       "      <defs>\n",
       "       <path id=\"DejaVuSans-76\" d=\"M 191 3500 \n",
       "L 800 3500 \n",
       "L 1894 563 \n",
       "L 2988 3500 \n",
       "L 3597 3500 \n",
       "L 2284 0 \n",
       "L 1503 0 \n",
       "L 191 3500 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "      </defs>\n",
       "      <use xlink:href=\"#DejaVuSans-76\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-61\" x=\"59.179688\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-6c\" x=\"120.458984\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-69\" x=\"148.242188\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-64\" x=\"176.025391\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-61\" x=\"239.501953\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-74\" x=\"300.78125\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-69\" x=\"339.990234\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-6f\" x=\"367.773438\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-6e\" x=\"428.955078\"/>\n",
       "     </g>\n",
       "    </g>\n",
       "   </g>\n",
       "  </g>\n",
       " </g>\n",
       " <defs>\n",
       "  <clipPath id=\"pa868c1d5ce\">\n",
       "   <rect x=\"50.14375\" y=\"22.318125\" width=\"334.8\" height=\"217.44\"/>\n",
       "  </clipPath>\n",
       " </defs>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_hist(history2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train_Loss: 0.139, Train_Acc: 0.969\n",
      "Test_Loss: 0.137, Test_Acc: 0.969\n"
     ]
    }
   ],
   "source": [
    "# evaluate the model\n",
    "train_loss, train_acc = model.evaluate(X_img_train, y_img_train, verbose=0)\n",
    "test_loss, test_acc = model.evaluate(X_img_test, y_img_test, verbose=0)\n",
    "print('Train_Loss: %.3f, Train_Acc: %.3f' % (train_loss, train_acc))\n",
    "print('Test_Loss: %.3f, Test_Acc: %.3f' % (test_loss, test_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200/200 [==============================] - 3s 14ms/step\n"
     ]
    }
   ],
   "source": [
    "pred = model.predict(X_img_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200/200 [==============================] - 3s 14ms/step\n"
     ]
    }
   ],
   "source": [
    "y_pred = (model.predict(X_img_test) > 0.5)*1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score: 0.9694165621079046\n",
      "Precision: 0.0\n",
      "Recall: 0.0\n",
      "F1_score: 0.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, classification_report, confusion_matrix\n",
    "score = accuracy_score(y_img_test, y_pred)\n",
    "precision = precision_score(y_img_test,y_pred)\n",
    "recall = recall_score(y_img_test,y_pred)\n",
    "f1 = f1_score(y_img_test,y_pred)\n",
    "print(\"score:\", score)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"F1_score:\", f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix : \n",
      " [[6181    0]\n",
      " [ 195    0]]\n"
     ]
    }
   ],
   "source": [
    "# confusion matrix\n",
    "matrix = confusion_matrix(y_img_test, y_pred, labels=[0,1])\n",
    "print('Confusion matrix : \\n',matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report : \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      1.00      0.98      6181\n",
      "           1       0.00      0.00      0.00       195\n",
      "\n",
      "    accuracy                           0.97      6376\n",
      "   macro avg       0.48      0.50      0.49      6376\n",
      "weighted avg       0.94      0.97      0.95      6376\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# classification report for precision, recall f1-score and accuracy\n",
    "matrix = classification_report(y_img_test, y_pred, labels=[0,1])\n",
    "print('Classification report : \\n',matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Outcome values : \n",
      " 6181 0 195 0\n"
     ]
    }
   ],
   "source": [
    "# outcome values order in sklearn\n",
    "tp, fn, fp, tn = confusion_matrix(y_img_test, y_pred,labels=[0,1]).reshape(-1)\n",
    "print('Outcome values : \\n', tp, fn, fp, tn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
